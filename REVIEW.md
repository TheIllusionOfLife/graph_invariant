## 統合レビュー: LLM駆動型グラフ不変量自動発見

両レビューを統合し、深刻度順に整理した。

---

### Critical: セキュリティ

| # | 問題 | 箇所 |
|---|------|------|
| C1 | `exec()` で `__builtins__` を遮断していない。LLM生成コードが `os.system`, `__import__` 等に到達可能。研究用途でもローカルファイル破壊・情報漏えいリスクがある | L262, L268 |

**対策:** `safe_globals = {"__builtins__": {}}` を設定し、許可する関数のみホワイトリストで注入。さらに `subprocess` + `resource` モジュールでプロセスレベルのサンドボックス化を推奨。Docker/nsjailの利用も検討すべき。

---

### High: 実験設計の根幹に関わる問題

| # | 問題 | 箇所 |
|---|------|------|
| H1 | **Validation Setがモデル選択に使われ続けている。** 各世代でValスコアによる選抜・保持を行っているため、最終性能が過大評価される。独立したTest Setが必要 | L356, L359, L374 |
| H2 | **8Bモデルの数学的推論能力が最大のリスク要因。** FunSearchがCodey/PaLM2規模を使った理由を考えると、Llama 3 8B (4-bit) が意味のある数式を「発明」できるか不明 | L32 |
| H3 | **FunSearchとの差別化が不十分。** 本研究独自の貢献（KGフィードバック、数式簡約など）が先行研究との比較で明確に述べられていない | セクション1-2全体 |
| H4 | **ベースライン比較の欠如。** PySR, gplearn等のシンボリック回帰との比較がなく、LLMアプローチの優位性を主張できない | 全体 |

---

### Medium: 実装と設計の不整合

| # | 問題 | 箇所 |
|---|------|------|
| M1 | **`evaluate_hypothesis_parallel` が実際には逐次実行。** 関数名・計画書の記述と乖離しており、性能見積もりの前提を誤らせる | L285, L299 |
| M2 | **`TIMEOUT_SEC` 定義済みだが未使用。** 全体10秒打ち切りのみで、1グラフ単位の制限が機能していない | L120, L300 |
| M3 | **エラー時に `0.0` を返す設計。** 定数出力（`std < 1e-9` で弾く処理）と区別がつかず、評価にノイズが入る。`None` を返してフィルタすべき | L283 |
| M4 | **`knowledge_base[:5]` の淘汰圧が強すぎる。** 多様性が失われ早期収束（premature convergence）する可能性が高い。MAP-Elites的な多様性保持戦略が必要 | L374 |
| M5 | **再現性の欠如。** トップレベルの乱数シード固定がなく、データ生成・LLM呼び出し条件ともに再現困難 | L167-168 |
| M6 | **`abs(corr)` で逆相関も高スコアになる。** 意図的か判断できない。近似式としての解釈性を重視するなら符号情報を保持すべき | L318 |
| M7 | **グラフ規模が N=30〜80 と小さすぎる。** 汎化性を主張するならスケーリング挙動（N=100, 500, 1000）の検証が不可欠 | L131 |
| M8 | **Geometric Graph が計画書に記載されているがコード未実装** | L41 vs コード |
| M9 | **`random.seed(seed)` / `np.random.seed(seed)` のグローバルシード設定は並列処理時に競合する。** `np.random.Generator` を使うべき | L129-130 |

---

### Low: 実装の細かな問題

| # | 問題 | 箇所 |
|---|------|------|
| L1 | `best['code'].splitlines()[1]` は行数不足で `IndexError` になりうる | L378 |
| L2 | `multiprocessing.set_start_method('spawn')` が環境によっては再設定で `RuntimeError` | L390 |
| L3 | 評価指標の定式化が不完全。簡潔性（トークン数？ASTノード数？）とMDLの具体的計算方法が未定義 | セクション5 |

---

### 研究設計への総合的提言

**1. 実験のデータ分割を3分割にする**
- Train（探索用）→ Validation（世代選抜用）→ **Test（最終報告専用、選抜に一切使わない）**
- 現状ではValが選抜に汚染されており、論文査読で確実に指摘される

**2. 探索戦略を構造化する**
- FunSearchの成功要因はテンプレート（skeleton）の固定。自由生成では探索空間が無限大になり8Bモデルでは収束が極めて困難
- 演算子プール（`+, -, *, /, log, sqrt, **`）と結合ルールを明示し、LLMにはその組み合わせ空間内で提案させる

**3. ベースラインを追加する**
- 最低限: PySR（シンボリック回帰SOTA）、ランダムフォレスト（ブラックボックス上限）
- これがなければ「LLMが有用か」を判断できない

**4. モデルサイズの感度分析を計画に含める**
- 8B / 32B / 70B での比較を少なくともPhase 1で実施し、8Bで十分かを早期に判断する

**5. スケジュールを現実的に修正する**
- 7日間は「Phase 1のPoCのみ」に限定すべき。algebraic_connectivityと論文は別フェーズ

**6. 先に決めるべき設計判断**
- 近似式は**正相関のみ採用**か、**単調関係なら逆相関も許容**か？→ 評価関数の `abs()` の有無に直結
- 簡潔性ペナルティの具体的定式化（ASTノード数ベースのMDLを推奨）

---

### 結論

研究の着眼点は出版可能性がある。特に「ローカル環境でのAI数学発見」は実践的で独自性がある。しかし**実験設計の妥当性**（データ分割、ベースライン、再現性）と**実装の信頼性**（セキュリティ、並列化、タイムアウト）の両面で、現状のままでは査読を通過できない。まずaverage_shortest_path_length 1ターゲットに絞り、上記の指摘を反映した堅実なPoCを完成させることを強く推奨する。
