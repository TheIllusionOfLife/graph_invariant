\section*{Full Formula Listings}

The following Python functions are the best-discovered formulas from each
experiment, reproduced verbatim from \texttt{phase1\_summary.json} artifacts.
All functions take a pre-computed feature dictionary \texttt{s} and return a
\texttt{float}.

\subsection*{MAP-Elites ASPL Formula (val $\rho = 0.935$)}

\begin{lstlisting}[language=Python, basicstyle=\small\ttfamily, breaklines=true]
def new_invariant(s):
    eps = 1e-12
    n          = s['n']
    m          = s['m']
    density    = s['density']
    avg_deg    = s['avg_degree']
    max_deg    = s['max_degree']
    min_deg    = s['min_degree']
    std_deg    = s['std_degree']
    avg_clust  = s['avg_clustering']
    trans      = s['transitivity']
    assort     = s['degree_assortativity']
    num_tri    = s['num_triangles']
    degrees    = s['degrees']
    base = pow(n, 0.5) / (avg_deg + 1)                    # size vs average degree
    dens_factor = 1 / (density + eps)                    # sparsity
    clu_factor  = pow(1 + avg_clust, 0.6)                # clustering
    trans_factor = pow(1 + trans, 0.5)                   # transitivity
    assort_factor = 1 + abs(assort)                      # assortativity
    tri_factor = 1 + num_tri / (m + 1)                   # triangles
    std_factor = 1 + std_deg / (avg_deg + eps)           # degree spread
    size_edge_factor = pow(n / (m + 1), 0.5)             # size-edge interaction
    nonzero = [d for d in degrees if d > 0]
    if nonzero:
        harmonic = len(nonzero) / sum(1.0 / d for d in nonzero)
    else:
        harmonic = 1.0
    deg_shape_factor = harmonic / (avg_deg + eps)        # harmonic mean of degrees
    rel_avg_max = 1 + avg_deg / (max_deg + 1)            # relative avg to max degree
    estimate = (base * dens_factor * clu_factor * trans_factor *
                assort_factor * tri_factor * std_factor *
                size_edge_factor * deg_shape_factor * rel_avg_max)
    estimate = max(1.0, min(estimate, float(n)))
    return estimate
\end{lstlisting}

The dominant factors $\sqrt{n}/({\bar{d}}+1) \cdot 1/\text{density}$ approximate
the mean-field ASPL $n^2/(2m)$ for sparse graphs, while the harmonic mean of the
degree sequence corrects for degree heterogeneity.

\subsection*{Algebraic Connectivity Formula (val $\rho = 0.765$)}

\begin{lstlisting}[language=Python, basicstyle=\small\ttfamily, breaklines=true]
def new_invariant(s):
    eps = 1e-12
    n          = float(s['n'])
    avg_deg    = float(s['avg_degree'])
    std_deg    = float(s['std_degree'])
    density    = float(s['density'])
    num_tri    = float(s['num_triangles'])
    avg_clust  = float(s['avg_clustering'])
    trans      = float(s['transitivity'])
    assort     = float(s['degree_assortativity'])
    size_term = n ** 0.5                                 # sqrt(n)
    degree_term = (avg_deg + 1.0) / (std_deg + 1.0 + eps)  # degree regularity
    max_tri_possible = n * (n - 1.0) * (n - 2.0) / 6.0
    tri_frac = num_tri / (max_tri_possible + eps)
    triangle_term = 1.0 + tri_frac ** 0.25
    density_term = density ** 0.5                        # sqrt(density)
    clustering_pen = 1.0 / (1.0 + avg_clust ** 1.5)    # penalty for clustering
    trans_pen = 1.0 / (1.0 + trans ** 1.2)              # penalty for transitivity
    assort_pen = 1.0 / (1.0 + abs(assort) ** 0.9)      # penalty for assortativity
    score = (size_term * degree_term * triangle_term *
             density_term * clustering_pen * trans_pen * assort_pen)
    return score
\end{lstlisting}

\subsection*{Upper-Bound ASPL Formula (BS = 0.514, SR = 87\%)}

\begin{lstlisting}[language=Python, basicstyle=\small\ttfamily, breaklines=true]
def new_invariant(s):
    n = s.get('n', 0)
    if n <= 1:
        return 0.0
    path_bound = (n + 1) / 3.0                          # exact ASPL for path graph
    density = s.get('density', 0.0)
    density_bound = 2.0 if density > 0.5 else n - 1
    # Moore bound using max/min/average degree
    def moore_radius(deg, n):
        if deg <= 1: return n - 1
        nodes, power, radius = 1, 1, 0
        while nodes < n:
            nodes += deg * power
            power *= (deg - 1)
            radius += 1
        return radius + 1
    moore_max = moore_radius(int(s.get('max_degree', 1)), n)
    moore_min = moore_radius(int(s.get('min_degree', 1)), n)
    moore_avg = moore_radius(int(s.get('avg_degree', 1)), n)
    final = min(path_bound, density_bound, moore_max, moore_min, moore_avg, n - 1)
    return float(final)
\end{lstlisting}

The formula takes the minimum of six independent upper bounds. The path-graph
bound $(n+1)/3$ is a direct rediscovery of the classical exact result; the
Moore-bound terms mirror how human mathematicians combine degree-based
inequalities.

\section*{Self-Correction Ablation}

Table~\ref{tab:sc_ablation} compares the system with and without the
self-correction loop across three matched seeds (seeds 11, 22, 33) on the
ASPL benchmark.  SC-off runs used identical configs except
\texttt{enable\_self\_correction: false}.

\begin{table}[h]
  \centering
  \small
  \caption{SC ablation: self-correction enabled vs.\ disabled across 3 matched
    seeds on the ASPL benchmark (seeds 11, 22, 33).  Val~$\rho$ is the
    composite-fitness-optimised validation metric; Test~$\rho$ measures
    held-out generalization.  $\Delta$ = SC\,on $-$ SC\,off.  $n{=}3$ seeds;
    differences should be interpreted cautiously.}
  \label{tab:sc_ablation}
  \begin{tabular}{lccc}
    \toprule
    Condition & Seeds & Val $\rho$ & Test $\rho$ \\
    \midrule
    SC enabled  & 3 & $0.928 \pm 0.006$ & $0.926 \pm 0.012$ \\
    SC disabled & 3 & $0.883 \pm 0.018$ & $0.943 \pm 0.004$ \\
    $\Delta$ (on $-$ off) & & $+0.045$ & $-0.018$ \\
    \bottomrule
  \end{tabular}
\end{table}

SC improves validation correlation by $+0.045$ (7.5$\times$ the SC-on
validation std), confirming the repair loop advances search progress against
the composite fitness objective.  The test gap ($-0.018$, SC-off marginally
higher) is within $1.5\times$ the SC-on test standard deviation and is not
statistically conclusive at $n{=}3$ seeds.  The 3$\times$ reduction in
validation standard deviation (0.006 vs.\ 0.018) indicates that SC stabilises
convergence across seeds rather than merely overfitting to the validation set.

\section{Rebuttal-Oriented Supplementary Tables}

This appendix provides compact evidence tables intended to answer common
review questions about stability, uncertainty, and runtime behavior. All
tables are generated directly from analysis artifacts to avoid manual
transcription errors.

\input{sections/appendix_tables_generated}
