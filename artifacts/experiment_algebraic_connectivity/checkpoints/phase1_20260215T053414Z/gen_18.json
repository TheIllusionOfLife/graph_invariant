{
  "experiment_id": "phase1_20260215T053414Z",
  "generation": 18,
  "rng_seed": 42,
  "rng_state": {
    "bit_generator": "PCG64",
    "state": {
      "state": 116575252241508790303742175916576730590,
      "inc": 332724090758049132448979897138935081983
    },
    "has_uint32": 1,
    "uinteger": 2832198650
  },
  "best_val_score": 0.4880785020502356,
  "no_improve_count": 0,
  "island_stagnation": {
    "0": 0,
    "1": 0,
    "2": 0,
    "3": 0
  },
  "island_prompt_mode": {
    "0": "free",
    "1": "free",
    "2": "free",
    "3": "free"
  },
  "island_constrained_generations": {
    "0": 0,
    "1": 0,
    "2": 0,
    "3": 0
  },
  "island_recent_failures": {
    "0": [
      "below_novelty_threshold: novelty_bonus=0.149496",
      "no_valid_train_predictions: static_invalid: forbidden token detected: import ",
      "below_novelty_threshold: novelty_bonus=0.149634"
    ],
    "1": [
      "below_novelty_threshold: novelty_bonus=0.134300",
      "no_valid_train_predictions: static_invalid: forbidden token detected: import ",
      "below_train_threshold: train_signal=0.115678"
    ],
    "2": [
      "below_novelty_threshold: novelty_bonus=0.052955",
      "no_valid_train_predictions: static_invalid: forbidden token detected: import ",
      "below_novelty_threshold: novelty_bonus=0.138130"
    ],
    "3": [
      "below_novelty_threshold: novelty_bonus=0.089503",
      "no_valid_train_predictions: static_invalid: forbidden token detected: import ",
      "below_novelty_threshold: novelty_bonus=0.118704"
    ]
  },
  "islands": {
    "0": [
      {
        "id": "g13_i0_p4_202363364",
        "code": "def new_invariant(s):\n    \"\"\"\n    Approximate algebraic connectivity from a set of pre‑computed graph statistics.\n    The expression combines several complementary structural features in a\n    multiplicative fashion.  All operations are built‑in; no external imports\n    are required.\n\n    Features used:\n        • density          – overall edge density\n        • min_degree       – lower bound on connectivity\n        • avg_degree       – average degree\n        • std_degree       – degree dispersion\n        • max_degree       – maximum degree\n        • avg_clustering   – average local clustering\n        • transitivity     – global clustering coefficient\n        • degree_assortativity – degree correlation\n        • num_triangles    – triangle count\n        • degrees          – list of degrees (used for skewness)\n    \"\"\"\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    std_deg    = s['std_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    eps = 1e-6\n\n    # 1. Degree regularity\n    reg_factor = avg_deg / (std_deg + eps)\n\n    # 2. Triangle richness (gentle growth)\n    tri_factor = (num_tri + 1) ** 0.2\n\n    # 3. Size–clustering balance\n    size_factor = (n ** 0.5) / (1 + clustering)\n\n    # 4. Transitivity moderation\n    trans_factor = 1.0 / (1 + trans)\n\n    # 5. Assortativity moderation\n    assort_factor = 1.0 / (1 + abs(assort))\n\n    # 6. Density amplification\n    density_factor = density * (1 + density)\n\n    # 7. Degree‑spread damping\n    spread = max_deg - min_deg + eps\n    spread_factor = 1.0 / (1 + spread ** 0.5)\n\n    # 8. Degree‑distribution skewness\n    sum_sq = sum(d * d for d in degrees)\n    mean_sq = sum_sq / len(degrees)\n    skew_factor = (mean_sq / (avg_deg * avg_deg + eps)) ** 0.25\n\n    # 9. Minimum‑degree boost\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    result = (reg_factor *\n              tri_factor *\n              size_factor *\n              trans_factor *\n              assort_factor *\n              density_factor *\n              spread_factor *\n              skew_factor *\n              min_factor)\n\n    return result",
        "island_id": 0,
        "generation": 13,
        "train_score": 0.662905162064826,
        "val_score": 0.48306008691688906,
        "simplicity_score": 0.19348238913330898,
        "novelty_bonus": 0.27818195454886363
      },
      {
        "id": "g17_i0_p2_849777895",
        "code": "def new_invariant(s):\n    \"\"\"\n    Approximate algebraic connectivity from a set of pre‑computed graph statistics.\n    The expression is a product of complementary structural factors that capture\n    density, degree regularity, triangle richness, clustering, assortativity,\n    degree spread, skewness, transitivity, and degree‑distribution kurtosis.\n    No external libraries are imported.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    std_deg    = s['std_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    clustering = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    trans      = s['transitivity']\n    degrees    = s['degrees']\n\n    eps = 1e-6\n\n    # 1. Density amplification\n    density_factor = density * (1.0 + density)\n\n    # 2. Minimum‑degree boost\n    min_factor = (min_deg + 1.0) / (avg_deg + 1.0)\n\n    # 3. Triangle richness (gentle growth)\n    tri_factor = (num_tri + 1.0) ** 0.2\n\n    # 4. Degree regularity\n    reg_factor = avg_deg / (std_deg + eps)\n\n    # 5. Size–clustering balance\n    size_factor = (n ** 0.5) / (1.0 + clustering)\n\n    # 6. Assortativity moderation\n    assort_factor = 1.0 / (1.0 + abs(assort))\n\n    # 7. Degree‑spread damping (square‑root form)\n    spread = max_deg - min_deg + eps\n    spread_factor = 1.0 / (1.0 + spread ** 0.5)\n\n    # 8. Degree‑distribution skewness (third‑moment based)\n    mean_cube = sum(d ** 3 for d in degrees) / len(degrees)\n    skew_factor = (mean_cube / (avg_deg ** 3 + eps)) ** (1.0 / 3.0)\n\n    # 9. Transitivity moderation\n    trans_factor = 1.0 / (1.0 + trans)\n\n    # 10. Max‑degree penalty (encourages bounded degree spread)\n    max_factor = (avg_deg + 1.0) / (max_deg + 1.0)\n\n    # 11. Degree‑distribution kurtosis factor (adds novelty)\n    mean_quad = sum((d - avg_deg) ** 4 for d in degrees) / len(degrees)\n    kurt_factor = (1.0 + mean_quad / (avg_deg ** 4 + eps)) ** 0.05\n\n    # Combine all factors multiplicatively\n    result = (density_factor *\n              min_factor *\n              tri_factor *\n              reg_factor *\n              size_factor *\n              assort_factor *\n              spread_factor *\n              skew_factor *\n              trans_factor *\n              max_factor *\n              kurt_factor)\n\n    return result",
        "island_id": 0,
        "generation": 17,
        "train_score": 0.6109483793517406,
        "val_score": 0.47126592329353634,
        "simplicity_score": 0.1916569996522609,
        "novelty_bonus": 0.33532738318457944
      },
      {
        "id": "g14_i0_p0_663298012",
        "code": "def new_invariant(s):\n    \"\"\"\n    Approximate algebraic connectivity from a set of pre‑computed graph statistics.\n    The expression blends several complementary structural features that are\n    known to influence algebraic connectivity.  All operations are built‑in;\n    no external imports are required.\n\n    Features used:\n        • density          – overall edge density\n        • min_degree       – lower bound on connectivity\n        • avg_degree       – average degree\n        • std_degree       – degree dispersion\n        • num_triangles    – triangle count\n        • avg_clustering   – average local clustering\n        • degree_assortativity – degree correlation\n        • max_degree       – maximum degree\n        • degrees          – list of degrees (used for skewness)\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    std_deg    = s['std_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    clustering = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    trans      = s['transitivity']\n    degrees    = s['degrees']\n\n    eps = 1e-6\n\n    # 1. Density amplification\n    density_factor = density * (1.0 + density)\n\n    # 2. Minimum‑degree boost\n    min_factor = (min_deg + 1.0) / (avg_deg + 1.0)\n\n    # 3. Triangle richness (gentle growth)\n    tri_factor = (num_tri + 1.0) ** 0.2\n\n    # 4. Degree regularity\n    reg_factor = avg_deg / (std_deg + eps)\n\n    # 5. Size–clustering balance\n    size_factor = (n ** 0.5) / (1.0 + clustering)\n\n    # 6. Assortativity moderation\n    assort_factor = 1.0 / (1.0 + abs(assort))\n\n    # 7. Degree‑spread damping (square‑root form)\n    spread = max_deg - min_deg + eps\n    spread_factor = 1.0 / (1.0 + spread ** 0.5)\n\n    # 8. Degree‑distribution skewness\n    sum_sq = sum(d * d for d in degrees)\n    mean_sq = sum_sq / len(degrees)\n    skew_factor = (mean_sq / (avg_deg * avg_deg + eps)) ** 0.25\n\n    # 9. Transitivity moderation\n    trans_factor = 1.0 / (1.0 + trans)\n\n    # 10. Max‑degree penalty (encourages bounded degree spread)\n    max_factor = (avg_deg + 1.0) / (max_deg + 1.0)\n\n    # Combine all factors multiplicatively\n    result = (density_factor *\n              min_factor *\n              tri_factor *\n              reg_factor *\n              size_factor *\n              assort_factor *\n              spread_factor *\n              skew_factor *\n              trans_factor *\n              max_factor)\n\n    return result",
        "island_id": 0,
        "generation": 14,
        "train_score": 0.6069147659063625,
        "val_score": 0.46727882841516405,
        "simplicity_score": 0.19298005227631154,
        "novelty_bonus": 0.35005075423369825
      },
      {
        "id": "g17_i0_p3_438911460",
        "code": "def new_invariant(s):\n    \"\"\"\n    Approximate algebraic connectivity from a set of pre‑computed graph statistics.\n    The expression is a product of several complementary structural factors,\n    each dimensionless, that together capture density, degree regularity,\n    triangle richness, clustering, assortativity, degree spread, skewness,\n    and size effects.  No external libraries are used.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    std_deg    = s['std_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    eps = 1e-6\n\n    # 1. Density amplification\n    density_factor = density * (1.0 + density)\n\n    # 2. Minimum‑degree boost\n    min_factor = (min_deg + 1.0) / (avg_deg + 1.0)\n\n    # 3. Triangle richness (gentle growth)\n    tri_factor = (num_tri + 1.0) ** 0.2\n\n    # 4. Degree regularity\n    reg_factor = avg_deg / (std_deg + eps)\n\n    # 5. Size–clustering balance\n    size_factor = (n ** 0.5) / (1.0 + clustering)\n\n    # 6. Assortativity moderation\n    assort_factor = 1.0 / (1.0 + abs(assort))\n\n    # 7. Degree‑spread damping (square‑root form)\n    spread = max_deg - min_deg + eps\n    spread_factor = 1.0 / (1.0 + spread ** 0.5)\n\n    # 8. Degree‑distribution skewness (second‑moment based)\n    mean_sq = sum(d * d for d in degrees) / len(degrees)\n    skew_factor = (mean_sq / (avg_deg * avg_deg + eps)) ** 0.25\n\n    # 9. Transitivity moderation\n    trans_factor = 1.0 / (1.0 + trans)\n\n    # 10. Max‑degree penalty (encourages bounded degree spread)\n    max_factor = (avg_deg + 1.0) / (max_deg + 1.0)\n\n    # Combine all factors multiplicatively\n    result = (density_factor *\n              min_factor *\n              tri_factor *\n              reg_factor *\n              size_factor *\n              assort_factor *\n              spread_factor *\n              skew_factor *\n              trans_factor *\n              max_factor)\n\n    return result",
        "island_id": 0,
        "generation": 17,
        "train_score": 0.6069147659063625,
        "val_score": 0.46726366814881987,
        "simplicity_score": 0.1929042509445904,
        "novelty_bonus": 0.35005075423369825
      },
      {
        "id": "g16_i0_p0_467107552",
        "code": "def new_invariant(s):\n    \"\"\"\n    Approximate algebraic connectivity from a set of pre‑computed graph statistics.\n    The expression is a product of several complementary structural factors,\n    each dimensionless, that together capture density, degree regularity,\n    triangle richness, clustering, assortativity, degree spread, skewness,\n    and size effects.  No external libraries are used.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    std_deg    = s['std_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    clustering = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    trans      = s['transitivity']\n    degrees    = s['degrees']\n\n    eps = 1e-6\n\n    # 1. Density amplification\n    density_factor = density * (1.0 + density)\n\n    # 2. Minimum‑degree boost\n    min_factor = (min_deg + 1.0) / (avg_deg + 1.0)\n\n    # 3. Triangle richness (gentle growth)\n    tri_factor = (num_tri + 1.0) ** 0.2\n\n    # 4. Triangle‑to‑edge ratio (captures clustering density)\n    tri_edge_factor = ((num_tri + 1.0) / (m + 1.0)) ** 0.1\n\n    # 5. Degree regularity\n    reg_factor = avg_deg / (std_deg + eps)\n\n    # 6. Size–clustering balance\n    size_factor = (n ** 0.5) / (1.0 + clustering)\n\n    # 7. Assortativity moderation\n    assort_factor = 1.0 / (1.0 + abs(assort))\n\n    # 8. Degree‑spread damping (square‑root form)\n    spread = max_deg - min_deg + eps\n    spread_factor = 1.0 / (1.0 + spread ** 0.5)\n\n    # 9. Degree‑distribution skewness (third‑moment based)\n    mean_cube = sum(d ** 3 for d in degrees) / len(degrees)\n    skew_factor = (mean_cube / (avg_deg ** 3 + eps)) ** (1.0 / 3.0)\n\n    # 10. Transitivity moderation\n    trans_factor = 1.0 / (1.0 + trans)\n\n    # 11. Max‑degree penalty (encourages bounded degree spread)\n    max_factor = (avg_deg + 1.0) / (max_deg + 1.0)\n\n    # Combine all factors multiplicatively\n    result = (density_factor *\n              min_factor *\n              tri_factor *\n              tri_edge_factor *\n              reg_factor *\n              size_factor *\n              assort_factor *\n              spread_factor *\n              skew_factor *\n              trans_factor *\n              max_factor)\n\n    return result",
        "island_id": 0,
        "generation": 16,
        "train_score": 0.6097959183673469,
        "val_score": 0.4666871256896352,
        "simplicity_score": 0.19235171571407014,
        "novelty_bonus": 0.3006411064518525
      }
    ],
    "1": [
      {
        "id": "g17_i1_p1_363678253",
        "code": "def new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    min_deg = s['min_degree']\n    max_deg = s['max_degree']\n    avg_deg = s['avg_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']  # already sorted\n\n    # Normalised triangle density\n    if n >= 3:\n        max_tri = n * (n - 1) * (n - 2) / 6\n    else:\n        max_tri = 1\n    tri_norm = num_tri / max_tri\n\n    # Median degree (uses only the sorted list)\n    l = len(degrees)\n    if l == 0:\n        median_deg = 0\n    elif l % 2 == 1:\n        median_deg = degrees[l // 2]\n    else:\n        median_deg = (degrees[l // 2 - 1] + degrees[l // 2]) / 2\n\n    # Combine features multiplicatively\n    term1 = (min_deg + 1) * (density + 1e-6)**0.5 * (abs(assort) + 1) / (avg_clust + 1)\n    term2 = (n**0.5) * (1 + avg_deg) * (1 + trans) * (1 + tri_norm) / (1 + std_deg)\n    term3 = (max_deg + 1) / (m + 1)\n    term4 = (max_deg - min_deg + 1) / (avg_deg + 1)\n    term5 = (1 + median_deg) / (1 + std_deg)\n\n    return term1 * term2 * term3 * term4 * term5",
        "island_id": 1,
        "generation": 17,
        "train_score": 0.6959423769507803,
        "val_score": 0.47708800860944106,
        "simplicity_score": 0.13830323126167304,
        "novelty_bonus": 0.17832821378216934
      },
      {
        "id": "g17_i1_p3_9916196",
        "code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    min_deg = s['min_degree']\n    assort = s['degree_assortativity']\n    avg_clust = s['avg_clustering']\n    avg_deg = s['avg_degree']\n    trans = s['transitivity']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Normalized triangle density\n    if n >= 3:\n        max_tri = n * (n - 1) * (n - 2) / 6\n    else:\n        max_tri = 1\n    tri_norm = num_tri / max_tri\n\n    # Harmonic mean of degrees\n    sum_recip = 0.0\n    for d in degrees:\n        if d > 0:\n            sum_recip += 1.0 / d\n    if len(degrees) > 0:\n        harm_mean_deg = len(degrees) / sum_recip\n    else:\n        harm_mean_deg = 0.0\n\n    # Combine features multiplicatively\n    term1 = (min_deg + 1) * pow(density + 1e-6, 0.5) * (abs(assort) + 1) / (avg_clust + 1)\n    term2 = pow(n, 0.5) * (1 + avg_deg) * (1 + trans) * (1 + tri_norm) / (1 + std_deg)\n    term3 = (max_deg + 1) / (m + 1)\n    term4 = (harm_mean_deg + 1) / (avg_deg + 1)\n\n    return term1 * term2 * term3 * term4",
        "island_id": 1,
        "generation": 17,
        "train_score": 0.6267947178871548,
        "val_score": 0.463615619211721,
        "simplicity_score": 0.1444774349433183,
        "novelty_bonus": 0.20630603838346517
      },
      {
        "id": "g11_i1_p4_495625870",
        "code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    min_deg = s['min_degree']\n    assort = s['degree_assortativity']\n    avg_clust = s['avg_clustering']\n    std_deg = s['std_degree']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    avg_deg = s['avg_degree']\n    trans = s['transitivity']\n\n    # Normalized triangle density\n    max_tri = n * (n - 1) * (n - 2) / 6 if n >= 3 else 1\n    tri_norm = num_tri / max_tri\n\n    # Combine features multiplicatively\n    term1 = (min_deg + 1) * (density + 1e-6)**0.5 * (abs(assort) + 1) / (avg_clust + 1)\n    term2 = (n**0.5) * (1 + avg_deg) * (1 + trans) * (1 + tri_norm) / (1 + std_deg)\n    term3 = (max_deg + 1) / (m + 1)\n\n    return term1 * term2 * term3",
        "island_id": 1,
        "generation": 11,
        "train_score": 0.6003841536614647,
        "val_score": 0.45479580483772086,
        "simplicity_score": 0.15492810024111026,
        "novelty_bonus": 0.1894275341379501
      },
      {
        "id": "g15_i1_p3_925120118",
        "code": "def new_invariant(s):\n    # extract features\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    min_deg = s['min_degree']\n    assort = s['degree_assortativity']\n    avg_clust = s['avg_clustering']\n    avg_deg = s['avg_degree']\n    trans = s['transitivity']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    num_tri = s['num_triangles']\n\n    # Normalized triangle density\n    max_tri = n * (n - 1) * (n - 2) / 6 if n >= 3 else 1\n    tri_norm = num_tri / max_tri\n\n    # Combine features multiplicatively\n    term1 = (min_deg + 1) * (density + 1e-6)**0.5 * (abs(assort) + 1) / (avg_clust + 1)\n    term2 = (n**0.5) * (1 + avg_deg) * (1 + trans) * (1 + tri_norm) / (1 + std_deg)\n    term3 = (max_deg + 1) / (m + 1)\n\n    return term1 * term2 * term3",
        "island_id": 1,
        "generation": 15,
        "train_score": 0.6003841536614647,
        "val_score": 0.45479580483772086,
        "simplicity_score": 0.15492810024111026,
        "novelty_bonus": 0.1894275341379501
      },
      {
        "id": "g13_i1_p1_305956623",
        "code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    min_deg = s['min_degree']\n    assort = s['degree_assortativity']\n    avg_clust = s['avg_clustering']\n    avg_deg = s['avg_degree']\n    trans = s['transitivity']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    num_tri = s['num_triangles']\n\n    # Normalized triangle density\n    if n >= 3:\n        max_tri = n * (n - 1) * (n - 2) / 6\n    else:\n        max_tri = 1\n    tri_norm = num_tri / max_tri\n\n    # Combine features multiplicatively\n    term1 = (min_deg + 1) * (density + 1e-6)**0.5 * (abs(assort) + 1) / (avg_clust + 1)\n    term2 = (n**0.5) * (1 + avg_deg) * (1 + trans) * (1 + tri_norm) / (1 + std_deg)\n    term3 = (max_deg + 1) / (m + 1)\n\n    return term1 * term2 * term3",
        "island_id": 1,
        "generation": 13,
        "train_score": 0.6003841536614647,
        "val_score": 0.45477154415500315,
        "simplicity_score": 0.15480679682752163,
        "novelty_bonus": 0.1894275341379501
      }
    ],
    "2": [
      {
        "id": "g17_i2_p0_542827091",
        "code": "def new_invariant(s):\n    \"\"\"\n    Heuristic estimate of algebraic connectivity (second‑smallest Laplacian eigenvalue)\n    using only pre‑computed graph statistics.\n\n    The formula multiplies normalised structural factors that tend to increase\n    connectivity and divides by penalties that capture degree heterogeneity,\n    assortativity and clustering transitivity.  All operations are pure Python,\n    no external imports are required.\n\n    Available keys in ``s``:\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees (sorted list)\n    \"\"\"\n    n = s['n']\n    degrees = s['degrees']\n\n    # --- median degree ----------------------------------------------------\n    mid = n // 2\n    if n % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n\n    eps = 1e-6  # avoid division by zero\n\n    # --- factors that tend to raise algebraic connectivity ----------------\n    core_factor      = (s['min_degree'] + eps) / (s['avg_degree'] + eps)\n    density_factor   = 1.0 + s['density']\n    triangle_factor  = 1.0 + s['num_triangles'] / (n * (n - 1) / 2.0 + eps)\n    clustering_factor= 1.0 + s['avg_clustering']\n    median_factor    = 1.0 + median_deg / (s['avg_degree'] + eps)\n    size_factor      = n ** 0.5\n\n    # --- penalties that reduce the estimate --------------------------------\n    hetero_penalty   = 1.0 + s['std_degree'] / (s['max_degree'] + eps)\n    assort_penalty   = 1.0 + abs(s['degree_assortativity'])\n    trans_penalty    = 1.0 + s['transitivity']\n\n    numerator   = (core_factor * density_factor * triangle_factor *\n                   clustering_factor * median_factor * size_factor)\n    denominator = hetero_penalty * assort_penalty * trans_penalty\n\n    return numerator / denominator",
        "island_id": 2,
        "generation": 17,
        "train_score": 0.46545018007202876,
        "val_score": 0.45510445487476353,
        "simplicity_score": 0.14787508319403816,
        "novelty_bonus": 0.37235280882022037
      },
      {
        "id": "g15_i2_p2_346869804",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate of algebraic connectivity from pre‑computed graph statistics.\n    The formula is a product of normalised structural factors that\n    typically increase connectivity, divided by penalties that\n    reduce the estimate for heterogeneous or assortative degree\n    distributions.  Only built‑in Python operations are used.\n    \"\"\"\n    # extract features\n    n          = s['n']\n    min_deg    = s['min_degree']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    num_tri    = s['num_triangles']\n    avg_clust  = s['avg_clustering']\n    std_deg    = s['std_degree']\n    max_deg    = s['max_degree']\n    assort     = s['degree_assortativity']\n    degrees    = s['degrees']          # sorted list of degrees\n\n    eps = 1e-6  # to avoid division by zero\n\n    # median degree (degrees is sorted)\n    mid = n // 2\n    median_deg = degrees[mid] if n % 2 else (degrees[mid - 1] + degrees[mid]) / 2.0\n\n    # normalised factors that tend to raise algebraic connectivity\n    core_factor      = min_deg / (avg_deg + eps)\n    density_factor   = 1.0 + density\n    triangle_factor  = 1.0 + num_tri / (n * (n - 1) / 2.0 + eps)\n    clustering_factor= 1.0 + avg_clust\n    median_factor    = 1.0 + median_deg / (avg_deg + eps)\n    size_factor      = n ** 0.5\n\n    # penalties for heterogeneity or assortativity\n    hetero_penalty   = 1.0 + std_deg / (max_deg + eps)\n    assort_penalty   = 1.0 + abs(assort)\n\n    # combine everything\n    numerator   = (core_factor * density_factor * triangle_factor *\n                   clustering_factor * median_factor * size_factor)\n    denominator = hetero_penalty * assort_penalty\n\n    return numerator / denominator",
        "island_id": 2,
        "generation": 15,
        "train_score": 0.4569027611044417,
        "val_score": 0.44926805681648685,
        "simplicity_score": 0.1474933253233807,
        "novelty_bonus": 0.3771307533255559
      },
      {
        "id": "g13_i2_p3_19523991",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate of algebraic connectivity from pre‑computed graph statistics.\n    The expression is a product of normalised structural factors, divided by\n    penalties that reduce the estimate for highly heterogeneous or assortative\n    degree distributions.\n\n    Available keys in ``s``:\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees (sorted list)\n\n    The function uses only built‑in Python operations – no imports or\n    external libraries are required.\n    \"\"\"\n    n          = s['n']\n    min_deg    = s['min_degree']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    num_tri    = s['num_triangles']\n    avg_clust  = s['avg_clustering']\n    std_deg    = s['std_degree']\n    max_deg    = s['max_degree']\n    assort     = s['degree_assortativity']\n    degrees    = s['degrees']          # sorted list of degrees\n\n    eps = 1e-6\n\n    # Median degree (degrees is sorted)\n    mid = n // 2\n    if n % 2:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n\n    # Normalised factors that typically increase algebraic connectivity\n    core_factor      = min_deg / (avg_deg + eps)\n    density_factor   = 1.0 + density\n    triangle_factor  = 1.0 + num_tri / (n * (n - 1) / 2.0 + eps)\n    clustering_factor= 1.0 + avg_clust\n    median_factor    = 1.0 + median_deg / (avg_deg + eps)\n    size_factor      = n ** 0.5\n\n    # Penalties that reduce the estimate for heterogeneity or assortativity\n    hetero_penalty   = 1.0 + std_deg / (max_deg + eps)\n    assort_penalty   = 1.0 + abs(assort)\n\n    numerator   = (core_factor * density_factor * triangle_factor *\n                   clustering_factor * median_factor * size_factor)\n    denominator = hetero_penalty * assort_penalty\n\n    return numerator / denominator",
        "island_id": 2,
        "generation": 13,
        "train_score": 0.4569027611044417,
        "val_score": 0.449249639881517,
        "simplicity_score": 0.14740124064853133,
        "novelty_bonus": 0.3771307533255559
      },
      {
        "id": "g14_i2_p2_415807401",
        "code": "def new_invariant(s):\n    \"\"\"\n    Heuristic estimate of the algebraic connectivity (second‑smallest Laplacian\n    eigenvalue) using only pre‑computed graph statistics.\n\n    The expression combines several normalised structural factors that tend to\n    increase connectivity with penalties that reduce the estimate when the\n    degree distribution is highly heterogeneous or the graph is assortative.\n\n    All calculations use only built‑in Python operations; no external imports\n    are required.\n    \"\"\"\n    n          = s['n']\n    min_deg    = s['min_degree']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    num_tri    = s['num_triangles']\n    avg_clust  = s['avg_clustering']\n    std_deg    = s['std_degree']\n    max_deg    = s['max_degree']\n    assort     = s['degree_assortativity']\n    degrees    = s['degrees']          # sorted list of degrees\n\n    eps = 1e-6\n\n    # --- median degree -------------------------------------------------------\n    mid = n // 2\n    if n % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n\n    # --- normalised factors --------------------------------------------------\n    core_factor      = min_deg / (avg_deg + eps)\n    density_factor   = 1.0 + density\n    triangle_factor  = 1.0 + num_tri / (n * (n - 1) / 2.0 + eps)\n    clustering_factor= 1.0 + avg_clust\n    median_factor    = 1.0 + median_deg / (avg_deg + eps)\n    size_factor      = n ** 0.5\n\n    # --- penalties -----------------------------------------------------------\n    hetero_penalty   = 1.0 + std_deg / (max_deg + eps)\n    assort_penalty   = 1.0 + abs(assort)\n\n    numerator   = (core_factor * density_factor * triangle_factor *\n                   clustering_factor * median_factor * size_factor)\n    denominator = hetero_penalty * assort_penalty\n\n    return numerator / denominator",
        "island_id": 2,
        "generation": 14,
        "train_score": 0.4569027611044417,
        "val_score": 0.44923147800601715,
        "simplicity_score": 0.14731043127103222,
        "novelty_bonus": 0.3771307533255559
      },
      {
        "id": "g17_i2_p1_140249088",
        "code": "def new_invariant(s):\n    \"\"\"\n    Heuristic estimate of algebraic connectivity (the second‑smallest\n    Laplacian eigenvalue) using only pre‑computed graph statistics.\n\n    The formula is a product of normalised structural factors that\n    typically increase connectivity, divided by penalties that reduce\n    the estimate for heterogeneous or assortative degree distributions.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph features.  Expected keys are\n        ``n``, ``m``, ``density``, ``avg_degree``, ``max_degree``,\n        ``min_degree``, ``std_degree``, ``avg_clustering``, ``transitivity``,\n        ``degree_assortativity``, ``num_triangles`` and ``degrees`` (a\n        sorted list of degrees).\n\n    Returns\n    -------\n    float\n        Estimated algebraic connectivity.\n    \"\"\"\n    # Basic features\n    n          = s['n']\n    min_deg    = s['min_degree']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    num_tri    = s['num_triangles']\n    avg_clust  = s['avg_clustering']\n    std_deg    = s['std_degree']\n    max_deg    = s['max_degree']\n    assort     = s['degree_assortativity']\n    degrees    = s['degrees']          # sorted list of degrees\n\n    # Small epsilon to avoid division by zero\n    eps = 1e-6\n\n    # Median degree (degrees is sorted)\n    mid = n // 2\n    if n % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n\n    # Normalised factors that typically increase algebraic connectivity\n    core_factor      = min_deg / (avg_deg + eps)\n    density_factor   = 1.0 + density\n    triangle_factor  = 1.0 + num_tri / (n * (n - 1) / 2.0 + eps)\n    clustering_factor= 1.0 + avg_clust\n    median_factor    = 1.0 + median_deg / (avg_deg + eps)\n    size_factor      = n ** 0.5\n\n    # Penalties that reduce the estimate for heterogeneity or assortativity\n    hetero_penalty   = 1.0 + std_deg / (max_deg + eps)\n    assort_penalty   = 1.0 + abs(assort)\n\n    numerator   = (core_factor * density_factor * triangle_factor *\n                   clustering_factor * median_factor * size_factor)\n    denominator = hetero_penalty * assort_penalty\n\n    return numerator / denominator",
        "island_id": 2,
        "generation": 17,
        "train_score": 0.4569027611044417,
        "val_score": 0.44923147800601715,
        "simplicity_score": 0.14731043127103222,
        "novelty_bonus": 0.3771307533255559
      }
    ],
    "3": [
      {
        "id": "g17_i3_p4_243873251",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate of the algebraic connectivity (Fiedler value) using only\n    pre‑computed structural statistics of the graph.  The score is a\n    product of several dimensionless factors that capture known\n    influences on the Laplacian spectrum:\n\n        • Degree regularity (penalises large spread between max/min)\n        • Triangle density (sub‑linear growth)\n        • Edge density (higher density tends to increase the gap)\n        • Clustering penalty (high local clustering can lower connectivity)\n        • Assortativity penalty (strong mixing patterns are mildly detrimental)\n        • Size scaling (√n keeps values comparable across graph sizes)\n        • Average degree weighting (larger mean degree generally favours\n          a larger algebraic connectivity)\n\n    Each component is strictly positive; the final score therefore\n    grows monotonically with the true algebraic connectivity.  All\n    operations are elementary arithmetic so the function can be used\n    without importing any additional modules.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary containing the following keys:\n            n                    # number of nodes\n            m                    # number of edges\n            density              # edge density  (m / (n*(n-1)/2))\n            avg_degree           # average degree  (2*m / n)\n            max_degree           # maximum degree\n            min_degree           # minimum degree\n            std_degree           # standard deviation of degrees\n            avg_clustering       # average local clustering coefficient\n            transitivity         # global transitivity\n            degree_assortativity # assortativity coefficient\n            num_triangles        # number of triangles\n            degrees              # sorted list of degrees (unused)\n\n    Returns\n    -------\n    float\n        Dimensionless score that correlates with the true algebraic\n        connectivity; a larger value indicates a graph expected to have\n        a larger second‑smallest Laplacian eigenvalue.\n    \"\"\"\n    # Small constant to avoid division by zero\n    eps = 1e-12\n\n    # --- 1. Degree regularity -------------------------------------------------\n    #  Regularity is high when max and min degrees are close\n    deg_range = float(s['max_degree'] - s['min_degree'])\n    deg_sum   = float(s['max_degree'] + eps)\n    regularity = 1.0 - (deg_range / deg_sum)\n\n    # --- 2. Triangle density factor ------------------------------------------\n    n  = float(s['n'])\n    num_tri = float(s['num_triangles'])\n    # maximum possible number of triangles in a simple graph\n    max_tri_possible = n * (n - 1.0) * (n - 2.0) / 6.0\n    tri_frac = num_tri / (max_tri_possible + eps)\n    triangle_factor = 1.0 + tri_frac ** 0.3\n\n    # --- 3. Edge density influence -------------------------------------------\n    density_factor = float(s['density']) ** 0.5\n\n    # --- 4. Clustering penalty -----------------------------------------------\n    clust = float(s['avg_clustering'])\n    clustering_penalty = 1.0 / (1.0 + clust ** 1.2)\n\n    # --- 5. Assortativity penalty --------------------------------------------\n    assort = float(s['degree_assortativity'])\n    assortativity_penalty = 1.0 / (1.0 + abs(assort) ** 0.8)\n\n    # --- 6. Size scaling ------------------------------------------------------\n    size_factor = n ** 0.4\n\n    # --- 7. Average degree weighting -----------------------------------------\n    avg_deg = float(s['avg_degree'])\n    avg_deg_factor = (avg_deg + 1.0) ** 0.2\n\n    # --- Final score ---------------------------------------------------------\n    score = (regularity *\n             triangle_factor *\n             density_factor *\n             clustering_penalty *\n             assortativity_penalty *\n             size_factor *\n             avg_deg_factor)\n\n    return score",
        "island_id": 3,
        "generation": 17,
        "train_score": 0.6728931572629052,
        "val_score": 0.4880785020502356,
        "simplicity_score": 0.20621115571731452,
        "novelty_bonus": 0.2658186454661364
      },
      {
        "id": "g16_i3_p4_331568997",
        "code": "def new_invariant(s):\n    \"\"\"\n    Dimensionless proxy for algebraic connectivity constructed only from\n    pre‑computed graph statistics.\n\n    The formula mixes several opposing effects:\n\n        * degree regularity (low std → higher connectivity)\n        * triangle richness (sub‑linear growth)\n        * edge density (denser → larger gap)\n        * penalties for local clustering and global transitivity\n        * penalty for strong degree assortativity\n        * a √n size normalisation\n\n    All factors are strictly positive; the final score is their product.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed features of a graph.  Expected keys:\n\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees\n\n    Returns\n    -------\n    float\n        Estimated algebraic connectivity proxy.\n    \"\"\"\n    # avoid division by zero\n    eps = 1e-12\n\n    # Convert to floats for safe arithmetic\n    n      = float(s['n'])\n    m      = float(s['m'])\n    density= float(s['density'])\n    avg_deg= float(s['avg_degree'])\n    max_deg= float(s['max_degree'])\n    min_deg= float(s['min_degree'])\n    std_deg= float(s['std_degree'])\n    num_tri=float(s['num_triangles'])\n    clust  = float(s['avg_clustering'])\n    trans  = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n\n    # 1. Degree regularity (low spread is better)\n    reg = (avg_deg + eps) / (std_deg + eps)\n\n    # 2. Triangle richness (sub‑linear in fraction of possible triangles)\n    max_tri_possible = n * (n - 1.0) * (n - 2.0) / 6.0\n    tri_frac = num_tri / (max_tri_possible + eps)\n    tri_fac  = 1.0 + tri_frac ** 0.5\n\n    # 3. Edge density influence\n    dens_fac = density ** 0.75\n\n    # 4. Penalties for high clustering/transitivity\n    cluster_pen = 1.0 / (1.0 + clust + eps)\n    trans_pen   = 1.0 / (1.0 + trans + eps)\n\n    # 5. Penalty for strong assortativity\n    assort_pen = 1.0 / (1.0 + abs(assort) + eps)\n\n    # 6. Size normalisation (√n keeps scores comparable)\n    size_fac = n ** 0.5\n\n    # Combine multiplicatively\n    score = (reg *\n             tri_fac *\n             dens_fac *\n             cluster_pen *\n             trans_pen *\n             assort_pen *\n             size_fac)\n\n    return score",
        "island_id": 3,
        "generation": 16,
        "train_score": 0.7709483793517407,
        "val_score": 0.48627258553697306,
        "simplicity_score": 0.20498176815587696,
        "novelty_bonus": 0.2736188404710117
      },
      {
        "id": "g12_i3_p3_96390962",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate of the algebraic connectivity (Fiedler value) built only from\n    pre‑computed graph statistics.  The score is a product of several\n    dimensionless factors that reflect known spectral influences:\n\n        • Degree homogeneity  – larger when max/min degrees are close\n        • Triangle density    – sub‑linear factor from num_triangles\n        • Edge density        – higher density boosts connectivity\n        • Clustering penalty  – high local clustering slightly lowers gap\n        • Assortativity penalty – strong mixing patterns are mildly\n          detrimental\n        • Size scaling        – √n keeps values comparable across\n          different graph sizes\n\n    Each component is strictly positive; the overall result is a\n    dimensionless proxy that grows with the true algebraic connectivity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary containing the following keys:\n            'n'                # number of nodes\n            'm'                # number of edges\n            'density'          # edge density\n            'avg_degree'       # average degree\n            'max_degree'       # maximum degree\n            'min_degree'       # minimum degree\n            'std_degree'       # standard deviation of degrees\n            'avg_clustering'   # average clustering coefficient\n            'transitivity'     # global transitivity\n            'degree_assortativity'  # assortativity coefficient\n            'num_triangles'    # number of triangles\n            'degrees'          # sorted list of degrees (unused here)\n\n    Returns\n    -------\n    float\n        Dimensionless estimate of the algebraic connectivity.\n    \"\"\"\n    # Safeguard against division by zero\n    eps = 1e-12\n\n    n = s['n']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    num_tri = s['num_triangles']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n\n    # 1. Degree homogeneity: values close to 1 when the degree range is small\n    homogeneity = 1.0 - (max_deg - min_deg) / (max_deg + eps)\n\n    # 2. Triangle density factor (sub‑linear scaling)\n    # maximum possible triangles in an n‑vertex graph\n    max_tri_possible = n * (n - 1) * (n - 2) / 6.0\n    tri_fraction = num_tri / (max_tri_possible + eps)\n    triangle_factor = 1.0 + tri_fraction ** 0.5\n\n    # 3. Edge density influence (√density)\n    density_factor = density ** 0.5\n\n    # 4. Clustering penalty (inverse relationship)\n    clustering_penalty = 1.0 / (1.0 + avg_clust + eps)\n\n    # 5. Assortativity penalty\n    assort_penalty = 1.0 / (1.0 + abs(assort) + eps)\n\n    # 6. Size scaling: larger graphs tend to have larger gaps\n    size_factor = n ** 0.5\n\n    # Combine all factors multiplicatively\n    score = (homogeneity *\n             triangle_factor *\n             density_factor *\n             clustering_penalty *\n             assort_penalty *\n             size_factor)\n\n    return score",
        "island_id": 3,
        "generation": 12,
        "train_score": 0.5945258103241297,
        "val_score": 0.480734916614692,
        "simplicity_score": 0.2079376896511243,
        "novelty_bonus": 0.3042631065776643
      },
      {
        "id": "g17_i3_p2_118874252",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate of the algebraic connectivity (Fiedler value) from a fixed set\n    of pre‑computed graph statistics.  The expression combines several\n    dimensionless factors that are known to influence the second‑smallest\n    Laplacian eigenvalue:\n\n        * degree regularity  – larger when the mean degree is high\n          compared to its standard deviation\n        * triangle density   – sub‑linear contribution from the\n          proportion of possible triangles\n        * overall edge density – denser graphs tend to have a larger gap\n        * clustering penalty – high local clustering slightly reduces the gap\n        * assortativity penalty – strong mixing patterns can be mildly\n          detrimental\n        * size normalisation – √n keeps scores comparable across\n          different graph sizes\n\n    All factors are strictly positive; the final score is their product,\n    a dimensionless proxy that grows with the true algebraic connectivity.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics.  Expected keys are:\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles, degrees\n\n    Returns\n    -------\n    float\n        Dimensionless estimate of the algebraic connectivity.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    n          = float(s['n'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    clust      = float(s['avg_clustering'])\n    assort     = float(s['degree_assortativity'])\n\n    # 1. Degree regularity (high mean, low spread)\n    reg = (avg_deg + eps) / (std_deg + eps)\n\n    # 2. Triangle density factor (sub‑linear)\n    max_tri_possible = n * (n - 1.0) * (n - 2.0) / 6.0\n    tri_frac = num_tri / (max_tri_possible + eps)\n    tri_fac = 1.0 + tri_frac ** 0.5\n\n    # 3. Edge density influence\n    dens_fac = density ** 0.75\n\n    # 4. Clustering penalty\n    cluster_pen = 1.0 / (1.0 + clust + eps)\n\n    # 5. Assortativity penalty\n    assort_pen = 1.0 / (1.0 + abs(assort) + eps)\n\n    # 6. Size normalisation\n    size_fac = n ** 0.5\n\n    # Combine multiplicatively\n    score = reg * tri_fac * dens_fac * cluster_pen * assort_pen * size_fac\n    return score",
        "island_id": 3,
        "generation": 17,
        "train_score": 0.7206242496998799,
        "val_score": 0.4778657780667374,
        "simplicity_score": 0.20716228195668954,
        "novelty_bonus": 0.23808732165756674
      },
      {
        "id": "g14_i3_p1_493990819",
        "code": "def new_invariant(s):\n    \"\"\"\n    Approximate algebraic connectivity from a fixed set of pre‑computed\n    graph statistics.  The expression combines several dimensionless\n    factors that are known to influence the Fiedler value: degree\n    regularity, triangle density, overall edge density, local clustering,\n    degree assortativity, and a size normalisation.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary with the following mandatory keys:\n            n                    # number of vertices\n            m                    # number of edges\n            density              # edge density  (m / (n*(n-1)/2))\n            avg_degree           # average degree  (2*m / n)\n            max_degree           # maximum degree\n            min_degree           # minimum degree\n            std_degree           # standard deviation of degrees\n            avg_clustering       # average local clustering coefficient\n            transitivity         # global transitivity (triangle count * 3 / # of connected triples)\n            degree_assortativity # assortativity coefficient\n            num_triangles        # number of triangles\n            degrees              # sorted list of degrees (unused)\n\n    Returns\n    -------\n    float\n        Dimensionless score that correlates with the true algebraic\n        connectivity.  A larger value indicates a graph that is\n        expected to have a larger second‑smallest Laplacian eigenvalue.\n    \"\"\"\n    eps = 1e-12          # guard against division by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    std_deg = float(s['std_degree'])\n    num_tri = float(s['num_triangles'])\n    clust  = float(s['avg_clustering'])\n    assort = float(s['degree_assortativity'])\n\n    # --- 1. Degree regularity  (high mean, low spread -> better connectivity)\n    reg = (avg_deg + eps) / (std_deg + eps)\n\n    # --- 2. Triangle richness  (sub‑linear growth)\n    max_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n    tri_frac = num_tri / (max_tri + eps)\n    tri_fac = 1.0 + tri_frac ** 0.5\n\n    # --- 3. Edge density influence  (higher density improves connectivity)\n    dens_fac = density ** 0.75\n\n    # --- 4. Clustering penalty  (too high local clustering can lower the gap)\n    cluster_pen = 1.0 / (1.0 + clust + eps)\n\n    # --- 5. Assortativity penalty  (strong mixing patterns are mildly detrimental)\n    assort_pen = 1.0 / (1.0 + abs(assort) + eps)\n\n    # --- 6. Size normalisation  (scale with sqrt(n) to make values comparable)\n    size_fac = n ** 0.5\n\n    # Combine multiplicatively to form the proxy score\n    score = (reg *\n             tri_fac *\n             dens_fac *\n             cluster_pen *\n             assort_pen *\n             size_fac)\n\n    return score",
        "island_id": 3,
        "generation": 14,
        "train_score": 0.7206242496998799,
        "val_score": 0.47777882251175174,
        "simplicity_score": 0.20672750418176117,
        "novelty_bonus": 0.23808732165756674
      }
    ]
  }
}