\section{Conclusion}

We presented an open-source framework for discovering interpretable graph
invariants using LLM-driven evolutionary search. By combining island-model
evolution with MAP-Elites quality-diversity archiving, composite scoring
(accuracy + simplicity + novelty), and LLM-driven self-correction, our system
discovers closed-form formulas that are competitive with symbolic regression
and statistical baselines while remaining interpretable. The bounds-mode
capability enables discovery of mathematical inequalities, opening a path
toward LLM-assisted theorem proving in graph theory.

Our systematic evaluation across four experiment configurations with
out-of-distribution validation demonstrates that the approach generalizes
across targets (ASPL, algebraic connectivity) and fitness modes (correlation,
upper bound). \textbf{[TBD: Summarize key quantitative findings.]}

The system is released as open-source software under the MIT license at
\url{https://github.com/yuyamukai/graph_invariant}, with full experiment
configurations, analysis scripts, and reproducibility artifacts.

\paragraph{Future work.}
Promising directions include: (i)~extending to multi-target discovery where a
single formula predicts multiple invariants, (ii)~integrating formal
verification to automatically prove discovered bounds, (iii)~scaling to larger
LLMs with stronger mathematical reasoning, and (iv)~applying the framework
to other domains (e.g., discovering physical laws from simulation data).

\begin{ack}
  \textbf{[TBD: Acknowledgments.]}
\end{ack}
