{
  "experiment_id": "phase1_20260215T053414Z",
  "generation": 20,
  "rng_seed": 42,
  "rng_state": {
    "bit_generator": "PCG64",
    "state": {
      "state": 139061985705626403293569025916677151858,
      "inc": 332724090758049132448979897138935081983
    },
    "has_uint32": 1,
    "uinteger": 4262220592
  },
  "best_val_score": 0.4939659075538685,
  "no_improve_count": 0,
  "island_stagnation": {
    "0": 0,
    "1": 0,
    "2": 0,
    "3": 0
  },
  "island_prompt_mode": {
    "0": "free",
    "1": "free",
    "2": "free",
    "3": "free"
  },
  "island_constrained_generations": {
    "0": 0,
    "1": 0,
    "2": 0,
    "3": 0
  },
  "island_recent_failures": {
    "0": [
      "below_novelty_threshold: novelty_bonus=0.149496",
      "no_valid_train_predictions: static_invalid: forbidden token detected: import ",
      "below_novelty_threshold: novelty_bonus=0.149634"
    ],
    "1": [
      "below_novelty_threshold: novelty_bonus=0.134300",
      "no_valid_train_predictions: static_invalid: forbidden token detected: import ",
      "below_train_threshold: train_signal=0.115678"
    ],
    "2": [
      "below_novelty_threshold: novelty_bonus=0.104528",
      "no_valid_train_predictions: static_invalid: forbidden token detected: import ",
      "below_novelty_threshold: novelty_bonus=0.148685"
    ],
    "3": [
      "below_train_threshold: train_signal=0.267131",
      "below_novelty_threshold: novelty_bonus=0.092894",
      "no_valid_train_predictions: static_invalid: forbidden token detected: import "
    ]
  },
  "islands": {
    "0": [
      {
        "id": "g19_i0_p0_808251471",
        "code": "def new_invariant(s):\n    \"\"\"\n    Approximate algebraic connectivity from a set of pre‑computed graph statistics.\n    The expression is a product of complementary structural factors that capture\n    density, degree regularity, triangle richness, clustering, assortativity,\n    degree spread, skewness of the degree distribution, and transitivity.\n    No external libraries are imported.\n    \"\"\"\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    std_deg    = s['std_degree']\n    min_deg    = s['min_degree']\n    max_deg    = s['max_degree']\n    clustering = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    trans      = s['transitivity']\n    degrees    = s['degrees']\n\n    eps = 1e-6\n\n    # 1. Density amplification\n    density_factor = density * (1.0 + density)\n\n    # 2. Minimum‑degree boost\n    min_factor = (min_deg + 1.0) / (avg_deg + 1.0)\n\n    # 3. Triangle richness (gentle growth)\n    tri_factor = (num_tri + 1.0) ** 0.2\n\n    # 4. Degree regularity\n    reg_factor = avg_deg / (std_deg + eps)\n\n    # 5. Size–clustering balance\n    size_factor = (n ** 0.5) / (1.0 + clustering)\n\n    # 6. Assortativity moderation\n    assort_factor = 1.0 / (1.0 + abs(assort))\n\n    # 7. Degree‑spread damping (square‑root form)\n    spread = max_deg - min_deg + eps\n    spread_factor = 1.0 / (1.0 + spread ** 0.5)\n\n    # 8. Degree‑distribution skewness (third‑moment based)\n    mean_cube = sum(d ** 3 for d in degrees) / len(degrees)\n    skew_factor = (mean_cube / (avg_deg ** 3 + eps)) ** (1.0 / 3.0)\n\n    # 9. Transitivity moderation\n    trans_factor = 1.0 / (1.0 + trans)\n\n    # Combine all factors multiplicatively\n    result = (density_factor *\n              min_factor *\n              tri_factor *\n              reg_factor *\n              size_factor *\n              assort_factor *\n              spread_factor *\n              skew_factor *\n              trans_factor)\n\n    return result",
        "island_id": 0,
        "generation": 19,
        "train_score": 0.6748139255702281,
        "val_score": 0.48728718839995333,
        "simplicity_score": 0.19359337093548992,
        "novelty_bonus": 0.25715742893572324
      },
      {
        "id": "g13_i0_p4_202363364",
        "code": "def new_invariant(s):\n    \"\"\"\n    Approximate algebraic connectivity from a set of pre‑computed graph statistics.\n    The expression combines several complementary structural features in a\n    multiplicative fashion.  All operations are built‑in; no external imports\n    are required.\n\n    Features used:\n        • density          – overall edge density\n        • min_degree       – lower bound on connectivity\n        • avg_degree       – average degree\n        • std_degree       – degree dispersion\n        • max_degree       – maximum degree\n        • avg_clustering   – average local clustering\n        • transitivity     – global clustering coefficient\n        • degree_assortativity – degree correlation\n        • num_triangles    – triangle count\n        • degrees          – list of degrees (used for skewness)\n    \"\"\"\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    std_deg    = s['std_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    eps = 1e-6\n\n    # 1. Degree regularity\n    reg_factor = avg_deg / (std_deg + eps)\n\n    # 2. Triangle richness (gentle growth)\n    tri_factor = (num_tri + 1) ** 0.2\n\n    # 3. Size–clustering balance\n    size_factor = (n ** 0.5) / (1 + clustering)\n\n    # 4. Transitivity moderation\n    trans_factor = 1.0 / (1 + trans)\n\n    # 5. Assortativity moderation\n    assort_factor = 1.0 / (1 + abs(assort))\n\n    # 6. Density amplification\n    density_factor = density * (1 + density)\n\n    # 7. Degree‑spread damping\n    spread = max_deg - min_deg + eps\n    spread_factor = 1.0 / (1 + spread ** 0.5)\n\n    # 8. Degree‑distribution skewness\n    sum_sq = sum(d * d for d in degrees)\n    mean_sq = sum_sq / len(degrees)\n    skew_factor = (mean_sq / (avg_deg * avg_deg + eps)) ** 0.25\n\n    # 9. Minimum‑degree boost\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    result = (reg_factor *\n              tri_factor *\n              size_factor *\n              trans_factor *\n              assort_factor *\n              density_factor *\n              spread_factor *\n              skew_factor *\n              min_factor)\n\n    return result",
        "island_id": 0,
        "generation": 13,
        "train_score": 0.662905162064826,
        "val_score": 0.48306008691688906,
        "simplicity_score": 0.19348238913330898,
        "novelty_bonus": 0.27818195454886363
      },
      {
        "id": "g18_i0_p1_730295586",
        "code": "def new_invariant(s):\n    \"\"\"\n    Approximate algebraic connectivity from pre‑computed graph statistics.\n    The formula is a product of complementary structural factors that\n    capture density, degree regularity, triangle richness, clustering,\n    assortativity, degree spread, skewness of the degree distribution,\n    and transitivity.  No external libraries are used.\n    \"\"\"\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    std_deg    = s['std_degree']\n    min_deg    = s['min_degree']\n    max_deg    = s['max_degree']\n    clustering = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    trans      = s['transitivity']\n    degrees    = s['degrees']\n\n    eps = 1e-6\n\n    # 1. Density amplification\n    density_factor = density * (1.0 + density)\n\n    # 2. Minimum‑degree boost\n    min_factor = (min_deg + 1.0) / (avg_deg + 1.0)\n\n    # 3. Triangle richness (gentle growth)\n    tri_factor = (num_tri + 1.0) ** 0.15\n\n    # 4. Degree regularity\n    reg_factor = avg_deg / (std_deg + eps)\n\n    # 5. Size–clustering balance\n    size_factor = (n ** 0.5) / (1.0 + clustering)\n\n    # 6. Assortativity moderation\n    assort_factor = 1.0 / (1.0 + abs(assort))\n\n    # 7. Degree‑spread damping (square‑root form)\n    spread = max_deg - min_deg + eps\n    spread_factor = 1.0 / (1.0 + spread ** 0.5)\n\n    # 8. Degree‑distribution skewness (third‑moment based)\n    mean_cube = sum(d ** 3 for d in degrees) / len(degrees)\n    skew_factor = (mean_cube / (avg_deg ** 3 + eps)) ** (1.0 / 3.0)\n\n    # 9. Transitivity moderation\n    trans_factor = 1.0 / (1.0 + trans)\n\n    # Combine all factors multiplicatively\n    result = (density_factor *\n              min_factor *\n              tri_factor *\n              reg_factor *\n              size_factor *\n              assort_factor *\n              spread_factor *\n              skew_factor *\n              trans_factor)\n\n    return result",
        "island_id": 0,
        "generation": 18,
        "train_score": 0.6556062424969987,
        "val_score": 0.4821567601392468,
        "simplicity_score": 0.19359337093548992,
        "novelty_bonus": 0.2828095702392559
      },
      {
        "id": "g19_i0_p3_202738313",
        "code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    std_deg = s['std_degree']\n    min_deg = s['min_degree']\n    max_deg = s['max_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    eps = 1e-6\n\n    # 1. Density amplification\n    density_factor = density * (1 + density)\n\n    # 2. Edge‑density factor (uses raw edge count)\n    m_factor = (m + 1) / (n * (n - 1) / 2 + 1)\n\n    # 3. Minimum‑degree boost\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # 4. Triangle richness (gentle growth)\n    tri_factor = (num_tri + 1) ** 0.15\n\n    # 5. Degree regularity\n    reg_factor = avg_deg / (std_deg + eps)\n\n    # 6. Size–clustering balance\n    size_factor = (n ** 0.5) / (1 + clustering)\n\n    # 7. Assortativity moderation\n    assort_factor = 1 / (1 + abs(assort))\n\n    # 8. Degree‑spread damping\n    spread_factor = 1 / (1 + (max_deg - min_deg + eps) ** 0.5)\n\n    # 9. Degree‑distribution skewness (third‑moment based)\n    mean_cube = sum(d ** 3 for d in degrees) / len(degrees)\n    skew_factor = (mean_cube / (avg_deg ** 3 + eps)) ** (1 / 3)\n\n    # 10. Transitivity moderation\n    trans_factor = 1 / (1 + trans)\n\n    # 11. Max‑degree penalty (encourages bounded degree spread)\n    max_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # 12. Degree‑distribution kurtosis factor (adds novelty)\n    mean_quad = sum((d - avg_deg) ** 4 for d in degrees) / len(degrees)\n    kurt_factor = (1 + mean_quad / (avg_deg ** 4 + eps)) ** 0.05\n\n    # Combine all factors multiplicatively\n    result = (density_factor *\n              m_factor *\n              min_factor *\n              tri_factor *\n              reg_factor *\n              size_factor *\n              assort_factor *\n              spread_factor *\n              skew_factor *\n              trans_factor *\n              max_factor *\n              kurt_factor)\n\n    return result",
        "island_id": 0,
        "generation": 19,
        "train_score": 0.6664585834333733,
        "val_score": 0.4774916115210666,
        "simplicity_score": 0.19122178161347844,
        "novelty_bonus": 0.27903038914969847
      },
      {
        "id": "g19_i3_p0_533156832",
        "code": "def new_invariant(s):\n    \"\"\"\n    Lightweight estimate of algebraic connectivity from pre‑computed\n    graph statistics.\n\n    The score is a product of several dimensionless factors that\n    capture the main structural influences on the second‑smallest\n    Laplacian eigenvalue.  Each component is strictly positive and\n    uses only built‑in arithmetic, so the function can be called\n    without any external libraries.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features.  Expected keys:\n\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees\n\n    Returns\n    -------\n    float\n        Proxy for the algebraic connectivity.  Larger values\n        indicate a graph expected to have a larger Fiedler value.\n    \"\"\"\n    # small constant to keep denominators safe\n    eps = 1e-12\n\n    n          = float(s['n'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    density    = float(s['density'])\n    num_tri    = float(s['num_triangles'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n\n    # ---- 1. Size normalisation ----\n    size_term = n ** 0.5                     # √n\n\n    # ---- 2. Degree regularity ----\n    # More regular degree distributions (low std) raise connectivity\n    degree_term = (avg_deg + 1.0) / (std_deg + 1.0 + eps)\n\n    # ---- 3. Triangle richness ----\n    max_tri_possible = n * (n - 1.0) * (n - 2.0) / 6.0\n    tri_frac = num_tri / (max_tri_possible + eps)\n    triangle_term = 1.0 + tri_frac ** 0.25\n\n    # ---- 4. Edge density effect ----\n    density_term = density ** 0.5             # √density\n\n    # ---- 5. Penalty for high clustering ----\n    clustering_pen = 1.0 / (1.0 + avg_clust ** 1.5)\n\n    # ---- 6. Penalty for high transitivity ----\n    trans_pen = 1.0 / (1.0 + trans ** 1.2)\n\n    # ---- 7. Penalty for strong assortativity ----\n    assort_pen = 1.0 / (1.0 + abs(assort) ** 0.9)\n\n    # ---- combine multiplicatively ----\n    score = (size_term *\n             degree_term *\n             triangle_term *\n             density_term *\n             clustering_pen *\n             trans_pen *\n             assort_pen)\n\n    return score",
        "island_id": 3,
        "generation": 19,
        "train_score": 0.8285714285714285,
        "val_score": 0.4939659075538685,
        "simplicity_score": 0.20534592567904023,
        "novelty_bonus": 0.23551638790969776
      }
    ],
    "1": [
      {
        "id": "g17_i1_p1_363678253",
        "code": "def new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    min_deg = s['min_degree']\n    max_deg = s['max_degree']\n    avg_deg = s['avg_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']  # already sorted\n\n    # Normalised triangle density\n    if n >= 3:\n        max_tri = n * (n - 1) * (n - 2) / 6\n    else:\n        max_tri = 1\n    tri_norm = num_tri / max_tri\n\n    # Median degree (uses only the sorted list)\n    l = len(degrees)\n    if l == 0:\n        median_deg = 0\n    elif l % 2 == 1:\n        median_deg = degrees[l // 2]\n    else:\n        median_deg = (degrees[l // 2 - 1] + degrees[l // 2]) / 2\n\n    # Combine features multiplicatively\n    term1 = (min_deg + 1) * (density + 1e-6)**0.5 * (abs(assort) + 1) / (avg_clust + 1)\n    term2 = (n**0.5) * (1 + avg_deg) * (1 + trans) * (1 + tri_norm) / (1 + std_deg)\n    term3 = (max_deg + 1) / (m + 1)\n    term4 = (max_deg - min_deg + 1) / (avg_deg + 1)\n    term5 = (1 + median_deg) / (1 + std_deg)\n\n    return term1 * term2 * term3 * term4 * term5",
        "island_id": 1,
        "generation": 17,
        "train_score": 0.6959423769507803,
        "val_score": 0.47708800860944106,
        "simplicity_score": 0.13830323126167304,
        "novelty_bonus": 0.17832821378216934
      },
      {
        "id": "g17_i1_p3_9916196",
        "code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    min_deg = s['min_degree']\n    assort = s['degree_assortativity']\n    avg_clust = s['avg_clustering']\n    avg_deg = s['avg_degree']\n    trans = s['transitivity']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Normalized triangle density\n    if n >= 3:\n        max_tri = n * (n - 1) * (n - 2) / 6\n    else:\n        max_tri = 1\n    tri_norm = num_tri / max_tri\n\n    # Harmonic mean of degrees\n    sum_recip = 0.0\n    for d in degrees:\n        if d > 0:\n            sum_recip += 1.0 / d\n    if len(degrees) > 0:\n        harm_mean_deg = len(degrees) / sum_recip\n    else:\n        harm_mean_deg = 0.0\n\n    # Combine features multiplicatively\n    term1 = (min_deg + 1) * pow(density + 1e-6, 0.5) * (abs(assort) + 1) / (avg_clust + 1)\n    term2 = pow(n, 0.5) * (1 + avg_deg) * (1 + trans) * (1 + tri_norm) / (1 + std_deg)\n    term3 = (max_deg + 1) / (m + 1)\n    term4 = (harm_mean_deg + 1) / (avg_deg + 1)\n\n    return term1 * term2 * term3 * term4",
        "island_id": 1,
        "generation": 17,
        "train_score": 0.6267947178871548,
        "val_score": 0.463615619211721,
        "simplicity_score": 0.1444774349433183,
        "novelty_bonus": 0.20630603838346517
      },
      {
        "id": "g18_i1_p3_916011844",
        "code": "def new_invariant(s):\n    # Basic graph statistics\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    min_deg = float(s['min_degree'])\n    max_deg = float(s['max_degree'])\n    avg_deg = float(s['avg_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']          # already sorted list\n\n    # Normalised triangle density\n    if n >= 3.0:\n        max_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n    else:\n        max_tri = 1.0\n    tri_norm = num_tri / max_tri\n\n    # Harmonic mean of degrees (ignoring zeros)\n    sum_recip = 0.0\n    for d in degrees:\n        if d > 0:\n            sum_recip += 1.0 / float(d)\n    if len(degrees) > 0 and sum_recip > 0.0:\n        harm_mean_deg = float(len(degrees)) / sum_recip\n    else:\n        harm_mean_deg = 0.0\n\n    # Combine features multiplicatively\n    term1 = (min_deg + 1.0) * pow(density + 1e-6, 0.5) * (abs(assort) + 1.0) / (avg_clust + 1.0)\n    term2 = pow(n, 0.5) * (1.0 + avg_deg) * (1.0 + trans) * (1.0 + tri_norm) / (1.0 + std_deg)\n    term3 = (max_deg + 1.0) / (m + 1.0)\n    term4 = (harm_mean_deg + 1.0) / (avg_deg + 1.0)\n\n    return term1 * term2 * term3 * term4",
        "island_id": 1,
        "generation": 18,
        "train_score": 0.6267947178871548,
        "val_score": 0.4633867246335571,
        "simplicity_score": 0.14333296205249882,
        "novelty_bonus": 0.20630603838346517
      },
      {
        "id": "g19_i0_p0_808251471",
        "code": "def new_invariant(s):\n    \"\"\"\n    Approximate algebraic connectivity from a set of pre‑computed graph statistics.\n    The expression is a product of complementary structural factors that capture\n    density, degree regularity, triangle richness, clustering, assortativity,\n    degree spread, skewness of the degree distribution, and transitivity.\n    No external libraries are imported.\n    \"\"\"\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    std_deg    = s['std_degree']\n    min_deg    = s['min_degree']\n    max_deg    = s['max_degree']\n    clustering = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    trans      = s['transitivity']\n    degrees    = s['degrees']\n\n    eps = 1e-6\n\n    # 1. Density amplification\n    density_factor = density * (1.0 + density)\n\n    # 2. Minimum‑degree boost\n    min_factor = (min_deg + 1.0) / (avg_deg + 1.0)\n\n    # 3. Triangle richness (gentle growth)\n    tri_factor = (num_tri + 1.0) ** 0.2\n\n    # 4. Degree regularity\n    reg_factor = avg_deg / (std_deg + eps)\n\n    # 5. Size–clustering balance\n    size_factor = (n ** 0.5) / (1.0 + clustering)\n\n    # 6. Assortativity moderation\n    assort_factor = 1.0 / (1.0 + abs(assort))\n\n    # 7. Degree‑spread damping (square‑root form)\n    spread = max_deg - min_deg + eps\n    spread_factor = 1.0 / (1.0 + spread ** 0.5)\n\n    # 8. Degree‑distribution skewness (third‑moment based)\n    mean_cube = sum(d ** 3 for d in degrees) / len(degrees)\n    skew_factor = (mean_cube / (avg_deg ** 3 + eps)) ** (1.0 / 3.0)\n\n    # 9. Transitivity moderation\n    trans_factor = 1.0 / (1.0 + trans)\n\n    # Combine all factors multiplicatively\n    result = (density_factor *\n              min_factor *\n              tri_factor *\n              reg_factor *\n              size_factor *\n              assort_factor *\n              spread_factor *\n              skew_factor *\n              trans_factor)\n\n    return result",
        "island_id": 0,
        "generation": 19,
        "train_score": 0.6748139255702281,
        "val_score": 0.48728718839995333,
        "simplicity_score": 0.19359337093548992,
        "novelty_bonus": 0.25715742893572324
      },
      {
        "id": "g15_i1_p3_925120118",
        "code": "def new_invariant(s):\n    # extract features\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    min_deg = s['min_degree']\n    assort = s['degree_assortativity']\n    avg_clust = s['avg_clustering']\n    avg_deg = s['avg_degree']\n    trans = s['transitivity']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    num_tri = s['num_triangles']\n\n    # Normalized triangle density\n    max_tri = n * (n - 1) * (n - 2) / 6 if n >= 3 else 1\n    tri_norm = num_tri / max_tri\n\n    # Combine features multiplicatively\n    term1 = (min_deg + 1) * (density + 1e-6)**0.5 * (abs(assort) + 1) / (avg_clust + 1)\n    term2 = (n**0.5) * (1 + avg_deg) * (1 + trans) * (1 + tri_norm) / (1 + std_deg)\n    term3 = (max_deg + 1) / (m + 1)\n\n    return term1 * term2 * term3",
        "island_id": 1,
        "generation": 15,
        "train_score": 0.6003841536614647,
        "val_score": 0.45479580483772086,
        "simplicity_score": 0.15492810024111026,
        "novelty_bonus": 0.1894275341379501
      }
    ],
    "2": [
      {
        "id": "g19_i2_p1_991382800",
        "code": "def new_invariant(s):\n    \"\"\"\n    Heuristic estimate of algebraic connectivity (second‑smallest Laplacian eigenvalue)\n    based only on pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed features of a graph.  Keys required:\n\n        n                : number of nodes\n        m                : number of edges\n        density          : edge density (2*m / (n*(n-1)) for undirected graphs)\n        avg_degree       : average degree\n        max_degree       : maximum degree\n        min_degree       : minimum degree\n        std_degree       : standard deviation of degrees\n        avg_clustering   : average local clustering coefficient\n        transitivity     : global transitivity (overall clustering)\n        degree_assortativity : degree assortativity coefficient\n        num_triangles    : total number of triangles\n        degrees          : sorted list of degrees (ascending)\n\n    Returns\n    -------\n    float\n        Estimated algebraic connectivity.\n    \"\"\"\n    eps = 1e-6  # small constant to avoid division by zero\n\n    n          = s['n']\n    min_deg    = s['min_degree']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    density    = s['density']\n    num_tri    = s['num_triangles']\n    avg_clust  = s['avg_clustering']\n    std_deg    = s['std_degree']\n    assort     = s['degree_assortativity']\n    trans      = s['transitivity']\n    degrees    = s['degrees']\n\n    # --------- median degree ----------------------------------------------\n    mid = n // 2\n    if n % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n\n    # --------- factors that tend to increase connectivity ------------------\n    core_factor      = (min_deg + eps) / (avg_deg + eps)          # core robustness\n    density_factor   = 1.0 + density                             # more edges → more paths\n    triangle_factor  = 1.0 + num_tri / (n * (n - 1) / 2.0 + eps)  # triangle density\n    clustering_factor= 1.0 + avg_clust                            # local clustering\n    median_factor    = 1.0 + median_deg / (avg_deg + eps)         # degree balance\n    size_factor      = n ** 0.5                                   # larger graphs give more routes\n\n    # --------- penalties that reduce the estimate -------------------------\n    hetero_penalty   = 1.0 + std_deg / (avg_deg + eps)            # high degree variance\n    assort_penalty   = 1.0 + abs(assort)                          # strong assortativity\n    trans_penalty    = 1.0 + trans                                 # high global clustering\n\n    # --------- combine everything -----------------------------------------\n    numerator   = (core_factor * density_factor * triangle_factor *\n                   clustering_factor * median_factor * size_factor)\n    denominator = hetero_penalty * assort_penalty * trans_penalty\n\n    return numerator / denominator",
        "island_id": 2,
        "generation": 19,
        "train_score": 0.517406962785114,
        "val_score": 0.45996773266211777,
        "simplicity_score": 0.14662633300233083,
        "novelty_bonus": 0.34678766969174224
      },
      {
        "id": "g18_i2_p3_37412556",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate of algebraic connectivity from pre‑computed graph statistics.\n    The expression is a product of normalised structural factors, divided by\n    penalties that reduce the estimate for highly heterogeneous, assortative,\n    or transitive degree distributions.\n\n    Available keys in ``s``:\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees (sorted list)\n    \"\"\"\n    n          = s['n']\n    min_deg    = s['min_degree']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    density    = s['density']\n    num_tri    = s['num_triangles']\n    avg_clust  = s['avg_clustering']\n    std_deg    = s['std_degree']\n    assort     = s['degree_assortativity']\n    trans      = s['transitivity']\n    degrees    = s['degrees']          # sorted list of degrees\n\n    eps = 1e-6\n\n    # Median degree (degrees is sorted)\n    mid = n // 2\n    median_deg = degrees[mid] if n % 2 else (degrees[mid - 1] + degrees[mid]) / 2.0\n\n    # Normalised factors that typically increase algebraic connectivity\n    core_factor      = min_deg / (avg_deg + eps)\n    density_factor   = 1.0 + density ** 0.5\n    triangle_factor  = 1.0 + num_tri / (n * (n - 1) / 2.0 + eps)\n    clustering_factor= 1.0 + avg_clust\n    median_factor    = 1.0 + median_deg / (avg_deg + eps)\n    size_factor      = n ** 0.5\n\n    # Penalties that reduce the estimate for heterogeneity, assortativity,\n    # or high transitivity\n    hetero_penalty   = 1.0 + std_deg / (max_deg + eps)\n    assort_penalty   = 1.0 + abs(assort)\n    trans_penalty    = 1.0 + trans\n\n    numerator   = (core_factor * density_factor * triangle_factor *\n                   clustering_factor * median_factor * size_factor)\n    denominator = hetero_penalty * assort_penalty * trans_penalty\n\n    return numerator / denominator",
        "island_id": 2,
        "generation": 18,
        "train_score": 0.4787995198079231,
        "val_score": 0.45724009376715335,
        "simplicity_score": 0.14681848428615302,
        "novelty_bonus": 0.3606180154503862
      },
      {
        "id": "g17_i2_p0_542827091",
        "code": "def new_invariant(s):\n    \"\"\"\n    Heuristic estimate of algebraic connectivity (second‑smallest Laplacian eigenvalue)\n    using only pre‑computed graph statistics.\n\n    The formula multiplies normalised structural factors that tend to increase\n    connectivity and divides by penalties that capture degree heterogeneity,\n    assortativity and clustering transitivity.  All operations are pure Python,\n    no external imports are required.\n\n    Available keys in ``s``:\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees (sorted list)\n    \"\"\"\n    n = s['n']\n    degrees = s['degrees']\n\n    # --- median degree ----------------------------------------------------\n    mid = n // 2\n    if n % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n\n    eps = 1e-6  # avoid division by zero\n\n    # --- factors that tend to raise algebraic connectivity ----------------\n    core_factor      = (s['min_degree'] + eps) / (s['avg_degree'] + eps)\n    density_factor   = 1.0 + s['density']\n    triangle_factor  = 1.0 + s['num_triangles'] / (n * (n - 1) / 2.0 + eps)\n    clustering_factor= 1.0 + s['avg_clustering']\n    median_factor    = 1.0 + median_deg / (s['avg_degree'] + eps)\n    size_factor      = n ** 0.5\n\n    # --- penalties that reduce the estimate --------------------------------\n    hetero_penalty   = 1.0 + s['std_degree'] / (s['max_degree'] + eps)\n    assort_penalty   = 1.0 + abs(s['degree_assortativity'])\n    trans_penalty    = 1.0 + s['transitivity']\n\n    numerator   = (core_factor * density_factor * triangle_factor *\n                   clustering_factor * median_factor * size_factor)\n    denominator = hetero_penalty * assort_penalty * trans_penalty\n\n    return numerator / denominator",
        "island_id": 2,
        "generation": 17,
        "train_score": 0.46545018007202876,
        "val_score": 0.45510445487476353,
        "simplicity_score": 0.14787508319403816,
        "novelty_bonus": 0.37235280882022037
      },
      {
        "id": "g18_i2_p4_141262147",
        "code": "def new_invariant(s):\n    \"\"\"\n    Heuristic estimate of the algebraic connectivity (second‑smallest Laplacian\n    eigenvalue) using only pre‑computed graph statistics.\n\n    The formula multiplies normalised structural factors that typically\n    increase connectivity (core, density, triangles, clustering,\n    degree balance, and graph size) and divides by penalties that\n    capture heterogeneity, assortativity, and global clustering.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed features with the following keys:\n        - n                : number of nodes\n        - m                : number of edges\n        - density          : edge density\n        - avg_degree       : average degree\n        - max_degree       : maximum degree\n        - min_degree       : minimum degree\n        - std_degree       : standard deviation of degrees\n        - avg_clustering   : average clustering coefficient\n        - transitivity     : global transitivity\n        - degree_assortativity : degree assortativity coefficient\n        - num_triangles    : total number of triangles\n        - degrees          : sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated algebraic connectivity.\n    \"\"\"\n    eps = 1e-6  # small constant to avoid division by zero\n\n    n          = s['n']\n    min_deg    = s['min_degree']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    density    = s['density']\n    num_tri    = s['num_triangles']\n    avg_clust  = s['avg_clustering']\n    std_deg    = s['std_degree']\n    assort     = s['degree_assortativity']\n    trans      = s['transitivity']\n\n    # ---------- structural factors that tend to raise connectivity ----------\n    core_factor      = min_deg / (avg_deg + eps)               # min/avg degree\n    density_factor   = 1.0 + density                          # more edges → higher\n    triangle_factor  = 1.0 + num_tri / (n * (n - 1) / 2.0 + eps)  # triangle density\n    clustering_factor= 1.0 + avg_clust                         # local clustering\n    size_factor      = n ** 0.5                                # larger graphs → more paths\n    avg_to_max_factor= avg_deg / (max_deg + eps)               # balance of degrees\n\n    # ---------- penalties that reduce the estimate -------------------------\n    hetero_penalty   = 1.0 + std_deg / (max_deg + eps)         # high heterogeneity\n    assort_penalty   = 1.0 + abs(assort)                       # strong assortativity\n    trans_penalty    = 1.0 + trans                              # high transitivity\n\n    # ---------- combine everything -----------------------------------------\n    numerator   = (core_factor * density_factor * triangle_factor *\n                   clustering_factor * size_factor * avg_to_max_factor)\n    denominator = hetero_penalty * assort_penalty * trans_penalty\n\n    return numerator / denominator",
        "island_id": 2,
        "generation": 18,
        "train_score": 0.5195198079231693,
        "val_score": 0.45434927843386896,
        "simplicity_score": 0.14863719708286263,
        "novelty_bonus": 0.34960198495402706
      },
      {
        "id": "g17_i1_p1_363678253",
        "code": "def new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    min_deg = s['min_degree']\n    max_deg = s['max_degree']\n    avg_deg = s['avg_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']  # already sorted\n\n    # Normalised triangle density\n    if n >= 3:\n        max_tri = n * (n - 1) * (n - 2) / 6\n    else:\n        max_tri = 1\n    tri_norm = num_tri / max_tri\n\n    # Median degree (uses only the sorted list)\n    l = len(degrees)\n    if l == 0:\n        median_deg = 0\n    elif l % 2 == 1:\n        median_deg = degrees[l // 2]\n    else:\n        median_deg = (degrees[l // 2 - 1] + degrees[l // 2]) / 2\n\n    # Combine features multiplicatively\n    term1 = (min_deg + 1) * (density + 1e-6)**0.5 * (abs(assort) + 1) / (avg_clust + 1)\n    term2 = (n**0.5) * (1 + avg_deg) * (1 + trans) * (1 + tri_norm) / (1 + std_deg)\n    term3 = (max_deg + 1) / (m + 1)\n    term4 = (max_deg - min_deg + 1) / (avg_deg + 1)\n    term5 = (1 + median_deg) / (1 + std_deg)\n\n    return term1 * term2 * term3 * term4 * term5",
        "island_id": 1,
        "generation": 17,
        "train_score": 0.6959423769507803,
        "val_score": 0.47708800860944106,
        "simplicity_score": 0.13830323126167304,
        "novelty_bonus": 0.17832821378216934
      }
    ],
    "3": [
      {
        "id": "g19_i3_p0_533156832",
        "code": "def new_invariant(s):\n    \"\"\"\n    Lightweight estimate of algebraic connectivity from pre‑computed\n    graph statistics.\n\n    The score is a product of several dimensionless factors that\n    capture the main structural influences on the second‑smallest\n    Laplacian eigenvalue.  Each component is strictly positive and\n    uses only built‑in arithmetic, so the function can be called\n    without any external libraries.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features.  Expected keys:\n\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees\n\n    Returns\n    -------\n    float\n        Proxy for the algebraic connectivity.  Larger values\n        indicate a graph expected to have a larger Fiedler value.\n    \"\"\"\n    # small constant to keep denominators safe\n    eps = 1e-12\n\n    n          = float(s['n'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    density    = float(s['density'])\n    num_tri    = float(s['num_triangles'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n\n    # ---- 1. Size normalisation ----\n    size_term = n ** 0.5                     # √n\n\n    # ---- 2. Degree regularity ----\n    # More regular degree distributions (low std) raise connectivity\n    degree_term = (avg_deg + 1.0) / (std_deg + 1.0 + eps)\n\n    # ---- 3. Triangle richness ----\n    max_tri_possible = n * (n - 1.0) * (n - 2.0) / 6.0\n    tri_frac = num_tri / (max_tri_possible + eps)\n    triangle_term = 1.0 + tri_frac ** 0.25\n\n    # ---- 4. Edge density effect ----\n    density_term = density ** 0.5             # √density\n\n    # ---- 5. Penalty for high clustering ----\n    clustering_pen = 1.0 / (1.0 + avg_clust ** 1.5)\n\n    # ---- 6. Penalty for high transitivity ----\n    trans_pen = 1.0 / (1.0 + trans ** 1.2)\n\n    # ---- 7. Penalty for strong assortativity ----\n    assort_pen = 1.0 / (1.0 + abs(assort) ** 0.9)\n\n    # ---- combine multiplicatively ----\n    score = (size_term *\n             degree_term *\n             triangle_term *\n             density_term *\n             clustering_pen *\n             trans_pen *\n             assort_pen)\n\n    return score",
        "island_id": 3,
        "generation": 19,
        "train_score": 0.8285714285714285,
        "val_score": 0.4939659075538685,
        "simplicity_score": 0.20534592567904023,
        "novelty_bonus": 0.23551638790969776
      },
      {
        "id": "g19_i3_p1_44910619",
        "code": "def new_invariant(s):\n    eps = 1e-12\n\n    n = float(s['n'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    std_deg = float(s['std_degree'])\n    num_tri = float(s['num_triangles'])\n    avg_clust = float(s['avg_clustering'])\n    assort = float(s['degree_assortativity'])\n\n    # Degree regularity (higher for homogeneous degree sequences)\n    reg_index = 1.0 - (std_deg / (avg_deg + eps))\n    if reg_index < 0.0:\n        reg_index = 0.0\n\n    # Triangle richness (sub‑linear growth)\n    max_possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n    tri_frac = num_tri / (max_possible_tri + eps)\n    tri_factor = 1.0 + tri_frac ** 0.4\n\n    # Edge‑density contribution\n    density_factor = density ** 0.5\n\n    # Exponential penalties for clustering and assortativity\n    e_const = 2.718281828459045\n    clustering_penalty = e_const ** (-avg_clust)\n    assort_penalty = e_const ** (-abs(assort))\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine multiplicatively\n    score = (size_factor *\n             reg_index *\n             tri_factor *\n             density_factor *\n             clustering_penalty *\n             assort_penalty)\n\n    return score",
        "island_id": 3,
        "generation": 19,
        "train_score": 0.8284472618777302,
        "val_score": 0.4884897058869202,
        "simplicity_score": 0.20704097854310094,
        "novelty_bonus": 0.2645924491084999
      },
      {
        "id": "g17_i3_p4_243873251",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate of the algebraic connectivity (Fiedler value) using only\n    pre‑computed structural statistics of the graph.  The score is a\n    product of several dimensionless factors that capture known\n    influences on the Laplacian spectrum:\n\n        • Degree regularity (penalises large spread between max/min)\n        • Triangle density (sub‑linear growth)\n        • Edge density (higher density tends to increase the gap)\n        • Clustering penalty (high local clustering can lower connectivity)\n        • Assortativity penalty (strong mixing patterns are mildly detrimental)\n        • Size scaling (√n keeps values comparable across graph sizes)\n        • Average degree weighting (larger mean degree generally favours\n          a larger algebraic connectivity)\n\n    Each component is strictly positive; the final score therefore\n    grows monotonically with the true algebraic connectivity.  All\n    operations are elementary arithmetic so the function can be used\n    without importing any additional modules.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary containing the following keys:\n            n                    # number of nodes\n            m                    # number of edges\n            density              # edge density  (m / (n*(n-1)/2))\n            avg_degree           # average degree  (2*m / n)\n            max_degree           # maximum degree\n            min_degree           # minimum degree\n            std_degree           # standard deviation of degrees\n            avg_clustering       # average local clustering coefficient\n            transitivity         # global transitivity\n            degree_assortativity # assortativity coefficient\n            num_triangles        # number of triangles\n            degrees              # sorted list of degrees (unused)\n\n    Returns\n    -------\n    float\n        Dimensionless score that correlates with the true algebraic\n        connectivity; a larger value indicates a graph expected to have\n        a larger second‑smallest Laplacian eigenvalue.\n    \"\"\"\n    # Small constant to avoid division by zero\n    eps = 1e-12\n\n    # --- 1. Degree regularity -------------------------------------------------\n    #  Regularity is high when max and min degrees are close\n    deg_range = float(s['max_degree'] - s['min_degree'])\n    deg_sum   = float(s['max_degree'] + eps)\n    regularity = 1.0 - (deg_range / deg_sum)\n\n    # --- 2. Triangle density factor ------------------------------------------\n    n  = float(s['n'])\n    num_tri = float(s['num_triangles'])\n    # maximum possible number of triangles in a simple graph\n    max_tri_possible = n * (n - 1.0) * (n - 2.0) / 6.0\n    tri_frac = num_tri / (max_tri_possible + eps)\n    triangle_factor = 1.0 + tri_frac ** 0.3\n\n    # --- 3. Edge density influence -------------------------------------------\n    density_factor = float(s['density']) ** 0.5\n\n    # --- 4. Clustering penalty -----------------------------------------------\n    clust = float(s['avg_clustering'])\n    clustering_penalty = 1.0 / (1.0 + clust ** 1.2)\n\n    # --- 5. Assortativity penalty --------------------------------------------\n    assort = float(s['degree_assortativity'])\n    assortativity_penalty = 1.0 / (1.0 + abs(assort) ** 0.8)\n\n    # --- 6. Size scaling ------------------------------------------------------\n    size_factor = n ** 0.4\n\n    # --- 7. Average degree weighting -----------------------------------------\n    avg_deg = float(s['avg_degree'])\n    avg_deg_factor = (avg_deg + 1.0) ** 0.2\n\n    # --- Final score ---------------------------------------------------------\n    score = (regularity *\n             triangle_factor *\n             density_factor *\n             clustering_penalty *\n             assortativity_penalty *\n             size_factor *\n             avg_deg_factor)\n\n    return score",
        "island_id": 3,
        "generation": 17,
        "train_score": 0.6728931572629052,
        "val_score": 0.4880785020502356,
        "simplicity_score": 0.20621115571731452,
        "novelty_bonus": 0.2658186454661364
      },
      {
        "id": "g18_i3_p3_309955439",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate of the algebraic connectivity (Fiedler value) from a collection\n    of pre‑computed graph statistics.  \n    The score is a product of several positive factors, each of which captures\n    a known influence on the second‑smallest Laplacian eigenvalue.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary containing the following keys:\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles, degrees\n\n    Returns\n    -------\n    float\n        Dimensionless proxy for the algebraic connectivity.  Larger values\n        correspond to larger expected Fiedler values.\n    \"\"\"\n    # small constant to avoid divisions by zero\n    eps = 1e-12\n\n    # ---------- 1. Degree homogeneity ----------\n    # close to 1.0 when the degree spread is small\n    deg_range   = float(s['max_degree'] - s['min_degree'])\n    deg_max_plus_eps = float(s['max_degree'] + eps)\n    homogeneity = 1.0 - (deg_range / deg_max_plus_eps)\n\n    # ---------- 2. Triangle richness ----------\n    n = float(s['n'])\n    num_tri = float(s['num_triangles'])\n    max_tri_possible = n * (n - 1.0) * (n - 2.0) / 6.0\n    tri_fraction = num_tri / (max_tri_possible + eps)\n    triangle_factor = 1.0 + pow(tri_fraction, 0.5)\n\n    # ---------- 3. Edge density effect ----------\n    density_factor = pow(float(s['density']), 0.7)\n\n    # ---------- 4. Clustering penalty ----------\n    clustering_penalty = 1.0 / (1.0 + pow(float(s['avg_clustering']), 1.2))\n\n    # ---------- 5. Assortativity penalty ----------\n    assortativity = float(s['degree_assortativity'])\n    assort_penalty = 1.0 / (1.0 + pow(abs(assortativity), 0.8))\n\n    # ---------- 6. Size scaling ----------\n    size_factor = pow(n, 0.5)\n\n    # ---------- Combine all factors ----------\n    score = (homogeneity *\n             triangle_factor *\n             density_factor *\n             clustering_penalty *\n             assort_penalty *\n             size_factor)\n\n    return score",
        "island_id": 3,
        "generation": 18,
        "train_score": 0.6683793517406963,
        "val_score": 0.48720978222911304,
        "simplicity_score": 0.20720319000253667,
        "novelty_bonus": 0.2711542788569714
      },
      {
        "id": "g19_i3_p2_298797959",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate a dimensionless proxy for the algebraic connectivity (Fiedler value)\n    using only pre‑computed graph statistics.\n\n    The score is the product of several positive factors, each capturing a\n    known influence on the Laplacian spectrum:\n\n        * degree regularity      – lower spread → higher connectivity\n        * triangle richness     – more triangles relative to the maximum\n        * edge density          – denser graphs tend to have larger gaps\n        * clustering penalty    – high local clustering can reduce connectivity\n        * assortativity penalty – strong assortative mixing slightly lowers it\n        * size scaling          – √n normalises across different graph sizes\n        * average degree weight – higher mean degree generally favours\n                                   higher connectivity\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed features of a graph.  Expected keys:\n\n            n                     : number of nodes\n            m                     : number of edges\n            density               : edge density  (m / (n*(n-1)/2))\n            avg_degree            : average degree  (2*m / n)\n            max_degree            : maximum degree\n            min_degree            : minimum degree\n            std_degree            : standard deviation of degrees\n            avg_clustering        : average local clustering coefficient\n            transitivity          : global transitivity\n            degree_assortativity  : degree assortativity coefficient\n            num_triangles         : number of triangles\n            degrees               : sorted list of degrees (unused)\n\n    Returns\n    -------\n    float\n        Dimensionless proxy for the algebraic connectivity.\n    \"\"\"\n    # Small constant to guard against division by zero\n    eps = 1e-12\n\n    # 1. Degree regularity (spread relative to max degree)\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    deg_spread = max_deg - min_deg\n    regularity = 1.0 - (deg_spread / (max_deg + 1.0))\n\n    # 2. Triangle richness (fraction of possible triangles)\n    n = float(s['n'])\n    num_tri = float(s['num_triangles'])\n    max_tri_possible = n * (n - 1.0) * (n - 2.0) / 6.0\n    tri_frac = num_tri / (max_tri_possible + eps)\n    triangle_factor = 1.0 + pow(tri_frac, 0.5)\n\n    # 3. Edge density influence\n    density = float(s['density'])\n    density_factor = pow(density + eps, 0.5)\n\n    # 4. Clustering penalty\n    avg_clust = float(s['avg_clustering'])\n    clustering_penalty = 1.0 / (1.0 + pow(avg_clust, 1.1) + eps)\n\n    # 5. Assortativity penalty\n    assort = float(s['degree_assortativity'])\n    assort_penalty = 1.0 / (1.0 + pow(abs(assort), 0.6) + eps)\n\n    # 6. Size scaling (√n)\n    size_factor = pow(n, 0.5)\n\n    # 7. Average degree weighting\n    avg_deg = float(s['avg_degree'])\n    avg_deg_factor = pow(avg_deg + 1.0, 0.3)\n\n    # Final product\n    score = (regularity *\n             triangle_factor *\n             density_factor *\n             clustering_penalty *\n             assort_penalty *\n             size_factor *\n             avg_deg_factor)\n\n    return score",
        "island_id": 3,
        "generation": 19,
        "train_score": 0.6671308523409364,
        "val_score": 0.4871715784412071,
        "simplicity_score": 0.2054086309745049,
        "novelty_bonus": 0.26955073876846924
      }
    ]
  }
}