{"timestamp": "2026-02-12T23:14:27.063869+00:00", "event_type": "phase1_started", "payload": {"experiment_id": "phase1_20260212T231418Z", "resume": null, "model_name": "gpt-oss:20b", "dataset_fingerprint": "af08648a118017775c4ac728a8e467b5c9cf7e503c9a2ce19baa0b26358f420b"}}
{"timestamp": "2026-02-12T23:15:15.206597+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 0, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:15:15.207148+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 0, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:15:49.376731+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 0, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.027651", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:15:49.377214+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 0, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:16:33.692193+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.244754", "model_name": "gpt-oss:20b", "train_signal": 0.24475390156062424}}
{"timestamp": "2026-02-12T23:17:28.489894+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:17:28.490243+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:18:02.852724+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 0, "population_idx": 2, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:18:02.852949+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 0, "population_idx": 2, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:18:43.098987+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 0, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.067458", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:19:52.837747+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g0_i0_p4_89250953", "generation": 0, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5549579831932773, "spearman": 0.5977539180057115, "pearson": 0.513427818322409, "rmse": 24.927647276984686, "mae": 22.038063984937317, "simplicity_score": 0.25253202944896747, "novelty_bonus": 0.21825764543786785, "total_score": 0.4148606585240096, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\nNone yet.\nRecent failures:\nbelow_train_threshold: train_signal=0.244754\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.067458\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density tends to shorten paths\n    val *= (1 + density)\n\n    # Higher clustering can create shortcuts, reducing average path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar-degree nodes, often shortening paths\n    # Negative assortativity can lengthen paths; we dampen the effect by dividing\n    val /= (1 + abs(assort))\n\n    # More triangles generally create local shortcuts\n    val *= (1 + num_tri / (n**2 + 1))\n\n    # Degree spread: a larger max/min difference can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability: higher std can indicate heterogeneity, often increasing path length\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    return val", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density tends to shorten paths\n    val *= (1 + density)\n\n    # Higher clustering can create shortcuts, reducing average path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar-degree nodes, often shortening paths\n    # Negative assortativity can lengthen paths; we dampen the effect by dividing\n    val /= (1 + abs(assort))\n\n    # More triangles generally create local shortcuts\n    val *= (1 + num_tri / (n**2 + 1))\n\n    # Degree spread: a larger max/min difference can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability: higher std can indicate heterogeneity, often increasing path length\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    return val"}}
{"timestamp": "2026-02-12T23:20:14.240308+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:20:14.240531+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:24:13.613495+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 1, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.015273", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:24:13.614211+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 1, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:24:47.316368+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g0_i1_p1_773956048", "generation": 0, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.33867947178871544, "spearman": 0.14573469801797245, "pearson": 0.3576141818863482, "rmse": 2.7358936483837146, "mae": 2.602010808436768, "simplicity_score": 0.1491870396492731, "novelty_bonus": 0.25479122023180456, "total_score": 0.17914212300838223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\nNone yet.\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.015273\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor"}}
{"timestamp": "2026-02-12T23:25:13.873187+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 1, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.038579", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:25:48.741268+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 1, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.132679", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:26:23.900051+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 1, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:26:23.900794+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 1, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:26:59.912912+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 1, "population_idx": 4, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:26:59.913984+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 1, "population_idx": 4, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:27:40.810126+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:27:40.811166+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:28:12.498815+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 2, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.026861", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:28:12.499687+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 2, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:28:58.362167+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.032899", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:29:39.637139+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.094752", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:30:06.899928+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:30:06.900397+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:30:50.883022+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 2, "population_idx": 3, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.019560", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:30:50.883671+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 2, "population_idx": 3, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:31:19.043870+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g0_i2_p4_654571518", "generation": 0, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8169507803121248, "spearman": 0.793688889855636, "pearson": 0.7786707471244625, "rmse": 0.9899269399330058, "mae": 0.7632524852270961, "simplicity_score": 0.14610179179670613, "novelty_bonus": 0.23487023851570143, "total_score": 0.49652587484186966, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\nNone yet.\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.094752\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.019560\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Approximate average shortest path length using known graph characteristics.\n    # The formula is a combination of:\n    #   * log(n)/log(avg_degree+1)  – typical distance in an Erdős–Rényi graph.\n    #   * a clustering multiplier (higher clustering → longer paths).\n    #   * a degree‑variance factor (high variance → shorter paths).\n    #\n    # All operations are safe against division by zero.\n\n    n = s['n']\n    avg_deg = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg = s['std_degree'] if s['std_degree'] > 0 else 1.0\n\n    # Base distance estimate from random graph theory.\n    base = np.log(n) / np.log(avg_deg + 1)\n\n    # Clustering adjustment: more triangles tend to increase path length.\n    clustering_adj = 1.0 + trans\n\n    # Degree variance adjustment: larger variance usually shortens paths.\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1))\n\n    return base * clustering_adj * variance_adj\n```", "extracted_code": "def new_invariant(s):\n    # Approximate average shortest path length using known graph characteristics.\n    # The formula is a combination of:\n    #   * log(n)/log(avg_degree+1)  – typical distance in an Erdős–Rényi graph.\n    #   * a clustering multiplier (higher clustering → longer paths).\n    #   * a degree‑variance factor (high variance → shorter paths).\n    #\n    # All operations are safe against division by zero.\n\n    n = s['n']\n    avg_deg = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg = s['std_degree'] if s['std_degree'] > 0 else 1.0\n\n    # Base distance estimate from random graph theory.\n    base = np.log(n) / np.log(avg_deg + 1)\n\n    # Clustering adjustment: more triangles tend to increase path length.\n    clustering_adj = 1.0 + trans\n\n    # Degree variance adjustment: larger variance usually shortens paths.\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1))\n\n    return base * clustering_adj * variance_adj"}}
{"timestamp": "2026-02-12T23:31:57.739391+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:31:57.739805+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:32:50.112267+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 0, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: code must define exactly one function named `new_invariant`", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:32:50.113008+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 3, "population_idx": 0, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:33:34.070473+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:33:34.071024+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:34:09.674256+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.095702", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:34:09.675389+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:34:45.076187+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.015256", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:35:32.209538+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.051351", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:36:26.146292+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:36:26.146943+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:37:01.201858+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 4, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.037327", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:37:01.202628+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 3, "population_idx": 4, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:37:01.204074+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "phase1_20260212T231418Z", "generation": 1, "model_name": "gpt-oss:20b", "best_val_score": 0.49652587484186966, "no_improve_count": 0}}
{"timestamp": "2026-02-12T23:38:07.533223+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i0_p0_438878439", "generation": 1, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7292677070828331, "spearman": 0.6228615551120048, "pearson": 0.707351338895142, "rmse": 22.75629571520001, "mae": 21.047006628532575, "simplicity_score": 0.25075862621685346, "novelty_bonus": 0.39008212158067557, "total_score": 0.4786071392735758, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density tends to shorten paths\n    val *= (1 + density)\n\n    # Higher clustering can create shortcuts, reducing average path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar-degree nodes, often shortening paths\n    # Negative assortativity can lengthen paths; we dampen the effect by dividing\n    val /= (1 + abs(assort))\n\n    # More triangles generally create local shortcuts\n    val *= (1 + num_tri / (n**2 + 1))\n\n    # Degree spread: a larger max/min difference can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability: higher std can indicate heterogeneity, often increasing path length\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.244754\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.067458\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val"}}
{"timestamp": "2026-02-12T23:41:09.781999+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i0_p1_433015235", "generation": 1, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.48686674669867946, "spearman": 0.5533010400139292, "pearson": 0.5793509130430958, "rmse": 498.2090199126747, "mae": 450.07427690413436, "simplicity_score": 0.2479823313533925, "novelty_bonus": 0.30588876341855886, "total_score": 0.41801361530321074, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density tends to shorten paths\n    val *= (1 + density)\n\n    # Higher clustering can create shortcuts, reducing average path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar-degree nodes, often shortening paths\n    # Negative assortativity can lengthen paths; we dampen the effect by dividing\n    val /= (1 + abs(assort))\n\n    # More triangles generally create local shortcuts\n    val *= (1 + num_tri / (n**2 + 1))\n\n    # Degree spread: a larger max/min difference can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability: higher std can indicate heterogeneity, often increasing path length\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.244754\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.067458\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n\n    # Assortativity: positive assortativity tends to shorten paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree (captures central tendency of degree distribution)\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Scale with graph size (sqrt factor)\n    val *= (1 + n ** 0.5)\n\n    return val", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n\n    # Assortativity: positive assortativity tends to shorten paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree (captures central tendency of degree distribution)\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Scale with graph size (sqrt factor)\n    val *= (1 + n ** 0.5)\n\n    return val"}}
{"timestamp": "2026-02-12T23:42:49.163224+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.077551", "model_name": "gpt-oss:20b", "train_signal": 0.07755102040816325}}
{"timestamp": "2026-02-12T23:44:38.652878+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i0_p3_858597919", "generation": 1, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5636974789915966, "spearman": 0.4374838511527538, "pearson": 0.30465936087041534, "rmse": 512.1380657916242, "mae": 316.0735249107826, "simplicity_score": 0.24838334325440808, "novelty_bonus": 0.525734581314981, "total_score": 0.4261389686217528, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density tends to shorten paths\n    val *= (1 + density)\n\n    # Higher clustering can create shortcuts, reducing average path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar-degree nodes, often shortening paths\n    # Negative assortativity can lengthen paths; we dampen the effect by dividing\n    val /= (1 + abs(assort))\n\n    # More triangles generally create local shortcuts\n    val *= (1 + num_tri / (n**2 + 1))\n\n    # Degree spread: a larger max/min difference can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability: higher std can indicate heterogeneity, often increasing path length\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    return val\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.067458\nbelow_train_threshold: train_signal=0.077551\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n    sum_sq = sum(d*d for d in degrees)\n    val = n / (avg_deg + 1)\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n    val /= (1 + abs(assort))\n    val *= (1 + num_tri / (n**2 + 1))\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n    return val", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n    sum_sq = sum(d*d for d in degrees)\n    val = n / (avg_deg + 1)\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n    val /= (1 + abs(assort))\n    val *= (1 + num_tri / (n**2 + 1))\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n    return val"}}
{"timestamp": "2026-02-12T23:45:47.498329+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 0, "population_idx": 4, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.252533", "model_name": "gpt-oss:20b", "train_signal": 0.25253301320528215}}
{"timestamp": "2026-02-12T23:46:30.976524+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.073325", "model_name": "gpt-oss:20b", "train_signal": 0.07332533013205282}}
{"timestamp": "2026-02-12T23:47:37.426077+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 1, "population_idx": 1, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.004178", "model_name": "gpt-oss:20b", "train_signal": 0.0041776710684273705}}
{"timestamp": "2026-02-12T23:47:57.536910+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 1, "population_idx": 2, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.016375", "model_name": "gpt-oss:20b", "train_signal": 0.01637454981992797}}
{"timestamp": "2026-02-12T23:48:39.462637+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 1, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:48:39.464264+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 1, "island_id": 1, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:50:11.268743+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i1_p3_201469535", "generation": 1, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3190876350540216, "spearman": 0.1055951794776867, "pearson": 0.2943901287693004, "rmse": 2.7462414764766097, "mae": 2.61183810540602, "simplicity_score": 0.12555141822077184, "novelty_bonus": 0.2682228380891878, "total_score": 0.15837472480975406, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\nRecent failures:\nbelow_train_threshold: train_signal=0.073325\nbelow_train_threshold: train_signal=0.004178\nbelow_train_threshold: train_signal=0.016375\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends several structural properties.\n    The function uses only pre‑computed features from the input dictionary `s`\n    and does not perform any graph traversal or shortest‑path computation.\n    \"\"\"\n    import numpy as np\n\n    # Basic counts\n    n, m = s['n'], s['m']\n\n    # Degree statistics\n    avg_deg   = s['avg_degree']\n    max_deg   = s['max_degree']\n    min_deg   = s['min_degree']\n    std_deg   = s.get('std_degree', 0.0)\n\n    # Density‑related features\n    density   = s['density']\n    clustering = s['avg_clustering']\n    trans     = s['transitivity']\n\n    # Additional structural signals\n    assort    = s.get('degree_assortativity', 0.0)\n    num_tri   = s.get('num_triangles', 0)\n\n    # ---- Component factors ----\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (log‑scaled to avoid dominance)\n    tri_factor = 1 + np.log1p(num_tri)\n\n    # ---- Final invariant ----\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n    )\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No graph traversal or external imports are used.\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No graph traversal or external imports are used.\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n    )"}}
{"timestamp": "2026-02-12T23:50:11.271734+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 1, "island_id": 1, "population_idx": 3, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:50:44.037878+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i1_p4_94177347", "generation": 1, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.38103241296518603, "spearman": 0.14129158527398625, "pearson": 0.4582539846966963, "rmse": 2.196486691529806, "mae": 2.055139149871568, "simplicity_score": 0.1412351497719307, "novelty_bonus": 0.20110825080337325, "total_score": 0.15922529783239125, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\nRecent failures:\nbelow_train_threshold: train_signal=0.004178\nbelow_train_threshold: train_signal=0.016375\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor"}}
{"timestamp": "2026-02-12T23:51:29.412507+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.127583", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:52:07.276672+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.105778", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:52:41.250176+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:52:41.250568+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 1, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:53:34.494954+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i2_p2_526478978", "generation": 1, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7471308523409363, "spearman": 0.8383105221295581, "pearson": 0.7042676482968664, "rmse": 5.9479458391294715, "mae": 4.318243304230551, "simplicity_score": 0.13256371548928164, "novelty_bonus": 0.16274623703388214, "total_score": 0.49449187527280003, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Approximate average shortest path length using known graph characteristics.\n    # The formula is a combination of:\n    #   * log(n)/log(avg_degree+1)  – typical distance in an Erdős–Rényi graph.\n    #   * a clustering multiplier (higher clustering → longer paths).\n    #   * a degree‑variance factor (high variance → shorter paths).\n    #\n    # All operations are safe against division by zero.\n\n    n = s['n']\n    avg_deg = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg = s['std_degree'] if s['std_degree'] > 0 else 1.0\n\n    # Base distance estimate from random graph theory.\n    base = np.log(n) / np.log(avg_deg + 1)\n\n    # Clustering adjustment: more triangles tend to increase path length.\n    clustering_adj = 1.0 + trans\n\n    # Degree variance adjustment: larger variance usually shortens paths.\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1))\n\n    return base * clustering_adj * variance_adj\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.019560\nbelow_novelty_threshold: novelty_bonus=0.127583\nbelow_novelty_threshold: novelty_bonus=0.105778\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    import numpy as np\n\n    # Basic parameters with safe defaults\n    n          = s['n']\n    avg_deg    = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans      = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg    = s['std_degree'] if s['std_degree'] > 0 else 1.0\n    max_deg    = s['max_degree'] if s['max_degree'] > 0 else 1.0\n    density    = s['density'] if s['density'] is not None else 0.0\n\n    # Base estimate from random‑graph theory\n    base = np.log(n) / np.log(avg_deg + 1)\n\n    # Adjustments\n    clustering_adj = 1.0 + trans                    # higher clustering → longer paths\n    variance_adj   = 1.0 / (1.0 + std_deg / (avg_deg + 1))  # higher variance → shorter paths\n    hub_adj        = 1.0 / (1.0 + max_deg / (avg_deg + 1))   # hubs shorten paths\n    density_adj    = 1.0 / (density + 1e-6)          # denser graphs → shorter paths\n\n    return base * clustering_adj * variance_adj * hub_adj * density_adj\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    # Basic parameters with safe defaults\n    n = s['n']\n    avg_deg = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg = s['std_degree'] if s['std_degree'] > 0 else 1.0\n    max_deg = s['max_degree'] if s['max_degree'] > 0 else 1.0\n    density = s['density'] if s['density'] is not None else 0.0\n\n    # Base estimate from random‑graph theory\n    base = math.log(n) / math.log(avg_deg + 1)\n\n    # Adjustments\n    clustering_adj = 1.0 + trans                     # higher clustering → longer paths\n    variance_adj   = 1.0 / (1.0 + std_deg / (avg_deg + 1))   # higher variance → shorter paths\n    hub_adj        = 1.0 / (1.0 + max_deg / (avg_deg + 1))   # hubs shorten paths\n    density_adj    = 1.0 / (density + 1e-6)           # denser graphs → shorter paths\n\n    return base * clustering_adj * variance_adj * hub_adj * density_adj\n```", "extracted_code": "def new_invariant(s):\n    # Basic parameters with safe defaults\n    n = s['n']\n    avg_deg = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg = s['std_degree'] if s['std_degree'] > 0 else 1.0\n    max_deg = s['max_degree'] if s['max_degree'] > 0 else 1.0\n    density = s['density'] if s['density'] is not None else 0.0\n\n    # Base estimate from random‑graph theory\n    base = math.log(n) / math.log(avg_deg + 1)\n\n    # Adjustments\n    clustering_adj = 1.0 + trans                     # higher clustering → longer paths\n    variance_adj   = 1.0 / (1.0 + std_deg / (avg_deg + 1))   # higher variance → shorter paths\n    hub_adj        = 1.0 / (1.0 + max_deg / (avg_deg + 1))   # hubs shorten paths\n    density_adj    = 1.0 / (density + 1e-6)           # denser graphs → shorter paths\n\n    return base * clustering_adj * variance_adj * hub_adj * density_adj"}}
{"timestamp": "2026-02-12T23:53:34.496226+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 1, "island_id": 2, "population_idx": 2, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:54:26.756478+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i2_p3_975622351", "generation": 1, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.47466986794717886, "spearman": 0.33111465203431867, "pearson": 0.4118802621598039, "rmse": 2.098560163143096, "mae": 1.9428142173485048, "simplicity_score": 0.13254240791033606, "novelty_bonus": 0.24898522463061556, "total_score": 0.2667613749884112, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Approximate average shortest path length using known graph characteristics.\n    # The formula is a combination of:\n    #   * log(n)/log(avg_degree+1)  – typical distance in an Erdős–Rényi graph.\n    #   * a clustering multiplier (higher clustering → longer paths).\n    #   * a degree‑variance factor (high variance → shorter paths).\n    #\n    # All operations are safe against division by zero.\n\n    n = s['n']\n    avg_deg = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg = s['std_degree'] if s['std_degree'] > 0 else 1.0\n\n    # Base distance estimate from random graph theory.\n    base = np.log(n) / np.log(avg_deg + 1)\n\n    # Clustering adjustment: more triangles tend to increase path length.\n    clustering_adj = 1.0 + trans\n\n    # Degree variance adjustment: larger variance usually shortens paths.\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1))\n\n    return base * clustering_adj * variance_adj\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.127583\nbelow_novelty_threshold: novelty_bonus=0.105778\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n\n    avg_deg = s.get('avg_degree', 0.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    std_deg = s.get('std_degree', 0.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    max_deg = s.get('max_degree', 0.0)\n    if max_deg <= 0:\n        max_deg = 1.0\n\n    trans = s.get('transitivity', 0.0)\n    if trans is None:\n        trans = 0.0\n\n    assort = s.get('degree_assortativity', 0.0)\n    if assort is None:\n        assort = 0.0\n\n    base = np.log(n) / np.log(avg_deg + 1)\n    clustering_adj = 1.0 + trans\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1))\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1))\n    assort_adj = 1.0 + assort\n\n    return base * clustering_adj * variance_adj * max_adj * assort_adj\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n\n    avg_deg = s.get('avg_degree', 0.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    std_deg = s.get('std_degree', 0.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    max_deg = s.get('max_degree', 0.0)\n    if max_deg <= 0:\n        max_deg = 1.0\n\n    trans = s.get('transitivity', 0.0)\n    if trans is None:\n        trans = 0.0\n\n    assort = s.get('degree_assortativity', 0.0)\n    if assort is None:\n        assort = 0.0\n\n    base = np.log(n) / np.log(avg_deg + 1)\n    clustering_adj = 1.0 + trans\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1))\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1))\n    assort_adj = 1.0 + assort\n\n    return base * clustering_adj * variance_adj * max_adj * assort_adj"}}
{"timestamp": "2026-02-12T23:55:04.652084+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i2_p4_735752370", "generation": 1, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9221128451380551, "spearman": 0.9370055265153013, "pearson": 0.8845269069028603, "rmse": 3.7143363826152735, "mae": 3.285241462565563, "simplicity_score": 0.13119988577898903, "novelty_bonus": 0.1811952881995048, "total_score": 0.5491013268732999, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Approximate average shortest path length using known graph characteristics.\n    # The formula is a combination of:\n    #   * log(n)/log(avg_degree+1)  – typical distance in an Erdős–Rényi graph.\n    #   * a clustering multiplier (higher clustering → longer paths).\n    #   * a degree‑variance factor (high variance → shorter paths).\n    #\n    # All operations are safe against division by zero.\n\n    n = s['n']\n    avg_deg = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg = s['std_degree'] if s['std_degree'] > 0 else 1.0\n\n    # Base distance estimate from random graph theory.\n    base = np.log(n) / np.log(avg_deg + 1)\n\n    # Clustering adjustment: more triangles tend to increase path length.\n    clustering_adj = 1.0 + trans\n\n    # Degree variance adjustment: larger variance usually shortens paths.\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1))\n\n    return base * clustering_adj * variance_adj\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.127583\nbelow_novelty_threshold: novelty_bonus=0.105778\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj"}}
{"timestamp": "2026-02-12T23:55:55.690044+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.206339", "model_name": "gpt-oss:20b", "train_signal": 0.2063385354141657}}
{"timestamp": "2026-02-12T23:56:21.960599+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i3_p1_761139701", "generation": 1, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.7733580018501388, "spearman": -0.5176074485235316, "pearson": -0.3323906555214724, "rmse": 53.42312398289512, "mae": 41.5169773934602, "simplicity_score": 0.14604545948798497, "novelty_bonus": 0.40562853270443633, "total_score": 0.40970137597069367, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how average path length relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\nNone yet.\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.037327\nbelow_train_threshold: train_signal=0.206339\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    A novel invariant intended to correlate with the average shortest path length\n    using only the pre‑computed structural features provided in *s*.\n\n    The formula blends several independent aspects of the network:\n      • Normalized size versus edge count (comp1)\n      • Degree spread relative to variability (comp2)\n      • Triangle density relative to size (comp3)\n      • Average clustering and global transitivity (comp4)\n      • Degree assortativity magnitude (comp5)\n\n    By multiplying the first three components and dividing by the latter two,\n    we encourage the invariant to increase when the graph is small, sparse, \n    has diverse degrees, many triangles, high clustering, and low assortativity,\n    all of which tend to reduce the typical path length.\n    \"\"\"\n\n    # Core components\n    comp1 = (s['n'] + 1.0) / (s['m'] + 1.0)                     # size–to–edges ratio\n    comp2 = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)  # degree spread vs std\n    comp3 = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)         # triangle density\n\n    # Regularization terms\n    comp4 = (s['avg_clustering']**2 + s['transitivity']**2) / 2.0   # clustering/ transitivity combo\n    comp5 = (s['degree_assortativity']**2 + 1.0)                    # assortativity magnitude\n\n    # Combine into a single scalar\n    return (comp1 * comp2 * comp3) / (comp4 * comp5)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    A novel invariant intended to correlate with the average shortest path length\n    using only the pre‑computed structural features provided in *s*.\n\n    The formula blends several independent aspects of the network:\n      • Normalized size versus edge count (comp1)\n      • Degree spread relative to variability (comp2)\n      • Triangle density relative to size (comp3)\n      • Average clustering and global transitivity (comp4)\n      • Degree assortativity magnitude (comp5)\n\n    By multiplying the first three components and dividing by the latter two,\n    we encourage the invariant to increase when the graph is small, sparse, \n    has diverse degrees, many triangles, high clustering, and low assortativity,\n    all of which tend to reduce the typical path length.\n    \"\"\"\n\n    # Core components\n    comp1 = (s['n'] + 1.0) / (s['m'] + 1.0)                     # size–to–edges ratio\n    comp2 = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)  # degree spread vs std\n    comp3 = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)         # triangle density\n\n    # Regularization terms\n    comp4 = (s['avg_clustering']**2 + s['transitivity']**2) / 2.0   # clustering/ transitivity combo\n    comp5 = (s['degree_assortativity']**2 + 1.0)                    # assortativity magnitude\n\n    # Combine into a single scalar\n    return (comp1 * comp2 * comp3) / (comp4 * comp5)"}}
{"timestamp": "2026-02-12T23:57:44.614134+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.129385", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:58:14.093076+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:58:14.093615+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 1, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:59:01.333177+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 3, "population_idx": 3, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.046653", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:59:01.334453+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 1, "island_id": 3, "population_idx": 3, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-12T23:59:36.937068+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i3_p4_717477276", "generation": 1, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.43673469387755093, "spearman": 0.24264390708915948, "pearson": -0.03000261864102479, "rmse": 22.617097955112886, "mae": 13.926066994005577, "simplicity_score": 0.13056962326112304, "novelty_bonus": 0.6231643716405374, "total_score": 0.3343851896889656, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how average path length relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\nNone yet.\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.129385\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.046653\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    A novel composite estimate for the average shortest path length\n    derived solely from pre‑computed graph statistics.\n    The formula combines several structural aspects of the graph in a\n    non‑trivial way, avoiding a direct use of any existing single feature.\n    \"\"\"\n    # Safe retrieval with defaults\n    n = s.get('n', 1)\n    avg_deg = s.get('avg_degree', 1)\n    density = s.get('density', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    triangles = s.get('num_triangles', 0)\n\n    # Individual components\n    size_factor      = n / (avg_deg + 1)          # influences by size and connectivity\n    sparsity_factor  = 1 - density / 2.0          # denser graphs tend to have shorter paths\n    clustering_factor= 1 + clustering            # high clustering can increase path lengths slightly\n    assort_factor    = 1 + assort / 2.0           # assortativity effect\n    triangle_bonus   = triangles / (n + 1)        # triangles contribute to shortcut opportunities\n\n    # Combine all contributions\n    return (\n        size_factor\n        * sparsity_factor\n        * clustering_factor\n        * assort_factor\n        + triangle_bonus\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    A novel composite estimate for the average shortest path length\n    derived solely from pre‑computed graph statistics.\n    The formula combines several structural aspects of the graph in a\n    non‑trivial way, avoiding a direct use of any existing single feature.\n    \"\"\"\n    # Safe retrieval with defaults\n    n = s.get('n', 1)\n    avg_deg = s.get('avg_degree', 1)\n    density = s.get('density', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    triangles = s.get('num_triangles', 0)\n\n    # Individual components\n    size_factor      = n / (avg_deg + 1)          # influences by size and connectivity\n    sparsity_factor  = 1 - density / 2.0          # denser graphs tend to have shorter paths\n    clustering_factor= 1 + clustering            # high clustering can increase path lengths slightly\n    assort_factor    = 1 + assort / 2.0           # assortativity effect\n    triangle_bonus   = triangles / (n + 1)        # triangles contribute to shortcut opportunities\n\n    # Combine all contributions\n    return (\n        size_factor\n        * sparsity_factor\n        * clustering_factor\n        * assort_factor\n        + triangle_bonus\n    )"}}
{"timestamp": "2026-02-12T23:59:36.938653+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "phase1_20260212T231418Z", "generation": 2, "model_name": "gpt-oss:20b", "best_val_score": 0.5491013268732999, "no_improve_count": 0}}
{"timestamp": "2026-02-13T00:00:14.481856+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 0, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:00:14.482324+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 2, "island_id": 0, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:02:32.671610+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i0_p0_786064305", "generation": 2, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6777911164465786, "spearman": 0.6987184799814787, "pearson": 0.7015628533420502, "rmse": 50.59496379836509, "mae": 47.23002477169673, "simplicity_score": 0.24860980274794608, "novelty_bonus": 0.23183155095845653, "total_score": 0.46863066582786556, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n    sum_sq = sum(d*d for d in degrees)\n    val = n / (avg_deg + 1)\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n    val /= (1 + abs(assort))\n    val *= (1 + num_tri / (n**2 + 1))\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n\n    # Assortativity: positive assortativity tends to shorten paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree (captures central tendency of degree distribution)\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Scale with graph size (sqrt factor)\n    val *= (1 + n ** 0.5)\n\n    return val\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.067458\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport math\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # ---- base estimate from random‑graph theory ----\n    # log(n) grows with size, log(avg_deg) grows with connectivity\n    base = math.log(n + 1) / (math.log(avg_deg + 1) + 1e-9)\n\n    # ---- factors that shorten paths ----\n    # higher density and higher transitivity give more shortcuts\n    base *= (1 + density) * (1 + trans)\n\n    # ---- factors that lengthen paths ----\n    # clustering tends to create local loops that can slightly increase path length\n    base *= (1 + clustering)\n\n    # positive assortativity tends to cluster similar‑degree nodes, which can reduce path length\n    # we counteract this by dividing by (1 + |assort|)\n    base /= (1 + abs(assort))\n\n    # triangles provide local shortcuts; use sqrt to dampen large counts\n    base *= (1 + math.sqrt(num_tri) / (n**2 + 1))\n\n    # degree spread and variability can increase path length\n    base *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    base *= (1 + std_deg / (avg_deg + 1))\n\n    # median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid-1] + degrees[mid]) / 2)\n    base *= (1 + median_deg / (avg_deg + 1))\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T00:02:32.672734+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 2, "island_id": 0, "population_idx": 0, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:02:59.035895+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:02:59.036318+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 2, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:03:54.312370+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i0_p1_513226573", "generation": 2, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.48235294117647054, "spearman": 0.5332230305344373, "pearson": 0.5732218723251861, "rmse": 507.33753049414486, "mae": 459.84898297959603, "simplicity_score": 0.2479823313533925, "novelty_bonus": 0.3388162471275259, "total_score": 0.41785285567615493, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n    sum_sq = sum(d*d for d in degrees)\n    val = n / (avg_deg + 1)\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n    val /= (1 + abs(assort))\n    val *= (1 + num_tri / (n**2 + 1))\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n\n    # Assortativity: positive assortativity tends to shorten paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree (captures central tendency of degree distribution)\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Scale with graph size (sqrt factor)\n    val *= (1 + n ** 0.5)\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport math\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a weighted product of structural properties that influence\n    path length: size, connectivity, clustering, transitivity, assortativity,\n    triangles, degree spread, variability and central tendency.\n    \"\"\"\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger graphs with lower average degree tend to have longer paths\n    val = n / (avg_deg + 1)\n\n    # Connectivity factors – higher density, clustering and transitivity shorten paths\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n\n    # Assortativity – positive assortativity tends to shorten paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen the effect\n    val *= (1 + math.sqrt(num_tri) / (n ** 1.5 + 1))\n\n    # Degree spread – a larger spread can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability – higher variance can increase path length\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree – captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Scale with graph size – log‑scale to avoid over‑amplification\n    val *= (1 + math.log1p(n))\n\n    return val\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n\n    # Base estimate: larger graphs with lower average degree tend to have longer paths\n    val = n / (avg_deg + 1)\n\n    # Connectivity factors – higher density, clustering and transitivity shorten paths\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n\n    # Assortativity – positive assortativity tends to shorten paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen the effect\n    val *= (1 + (num_tri ** 0.5) / (n ** 1.5 + 1))\n\n    # Degree spread – a larger spread can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability – higher variance can increase path length\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree – captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Scale with graph size – log‑scale to avoid over‑amplification\n    val *= (1 + n ** 0.5)\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n\n    # Base estimate: larger graphs with lower average degree tend to have longer paths\n    val = n / (avg_deg + 1)\n\n    # Connectivity factors – higher density, clustering and transitivity shorten paths\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n\n    # Assortativity – positive assortativity tends to shorten paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen the effect\n    val *= (1 + (num_tri ** 0.5) / (n ** 1.5 + 1))\n\n    # Degree spread – a larger spread can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability – higher variance can increase path length\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree – captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Scale with graph size – log‑scale to avoid over‑amplification\n    val *= (1 + n ** 0.5)\n\n    return val"}}
{"timestamp": "2026-02-13T00:03:54.313659+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 2, "island_id": 0, "population_idx": 1, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:04:28.392788+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i0_p2_128113632", "generation": 2, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5078031212484994, "spearman": 0.593227553149203, "pearson": 0.49817776283084225, "rmse": 159.26924120715387, "mae": 134.2940457936065, "simplicity_score": 0.24605883638966372, "novelty_bonus": 0.2011886355009932, "total_score": 0.4061821345028322, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n    sum_sq = sum(d*d for d in degrees)\n    val = n / (avg_deg + 1)\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n    val /= (1 + abs(assort))\n    val *= (1 + num_tri / (n**2 + 1))\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n\n    # Assortativity: positive assortativity tends to shorten paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree (captures central tendency of degree distribution)\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Scale with graph size (sqrt factor)\n    val *= (1 + n ** 0.5)\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic size/degree term\n    n = s['n']\n    avg_deg = s['avg_degree']\n    val = n / (avg_deg + 1)\n\n    # Shortening effects\n    val *= (1 + 0.8 * s['density'])\n    val *= (1 + 0.9 * s['avg_clustering'])\n    val *= (1 + 0.7 * s['transitivity'])\n\n    # Assortativity penalty\n    val /= (1 + abs(s['degree_assortativity']))\n\n    # Triangle shortcut effect (use sqrt for diminishing returns)\n    val *= (1 + 0.4 * (s['num_triangles'] ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread effect\n    val *= (1 + 0.3 * (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1))\n\n    # Degree variability effect\n    val *= (1 + 0.3 * s['std_degree'] / (avg_deg + 1))\n\n    # Median degree effect (captures central tendency)\n    degs = s['degrees']          # already sorted\n    mid = len(degs) // 2\n    if len(degs) % 2 == 0:\n        median_deg = (degs[mid - 1] + degs[mid]) / 2\n    else:\n        median_deg = degs[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Size scaling (sqrt factor)\n    val *= (1 + 0.5 * (n ** 0.5))\n\n    # Sum of squares of degrees (captures heavy‑tailedness)\n    sum_sq = sum(d * d for d in degs)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    # Max/min degree ratio effects\n    val *= (1 + 0.1 * s['max_degree'] / (avg_deg + 1))\n    val *= (1 + 0.1 * avg_deg / (s['max_degree'] + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # Basic size/degree term\n    n = s['n']\n    avg_deg = s['avg_degree']\n    val = n / (avg_deg + 1)\n\n    # Shortening effects\n    val *= (1 + 0.8 * s['density'])\n    val *= (1 + 0.9 * s['avg_clustering'])\n    val *= (1 + 0.7 * s['transitivity'])\n\n    # Assortativity penalty\n    val /= (1 + abs(s['degree_assortativity']))\n\n    # Triangle shortcut effect (use sqrt for diminishing returns)\n    val *= (1 + 0.4 * (s['num_triangles'] ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread effect\n    val *= (1 + 0.3 * (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1))\n\n    # Degree variability effect\n    val *= (1 + 0.3 * s['std_degree'] / (avg_deg + 1))\n\n    # Median degree effect (captures central tendency)\n    degs = s['degrees']          # already sorted\n    mid = len(degs) // 2\n    if len(degs) % 2 == 0:\n        median_deg = (degs[mid - 1] + degs[mid]) / 2\n    else:\n        median_deg = degs[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Size scaling (sqrt factor)\n    val *= (1 + 0.5 * (n ** 0.5))\n\n    # Sum of squares of degrees (captures heavy‑tailedness)\n    sum_sq = sum(d * d for d in degs)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    # Max/min degree ratio effects\n    val *= (1 + 0.1 * s['max_degree'] / (avg_deg + 1))\n    val *= (1 + 0.1 * avg_deg / (s['max_degree'] + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T00:04:48.545875+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i0_p3_839748229", "generation": 2, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.41992797118847536, "spearman": 0.4165403197106419, "pearson": 0.47117175327683636, "rmse": 537.3998192766094, "mae": 486.6839868536866, "simplicity_score": 0.2493025190090454, "novelty_bonus": 0.515824535252237, "total_score": 0.4128780242328012, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n    sum_sq = sum(d*d for d in degrees)\n    val = n / (avg_deg + 1)\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n    val /= (1 + abs(assort))\n    val *= (1 + num_tri / (n**2 + 1))\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n\n    # Assortativity: positive assortativity tends to shorten paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree (captures central tendency of degree distribution)\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Scale with graph size (sqrt factor)\n    val *= (1 + n ** 0.5)\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic scaling: larger graphs and lower average degree tend to increase path length\n    n = s['n']\n    avg_deg = s['avg_degree']\n    val = n / (avg_deg + 1)\n\n    # Shortening effects: density, clustering, and transitivity\n    val *= (1 + s['density'])\n    val *= (1 + s['avg_clustering'])\n    val *= (1 + s['transitivity'])\n\n    # Assortativity: positive assortativity usually shortens paths\n    val /= (1 + abs(s['degree_assortativity']))\n\n    # Local shortcut effects: triangles, degree spread, and variability\n    val *= (1 + s['num_triangles'] / (n**2 + 1))\n    val *= (1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1))\n    val *= (1 + s['std_degree'] / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    degs = s['degrees']\n    mid = len(degs) // 2\n    if len(degs) % 2 == 0:\n        median_deg = (degs[mid - 1] + degs[mid]) / 2\n    else:\n        median_deg = degs[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Size scaling: a mild sqrt factor to reflect the typical growth of path length with graph size\n    val *= (1 + n**0.5)\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # Basic scaling: larger graphs and lower average degree tend to increase path length\n    n = s['n']\n    avg_deg = s['avg_degree']\n    val = n / (avg_deg + 1)\n\n    # Shortening effects: density, clustering, and transitivity\n    val *= (1 + s['density'])\n    val *= (1 + s['avg_clustering'])\n    val *= (1 + s['transitivity'])\n\n    # Assortativity: positive assortativity usually shortens paths\n    val /= (1 + abs(s['degree_assortativity']))\n\n    # Local shortcut effects: triangles, degree spread, and variability\n    val *= (1 + s['num_triangles'] / (n**2 + 1))\n    val *= (1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1))\n    val *= (1 + s['std_degree'] / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    degs = s['degrees']\n    mid = len(degs) // 2\n    if len(degs) % 2 == 0:\n        median_deg = (degs[mid - 1] + degs[mid]) / 2\n    else:\n        median_deg = degs[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Size scaling: a mild sqrt factor to reflect the typical growth of path length with graph size\n    val *= (1 + n**0.5)\n\n    return val"}}
{"timestamp": "2026-02-13T00:05:31.861836+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i0_p4_450385937", "generation": 2, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.4558463385354141, "spearman": 0.4640690257515611, "pearson": 0.31653185828806296, "rmse": 7284.622991024754, "mae": 4648.201297409187, "simplicity_score": 0.24610315650479084, "novelty_bonus": 0.3606734001102311, "total_score": 0.3894571642098081, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n    sum_sq = sum(d*d for d in degrees)\n    val = n / (avg_deg + 1)\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n    val /= (1 + abs(assort))\n    val *= (1 + num_tri / (n**2 + 1))\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n\n    # Assortativity: positive assortativity tends to shorten paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree (captures central tendency of degree distribution)\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Scale with graph size (sqrt factor)\n    val *= (1 + n ** 0.5)\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic graph attributes\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # already sorted\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Shortening effects\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n\n    # Assortativity tends to shorten paths when positive\n    val /= (1 + abs(assort))\n\n    # Local shortcuts from triangles (use sqrt to dampen large values)\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree (captures central tendency)\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Scale with graph size (sqrt factor)\n    val *= (1 + n ** 0.5)\n\n    # Additional degree‑based scaling\n    val *= (1 + avg_deg / (max_deg + 1))\n    val *= (1 + max_deg / (avg_deg + 1))\n\n    # Sum of squared degrees (captures heavy‑tailedness)\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # Basic graph attributes\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # already sorted\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Shortening effects\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n\n    # Assortativity tends to shorten paths when positive\n    val /= (1 + abs(assort))\n\n    # Local shortcuts from triangles (use sqrt to dampen large values)\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree (captures central tendency)\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Scale with graph size (sqrt factor)\n    val *= (1 + n ** 0.5)\n\n    # Additional degree‑based scaling\n    val *= (1 + avg_deg / (max_deg + 1))\n    val *= (1 + max_deg / (avg_deg + 1))\n\n    # Sum of squared degrees (captures heavy‑tailedness)\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T00:05:58.851770+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i1_p0_500351915", "generation": 2, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3358943577430972, "spearman": 0.09891250990494581, "pearson": 0.3626909632405285, "rmse": 2.2894517604310285, "mae": 2.1332925004825825, "simplicity_score": 0.12320353991139658, "novelty_bonus": 0.22886852778223554, "total_score": 0.14275752126942287, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No graph traversal or external imports are used.\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.004178\nbelow_train_threshold: train_signal=0.016375\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No external imports or graph traversal are used.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n        * sqrt_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No external imports or graph traversal are used.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n        * sqrt_factor\n    )"}}
{"timestamp": "2026-02-13T00:06:28.438160+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i1_p1_370798024", "generation": 2, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3358943577430972, "spearman": 0.09891250990494581, "pearson": 0.3626909632405285, "rmse": 2.2894517604310285, "mae": 2.1332925004825825, "simplicity_score": 0.12309019173379283, "novelty_bonus": 0.22886852778223554, "total_score": 0.14273485163390215, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No graph traversal or external imports are used.\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.004178\nbelow_train_threshold: train_signal=0.016375\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant combining several pre‑computed graph features.\n    Uses only built‑in operations (no imports, no graph traversal).\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n        * sqrt_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite invariant combining several pre‑computed graph features.\n    Uses only built‑in operations (no imports, no graph traversal).\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n        * sqrt_factor\n    )"}}
{"timestamp": "2026-02-13T00:06:56.826879+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i1_p2_182549636", "generation": 2, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3358943577430972, "spearman": 0.09891250990494581, "pearson": 0.3626909632405285, "rmse": 2.2894517604310285, "mae": 2.1332925004825825, "simplicity_score": 0.12301565439277759, "novelty_bonus": 0.22886852778223554, "total_score": 0.14271994416569908, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No graph traversal or external imports are used.\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.004178\nbelow_train_threshold: train_signal=0.016375\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No graph traversal or external imports are used.\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s.get('min_degree', 0.0)\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n        * sqrt_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No graph traversal or external imports are used.\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s.get('min_degree', 0.0)\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n        * sqrt_factor\n    )"}}
{"timestamp": "2026-02-13T00:07:47.332240+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i1_p3_926764988", "generation": 2, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3358943577430972, "spearman": 0.09891250990494581, "pearson": 0.3626909632405285, "rmse": 2.2894517604310285, "mae": 2.1332925004825825, "simplicity_score": 0.12320353991139658, "novelty_bonus": 0.22886852778223554, "total_score": 0.14275752126942287, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No graph traversal or external imports are used.\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.004178\nbelow_train_threshold: train_signal=0.016375\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    Combines the strengths of the top two baseline formulas\n    (base ratio, degree factor, structural factor, sqrt scaling)\n    and augments them with additional structural signals.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n        * sqrt_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    Combines the strengths of the top two baseline formulas\n    (base ratio, degree factor, structural factor, sqrt scaling)\n    and augments them with additional structural signals.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n        * sqrt_factor\n    )"}}
{"timestamp": "2026-02-13T00:08:06.096898+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i1_p4_781567455", "generation": 2, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3358943577430972, "spearman": 0.09891250990494581, "pearson": 0.3626909632405285, "rmse": 2.2894517604310285, "mae": 2.1332925004825825, "simplicity_score": 0.12309019173379283, "novelty_bonus": 0.22886852778223554, "total_score": 0.14273485163390215, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No graph traversal or external imports are used.\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.004178\nbelow_train_threshold: train_signal=0.016375\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No graph traversal or external imports are used.\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * tri_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No graph traversal or external imports are used.\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * tri_factor\n    )"}}
{"timestamp": "2026-02-13T00:08:55.082048+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.147048", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:10:03.470112+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.046836", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:10:33.839403+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i2_p2_643865119", "generation": 2, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7309003601440576, "spearman": 0.601519013545011, "pearson": 0.6430840095846424, "rmse": 10.244052605327619, "mae": 8.190457522153617, "simplicity_score": 0.12467051834602058, "novelty_bonus": 0.3813168014505228, "total_score": 0.4400886508768665, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Approximate average shortest path length using known graph characteristics.\n    # The formula is a combination of:\n    #   * log(n)/log(avg_degree+1)  – typical distance in an Erdős–Rényi graph.\n    #   * a clustering multiplier (higher clustering → longer paths).\n    #   * a degree‑variance factor (high variance → shorter paths).\n    #\n    # All operations are safe against division by zero.\n\n    n = s['n']\n    avg_deg = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg = s['std_degree'] if s['std_degree'] > 0 else 1.0\n\n    # Base distance estimate from random graph theory.\n    base = np.log(n) / np.log(avg_deg + 1)\n\n    # Clustering adjustment: more triangles tend to increase path length.\n    clustering_adj = 1.0 + trans\n\n    # Degree variance adjustment: larger variance usually shortens paths.\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1))\n\n    return base * clustering_adj * variance_adj\n\ndef new_invariant(s):\n    # Basic parameters with safe defaults\n    n = s['n']\n    avg_deg = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg = s['std_degree'] if s['std_degree'] > 0 else 1.0\n    max_deg = s['max_degree'] if s['max_degree'] > 0 else 1.0\n    density = s['density'] if s['density'] is not None else 0.0\n\n    # Base estimate from random‑graph theory\n    base = math.log(n) / math.log(avg_deg + 1)\n\n    # Adjustments\n    clustering_adj = 1.0 + trans                     # higher clustering → longer paths\n    variance_adj   = 1.0 / (1.0 + std_deg / (avg_deg + 1))   # higher variance → shorter paths\n    hub_adj        = 1.0 / (1.0 + max_deg / (avg_deg + 1))   # hubs shorten paths\n    density_adj    = 1.0 / (density + 1e-6)           # denser graphs → shorter paths\n\n    return base * clustering_adj * variance_adj * hub_adj * density_adj\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.147048\nbelow_novelty_threshold: novelty_bonus=0.046836\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula builds on the random‑graph baseline and applies multiplicative\n    corrections for clustering, degree heterogeneity, hubs, density,\n    assortativity, and triangle density.  All operations are guarded\n    against division by zero and missing values.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    max_deg    = s.get('max_degree', 0.0) or 1.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n    num_tri    = s.get('num_triangles', 0) or 0\n\n    eps = 1e-12\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = math.log(max(n, 2)) / math.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: higher clustering → longer paths\n    clustering_adj = 1.0 + 0.4 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Hub adjustment: very high degree nodes shorten distances\n    hub_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 5. Density adjustment: denser graphs have shorter paths\n    density_adj = 1.0 / (density + eps)\n\n    # 6. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.3 * assort\n\n    # 7. Triangle density adjustment: many triangles tend to increase distances\n    tri_adj = 1.0 + (num_tri / (m + eps))\n\n    # Combine all adjustments multiplicatively\n    return (base *\n            clustering_adj *\n            variance_adj *\n            hub_adj *\n            density_adj *\n            assort_adj *\n            tri_adj)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula builds on the random‑graph baseline and applies multiplicative\n    corrections for clustering, degree heterogeneity, hubs, density,\n    assortativity, and triangle density.  All operations are guarded\n    against division by zero and missing values.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    max_deg    = s.get('max_degree', 0.0) or 1.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n    num_tri    = s.get('num_triangles', 0) or 0\n\n    eps = 1e-12\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = math.log(max(n, 2)) / math.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: higher clustering → longer paths\n    clustering_adj = 1.0 + 0.4 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Hub adjustment: very high degree nodes shorten distances\n    hub_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 5. Density adjustment: denser graphs have shorter paths\n    density_adj = 1.0 / (density + eps)\n\n    # 6. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.3 * assort\n\n    # 7. Triangle density adjustment: many triangles tend to increase distances\n    tri_adj = 1.0 + (num_tri / (m + eps))\n\n    # Combine all adjustments multiplicatively\n    return (base *\n            clustering_adj *\n            variance_adj *\n            hub_adj *\n            density_adj *\n            assort_adj *\n            tri_adj)"}}
{"timestamp": "2026-02-13T00:11:10.205814+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.047955", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:11:40.945702+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:11:40.946227+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 2, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:12:24.532945+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 2, "population_idx": 4, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: __import__", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:12:24.536114+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 2, "island_id": 2, "population_idx": 4, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:13:15.189624+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.038357", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:13:46.369722+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i3_p1_402414364", "generation": 2, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.5101080432172869, "spearman": -0.4193986422405764, "pearson": 0.36719056843737063, "rmse": 2070.728695137573, "mae": 390.5860557038478, "simplicity_score": 0.25075862621685346, "novelty_bonus": 0.47152569006520906, "total_score": 0.4013087533832216, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how average path length relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    A novel invariant intended to correlate with the average shortest path length\n    using only the pre‑computed structural features provided in *s*.\n\n    The formula blends several independent aspects of the network:\n      • Normalized size versus edge count (comp1)\n      • Degree spread relative to variability (comp2)\n      • Triangle density relative to size (comp3)\n      • Average clustering and global transitivity (comp4)\n      • Degree assortativity magnitude (comp5)\n\n    By multiplying the first three components and dividing by the latter two,\n    we encourage the invariant to increase when the graph is small, sparse, \n    has diverse degrees, many triangles, high clustering, and low assortativity,\n    all of which tend to reduce the typical path length.\n    \"\"\"\n\n    # Core components\n    comp1 = (s['n'] + 1.0) / (s['m'] + 1.0)                     # size–to–edges ratio\n    comp2 = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)  # degree spread vs std\n    comp3 = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)         # triangle density\n\n    # Regularization terms\n    comp4 = (s['avg_clustering']**2 + s['transitivity']**2) / 2.0   # clustering/ transitivity combo\n    comp5 = (s['degree_assortativity']**2 + 1.0)                    # assortativity magnitude\n\n    # Combine into a single scalar\n    return (comp1 * comp2 * comp3) / (comp4 * comp5)\n\ndef new_invariant(s):\n    \"\"\"\n    A novel composite estimate for the average shortest path length\n    derived solely from pre‑computed graph statistics.\n    The formula combines several structural aspects of the graph in a\n    non‑trivial way, avoiding a direct use of any existing single feature.\n    \"\"\"\n    # Safe retrieval with defaults\n    n = s.get('n', 1)\n    avg_deg = s.get('avg_degree', 1)\n    density = s.get('density', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    triangles = s.get('num_triangles', 0)\n\n    # Individual components\n    size_factor      = n / (avg_deg + 1)          # influences by size and connectivity\n    sparsity_factor  = 1 - density / 2.0          # denser graphs tend to have shorter paths\n    clustering_factor= 1 + clustering            # high clustering can increase path lengths slightly\n    assort_factor    = 1 + assort / 2.0           # assortativity effect\n    triangle_bonus   = triangles / (n + 1)        # triangles contribute to shortcut opportunities\n\n    # Combine all contributions\n    return (\n        size_factor\n        * sparsity_factor\n        * clustering_factor\n        * assort_factor\n        + triangle_bonus\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.046653\nbelow_novelty_threshold: novelty_bonus=0.038357\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant crafted from a set of pre‑computed structural\n    statistics. The expression mixes size, density, degree dispersion,\n    triangle density, clustering, transitivity, assortativity and degree\n    balance in a non‑trivial way, avoiding a single dominant term.\n    \"\"\"\n    # Core measurements\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    clust      = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triads     = s['num_triangles']\n\n    # Build component ratios that reflect different aspects of the topology\n    size_edge_ratio   = (n + 1.0) / (m + 1.0)                     # relative sparsity\n    degree_dispersion = (max_deg - min_deg + 1.0) / (std_deg + 1.0)  # spread vs variation\n    triangle_density  = (triads + 1.0) / (n + 1.0)                   # shortcut opportunities\n    clustering_power  = (clust**2 + trans**2)                        # strength of local triangles\n    assort_power      = (assort**2 + 1.0)                            # magnitude of degree correlation\n\n    # Combine all ingredients with a few additional multiplicative corrections\n    inv = size_edge_ratio * degree_dispersion * triangle_density\n    inv /= (clustering_power + 1e-6)                                 # avoid division by zero\n    inv /= (assort_power + 1e-6)\n\n    # Minor adjustment with average degree to keep the scale reasonable\n    inv *= (avg_deg + 1.0) / (max_deg + 1.0)\n\n    return inv\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    A composite graph invariant crafted from a set of pre‑computed structural\n    statistics. The expression mixes size, density, degree dispersion,\n    triangle density, clustering, transitivity, assortativity and degree\n    balance in a non‑trivial way, avoiding a single dominant term.\n    \"\"\"\n    # Core measurements\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    clust      = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triads     = s['num_triangles']\n\n    # Build component ratios that reflect different aspects of the topology\n    size_edge_ratio   = (n + 1.0) / (m + 1.0)                     # relative sparsity\n    degree_dispersion = (max_deg - min_deg + 1.0) / (std_deg + 1.0)  # spread vs variation\n    triangle_density  = (triads + 1.0) / (n + 1.0)                   # shortcut opportunities\n    clustering_power  = (clust**2 + trans**2)                        # strength of local triangles\n    assort_power      = (assort**2 + 1.0)                            # magnitude of degree correlation\n\n    # Combine all ingredients with a few additional multiplicative corrections\n    inv = size_edge_ratio * degree_dispersion * triangle_density\n    inv /= (clustering_power + 1e-6)                                 # avoid division by zero\n    inv /= (assort_power + 1e-6)\n\n    # Minor adjustment with average degree to keep the scale reasonable\n    inv *= (avg_deg + 1.0) / (max_deg + 1.0)\n\n    return inv"}}
{"timestamp": "2026-02-13T00:14:13.808507+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.074178", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:14:38.728204+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:14:38.728607+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 2, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:15:05.943646+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 3, "population_idx": 3, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.140566", "model_name": "gpt-oss:20b", "train_signal": 0.14056572124578617}}
{"timestamp": "2026-02-13T00:15:05.944124+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 2, "island_id": 3, "population_idx": 3, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:15:43.721029+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.083898", "model_name": "gpt-oss:20b", "train_signal": 0.0838976136031392}}
{"timestamp": "2026-02-13T00:15:43.722870+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "phase1_20260212T231418Z", "generation": 3, "model_name": "gpt-oss:20b", "best_val_score": 0.5491013268732999, "no_improve_count": 1}}
{"timestamp": "2026-02-13T00:16:16.272203+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i0_p0_822761613", "generation": 3, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6908523409363745, "spearman": 0.6738268483563243, "pearson": 0.5847698215189023, "rmse": 121.0581251378014, "mae": 107.67923246231236, "simplicity_score": 0.24738254017056902, "novelty_bonus": 0.24452193008368373, "total_score": 0.4597465112373811, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n    sum_sq = sum(d*d for d in degrees)\n    val = n / (avg_deg + 1)\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n    val /= (1 + abs(assort))\n    val *= (1 + num_tri / (n**2 + 1))\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic graph statistics\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Start with a size‑degree baseline\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering slightly increases path length\n    val *= (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes → shorter paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts (use sqrt to dampen large counts)\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can lengthen paths\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees reflects higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # Basic graph statistics\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Start with a size‑degree baseline\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering slightly increases path length\n    val *= (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes → shorter paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts (use sqrt to dampen large counts)\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can lengthen paths\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees reflects higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T00:17:29.483848+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i0_p1_545429118", "generation": 3, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.47793517406962777, "spearman": 0.3859522935394758, "pearson": 0.32296931801604517, "rmse": 795.7239920028143, "mae": 585.7992181542426, "simplicity_score": 0.24649332816178304, "novelty_bonus": 0.5851708569744226, "total_score": 0.41782606949442125, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n    sum_sq = sum(d*d for d in degrees)\n    val = n / (avg_deg + 1)\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n    val /= (1 + abs(assort))\n    val *= (1 + num_tri / (n**2 + 1))\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering slightly increases path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squares of degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    # Ratios of max to avg and avg to max capture extreme degree effects\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering slightly increases path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squares of degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    # Ratios of max to avg and avg to max capture extreme degree effects\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T00:18:13.151334+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i0_p2_443414198", "generation": 3, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6908523409363745, "spearman": 0.6738268483563243, "pearson": 0.5847698215189023, "rmse": 121.0581251378014, "mae": 107.67923246231236, "simplicity_score": 0.24743731992501486, "novelty_bonus": 0.24452193008368373, "total_score": 0.45975746718827026, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n    sum_sq = sum(d*d for d in degrees)\n    val = n / (avg_deg + 1)\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n    val /= (1 + abs(assort))\n    val *= (1 + num_tri / (n**2 + 1))\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T00:18:47.986405+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i0_p3_450459553", "generation": 3, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5488115246098438, "spearman": 0.49999193729544406, "pearson": 0.5967148691949471, "rmse": 60.27622117051265, "mae": 56.86759487310753, "simplicity_score": 0.2484472613346054, "novelty_bonus": 0.48841352526532766, "total_score": 0.4462094784942414, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n    sum_sq = sum(d*d for d in degrees)\n    val = n / (avg_deg + 1)\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n    val /= (1 + abs(assort))\n    val *= (1 + num_tri / (n**2 + 1))\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # factors that shorten paths\n    val *= (1 + density)\n    val *= (1 + trans)\n    val *= (1 + clustering)\n\n    # positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # triangles provide local shortcuts; dampen large counts with a square‑root\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # factors that shorten paths\n    val *= (1 + density)\n    val *= (1 + trans)\n    val *= (1 + clustering)\n\n    # positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # triangles provide local shortcuts; dampen large counts with a square‑root\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T00:19:53.042725+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i0_p4_227238721", "generation": 3, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.46372148859543816, "spearman": 0.40290272365664115, "pearson": 0.30527256987035156, "rmse": 750.4508518126398, "mae": 530.7242825078649, "simplicity_score": 0.24656480581498377, "novelty_bonus": 0.5164283032898144, "total_score": 0.4056928139782616, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n    sum_sq = sum(d*d for d in degrees)\n    val = n / (avg_deg + 1)\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n    val /= (1 + abs(assort))\n    val *= (1 + num_tri / (n**2 + 1))\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n    sum_sq = sum(d*d for d in degrees)\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and transitivity tend to shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering has a moderate shortening effect\n    val *= (1 + 0.5 * clustering)\n\n    # Triangles provide local shortcuts (use sqrt to dampen large counts)\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures degree heterogeneity\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n\n    # Max/min ratio and reciprocal terms\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    return val", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n    sum_sq = sum(d*d for d in degrees)\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and transitivity tend to shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering has a moderate shortening effect\n    val *= (1 + 0.5 * clustering)\n\n    # Triangles provide local shortcuts (use sqrt to dampen large counts)\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures degree heterogeneity\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n\n    # Max/min ratio and reciprocal terms\n    val *= (1 + max_deg / (avg_deg + 1))\n    val *= (1 + avg_deg / (max_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    return val"}}
{"timestamp": "2026-02-13T00:20:15.345223+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i1_p0_92135914", "generation": 3, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.38103241296518603, "spearman": 0.14129158527398625, "pearson": 0.4582539846966963, "rmse": 2.196486691529806, "mae": 2.055139149871568, "simplicity_score": 0.14105903366620412, "novelty_bonus": 0.20110825080337325, "total_score": 0.1591900746112459, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No graph traversal or external imports are used.\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.004178\nbelow_train_threshold: train_signal=0.016375\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strongest parts of the top two candidate formulas:\n    - Base ratio of nodes to edges (with safety offset)\n    - Degree balance factor (average vs maximum degree)\n    - Structural cohesion factor (density + clustering) modulated by transitivity\n    - Size scaling factor (square root of node count)\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strongest parts of the top two candidate formulas:\n    - Base ratio of nodes to edges (with safety offset)\n    - Degree balance factor (average vs maximum degree)\n    - Structural cohesion factor (density + clustering) modulated by transitivity\n    - Size scaling factor (square root of node count)\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor"}}
{"timestamp": "2026-02-13T00:20:45.377247+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i1_p1_554584786", "generation": 3, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3358943577430972, "spearman": 0.09891250990494581, "pearson": 0.3626909632405285, "rmse": 2.2894517604310285, "mae": 2.1332925004825825, "simplicity_score": 0.12328015732256534, "novelty_bonus": 0.22886852778223554, "total_score": 0.14277284475165664, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No graph traversal or external imports are used.\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.004178\nbelow_train_threshold: train_signal=0.016375\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    min_factor = (min_deg + 1) / (max_deg + 1)\n    std_factor = 1 + std_deg / (avg_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    assort_factor = 1 + abs(assort)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n    sqrt_factor = pow(n, 0.5)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n        * sqrt_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    min_factor = (min_deg + 1) / (max_deg + 1)\n    std_factor = 1 + std_deg / (avg_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    assort_factor = 1 + abs(assort)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n    sqrt_factor = pow(n, 0.5)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n        * sqrt_factor\n    )"}}
{"timestamp": "2026-02-13T00:21:12.661443+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 1, "population_idx": 2, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.299016", "model_name": "gpt-oss:20b", "train_signal": 0.29901560624249696}}
{"timestamp": "2026-02-13T00:21:40.065532+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i1_p3_887889843", "generation": 3, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.38103241296518603, "spearman": 0.14129158527398625, "pearson": 0.4582539846966963, "rmse": 2.196486691529806, "mae": 2.055139149871568, "simplicity_score": 0.14105903366620412, "novelty_bonus": 0.20110825080337325, "total_score": 0.1591900746112459, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No graph traversal or external imports are used.\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.016375\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.299016\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strengths of the two leading formulas:\n    - Base ratio of nodes to edges (n/(m+1))\n    - Degree balance factor ((avg_degree+1)/(max_degree+1))\n    - Structural cohesion factor ((density+avg_clustering)*(1+transitivity))\n    - Size scaling factor (sqrt(n))\n    \"\"\"\n    n = s['n']\n    m = s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strengths of the two leading formulas:\n    - Base ratio of nodes to edges (n/(m+1))\n    - Degree balance factor ((avg_degree+1)/(max_degree+1))\n    - Structural cohesion factor ((density+avg_clustering)*(1+transitivity))\n    - Size scaling factor (sqrt(n))\n    \"\"\"\n    n = s['n']\n    m = s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor"}}
{"timestamp": "2026-02-13T00:22:10.233794+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i1_p4_63817255", "generation": 3, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3358943577430972, "spearman": 0.09891250990494581, "pearson": 0.3626909632405285, "rmse": 2.2894517604310285, "mae": 2.1332925004825825, "simplicity_score": 0.12320353991139658, "novelty_bonus": 0.22886852778223554, "total_score": 0.14275752126942287, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant built from pre‑computed features.\n    No graph traversal or external imports are used.\n    \"\"\"\n    n, m = s['n'], s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Minimum‑degree influence\n    min_factor = (min_deg + 1) / (max_deg + 1)\n\n    # Degree dispersion adjustment\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost (absolute value to keep it positive)\n    assort_factor = 1 + abs(assort)\n\n    # Triangle count influence (scaled to avoid dominance)\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.016375\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.299016\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant for average shortest path length.\n    Uses only pre‑computed graph features and built‑in arithmetic.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree balance factors\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    min_factor = (min_deg + 1) / (max_deg + 1)\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost\n    assort_factor = 1 + abs(assort)\n\n    # Triangle influence\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    # Size scaling\n    sqrt_factor = pow(n, 0.5)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n        * sqrt_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite invariant for average shortest path length.\n    Uses only pre‑computed graph features and built‑in arithmetic.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s.get('std_degree', 0.0)\n\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree balance factors\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    min_factor = (min_deg + 1) / (max_deg + 1)\n    std_factor = 1 + std_deg / (avg_deg + 1)\n\n    # Structural cohesion factor\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Assortativity boost\n    assort_factor = 1 + abs(assort)\n\n    # Triangle influence\n    tri_factor = 1 + num_tri / (num_tri + 1)\n\n    # Size scaling\n    sqrt_factor = pow(n, 0.5)\n\n    return (\n        base\n        * deg_factor\n        * min_factor\n        * std_factor\n        * struct_factor\n        * assort_factor\n        * tri_factor\n        * sqrt_factor\n    )"}}
{"timestamp": "2026-02-13T00:22:56.465906+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i2_p0_858291293", "generation": 3, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9177911164465786, "spearman": 0.9489450794814587, "pearson": 0.8929764451673257, "rmse": 1.9157989856551896, "mae": 1.8255891093664212, "simplicity_score": 0.13343273744596368, "novelty_bonus": 0.15721743043576064, "total_score": 0.5483243163606503, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Approximate average shortest path length using known graph characteristics.\n    # The formula is a combination of:\n    #   * log(n)/log(avg_degree+1)  – typical distance in an Erdős–Rényi graph.\n    #   * a clustering multiplier (higher clustering → longer paths).\n    #   * a degree‑variance factor (high variance → shorter paths).\n    #\n    # All operations are safe against division by zero.\n\n    n = s['n']\n    avg_deg = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg = s['std_degree'] if s['std_degree'] > 0 else 1.0\n\n    # Base distance estimate from random graph theory.\n    base = np.log(n) / np.log(avg_deg + 1)\n\n    # Clustering adjustment: more triangles tend to increase path length.\n    clustering_adj = 1.0 + trans\n\n    # Degree variance adjustment: larger variance usually shortens paths.\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1))\n\n    return base * clustering_adj * variance_adj\n\ndef new_invariant(s):\n    # Basic parameters with safe defaults\n    n = s['n']\n    avg_deg = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg = s['std_degree'] if s['std_degree'] > 0 else 1.0\n    max_deg = s['max_degree'] if s['max_degree'] > 0 else 1.0\n    density = s['density'] if s['density'] is not None else 0.0\n\n    # Base estimate from random‑graph theory\n    base = math.log(n) / math.log(avg_deg + 1)\n\n    # Adjustments\n    clustering_adj = 1.0 + trans                     # higher clustering → longer paths\n    variance_adj   = 1.0 / (1.0 + std_deg / (avg_deg + 1))   # higher variance → shorter paths\n    hub_adj        = 1.0 / (1.0 + max_deg / (avg_deg + 1))   # hubs shorten paths\n    density_adj    = 1.0 / (density + 1e-6)           # denser graphs → shorter paths\n\n    return base * clustering_adj * variance_adj * hub_adj * density_adj\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.047955\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: static_invalid: forbidden token detected: __import__\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n```", "extracted_code": "def new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj"}}
{"timestamp": "2026-02-13T00:23:22.762127+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.104917", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:23:59.378660+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:23:59.379114+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 3, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:24:40.259338+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 2, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.095031", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:24:40.259884+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 3, "island_id": 2, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:25:12.850090+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:25:12.850522+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 3, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:26:06.940741+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i2_p3_827631171", "generation": 3, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7116926770708282, "spearman": 0.7139183656785794, "pearson": 0.6314945078833721, "rmse": 1.947049151459618, "mae": 1.809978512554877, "simplicity_score": 0.1269775131633089, "novelty_bonus": 0.22079597617983038, "total_score": 0.4485934783259006, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Approximate average shortest path length using known graph characteristics.\n    # The formula is a combination of:\n    #   * log(n)/log(avg_degree+1)  – typical distance in an Erdős–Rényi graph.\n    #   * a clustering multiplier (higher clustering → longer paths).\n    #   * a degree‑variance factor (high variance → shorter paths).\n    #\n    # All operations are safe against division by zero.\n\n    n = s['n']\n    avg_deg = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg = s['std_degree'] if s['std_degree'] > 0 else 1.0\n\n    # Base distance estimate from random graph theory.\n    base = np.log(n) / np.log(avg_deg + 1)\n\n    # Clustering adjustment: more triangles tend to increase path length.\n    clustering_adj = 1.0 + trans\n\n    # Degree variance adjustment: larger variance usually shortens paths.\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1))\n\n    return base * clustering_adj * variance_adj\n\ndef new_invariant(s):\n    # Basic parameters with safe defaults\n    n = s['n']\n    avg_deg = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg = s['std_degree'] if s['std_degree'] > 0 else 1.0\n    max_deg = s['max_degree'] if s['max_degree'] > 0 else 1.0\n    density = s['density'] if s['density'] is not None else 0.0\n\n    # Base estimate from random‑graph theory\n    base = math.log(n) / math.log(avg_deg + 1)\n\n    # Adjustments\n    clustering_adj = 1.0 + trans                     # higher clustering → longer paths\n    variance_adj   = 1.0 / (1.0 + std_deg / (avg_deg + 1))   # higher variance → shorter paths\n    hub_adj        = 1.0 / (1.0 + max_deg / (avg_deg + 1))   # hubs shorten paths\n    density_adj    = 1.0 / (density + 1e-6)           # denser graphs → shorter paths\n\n    return base * clustering_adj * variance_adj * hub_adj * density_adj\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.095031\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport numpy as np\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed graph features.\n    The formula is a compact combination of random‑graph theory and empirical\n    adjustments for clustering, degree heterogeneity, density, hubs, and assortativity.\n    All arithmetic is protected against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics with safe defaults\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0\n    max_deg    = s.get('max_degree', 0.0) or 1.0\n    min_deg    = s.get('min_degree', 0.0)\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    trans      = s.get('transitivity', 0.0) or 0.0\n    density    = s.get('density', 0.0) or 1e-6\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    # If the graph has isolated vertices the average distance is undefined.\n    # In that case we return a large value proportional to the graph size.\n    if min_deg == 0:\n        return float(n)  # a crude upper bound\n\n    # 1. Random‑graph baseline: typical distance in an Erdős–Rényi graph.\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: higher clustering tends to increase path length.\n    clustering_adj = 1.0 + 0.4 * trans\n\n    # 3. Degree‑variance adjustment: high variance (hubs) usually shortens paths.\n    variance_adj = 1.0 / (1.0 + 0.5 * std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: denser graphs have shorter paths.\n    density_adj = 1.0 / (1.0 + 5.0 * density)\n\n    # 5. Hub adjustment: a larger max degree relative to the mean shortens distances.\n    hub_adj = 1.0 / (1.0 + 0.3 * (max_deg - avg_deg) / (avg_deg + 1.0))\n\n    # 6. Assortativity adjustment: positive assortativity can lengthen paths.\n    assort_adj = 1.0 + 0.2 * assort\n\n    return base * clustering_adj * variance_adj * density_adj * hub_adj * assort_adj\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines a random‑graph baseline (using integer bit‑lengths as a\n    cheap log approximation) with empirical adjustments for clustering,\n    degree heterogeneity, density, hubs, and assortativity.\n    \"\"\"\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0\n    max_deg    = s.get('max_degree', 0.0) or 1.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    trans      = s.get('transitivity', 0.0) or 0.0\n    density    = s.get('density', 0.0) or 1e-6\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n    min_deg    = s.get('min_degree', 0)\n\n    # If the graph contains isolated vertices the average distance is undefined.\n    # Return a crude upper bound proportional to the graph size.\n    if min_deg == 0:\n        return float(n)\n\n    # Random‑graph baseline: log(n)/log(avg_deg+1) approximated with bit lengths.\n    n_bits   = n.bit_length() or 1\n    deg_int  = int(avg_deg) + 1\n    deg_bits = deg_int.bit_length() or 1\n    base = n_bits / deg_bits\n\n    # Adjustments based on graph properties\n    clustering_adj = 1.0 + 0.4 * trans\n    variance_adj   = 1.0 / (1.0 + 0.5 * std_deg / (avg_deg + 1.0))\n    density_adj    = 1.0 / (1.0 + 5.0 * density)\n    hub_adj        = 1.0 / (1.0 + 0.3 * (max_deg - avg_deg) / (avg_deg + 1.0))\n    assort_adj     = 1.0 + 0.2 * assort\n\n    return base * clustering_adj * variance_adj * density_adj * hub_adj * assort_adj\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines a random‑graph baseline (using integer bit‑lengths as a\n    cheap log approximation) with empirical adjustments for clustering,\n    degree heterogeneity, density, hubs, and assortativity.\n    \"\"\"\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0\n    max_deg    = s.get('max_degree', 0.0) or 1.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    trans      = s.get('transitivity', 0.0) or 0.0\n    density    = s.get('density', 0.0) or 1e-6\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n    min_deg    = s.get('min_degree', 0)\n\n    # If the graph contains isolated vertices the average distance is undefined.\n    # Return a crude upper bound proportional to the graph size.\n    if min_deg == 0:\n        return float(n)\n\n    # Random‑graph baseline: log(n)/log(avg_deg+1) approximated with bit lengths.\n    n_bits   = n.bit_length() or 1\n    deg_int  = int(avg_deg) + 1\n    deg_bits = deg_int.bit_length() or 1\n    base = n_bits / deg_bits\n\n    # Adjustments based on graph properties\n    clustering_adj = 1.0 + 0.4 * trans\n    variance_adj   = 1.0 / (1.0 + 0.5 * std_deg / (avg_deg + 1.0))\n    density_adj    = 1.0 / (1.0 + 5.0 * density)\n    hub_adj        = 1.0 / (1.0 + 0.3 * (max_deg - avg_deg) / (avg_deg + 1.0))\n    assort_adj     = 1.0 + 0.2 * assort\n\n    return base * clustering_adj * variance_adj * density_adj * hub_adj * assort_adj"}}
{"timestamp": "2026-02-13T00:26:06.943012+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 3, "island_id": 2, "population_idx": 3, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:27:01.086882+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i2_p4_276759694", "generation": 3, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7717166866746699, "spearman": 0.7942491540723404, "pearson": 0.7778345034966294, "rmse": 137.44341266720238, "mae": 96.54304750380645, "simplicity_score": 0.1804519941033686, "novelty_bonus": 0.29681799242916773, "total_score": 0.5222603735855943, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Approximate average shortest path length using known graph characteristics.\n    # The formula is a combination of:\n    #   * log(n)/log(avg_degree+1)  – typical distance in an Erdős–Rényi graph.\n    #   * a clustering multiplier (higher clustering → longer paths).\n    #   * a degree‑variance factor (high variance → shorter paths).\n    #\n    # All operations are safe against division by zero.\n\n    n = s['n']\n    avg_deg = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg = s['std_degree'] if s['std_degree'] > 0 else 1.0\n\n    # Base distance estimate from random graph theory.\n    base = np.log(n) / np.log(avg_deg + 1)\n\n    # Clustering adjustment: more triangles tend to increase path length.\n    clustering_adj = 1.0 + trans\n\n    # Degree variance adjustment: larger variance usually shortens paths.\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1))\n\n    return base * clustering_adj * variance_adj\n\ndef new_invariant(s):\n    # Basic parameters with safe defaults\n    n = s['n']\n    avg_deg = s['avg_degree'] if s['avg_degree'] > 0 else 1.0\n    trans = s['transitivity'] if s['transitivity'] is not None else 0.0\n    std_deg = s['std_degree'] if s['std_degree'] > 0 else 1.0\n    max_deg = s['max_degree'] if s['max_degree'] > 0 else 1.0\n    density = s['density'] if s['density'] is not None else 0.0\n\n    # Base estimate from random‑graph theory\n    base = math.log(n) / math.log(avg_deg + 1)\n\n    # Adjustments\n    clustering_adj = 1.0 + trans                     # higher clustering → longer paths\n    variance_adj   = 1.0 / (1.0 + std_deg / (avg_deg + 1))   # higher variance → shorter paths\n    hub_adj        = 1.0 / (1.0 + max_deg / (avg_deg + 1))   # hubs shorten paths\n    density_adj    = 1.0 / (density + 1e-6)           # denser graphs → shorter paths\n\n    return base * clustering_adj * variance_adj * hub_adj * density_adj\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is deliberately simple: a base term proportional to n / avg_degree\n    multiplied by several multiplicative adjustments that capture clustering,\n    degree variance, density, assortativity and triangle abundance.  All\n    operations use only built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)           # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ---- Base estimate ----------------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ---------------------------------------\n    # Compute variance of the degree sequence\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - (avg_deg * avg_deg)\n        var_deg = max(var_deg, 0.0)\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment -----------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment -----------------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors -----------------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is deliberately simple: a base term proportional to n / avg_degree\n    multiplied by several multiplicative adjustments that capture clustering,\n    degree variance, density, assortativity and triangle abundance.  All\n    operations use only built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)           # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ---- Base estimate ----------------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ---------------------------------------\n    # Compute variance of the degree sequence\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - (avg_deg * avg_deg)\n        var_deg = max(var_deg, 0.0)\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment -----------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment -----------------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors -----------------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T00:27:40.746527+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i3_p0_165229079", "generation": 3, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.39841536614645856, "spearman": -0.4030864783194158, "pearson": 0.3364064823966758, "rmse": 46632.367638793745, "mae": 8686.910508548492, "simplicity_score": 0.1314902279207559, "novelty_bonus": 0.5292837320933023, "total_score": 0.38662640437184975, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how average path length relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    A novel invariant intended to correlate with the average shortest path length\n    using only the pre‑computed structural features provided in *s*.\n\n    The formula blends several independent aspects of the network:\n      • Normalized size versus edge count (comp1)\n      • Degree spread relative to variability (comp2)\n      • Triangle density relative to size (comp3)\n      • Average clustering and global transitivity (comp4)\n      • Degree assortativity magnitude (comp5)\n\n    By multiplying the first three components and dividing by the latter two,\n    we encourage the invariant to increase when the graph is small, sparse, \n    has diverse degrees, many triangles, high clustering, and low assortativity,\n    all of which tend to reduce the typical path length.\n    \"\"\"\n\n    # Core components\n    comp1 = (s['n'] + 1.0) / (s['m'] + 1.0)                     # size–to–edges ratio\n    comp2 = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)  # degree spread vs std\n    comp3 = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)         # triangle density\n\n    # Regularization terms\n    comp4 = (s['avg_clustering']**2 + s['transitivity']**2) / 2.0   # clustering/ transitivity combo\n    comp5 = (s['degree_assortativity']**2 + 1.0)                    # assortativity magnitude\n\n    # Combine into a single scalar\n    return (comp1 * comp2 * comp3) / (comp4 * comp5)\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant crafted from a set of pre‑computed structural\n    statistics. The expression mixes size, density, degree dispersion,\n    triangle density, clustering, transitivity, assortativity and degree\n    balance in a non‑trivial way, avoiding a single dominant term.\n    \"\"\"\n    # Core measurements\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    clust      = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triads     = s['num_triangles']\n\n    # Build component ratios that reflect different aspects of the topology\n    size_edge_ratio   = (n + 1.0) / (m + 1.0)                     # relative sparsity\n    degree_dispersion = (max_deg - min_deg + 1.0) / (std_deg + 1.0)  # spread vs variation\n    triangle_density  = (triads + 1.0) / (n + 1.0)                   # shortcut opportunities\n    clustering_power  = (clust**2 + trans**2)                        # strength of local triangles\n    assort_power      = (assort**2 + 1.0)                            # magnitude of degree correlation\n\n    # Combine all ingredients with a few additional multiplicative corrections\n    inv = size_edge_ratio * degree_dispersion * triangle_density\n    inv /= (clustering_power + 1e-6)                                 # avoid division by zero\n    inv /= (assort_power + 1e-6)\n\n    # Minor adjustment with average degree to keep the scale reasonable\n    inv *= (avg_deg + 1.0) / (max_deg + 1.0)\n\n    return inv\n\ndef new_invariant(s):\n    \"\"\"\n    A novel composite estimate for the average shortest path length\n    derived solely from pre‑computed graph statistics.\n    The formula combines several structural aspects of the graph in a\n    non‑trivial way, avoiding a direct use of any existing single feature.\n    \"\"\"\n    # Safe retrieval with defaults\n    n = s.get('n', 1)\n    avg_deg = s.get('avg_degree', 1)\n    density = s.get('density', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    triangles = s.get('num_triangles', 0)\n\n    # Individual components\n    size_factor      = n / (avg_deg + 1)          # influences by size and connectivity\n    sparsity_factor  = 1 - density / 2.0          # denser graphs tend to have shorter paths\n    clustering_factor= 1 + clustering            # high clustering can increase path lengths slightly\n    assort_factor    = 1 + assort / 2.0           # assortativity effect\n    triangle_bonus   = triangles / (n + 1)        # triangles contribute to shortcut opportunities\n\n    # Combine all contributions\n    return (\n        size_factor\n        * sparsity_factor\n        * clustering_factor\n        * assort_factor\n        + triangle_bonus\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.140566\nbelow_train_threshold: train_signal=0.083898\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant for average shortest path length derived from\n    pre‑computed structural features.\n\n    The expression blends:\n      * relative sparsity  (size / edges)\n      * degree dispersion (spread vs. std. dev.)\n      * triangle abundance (shortcut potential)\n      * a combined clustering strength (sqrt of sum of squares)\n      * the magnitude of degree assortativity\n\n    It avoids using any single raw feature directly and relies only on\n    elementary arithmetic operations.\n    \"\"\"\n    # Safely fetch values with defaults\n    n      = s.get('n', 1)\n    m      = s.get('m', 1)\n    max_d  = s.get('max_degree', 1)\n    min_d  = s.get('min_degree', 0)\n    std_d  = s.get('std_degree', 1)\n    tri    = s.get('num_triangles', 0)\n    clust  = s.get('avg_clustering', 0.0)\n    trans  = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n\n    # Core components\n    size_edge   = (n + 1.0) / (m + 1.0)                      # sparsity ratio\n    degree_disp = (max_d - min_d + 1.0) / (std_d + 1.0)      # dispersion vs. std\n    tri_bonus   = (tri + 1.0) / (n + 1.0)                     # triangle density\n    cluster_val = (clust ** 2 + trans ** 2 + 1e-12) ** 0.5   # sqrt of combined clustering\n    assort_mag  = (abs(assort) + 1e-12)                       # magnitude of assortativity\n\n    # Final invariant\n    return (size_edge * degree_disp * tri_bonus) / (cluster_val * assort_mag)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite invariant for average shortest path length derived from\n    pre‑computed structural features.\n\n    The expression blends:\n      * relative sparsity  (size / edges)\n      * degree dispersion (spread vs. std. dev.)\n      * triangle abundance (shortcut potential)\n      * a combined clustering strength (sqrt of sum of squares)\n      * the magnitude of degree assortativity\n\n    It avoids using any single raw feature directly and relies only on\n    elementary arithmetic operations.\n    \"\"\"\n    # Safely fetch values with defaults\n    n      = s.get('n', 1)\n    m      = s.get('m', 1)\n    max_d  = s.get('max_degree', 1)\n    min_d  = s.get('min_degree', 0)\n    std_d  = s.get('std_degree', 1)\n    tri    = s.get('num_triangles', 0)\n    clust  = s.get('avg_clustering', 0.0)\n    trans  = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n\n    # Core components\n    size_edge   = (n + 1.0) / (m + 1.0)                      # sparsity ratio\n    degree_disp = (max_d - min_d + 1.0) / (std_d + 1.0)      # dispersion vs. std\n    tri_bonus   = (tri + 1.0) / (n + 1.0)                     # triangle density\n    cluster_val = (clust ** 2 + trans ** 2 + 1e-12) ** 0.5   # sqrt of combined clustering\n    assort_mag  = (abs(assort) + 1e-12)                       # magnitude of assortativity\n\n    # Final invariant\n    return (size_edge * degree_disp * tri_bonus) / (cluster_val * assort_mag)"}}
{"timestamp": "2026-02-13T00:28:12.782831+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.003794", "model_name": "gpt-oss:20b", "train_signal": 0.0037938817828551785}}
{"timestamp": "2026-02-13T00:28:50.572077+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:28:50.572984+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 3, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:29:23.327185+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 3, "population_idx": 2, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.022041", "model_name": "gpt-oss:20b", "train_signal": 0.022040816326530613}}
{"timestamp": "2026-02-13T00:29:23.327724+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 3, "island_id": 3, "population_idx": 2, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:29:57.772585+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i3_p3_700522966", "generation": 3, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.7733580018501388, "spearman": -0.5176074485235316, "pearson": -0.3323906555214724, "rmse": 53.42312398289512, "mae": 41.5169773934602, "simplicity_score": 0.18081162828799893, "novelty_bonus": 0.40562853270443633, "total_score": 0.41665460973069646, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how average path length relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    A novel invariant intended to correlate with the average shortest path length\n    using only the pre‑computed structural features provided in *s*.\n\n    The formula blends several independent aspects of the network:\n      • Normalized size versus edge count (comp1)\n      • Degree spread relative to variability (comp2)\n      • Triangle density relative to size (comp3)\n      • Average clustering and global transitivity (comp4)\n      • Degree assortativity magnitude (comp5)\n\n    By multiplying the first three components and dividing by the latter two,\n    we encourage the invariant to increase when the graph is small, sparse, \n    has diverse degrees, many triangles, high clustering, and low assortativity,\n    all of which tend to reduce the typical path length.\n    \"\"\"\n\n    # Core components\n    comp1 = (s['n'] + 1.0) / (s['m'] + 1.0)                     # size–to–edges ratio\n    comp2 = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)  # degree spread vs std\n    comp3 = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)         # triangle density\n\n    # Regularization terms\n    comp4 = (s['avg_clustering']**2 + s['transitivity']**2) / 2.0   # clustering/ transitivity combo\n    comp5 = (s['degree_assortativity']**2 + 1.0)                    # assortativity magnitude\n\n    # Combine into a single scalar\n    return (comp1 * comp2 * comp3) / (comp4 * comp5)\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant crafted from a set of pre‑computed structural\n    statistics. The expression mixes size, density, degree dispersion,\n    triangle density, clustering, transitivity, assortativity and degree\n    balance in a non‑trivial way, avoiding a single dominant term.\n    \"\"\"\n    # Core measurements\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    clust      = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triads     = s['num_triangles']\n\n    # Build component ratios that reflect different aspects of the topology\n    size_edge_ratio   = (n + 1.0) / (m + 1.0)                     # relative sparsity\n    degree_dispersion = (max_deg - min_deg + 1.0) / (std_deg + 1.0)  # spread vs variation\n    triangle_density  = (triads + 1.0) / (n + 1.0)                   # shortcut opportunities\n    clustering_power  = (clust**2 + trans**2)                        # strength of local triangles\n    assort_power      = (assort**2 + 1.0)                            # magnitude of degree correlation\n\n    # Combine all ingredients with a few additional multiplicative corrections\n    inv = size_edge_ratio * degree_dispersion * triangle_density\n    inv /= (clustering_power + 1e-6)                                 # avoid division by zero\n    inv /= (assort_power + 1e-6)\n\n    # Minor adjustment with average degree to keep the scale reasonable\n    inv *= (avg_deg + 1.0) / (max_deg + 1.0)\n\n    return inv\n\ndef new_invariant(s):\n    \"\"\"\n    A novel composite estimate for the average shortest path length\n    derived solely from pre‑computed graph statistics.\n    The formula combines several structural aspects of the graph in a\n    non‑trivial way, avoiding a direct use of any existing single feature.\n    \"\"\"\n    # Safe retrieval with defaults\n    n = s.get('n', 1)\n    avg_deg = s.get('avg_degree', 1)\n    density = s.get('density', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    triangles = s.get('num_triangles', 0)\n\n    # Individual components\n    size_factor      = n / (avg_deg + 1)          # influences by size and connectivity\n    sparsity_factor  = 1 - density / 2.0          # denser graphs tend to have shorter paths\n    clustering_factor= 1 + clustering            # high clustering can increase path lengths slightly\n    assort_factor    = 1 + assort / 2.0           # assortativity effect\n    triangle_bonus   = triangles / (n + 1)        # triangles contribute to shortcut opportunities\n\n    # Combine all contributions\n    return (\n        size_factor\n        * sparsity_factor\n        * clustering_factor\n        * assort_factor\n        + triangle_bonus\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.003794\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.022041\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    A composite invariant that mixes several pre‑computed graph statistics\n    to produce a value correlated with the average shortest‑path length.\n    It uses only arithmetic, comparisons, and basic Python built‑ins.\n\n    Keys required from the dictionary `s`:\n        - n                 (int) number of nodes\n        - m                 (int) number of edges\n        - density           (float) edge density\n        - avg_degree        (float) average degree\n        - max_degree        (int) maximum degree\n        - min_degree        (int) minimum degree\n        - std_degree        (float) degree standard deviation\n        - avg_clustering    (float) average local clustering coefficient\n        - transitivity      (float) global transitivity (overall clustering)\n        - degree_assortativity (float) degree assortativity coefficient\n        - num_triangles     (int) number of triangles\n        - degrees           (list[int]) sorted degree sequence\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Size to sparsity ratio\n    size_edge_ratio = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree dispersion: relative spread compared to variation\n    degree_spread = (s['max_degree'] - s['min_degree'] + 1.0)\n    degree_variation = s['std_degree'] + 1.0\n    degree_dispersion = degree_spread / degree_variation\n\n    # 3. Triangle density: triangles per node (shifted to avoid zero)\n    triangle_density = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Local triangle power: square of clustering and transitivity\n    clustering_power = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # 5. Assortativity magnitude: square to make always positive\n    assort_magnitude = s['degree_assortativity'] ** 2 + 1.0\n\n    # ------------------------------------------------------------------\n    # Combine everything into one scalar\n    # The product of the first three components emphasizes sparsity,\n    # degree spread, and triangle abundance – all of which can affect\n    # path lengths.  Dividing by the clustering and assortativity terms\n    # dampens the effect of very high clustering or strong degree\n    # correlations.\n    invariant = (\n        size_edge_ratio\n        * degree_dispersion\n        * triangle_density\n    ) / (\n        clustering_power\n        * assort_magnitude\n    )\n\n    return invariant\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    A composite invariant that mixes several pre‑computed graph statistics\n    to produce a value correlated with the average shortest‑path length.\n    It uses only arithmetic, comparisons, and basic Python built‑ins.\n\n    Keys required from the dictionary `s`:\n        - n                 (int) number of nodes\n        - m                 (int) number of edges\n        - density           (float) edge density\n        - avg_degree        (float) average degree\n        - max_degree        (int) maximum degree\n        - min_degree        (int) minimum degree\n        - std_degree        (float) degree standard deviation\n        - avg_clustering    (float) average local clustering coefficient\n        - transitivity      (float) global transitivity (overall clustering)\n        - degree_assortativity (float) degree assortativity coefficient\n        - num_triangles     (int) number of triangles\n        - degrees           (list[int]) sorted degree sequence\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Size to sparsity ratio\n    size_edge_ratio = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree dispersion: relative spread compared to variation\n    degree_spread = (s['max_degree'] - s['min_degree'] + 1.0)\n    degree_variation = s['std_degree'] + 1.0\n    degree_dispersion = degree_spread / degree_variation\n\n    # 3. Triangle density: triangles per node (shifted to avoid zero)\n    triangle_density = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Local triangle power: square of clustering and transitivity\n    clustering_power = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # 5. Assortativity magnitude: square to make always positive\n    assort_magnitude = s['degree_assortativity'] ** 2 + 1.0\n\n    # ------------------------------------------------------------------\n    # Combine everything into one scalar\n    # The product of the first three components emphasizes sparsity,\n    # degree spread, and triangle abundance – all of which can affect\n    # path lengths.  Dividing by the clustering and assortativity terms\n    # dampens the effect of very high clustering or strong degree\n    # correlations.\n    invariant = (\n        size_edge_ratio\n        * degree_dispersion\n        * triangle_density\n    ) / (\n        clustering_power\n        * assort_magnitude\n    )\n\n    return invariant"}}
{"timestamp": "2026-02-13T00:30:25.941949+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.165906", "model_name": "gpt-oss:20b", "train_signal": 0.165906362545018}}
{"timestamp": "2026-02-13T00:30:25.943950+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "phase1_20260212T231418Z", "generation": 4, "model_name": "gpt-oss:20b", "best_val_score": 0.5491013268732999, "no_improve_count": 2}}
{"timestamp": "2026-02-13T00:31:05.520421+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i0_p0_354525967", "generation": 4, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6908523409363745, "spearman": 0.6738268483563243, "pearson": 0.5847698215189023, "rmse": 121.0581251378014, "mae": 107.67923246231236, "simplicity_score": 0.24727436714267484, "novelty_bonus": 0.24452193008368373, "total_score": 0.4597248766318022, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # already sorted\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # already sorted\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T00:31:41.684285+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i0_p1_67920001", "generation": 4, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6908523409363745, "spearman": 0.6738268483563243, "pearson": 0.5847698215189023, "rmse": 121.0581251378014, "mae": 107.67923246231236, "simplicity_score": 0.24727436714267484, "novelty_bonus": 0.24452193008368373, "total_score": 0.4597248766318022, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T00:32:26.492449+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i0_p2_970698024", "generation": 4, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7533733493397358, "spearman": 0.667036176043014, "pearson": 0.6516945644204613, "rmse": 79.44779183538786, "mae": 70.4930208532406, "simplicity_score": 0.2469604539334509, "novelty_bonus": 0.3537596935631657, "total_score": 0.48903808687714695, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density) * (1 + 1.2 * trans) * (1 + 1.1 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density) * (1 + 1.2 * trans) * (1 + 1.1 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T00:33:53.772420+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i0_p3_445687486", "generation": 4, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6908523409363745, "spearman": 0.6738268483563243, "pearson": 0.5847698215189023, "rmse": 121.0581251378014, "mae": 107.67923246231236, "simplicity_score": 0.24724760766844345, "novelty_bonus": 0.24452193008368373, "total_score": 0.459719524736956, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # sum of squared degrees captures higher‑order degree effects\n    sum_sq = 0\n    for d in degrees:\n        sum_sq += d * d\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # sum of squared degrees captures higher‑order degree effects\n    sum_sq = 0\n    for d in degrees:\n        sum_sq += d * d\n    val *= (1 + sum_sq / (n * (avg_deg**2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T00:34:23.907036+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 0, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:34:23.907477+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 4, "island_id": 0, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:34:54.645745+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i0_p4_893121121", "generation": 4, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5694597839135654, "spearman": 0.4870331084651616, "pearson": 0.5339358182453438, "rmse": 140.2591621343767, "mae": 128.11988440155096, "simplicity_score": 0.24735532492075304, "novelty_bonus": 0.5068180750387854, "total_score": 0.44503304172836705, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to increase or\n    decrease the typical distance between nodes.\n    \"\"\"\n    import math\n\n    # Unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger graphs with lower average degree tend to have\n    # longer paths.\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, usually\n    # shortening paths; we divide by a factor that grows with |assort|.\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts.\n    val *= (1 + math.sqrt(num_tri) / (n + 1))\n\n    # Degree spread and variability can increase path length.\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution.\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects.\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n\n    val = n / (avg_deg + 1)\n\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    val /= (1 + abs(assort))\n\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n\n    val = n / (avg_deg + 1)\n\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    val /= (1 + abs(assort))\n\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T00:34:54.647311+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 4, "island_id": 0, "population_idx": 4, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:35:32.778670+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.004274", "model_name": "gpt-oss:20b", "train_signal": 0.004273709483793517}}
{"timestamp": "2026-02-13T00:35:55.203167+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i1_p1_677919011", "generation": 4, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.38103241296518603, "spearman": 0.14129158527398625, "pearson": 0.4582539846966963, "rmse": 2.196486691529806, "mae": 2.055139149871568, "simplicity_score": 0.14105903366620412, "novelty_bonus": 0.20110825080337325, "total_score": 0.1591900746112459, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\n\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strongest parts of the top two candidate formulas:\n    - Base ratio of nodes to edges (with safety offset)\n    - Degree balance factor (average vs maximum degree)\n    - Structural cohesion factor (density + clustering) modulated by transitivity\n    - Size scaling factor (square root of node count)\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.299016\nbelow_train_threshold: train_signal=0.004274\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant combining:\n    - Base ratio of nodes to edges (n/(m+1))\n    - Degree balance factor ((avg_degree+1)/(max_degree+1))\n    - Structural cohesion factor ((density+avg_clustering)*(1+transitivity))\n    - Size scaling factor (sqrt(n))\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite invariant combining:\n    - Base ratio of nodes to edges (n/(m+1))\n    - Degree balance factor ((avg_degree+1)/(max_degree+1))\n    - Structural cohesion factor ((density+avg_clustering)*(1+transitivity))\n    - Size scaling factor (sqrt(n))\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor"}}
{"timestamp": "2026-02-13T00:36:28.556831+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 1, "population_idx": 2, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.041056", "model_name": "gpt-oss:20b", "train_signal": 0.041056422569027605}}
{"timestamp": "2026-02-13T00:36:53.301049+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 1, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:36:53.301638+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 4, "island_id": 1, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:37:13.749113+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 1, "population_idx": 3, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.090900", "model_name": "gpt-oss:20b", "train_signal": 0.09090036014405761}}
{"timestamp": "2026-02-13T00:37:13.749578+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 4, "island_id": 1, "population_idx": 3, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:37:47.707389+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i1_p4_778383496", "generation": 4, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3323409363745498, "spearman": 0.17298213942180002, "pearson": 0.39567991229263216, "rmse": 2.690073240518276, "mae": 2.5606747772904845, "simplicity_score": 0.12238135233830169, "novelty_bonus": 0.3041989930002468, "total_score": 0.20222703807863437, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\n\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strongest parts of the top two candidate formulas:\n    - Base ratio of nodes to edges (with safety offset)\n    - Degree balance factor (average vs maximum degree)\n    - Structural cohesion factor (density + clustering) modulated by transitivity\n    - Size scaling factor (square root of node count)\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strongest parts of the top two candidate formulas\n    and enriches them with additional structural statistics.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density factor (normalized by maximum possible triangles)\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Standard deviation penalty (larger std → smaller factor)\n    std_factor = 1 / (1 + std_deg)\n\n    # Minimum degree relative to average (encourages uniformity)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strongest parts of the top two candidate formulas\n    and enriches them with additional structural statistics.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density factor (normalized by maximum possible triangles)\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Standard deviation penalty (larger std → smaller factor)\n    std_factor = 1 / (1 + std_deg)\n\n    # Minimum degree relative to average (encourages uniformity)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )"}}
{"timestamp": "2026-02-13T00:38:20.977277+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:38:20.977815+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 4, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:39:04.615336+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i2_p0_759899441", "generation": 4, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.6581992797118849, "spearman": 0.5491924357580961, "pearson": 0.657093480745478, "rmse": 1.745781425751217, "mae": 1.6179722025356984, "simplicity_score": 0.17901091630774404, "novelty_bonus": 0.4087682044276554, "total_score": 0.4330288624688935, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is deliberately simple: a base term proportional to n / avg_degree\n    multiplied by several multiplicative adjustments that capture clustering,\n    degree variance, density, assortativity and triangle abundance.  All\n    operations use only built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)           # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ---- Base estimate ----------------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ---------------------------------------\n    # Compute variance of the degree sequence\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - (avg_deg * avg_deg)\n        var_deg = max(var_deg, 0.0)\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment -----------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment -----------------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors -----------------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length using a simple analytical model.\n    The model combines a random‑graph baseline with multiplicative adjustments\n    for clustering, degree variance, density, assortativity, and triangle\n    abundance.  Only the standard library is used, no external imports.\n    \"\"\"\n    import math\n\n    # --- Basic graph statistics with safe defaults --------------------------------\n    n          = s.get('n', 1)                     # number of nodes\n    m          = s.get('m', 1)                     # number of edges\n    avg_deg    = s.get('avg_degree', 1.0)          # mean degree\n    std_deg    = s.get('std_degree', 1.0)          # standard deviation of degrees\n    density    = s.get('density', 1e-6)            # edge density\n    trans      = s.get('transitivity', 0.0)        # global clustering\n    assort     = s.get('degree_assortativity', 0.0)# assortativity\n    triangles  = s.get('num_triangles', 0)         # total number of triangles\n\n    # Guard against pathological values\n    if n <= 1:\n        return 0.0\n    if avg_deg <= 0.0:\n        avg_deg = 1e-6\n    if std_deg <= 0.0:\n        std_deg = 1e-6\n    if density <= 0.0:\n        density = 1e-6\n    if m <= 0:\n        m = 1\n\n    # --- Random‑graph baseline ----------------------------------------------------\n    # Expected distance in an Erdős–Rényi graph scales as log(n)/log(avg_deg+1)\n    base = math.log(max(n, 2)) / math.log(max(avg_deg + 1.0, 2.0))\n\n    # --- Adjustments ----------------------------------------------------------------\n    # 1. Clustering: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * trans\n\n    # 2. Degree variance: higher variance tends to create hubs → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 3. Density: sparser graphs have longer paths\n    density_adj = math.sqrt(1.0 / (density + 1e-12))\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Triangle abundance relative to edges\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # --- Final estimate ------------------------------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula uses only built‑in Python functions, avoiding any external imports.\n    \"\"\"\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    std_deg    = s.get('std_degree', 1.0)\n    density    = s.get('density', 1e-6)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # guard against pathological values\n    if n <= 1:\n        return 0.0\n    if avg_deg <= 0:\n        avg_deg = 1e-6\n    if std_deg <= 0:\n        std_deg = 1e-6\n    if density <= 0:\n        density = 1e-6\n    if m <= 0:\n        m = 1\n\n    # base estimate – grows with sqrt(n) and shrinks with avg_degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # clustering adjustment – more global clustering lengthens paths\n    clustering_adj = 1.0 + trans\n\n    # variance adjustment – high degree variance (hubs) shortens paths\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - (avg_deg * avg_deg)\n        if var_deg < 0:\n            var_deg = 0.0\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # density adjustment – denser graphs have shorter paths\n    density_adj = 1.0 / (1.0 + density)\n\n    # assortativity adjustment – positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # triangle adjustment – many triangles relative to edges lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # combine all factors\n    estimate = (\n        base *\n        clustering_adj *\n        variance_adj *\n        density_adj *\n        assort_adj *\n        tri_adj\n    )\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula uses only built‑in Python functions, avoiding any external imports.\n    \"\"\"\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    std_deg    = s.get('std_degree', 1.0)\n    density    = s.get('density', 1e-6)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # guard against pathological values\n    if n <= 1:\n        return 0.0\n    if avg_deg <= 0:\n        avg_deg = 1e-6\n    if std_deg <= 0:\n        std_deg = 1e-6\n    if density <= 0:\n        density = 1e-6\n    if m <= 0:\n        m = 1\n\n    # base estimate – grows with sqrt(n) and shrinks with avg_degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # clustering adjustment – more global clustering lengthens paths\n    clustering_adj = 1.0 + trans\n\n    # variance adjustment – high degree variance (hubs) shortens paths\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - (avg_deg * avg_deg)\n        if var_deg < 0:\n            var_deg = 0.0\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # density adjustment – denser graphs have shorter paths\n    density_adj = 1.0 / (1.0 + density)\n\n    # assortativity adjustment – positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # triangle adjustment – many triangles relative to edges lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # combine all factors\n    estimate = (\n        base *\n        clustering_adj *\n        variance_adj *\n        density_adj *\n        assort_adj *\n        tri_adj\n    )\n\n    return estimate"}}
{"timestamp": "2026-02-13T00:39:04.616203+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 4, "island_id": 2, "population_idx": 0, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:40:07.971446+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i2_p1_194638707", "generation": 4, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.661656662665066, "spearman": 0.6036205668719268, "pearson": 0.6296150542905159, "rmse": 99.46000814499962, "mae": 63.15199295627992, "simplicity_score": 0.1780906593843658, "novelty_bonus": 0.44037318439360107, "total_score": 0.4695403706309169, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is deliberately simple: a base term proportional to n / avg_degree\n    multiplied by several multiplicative adjustments that capture clustering,\n    degree variance, density, assortativity and triangle abundance.  All\n    operations use only built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)           # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ---- Base estimate ----------------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ---------------------------------------\n    # Compute variance of the degree sequence\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - (avg_deg * avg_deg)\n        var_deg = max(var_deg, 0.0)\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment -----------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment -----------------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors -----------------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula uses only built‑in Python operations (no imports) and applies\n    multiplicative adjustments for clustering, degree variance, density,\n    assortativity, triangles, and degree extremes.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)                     # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n    max_deg    = s.get('max_degree', 0.0)\n    min_deg    = s.get('min_degree', 0.0)\n\n    # 1. Base estimate: grows with n, shrinks with avg degree\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering / transitivity increase path length\n    clustering_adj = 1.0 + avg_clust\n    trans_adj      = 1.0 + trans\n\n    # 3. Degree variance: higher variance shortens paths\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - avg_deg * avg_deg\n        var_deg = max(var_deg, 0.0)\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # 4. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 5. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + assort\n\n    # 6. Triangle abundance: more triangles lengthen paths\n    tri_adj = 1.0 + num_tri / (m + 1.0)\n\n    # 7. Max degree: very high hubs reduce path length\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 8. Min degree: low minimum degree can increase path length\n    min_adj = 1.0 + min_deg / (avg_deg + 1.0)\n\n    # Combine all factors\n    estimate = (base *\n                clustering_adj *\n                trans_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj *\n                max_adj *\n                min_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula uses only built‑in Python operations (no imports) and applies\n    multiplicative adjustments for clustering, degree variance, density,\n    assortativity, triangles, and degree extremes.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)                     # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n    max_deg    = s.get('max_degree', 0.0)\n    min_deg    = s.get('min_degree', 0.0)\n\n    # 1. Base estimate: grows with n, shrinks with avg degree\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering / transitivity increase path length\n    clustering_adj = 1.0 + avg_clust\n    trans_adj      = 1.0 + trans\n\n    # 3. Degree variance: higher variance shortens paths\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - avg_deg * avg_deg\n        var_deg = max(var_deg, 0.0)\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # 4. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 5. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + assort\n\n    # 6. Triangle abundance: more triangles lengthen paths\n    tri_adj = 1.0 + num_tri / (m + 1.0)\n\n    # 7. Max degree: very high hubs reduce path length\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 8. Min degree: low minimum degree can increase path length\n    min_adj = 1.0 + min_deg / (avg_deg + 1.0)\n\n    # Combine all factors\n    estimate = (base *\n                clustering_adj *\n                trans_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj *\n                max_adj *\n                min_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T00:40:49.203341+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i2_p2_363906031", "generation": 4, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.5431452581032412, "spearman": 0.41058666863674553, "pearson": 0.4114858212578708, "rmse": 11.640333219138084, "mae": 9.245446642084278, "simplicity_score": 0.18198143973225098, "novelty_bonus": 0.5135093377334432, "total_score": 0.3957424235848559, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is deliberately simple: a base term proportional to n / avg_degree\n    multiplied by several multiplicative adjustments that capture clustering,\n    degree variance, density, assortativity and triangle abundance.  All\n    operations use only built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)           # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ---- Base estimate ----------------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ---------------------------------------\n    # Compute variance of the degree sequence\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - (avg_deg * avg_deg)\n        var_deg = max(var_deg, 0.0)\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment -----------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment -----------------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors -----------------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula uses only built‑in Python operations and safe defaults.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    if density <= 0:\n        density = 1e-6\n\n    clustering = s.get('avg_clustering', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # 1. Base estimate: grows with size and shrinks with connectivity\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + clustering\n\n    # 3. Degree‑variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1.0)\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 6. Triangle count adjustment: many triangles relative to edges → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula uses only built‑in Python operations and safe defaults.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    if density <= 0:\n        density = 1e-6\n\n    clustering = s.get('avg_clustering', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # 1. Base estimate: grows with size and shrinks with connectivity\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + clustering\n\n    # 3. Degree‑variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1.0)\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 6. Triangle count adjustment: many triangles relative to edges → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T00:42:09.556099+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i2_p3_466721003", "generation": 4, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7774789915966386, "spearman": 0.7915723361480855, "pearson": 0.7664959972004122, "rmse": 36.00341843406528, "mae": 26.21029429314776, "simplicity_score": 0.1792920388593393, "novelty_bonus": 0.2821550543737191, "total_score": 0.5162910921580264, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is deliberately simple: a base term proportional to n / avg_degree\n    multiplied by several multiplicative adjustments that capture clustering,\n    degree variance, density, assortativity and triangle abundance.  All\n    operations use only built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)           # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ---- Base estimate ----------------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ---------------------------------------\n    # Compute variance of the degree sequence\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - (avg_deg * avg_deg)\n        var_deg = max(var_deg, 0.0)\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment -----------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment -----------------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors -----------------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    min_deg    = s.get('min_degree', 0)\n    max_deg    = s.get('max_degree', 0)\n\n    # Avoid division by zero / negative values\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    if std_deg < 0:\n        std_deg = 0.0\n\n    # 1. Base estimate: larger graphs and lower average degree give longer paths\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment – more triangles or transitivity → longer paths\n    clustering_adj = 1.0 + 0.5 * (avg_clust + trans)\n\n    # 3. Degree‑variance adjustment – high variance (hubs) → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment – denser graphs → shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 5. Assortativity adjustment – positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 6. Triangle ratio adjustment – many triangles relative to edges → longer paths\n    tri_ratio = num_tri / (m + 1.0)\n    tri_adj   = 1.0 + 0.5 * tri_ratio\n\n    # 7. Minimum degree adjustment – higher min degree indicates better connectivity\n    min_adj = 1.0 / (1.0 + min_deg / (avg_deg + 1.0))\n\n    # 8. Maximum degree adjustment – hubs (high max degree) shorten paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # Combine all factors multiplicatively\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj *\n                min_adj *\n                max_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    min_deg    = s.get('min_degree', 0)\n    max_deg    = s.get('max_degree', 0)\n\n    # Avoid division by zero / negative values\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    if std_deg < 0:\n        std_deg = 0.0\n\n    # 1. Base estimate: larger graphs and lower average degree give longer paths\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment – more triangles or transitivity → longer paths\n    clustering_adj = 1.0 + 0.5 * (avg_clust + trans)\n\n    # 3. Degree‑variance adjustment – high variance (hubs) → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment – denser graphs → shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 5. Assortativity adjustment – positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 6. Triangle ratio adjustment – many triangles relative to edges → longer paths\n    tri_ratio = num_tri / (m + 1.0)\n    tri_adj   = 1.0 + 0.5 * tri_ratio\n\n    # 7. Minimum degree adjustment – higher min degree indicates better connectivity\n    min_adj = 1.0 / (1.0 + min_deg / (avg_deg + 1.0))\n\n    # 8. Maximum degree adjustment – hubs (high max degree) shorten paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # Combine all factors multiplicatively\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj *\n                min_adj *\n                max_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T00:42:48.393024+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i2_p4_497791541", "generation": 4, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.740408163265306, "spearman": 0.7094625026110537, "pearson": 0.7847771281008242, "rmse": 175.4977924756807, "mae": 130.03556801684707, "simplicity_score": 0.18224288748445794, "novelty_bonus": 0.3494580560566627, "total_score": 0.49601724561941724, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is deliberately simple: a base term proportional to n / avg_degree\n    multiplied by several multiplicative adjustments that capture clustering,\n    degree variance, density, assortativity and triangle abundance.  All\n    operations use only built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)           # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ---- Base estimate ----------------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ---------------------------------------\n    # Compute variance of the degree sequence\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - (avg_deg * avg_deg)\n        var_deg = max(var_deg, 0.0)\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment -----------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment -----------------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors -----------------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula uses only built‑in Python operations and avoids any imports.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n            = s.get('n', 0)\n    m            = s.get('m', 0)\n    avg_deg      = s.get('avg_degree', 1.0)\n    avg_deg      = max(avg_deg, 1e-6)          # avoid division by zero\n    avg_clust    = s.get('avg_clustering', 0.0)\n    std_deg      = s.get('std_degree', 0.0)\n    std_deg      = max(std_deg, 0.0)\n    density      = s.get('density', 0.0)\n    density      = max(density, 1e-6)          # avoid division by zero\n    assort       = s.get('degree_assortativity', 0.0)\n    num_tri      = s.get('num_triangles', 0)\n\n    # 1. Base estimate: larger n and smaller average degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment: more triangles tend to increase path lengths\n    clustering_adj = 1.0 + avg_clust\n\n    # 3. Degree‑variance adjustment: higher variance tends to shorten paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: denser graphs usually have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # 6. Triangle adjustment: more triangles relative to edges lengthen paths\n    tri_adj = 1.0 + num_tri / (m + 1.0)\n\n    # Combine all factors\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula uses only built‑in Python operations and avoids any imports.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n            = s.get('n', 0)\n    m            = s.get('m', 0)\n    avg_deg      = s.get('avg_degree', 1.0)\n    avg_deg      = max(avg_deg, 1e-6)          # avoid division by zero\n    avg_clust    = s.get('avg_clustering', 0.0)\n    std_deg      = s.get('std_degree', 0.0)\n    std_deg      = max(std_deg, 0.0)\n    density      = s.get('density', 0.0)\n    density      = max(density, 1e-6)          # avoid division by zero\n    assort       = s.get('degree_assortativity', 0.0)\n    num_tri      = s.get('num_triangles', 0)\n\n    # 1. Base estimate: larger n and smaller average degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment: more triangles tend to increase path lengths\n    clustering_adj = 1.0 + avg_clust\n\n    # 3. Degree‑variance adjustment: higher variance tends to shorten paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: denser graphs usually have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # 6. Triangle adjustment: more triangles relative to edges lengthen paths\n    tri_adj = 1.0 + num_tri / (m + 1.0)\n\n    # Combine all factors\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T00:43:17.327997+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.070981", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:43:58.649229+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:43:58.649802+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 4, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:44:26.623730+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.076889", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:44:26.624440+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 4, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:45:04.901448+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.087059", "model_name": "gpt-oss:20b", "train_signal": 0.08705882352941177}}
{"timestamp": "2026-02-13T00:45:29.544873+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i3_p3_43803765", "generation": 4, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.7733580018501388, "spearman": -0.5176074485235316, "pearson": -0.3323906555214724, "rmse": 53.42312398289512, "mae": 41.5169773934602, "simplicity_score": 0.18156973355038536, "novelty_bonus": 0.40562853270443633, "total_score": 0.4168062307831738, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how average path length relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    A composite invariant that mixes several pre‑computed graph statistics\n    to produce a value correlated with the average shortest‑path length.\n    It uses only arithmetic, comparisons, and basic Python built‑ins.\n\n    Keys required from the dictionary `s`:\n        - n                 (int) number of nodes\n        - m                 (int) number of edges\n        - density           (float) edge density\n        - avg_degree        (float) average degree\n        - max_degree        (int) maximum degree\n        - min_degree        (int) minimum degree\n        - std_degree        (float) degree standard deviation\n        - avg_clustering    (float) average local clustering coefficient\n        - transitivity      (float) global transitivity (overall clustering)\n        - degree_assortativity (float) degree assortativity coefficient\n        - num_triangles     (int) number of triangles\n        - degrees           (list[int]) sorted degree sequence\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Size to sparsity ratio\n    size_edge_ratio = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree dispersion: relative spread compared to variation\n    degree_spread = (s['max_degree'] - s['min_degree'] + 1.0)\n    degree_variation = s['std_degree'] + 1.0\n    degree_dispersion = degree_spread / degree_variation\n\n    # 3. Triangle density: triangles per node (shifted to avoid zero)\n    triangle_density = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Local triangle power: square of clustering and transitivity\n    clustering_power = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # 5. Assortativity magnitude: square to make always positive\n    assort_magnitude = s['degree_assortativity'] ** 2 + 1.0\n\n    # ------------------------------------------------------------------\n    # Combine everything into one scalar\n    # The product of the first three components emphasizes sparsity,\n    # degree spread, and triangle abundance – all of which can affect\n    # path lengths.  Dividing by the clustering and assortativity terms\n    # dampens the effect of very high clustering or strong degree\n    # correlations.\n    invariant = (\n        size_edge_ratio\n        * degree_dispersion\n        * triangle_density\n    ) / (\n        clustering_power\n        * assort_magnitude\n    )\n\n    return invariant\n\ndef new_invariant(s):\n    \"\"\"\n    A novel invariant intended to correlate with the average shortest path length\n    using only the pre‑computed structural features provided in *s*.\n\n    The formula blends several independent aspects of the network:\n      • Normalized size versus edge count (comp1)\n      • Degree spread relative to variability (comp2)\n      • Triangle density relative to size (comp3)\n      • Average clustering and global transitivity (comp4)\n      • Degree assortativity magnitude (comp5)\n\n    By multiplying the first three components and dividing by the latter two,\n    we encourage the invariant to increase when the graph is small, sparse, \n    has diverse degrees, many triangles, high clustering, and low assortativity,\n    all of which tend to reduce the typical path length.\n    \"\"\"\n\n    # Core components\n    comp1 = (s['n'] + 1.0) / (s['m'] + 1.0)                     # size–to–edges ratio\n    comp2 = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)  # degree spread vs std\n    comp3 = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)         # triangle density\n\n    # Regularization terms\n    comp4 = (s['avg_clustering']**2 + s['transitivity']**2) / 2.0   # clustering/ transitivity combo\n    comp5 = (s['degree_assortativity']**2 + 1.0)                    # assortativity magnitude\n\n    # Combine into a single scalar\n    return (comp1 * comp2 * comp3) / (comp4 * comp5)\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant crafted from a set of pre‑computed structural\n    statistics. The expression mixes size, density, degree dispersion,\n    triangle density, clustering, transitivity, assortativity and degree\n    balance in a non‑trivial way, avoiding a single dominant term.\n    \"\"\"\n    # Core measurements\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    clust      = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triads     = s['num_triangles']\n\n    # Build component ratios that reflect different aspects of the topology\n    size_edge_ratio   = (n + 1.0) / (m + 1.0)                     # relative sparsity\n    degree_dispersion = (max_deg - min_deg + 1.0) / (std_deg + 1.0)  # spread vs variation\n    triangle_density  = (triads + 1.0) / (n + 1.0)                   # shortcut opportunities\n    clustering_power  = (clust**2 + trans**2)                        # strength of local triangles\n    assort_power      = (assort**2 + 1.0)                            # magnitude of degree correlation\n\n    # Combine all ingredients with a few additional multiplicative corrections\n    inv = size_edge_ratio * degree_dispersion * triangle_density\n    inv /= (clustering_power + 1e-6)                                 # avoid division by zero\n    inv /= (assort_power + 1e-6)\n\n    # Minor adjustment with average degree to keep the scale reasonable\n    inv *= (avg_deg + 1.0) / (max_deg + 1.0)\n\n    return inv\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.076889\nbelow_train_threshold: train_signal=0.087059\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that mixes size, sparsity, degree dispersion,\n    triangle abundance, clustering strength, and degree assortativity.\n    All operations use only built‑in arithmetic to avoid external imports.\n    \"\"\"\n    # Size to edge ratio – captures overall sparsity\n    size_edge = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # Degree dispersion relative to variability – higher spread suggests\n    # longer paths through hubs\n    deg_disp = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # Triangle density – more triangles usually shorten paths\n    tri_dense = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # Combined clustering factor – square to amplify the effect\n    cluster_factor = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # Assortativity magnitude – strong correlation can create bottlenecks\n    assort_factor = (s['degree_assortativity'] ** 2 + 1.0)\n\n    # Final invariant: product of sparsity, dispersion, and triangle terms,\n    # divided by clustering and assortativity terms\n    invariant = (size_edge * deg_disp * tri_dense) / (cluster_factor * assort_factor)\n\n    return invariant\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that mixes size, sparsity, degree dispersion,\n    triangle abundance, clustering strength, and degree assortativity.\n    All operations use only built‑in arithmetic to avoid external imports.\n    \"\"\"\n    # Size to edge ratio – captures overall sparsity\n    size_edge = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # Degree dispersion relative to variability – higher spread suggests\n    # longer paths through hubs\n    deg_disp = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # Triangle density – more triangles usually shorten paths\n    tri_dense = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # Combined clustering factor – square to amplify the effect\n    cluster_factor = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # Assortativity magnitude – strong correlation can create bottlenecks\n    assort_factor = (s['degree_assortativity'] ** 2 + 1.0)\n\n    # Final invariant: product of sparsity, dispersion, and triangle terms,\n    # divided by clustering and assortativity terms\n    invariant = (size_edge * deg_disp * tri_dense) / (cluster_factor * assort_factor)\n\n    return invariant"}}
{"timestamp": "2026-02-13T00:45:58.083828+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i3_p4_546569503", "generation": 4, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.34213685474189676, "spearman": -0.018974731483812738, "pearson": 0.34618195010540975, "rmse": 17298.765252457884, "mae": 3164.0565039235667, "simplicity_score": 0.25384115519850103, "novelty_bonus": 0.16468957553628016, "total_score": 0.10966246944249063, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how average path length relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    A composite invariant that mixes several pre‑computed graph statistics\n    to produce a value correlated with the average shortest‑path length.\n    It uses only arithmetic, comparisons, and basic Python built‑ins.\n\n    Keys required from the dictionary `s`:\n        - n                 (int) number of nodes\n        - m                 (int) number of edges\n        - density           (float) edge density\n        - avg_degree        (float) average degree\n        - max_degree        (int) maximum degree\n        - min_degree        (int) minimum degree\n        - std_degree        (float) degree standard deviation\n        - avg_clustering    (float) average local clustering coefficient\n        - transitivity      (float) global transitivity (overall clustering)\n        - degree_assortativity (float) degree assortativity coefficient\n        - num_triangles     (int) number of triangles\n        - degrees           (list[int]) sorted degree sequence\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Size to sparsity ratio\n    size_edge_ratio = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree dispersion: relative spread compared to variation\n    degree_spread = (s['max_degree'] - s['min_degree'] + 1.0)\n    degree_variation = s['std_degree'] + 1.0\n    degree_dispersion = degree_spread / degree_variation\n\n    # 3. Triangle density: triangles per node (shifted to avoid zero)\n    triangle_density = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Local triangle power: square of clustering and transitivity\n    clustering_power = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # 5. Assortativity magnitude: square to make always positive\n    assort_magnitude = s['degree_assortativity'] ** 2 + 1.0\n\n    # ------------------------------------------------------------------\n    # Combine everything into one scalar\n    # The product of the first three components emphasizes sparsity,\n    # degree spread, and triangle abundance – all of which can affect\n    # path lengths.  Dividing by the clustering and assortativity terms\n    # dampens the effect of very high clustering or strong degree\n    # correlations.\n    invariant = (\n        size_edge_ratio\n        * degree_dispersion\n        * triangle_density\n    ) / (\n        clustering_power\n        * assort_magnitude\n    )\n\n    return invariant\n\ndef new_invariant(s):\n    \"\"\"\n    A novel invariant intended to correlate with the average shortest path length\n    using only the pre‑computed structural features provided in *s*.\n\n    The formula blends several independent aspects of the network:\n      • Normalized size versus edge count (comp1)\n      • Degree spread relative to variability (comp2)\n      • Triangle density relative to size (comp3)\n      • Average clustering and global transitivity (comp4)\n      • Degree assortativity magnitude (comp5)\n\n    By multiplying the first three components and dividing by the latter two,\n    we encourage the invariant to increase when the graph is small, sparse, \n    has diverse degrees, many triangles, high clustering, and low assortativity,\n    all of which tend to reduce the typical path length.\n    \"\"\"\n\n    # Core components\n    comp1 = (s['n'] + 1.0) / (s['m'] + 1.0)                     # size–to–edges ratio\n    comp2 = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)  # degree spread vs std\n    comp3 = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)         # triangle density\n\n    # Regularization terms\n    comp4 = (s['avg_clustering']**2 + s['transitivity']**2) / 2.0   # clustering/ transitivity combo\n    comp5 = (s['degree_assortativity']**2 + 1.0)                    # assortativity magnitude\n\n    # Combine into a single scalar\n    return (comp1 * comp2 * comp3) / (comp4 * comp5)\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant crafted from a set of pre‑computed structural\n    statistics. The expression mixes size, density, degree dispersion,\n    triangle density, clustering, transitivity, assortativity and degree\n    balance in a non‑trivial way, avoiding a single dominant term.\n    \"\"\"\n    # Core measurements\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    clust      = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triads     = s['num_triangles']\n\n    # Build component ratios that reflect different aspects of the topology\n    size_edge_ratio   = (n + 1.0) / (m + 1.0)                     # relative sparsity\n    degree_dispersion = (max_deg - min_deg + 1.0) / (std_deg + 1.0)  # spread vs variation\n    triangle_density  = (triads + 1.0) / (n + 1.0)                   # shortcut opportunities\n    clustering_power  = (clust**2 + trans**2)                        # strength of local triangles\n    assort_power      = (assort**2 + 1.0)                            # magnitude of degree correlation\n\n    # Combine all ingredients with a few additional multiplicative corrections\n    inv = size_edge_ratio * degree_dispersion * triangle_density\n    inv /= (clustering_power + 1e-6)                                 # avoid division by zero\n    inv /= (assort_power + 1e-6)\n\n    # Minor adjustment with average degree to keep the scale reasonable\n    inv *= (avg_deg + 1.0) / (max_deg + 1.0)\n\n    return inv\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.076889\nbelow_train_threshold: train_signal=0.087059\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    A composite invariant that mixes several pre‑computed graph statistics\n    to produce a value that correlates with the average shortest‑path length.\n\n    The invariant uses only arithmetic, comparisons, and Python built‑ins.\n    It combines:\n      • Size‑to‑edge ratio  (s['n'] / s['m'])\n      • Degree dispersion  (max – min over std)\n      • Triangle abundance  (num_triangles per node, cube‑root scaled)\n      • Clustering / transitivity (denominator)\n      • Degree assortativity magnitude (denominator)\n      • Average degree (square‑root scaling)\n\n    The expression avoids division by zero by adding +1 or small epsilons\n    where necessary. No external libraries are imported.\n    \"\"\"\n    # Core ratios and scales\n    size_edge  = (s['n'] + 1.0) / (s['m'] + 1.0)                      # sparsity\n    degree_spread = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)  # dispersion\n    triangle_root = (s['num_triangles'] + 1.0) ** (1.0/3.0) / (s['n'] + 1.0)  # triangle density, cube‑root\n\n    # Normalising factors\n    clustering = (s['avg_clustering'] + s['transitivity'] + 1e-6)     # to avoid zero\n    assort_mag  = abs(s['degree_assortativity']) + 1.0                # magnitude\n\n    # Assemble the invariant\n    inv = size_edge * degree_spread * triangle_root\n    inv /= (clustering * assort_mag)\n\n    # Optional adjustment with average degree to keep the scale reasonable\n    inv *= (s['avg_degree'] + 1.0) ** 0.5\n\n    return inv\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    A composite invariant that mixes several pre‑computed graph statistics\n    to produce a value that correlates with the average shortest‑path length.\n\n    The invariant uses only arithmetic, comparisons, and Python built‑ins.\n    It combines:\n      • Size‑to‑edge ratio  (s['n'] / s['m'])\n      • Degree dispersion  (max – min over std)\n      • Triangle abundance  (num_triangles per node, cube‑root scaled)\n      • Clustering / transitivity (denominator)\n      • Degree assortativity magnitude (denominator)\n      • Average degree (square‑root scaling)\n\n    The expression avoids division by zero by adding +1 or small epsilons\n    where necessary. No external libraries are imported.\n    \"\"\"\n    # Core ratios and scales\n    size_edge  = (s['n'] + 1.0) / (s['m'] + 1.0)                      # sparsity\n    degree_spread = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)  # dispersion\n    triangle_root = (s['num_triangles'] + 1.0) ** (1.0/3.0) / (s['n'] + 1.0)  # triangle density, cube‑root\n\n    # Normalising factors\n    clustering = (s['avg_clustering'] + s['transitivity'] + 1e-6)     # to avoid zero\n    assort_mag  = abs(s['degree_assortativity']) + 1.0                # magnitude\n\n    # Assemble the invariant\n    inv = size_edge * degree_spread * triangle_root\n    inv /= (clustering * assort_mag)\n\n    # Optional adjustment with average degree to keep the scale reasonable\n    inv *= (s['avg_degree'] + 1.0) ** 0.5\n\n    return inv"}}
{"timestamp": "2026-02-13T00:45:58.086599+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "phase1_20260212T231418Z", "generation": 5, "model_name": "gpt-oss:20b", "best_val_score": 0.5491013268732999, "no_improve_count": 3}}
{"timestamp": "2026-02-13T00:47:14.275302+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i0_p0_154289491", "generation": 5, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.721968787515006, "spearman": 0.6058661238529354, "pearson": 0.684174274798132, "rmse": 38.251725825504565, "mae": 35.24648419569935, "simplicity_score": 0.24673484053409034, "novelty_bonus": 0.40150773642474036, "total_score": 0.47273235096070787, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density) * (1 + 1.2 * trans) * (1 + 1.1 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list of degrees\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.6 * density) * (1 + 1.3 * clustering) * (1 + trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.4 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.3 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.3 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list of degrees\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.6 * density) * (1 + 1.3 * clustering) * (1 + trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.4 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.3 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.3 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T00:48:12.617272+00:00", "event_type": "candidate_rejected", "payload": {"generation": 5, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:48:12.619950+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 5, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:48:39.801149+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i0_p1_743375907", "generation": 5, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7052581032412966, "spearman": 0.5487311740535803, "pearson": 0.6067136738272993, "rmse": 84.90106859068977, "mae": 73.37160022783917, "simplicity_score": 0.2477472396632161, "novelty_bonus": 0.3950579294088712, "total_score": 0.4424324137820947, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density) * (1 + 1.2 * trans) * (1 + 1.1 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    import numpy as np\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n\n    # Baseline estimate based on log‑ratio of size to average degree\n    base = np.log(n + 1) / np.log(avg_deg + 2)\n\n    # Multiplicative adjustments\n    f_density = 1 + (1 - density)          # lower density → longer paths\n    f_trans   = 1 + (1 - trans)            # lower transitivity → longer paths\n    f_cluster = 1 + (1 - clustering)       # lower clustering → longer paths\n    f_assort  = 1 + abs(assort)             # higher assortativity → shorter paths\n    f_tri     = 1 + (num_tri / (n**2 + 1))  # more triangles → shorter paths\n    f_std     = 1 + (std_deg / (avg_deg + 1))   # higher degree variance → longer paths\n    f_spread  = 1 + ((max_deg - min_deg) / (max_deg + 1))  # larger spread → longer paths\n\n    # Median degree factor\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    f_median = 1 + (median_deg / (avg_deg + 1))\n\n    val = base * f_density * f_trans * f_cluster * f_assort * f_tri * f_std * f_spread * f_median\n    return val\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    # Unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger graphs with lower average degree tend to have longer paths\n    base = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    f_density = 1 + density          # higher density → shorter paths\n    f_trans   = 1 + trans            # higher transitivity → shorter paths\n    f_cluster = 1 + clustering       # higher clustering → shorter paths\n    f_assort  = 1 + abs(assort)      # higher assortativity → shorter paths\n    f_tri     = 1 + num_tri / (n**2 + 1)  # more triangles → shorter paths\n\n    # Factors that tend to lengthen paths\n    f_std     = 1 + std_deg / (avg_deg + 1)          # higher degree variance → longer paths\n    f_spread  = 1 + (max_deg - min_deg) / (max_deg + 1)  # larger degree spread → longer paths\n\n    # Median degree factor\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    f_median = 1 + median_deg / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    val = base * f_density * f_trans * f_cluster * f_assort * f_tri * f_std * f_spread * f_median\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # Unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger graphs with lower average degree tend to have longer paths\n    base = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    f_density = 1 + density          # higher density → shorter paths\n    f_trans   = 1 + trans            # higher transitivity → shorter paths\n    f_cluster = 1 + clustering       # higher clustering → shorter paths\n    f_assort  = 1 + abs(assort)      # higher assortativity → shorter paths\n    f_tri     = 1 + num_tri / (n**2 + 1)  # more triangles → shorter paths\n\n    # Factors that tend to lengthen paths\n    f_std     = 1 + std_deg / (avg_deg + 1)          # higher degree variance → longer paths\n    f_spread  = 1 + (max_deg - min_deg) / (max_deg + 1)  # larger degree spread → longer paths\n\n    # Median degree factor\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    f_median = 1 + median_deg / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    val = base * f_density * f_trans * f_cluster * f_assort * f_tri * f_std * f_spread * f_median\n    return val"}}
{"timestamp": "2026-02-13T00:48:39.802770+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 5, "island_id": 0, "population_idx": 1, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T00:49:15.055709+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i0_p2_683048953", "generation": 5, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6908523409363745, "spearman": 0.6738268483563243, "pearson": 0.5847698215189026, "rmse": 121.0581251378014, "mae": 107.67923246231236, "simplicity_score": 0.24730123927307743, "novelty_bonus": 0.24452193008368373, "total_score": 0.4597302510578828, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density) * (1 + 1.2 * trans) * (1 + 1.1 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # already sorted\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and transitivity provide shortcuts\n    val *= (1 + density) * (1 + trans)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles give local shortcuts; dampen large counts with sqrt\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # already sorted\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and transitivity provide shortcuts\n    val *= (1 + density) * (1 + trans)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles give local shortcuts; dampen large counts with sqrt\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T00:50:49.057680+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i0_p3_922527839", "generation": 5, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7439615846338534, "spearman": 0.655025371268842, "pearson": 0.7429143633550883, "rmse": 20.643977528172748, "mae": 19.142462466422064, "simplicity_score": 0.25062504096016025, "novelty_bonus": 0.37230234383339034, "total_score": 0.4893283969764702, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density) * (1 + 1.2 * trans) * (1 + 1.1 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density, clustering and transitivity tend to shorten paths\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.3 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density, clustering and transitivity tend to shorten paths\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.3 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T00:52:41.011440+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i0_p4_744762155", "generation": 5, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7438655462184873, "spearman": 0.6878214534694302, "pearson": 0.6938919334595143, "rmse": 52.39100159910548, "mae": 47.88619473907707, "simplicity_score": 0.24656480581498377, "novelty_bonus": 0.3336725934608116, "total_score": 0.4933254659359554, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density) * (1 + 1.2 * trans) * (1 + 1.1 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    trans = s['transitivity']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density and clustering tend to shorten paths; give them a stronger effect\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n\n    # Transitivity adds additional shortcut potential\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar-degree nodes, often shortening paths\n    # Reduce the penalty for negative assortativity\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles create local shortcuts; moderate their influence\n    val *= (1 + 0.5 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that shorten paths\n    val *= (1 + density) * (1 + trans)\n\n    # Clustering can slightly increase path length\n    val *= (1 + clustering)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # already sorted\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n    val *= (1 + trans)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.5 * (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # already sorted\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n    val *= (1 + trans)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.5 * (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T00:54:11.357326+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i1_p0_366642656", "generation": 5, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3323409363745498, "spearman": 0.17298213942180002, "pearson": 0.39567991229263216, "rmse": 2.690073240518276, "mae": 2.5606747772904845, "simplicity_score": 0.12245670947119695, "novelty_bonus": 0.3041989930002468, "total_score": 0.20224210950521343, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strongest parts of the top two candidate formulas\n    and enriches them with additional structural statistics.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density factor (normalized by maximum possible triangles)\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Standard deviation penalty (larger std → smaller factor)\n    std_factor = 1 / (1 + std_deg)\n\n    # Minimum degree relative to average (encourages uniformity)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )"}}
{"timestamp": "2026-02-13T00:55:31.073842+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i1_p1_967509732", "generation": 5, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3323409363745498, "spearman": 0.17298213942180002, "pearson": 0.39567991229263216, "rmse": 2.690073240518276, "mae": 2.5606747772904845, "simplicity_score": 0.12238135233830169, "novelty_bonus": 0.3041989930002468, "total_score": 0.20222703807863437, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strongest parts of the top two candidate formulas\n    and enriches them with additional structural statistics.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density factor (normalized by maximum possible triangles)\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Standard deviation penalty (larger std → smaller factor)\n    std_factor = 1 / (1 + std_deg)\n\n    # Minimum degree relative to average (encourages uniformity)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strongest parts of the top two candidate formulas\n    and enriches them with additional structural statistics.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density factor (normalized by maximum possible triangles)\n    max_triangles = max(1, (n * (n - 1)) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Standard deviation penalty (larger std → smaller factor)\n    std_factor = 1 / (1 + std_deg)\n\n    # Minimum degree relative to average (encourages uniformity)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strongest parts of the top two candidate formulas\n    and enriches them with additional structural statistics.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density factor (normalized by maximum possible triangles)\n    max_triangles = max(1, (n * (n - 1)) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Standard deviation penalty (larger std → smaller factor)\n    std_factor = 1 / (1 + std_deg)\n\n    # Minimum degree relative to average (encourages uniformity)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )"}}
{"timestamp": "2026-02-13T00:57:28.907795+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i1_p2_905535765", "generation": 5, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3323409363745498, "spearman": 0.17298213942180002, "pearson": 0.39567991229263216, "rmse": 2.690073240518276, "mae": 2.5606747772904845, "simplicity_score": 0.12245670947119695, "novelty_bonus": 0.3041989930002468, "total_score": 0.20224210950521343, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strongest parts of the top two candidate formulas\n    and enriches them with additional structural statistics.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density factor (normalized by maximum possible triangles)\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Standard deviation penalty (larger std → smaller factor)\n    std_factor = 1 / (1 + std_deg)\n\n    # Minimum degree relative to average (encourages uniformity)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return base * deg_factor * struct_factor * sqrt_factor * assort_factor * triangle_factor * std_factor * min_factor", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return base * deg_factor * struct_factor * sqrt_factor * assort_factor * triangle_factor * std_factor * min_factor"}}
{"timestamp": "2026-02-13T00:58:59.353895+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i1_p3_370459705", "generation": 5, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3323409363745498, "spearman": 0.17298213942180002, "pearson": 0.39567991229263216, "rmse": 2.690073240518276, "mae": 2.5606747772904845, "simplicity_score": 0.12238135233830169, "novelty_bonus": 0.3041989930002468, "total_score": 0.20222703807863437, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strongest parts of the top two candidate formulas\n    and enriches them with additional structural statistics.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density factor (normalized by maximum possible triangles)\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Standard deviation penalty (larger std → smaller factor)\n    std_factor = 1 / (1 + std_deg)\n\n    # Minimum degree relative to average (encourages uniformity)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strongest parts of the top two candidate formulas\n    and enriches them with additional structural statistics.\n    \"\"\"\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density factor (normalized by maximum possible triangles)\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Standard deviation penalty (larger std → smaller factor)\n    std_factor = 1 / (1 + std_deg)\n\n    # Minimum degree relative to average (encourages uniformity)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Final invariant value\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strongest parts of the top two candidate formulas\n    and enriches them with additional structural statistics.\n    \"\"\"\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density factor (normalized by maximum possible triangles)\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Standard deviation penalty (larger std → smaller factor)\n    std_factor = 1 / (1 + std_deg)\n\n    # Minimum degree relative to average (encourages uniformity)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Final invariant value\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )"}}
{"timestamp": "2026-02-13T01:01:16.931260+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i1_p4_76343185", "generation": 5, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3323409363745498, "spearman": 0.17298213942180002, "pearson": 0.39567991229263216, "rmse": 2.690073240518276, "mae": 2.5606747772904845, "simplicity_score": 0.1243112330904912, "novelty_bonus": 0.3041989930002468, "total_score": 0.2026130142290723, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant that blends the strongest parts of the top two candidate formulas\n    and enriches them with additional structural statistics.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Base ratio of nodes to edges (with safety offset)\n    base = n / (m + 1)\n\n    # Degree balance factor (average vs maximum)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion factor (density + clustering) modulated by transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density factor (normalized by maximum possible triangles)\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Standard deviation penalty (larger std → smaller factor)\n    std_factor = 1 / (1 + std_deg)\n\n    # Minimum degree relative to average (encourages uniformity)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges (with a safety offset)\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    return base * deg_factor * struct_factor\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Base ratio of nodes to edges\n    base = n / (m + 1)\n\n    # Degree factor balancing average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural factor combining density, clustering, and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling factor (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    return base * deg_factor * struct_factor * sqrt_factor\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )"}}
{"timestamp": "2026-02-13T01:02:57.334822+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i2_p0_469555811", "generation": 5, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7260984393757502, "spearman": 0.6701397547963251, "pearson": 0.7550755203629158, "rmse": 241.9229437798454, "mae": 169.23526014213496, "simplicity_score": 0.18164728412469894, "novelty_bonus": 0.35294829484484824, "total_score": 0.4772838226765568, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is deliberately simple: a base term proportional to n / avg_degree\n    multiplied by several multiplicative adjustments that capture clustering,\n    degree variance, density, assortativity and triangle abundance.  All\n    operations use only built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)           # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ---- Base estimate ----------------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ---------------------------------------\n    # Compute variance of the degree sequence\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - (avg_deg * avg_deg)\n        var_deg = max(var_deg, 0.0)\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment -----------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment -----------------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors -----------------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines several multiplicative adjustments that capture\n    clustering, degree heterogeneity, density, assortativity and triangle\n    abundance.  All operations use only built‑in Python functions – no\n    external imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)           # avoid division by zero\n\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    std_deg    = s.get('std_degree', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # ---- Base estimate ----------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment ---------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Transitivity adjustment ------------------------------------\n    trans_adj = 1.0 + trans\n\n    # ---- Assortativity adjustment ------------------------------------\n    assort_adj = 1.0 + assort\n\n    # ---- Density adjustment -----------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Degree‑variance adjustment ----------------------------------\n    # Higher variance tends to shorten paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # ---- Triangle adjustment ----------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors ----------------------------------------\n    estimate = (base *\n                clustering_adj *\n                trans_adj *\n                assort_adj *\n                density_adj *\n                variance_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines several multiplicative adjustments that capture\n    clustering, degree heterogeneity, density, assortativity and triangle\n    abundance.  All operations use only built‑in Python functions – no\n    external imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)           # avoid division by zero\n\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    std_deg    = s.get('std_degree', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # ---- Base estimate ----------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment ---------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Transitivity adjustment ------------------------------------\n    trans_adj = 1.0 + trans\n\n    # ---- Assortativity adjustment ------------------------------------\n    assort_adj = 1.0 + assort\n\n    # ---- Density adjustment -----------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Degree‑variance adjustment ----------------------------------\n    # Higher variance tends to shorten paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # ---- Triangle adjustment ----------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors ----------------------------------------\n    estimate = (base *\n                clustering_adj *\n                trans_adj *\n                assort_adj *\n                density_adj *\n                variance_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T01:04:52.095647+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i2_p1_795679975", "generation": 5, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7717166866746699, "spearman": 0.7942491540723404, "pearson": 0.7778345034966295, "rmse": 137.44341266720238, "mae": 96.54304750380643, "simplicity_score": 0.18224288748445794, "novelty_bonus": 0.29681799242916773, "total_score": 0.5226185522618121, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is deliberately simple: a base term proportional to n / avg_degree\n    multiplied by several multiplicative adjustments that capture clustering,\n    degree variance, density, assortativity and triangle abundance.  All\n    operations use only built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)           # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ---- Base estimate ----------------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ---------------------------------------\n    # Compute variance of the degree sequence\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - (avg_deg * avg_deg)\n        var_deg = max(var_deg, 0.0)\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment -----------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment -----------------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors -----------------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term (n / (avg_degree+1)) and several\n    multiplicative adjustments that capture clustering, degree variance,\n    density, assortativity and triangle abundance.  All operations use only\n    built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n   = s.get('n', 1)\n    m   = s.get('m', 1)\n    avg_deg   = s.get('avg_degree', 1.0)\n    avg_deg   = max(avg_deg, 1e-6)           # avoid division by zero\n    density   = s.get('density', 0.0)\n    density   = max(density, 1e-6)           # avoid division by zero\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    std_deg    = s.get('std_degree', 0.0)\n\n    # ---- Base estimate ----------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ----------------------------------\n    # Higher variance tends to shorten paths\n    var_deg = std_deg * std_deg\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment ------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment ----------------------------------------\n    # More triangles relative to edges lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors ----------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term (n / (avg_degree+1)) and several\n    multiplicative adjustments that capture clustering, degree variance,\n    density, assortativity and triangle abundance.  All operations use only\n    built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n   = s.get('n', 1)\n    m   = s.get('m', 1)\n    avg_deg   = s.get('avg_degree', 1.0)\n    avg_deg   = max(avg_deg, 1e-6)           # avoid division by zero\n    density   = s.get('density', 0.0)\n    density   = max(density, 1e-6)           # avoid division by zero\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    std_deg    = s.get('std_degree', 0.0)\n\n    # ---- Base estimate ----------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ----------------------------------\n    # Higher variance tends to shorten paths\n    var_deg = std_deg * std_deg\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment ------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment ----------------------------------------\n    # More triangles relative to edges lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors ----------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T01:05:26.970057+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i2_p2_189471358", "generation": 5, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.5024249699879952, "spearman": 0.3511881613996202, "pearson": 0.37717277123796233, "rmse": 15.846821405419366, "mae": 12.0034667068228, "simplicity_score": 0.18148601170916304, "novelty_bonus": 0.45458186454661365, "total_score": 0.34826584240562686, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is deliberately simple: a base term proportional to n / avg_degree\n    multiplied by several multiplicative adjustments that capture clustering,\n    degree variance, density, assortativity and triangle abundance.  All\n    operations use only built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)           # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ---- Base estimate ----------------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ---------------------------------------\n    # Compute variance of the degree sequence\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - (avg_deg * avg_deg)\n        var_deg = max(var_deg, 0.0)\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment -----------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment -----------------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors -----------------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term (larger n and smaller average degree\n    imply longer paths) and multiplicative adjustments for clustering,\n    degree variance, density, assortativity and triangle abundance.\n    All operations are safe against missing keys and division‑by‑zero.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    # Base term: larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # Clustering adjustment: more clustering and transitivity tend to increase path lengths\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    clustering_adj = 1.0 + clustering + trans\n\n    # Degree‑variance adjustment: higher variance tends to shorten paths\n    std_deg = s.get('std_degree', 0.0)\n    std_deg = max(std_deg, 1e-6)          # avoid division by zero\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # Density adjustment: denser graphs have shorter average paths\n    density = s.get('density', 0.0)\n    density = max(density, 1e-6)          # avoid division by zero\n    density_adj = 1.0 / (1.0 + density)\n\n    # Assortativity adjustment: positive assortativity can lengthen paths\n    assort = s.get('degree_assortativity', 0.0)\n    assort_adj = 1.0 + 0.5 * assort\n\n    # Triangle adjustment: more triangles (relative to edges) lengthen paths\n    triangles = s.get('num_triangles', 0)\n    m = s.get('m', 1)\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combine all factors\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term (larger n and smaller average degree\n    imply longer paths) and multiplicative adjustments for clustering,\n    degree variance, density, assortativity and triangle abundance.\n    All operations are safe against missing keys and division‑by‑zero.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    # Base term: larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # Clustering adjustment: more clustering and transitivity tend to increase path lengths\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    clustering_adj = 1.0 + clustering + trans\n\n    # Degree‑variance adjustment: higher variance tends to shorten paths\n    std_deg = s.get('std_degree', 0.0)\n    std_deg = max(std_deg, 1e-6)          # avoid division by zero\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # Density adjustment: denser graphs have shorter average paths\n    density = s.get('density', 0.0)\n    density = max(density, 1e-6)          # avoid division by zero\n    density_adj = 1.0 / (1.0 + density)\n\n    # Assortativity adjustment: positive assortativity can lengthen paths\n    assort = s.get('degree_assortativity', 0.0)\n    assort_adj = 1.0 + 0.5 * assort\n\n    # Triangle adjustment: more triangles (relative to edges) lengthen paths\n    triangles = s.get('num_triangles', 0)\n    m = s.get('m', 1)\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combine all factors\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T01:06:18.380345+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i2_p3_462940571", "generation": 5, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7697959183673468, "spearman": 0.8102658104949984, "pearson": 0.7632542177315451, "rmse": 135.96325407354212, "mae": 96.9906390175017, "simplicity_score": 0.1795559277361217, "novelty_bonus": 0.23097502536974435, "total_score": 0.5103365984056468, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is deliberately simple: a base term proportional to n / avg_degree\n    multiplied by several multiplicative adjustments that capture clustering,\n    degree variance, density, assortativity and triangle abundance.  All\n    operations use only built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)           # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ---- Base estimate ----------------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ---------------------------------------\n    # Compute variance of the degree sequence\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - (avg_deg * avg_deg)\n        var_deg = max(var_deg, 0.0)\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment -----------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment -----------------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors -----------------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length using only pre‑computed graph\n    features.  The formula is a product of a base term and several\n    multiplicative adjustments that capture the effect of clustering,\n    degree variance, density, assortativity and triangle abundance.\n    All operations are safe against division by zero and missing values.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)          # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # ----- Base estimate -------------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ----- Clustering adjustment -----------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ----- Degree‑variance adjustment -------------------------------------\n    degrees = s.get('degrees', None)\n    if degrees and len(degrees) > 0:\n        # compute variance from the degree list\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - avg_deg * avg_deg\n        if var_deg < 0.0:\n            var_deg = 0.0\n    else:\n        # fallback to std_degree if available\n        std_deg = s.get('std_degree', 0.0)\n        var_deg = std_deg * std_deg\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ----- Density adjustment --------------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ----- Assortativity adjustment --------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # ----- Triangle adjustment --------------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ----- Combine all factors --------------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length using only pre‑computed graph\n    features.  The formula is a product of a base term and several\n    multiplicative adjustments that capture the effect of clustering,\n    degree variance, density, assortativity and triangle abundance.\n    All operations are safe against division by zero and missing values.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)          # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # ----- Base estimate -------------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ----- Clustering adjustment -----------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ----- Degree‑variance adjustment -------------------------------------\n    degrees = s.get('degrees', None)\n    if degrees and len(degrees) > 0:\n        # compute variance from the degree list\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - avg_deg * avg_deg\n        if var_deg < 0.0:\n            var_deg = 0.0\n    else:\n        # fallback to std_degree if available\n        std_deg = s.get('std_degree', 0.0)\n        var_deg = std_deg * std_deg\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ----- Density adjustment --------------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ----- Assortativity adjustment --------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # ----- Triangle adjustment --------------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ----- Combine all factors --------------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T01:07:03.026776+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i2_p4_129921505", "generation": 5, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8580552220888356, "spearman": 0.8130963823207585, "pearson": 0.8616097127388691, "rmse": 18.175010718381163, "mae": 13.49238006652603, "simplicity_score": 0.18193879038230518, "novelty_bonus": 0.2330977371377455, "total_score": 0.512865270378164, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is deliberately simple: a base term proportional to n / avg_degree\n    multiplied by several multiplicative adjustments that capture clustering,\n    degree variance, density, assortativity and triangle abundance.  All\n    operations use only built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 0)\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    avg_deg    = max(avg_deg, 1e-6)           # avoid division by zero\n    density    = s.get('density', 0.0)\n    density    = max(density, 1e-6)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ---- Base estimate ----------------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ---------------------------------------\n    # Compute variance of the degree sequence\n    if degrees:\n        mean_sq = sum(d * d for d in degrees) / len(degrees)\n        var_deg = mean_sq - (avg_deg * avg_deg)\n        var_deg = max(var_deg, 0.0)\n    else:\n        var_deg = 0.0\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment -----------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment -----------------------------------------------\n    # More triangles (relative to edges) lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors -----------------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines a simple baseline with multiplicative corrections that\n    capture clustering, degree heterogeneity, density, assortativity and triangle\n    abundance.  No external libraries are used; only built‑in Python functions.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n   = s.get('n', 1)\n    m   = s.get('m', 0)\n    avg_deg   = s.get('avg_degree', 1.0)\n    if avg_deg <= 0.0:\n        avg_deg = 1.0\n    density    = s.get('density', 0.0)\n    if density <= 0.0:\n        density = 1e-6\n    avg_clust  = s.get('avg_clustering', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0.0:\n        std_deg = 1.0\n    assort     = s.get('degree_assortativity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment – more triangles → longer paths\n    clustering_adj = 1.0 + avg_clust\n\n    # 3. Degree‑variance adjustment – higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment – denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 5. Assortativity adjustment – positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # 6. Triangle adjustment – more triangles relative to edges lengthen paths\n    tri_adj = 1.0 + num_tri / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines a simple baseline with multiplicative corrections that\n    capture clustering, degree heterogeneity, density, assortativity and triangle\n    abundance.  No external libraries are used; only built‑in Python functions.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n   = s.get('n', 1)\n    m   = s.get('m', 0)\n    avg_deg   = s.get('avg_degree', 1.0)\n    if avg_deg <= 0.0:\n        avg_deg = 1.0\n    density    = s.get('density', 0.0)\n    if density <= 0.0:\n        density = 1e-6\n    avg_clust  = s.get('avg_clustering', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0.0:\n        std_deg = 1.0\n    assort     = s.get('degree_assortativity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment – more triangles → longer paths\n    clustering_adj = 1.0 + avg_clust\n\n    # 3. Degree‑variance adjustment – higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment – denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 5. Assortativity adjustment – positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # 6. Triangle adjustment – more triangles relative to edges lengthen paths\n    tri_adj = 1.0 + num_tri / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T01:07:48.485609+00:00", "event_type": "candidate_rejected", "payload": {"generation": 5, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.025878", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:08:24.455484+00:00", "event_type": "candidate_rejected", "payload": {"generation": 5, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:08:24.456917+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 5, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:09:03.222532+00:00", "event_type": "candidate_rejected", "payload": {"generation": 5, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.135793", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:09:03.226495+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 5, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:09:38.398283+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i3_p2_686478210", "generation": 5, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.7733580018501388, "spearman": -0.5176074485235316, "pearson": -0.3323906555214724, "rmse": 53.42312398289512, "mae": 41.5169773934602, "simplicity_score": 0.18133468042478507, "novelty_bonus": 0.40562853270443633, "total_score": 0.41675922015805367, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how average path length relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that mixes size, sparsity, degree dispersion,\n    triangle abundance, clustering strength, and degree assortativity.\n    All operations use only built‑in arithmetic to avoid external imports.\n    \"\"\"\n    # Size to edge ratio – captures overall sparsity\n    size_edge = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # Degree dispersion relative to variability – higher spread suggests\n    # longer paths through hubs\n    deg_disp = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # Triangle density – more triangles usually shorten paths\n    tri_dense = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # Combined clustering factor – square to amplify the effect\n    cluster_factor = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # Assortativity magnitude – strong correlation can create bottlenecks\n    assort_factor = (s['degree_assortativity'] ** 2 + 1.0)\n\n    # Final invariant: product of sparsity, dispersion, and triangle terms,\n    # divided by clustering and assortativity terms\n    invariant = (size_edge * deg_disp * tri_dense) / (cluster_factor * assort_factor)\n\n    return invariant\n\ndef new_invariant(s):\n    \"\"\"\n    A composite invariant that mixes several pre‑computed graph statistics\n    to produce a value correlated with the average shortest‑path length.\n    It uses only arithmetic, comparisons, and basic Python built‑ins.\n\n    Keys required from the dictionary `s`:\n        - n                 (int) number of nodes\n        - m                 (int) number of edges\n        - density           (float) edge density\n        - avg_degree        (float) average degree\n        - max_degree        (int) maximum degree\n        - min_degree        (int) minimum degree\n        - std_degree        (float) degree standard deviation\n        - avg_clustering    (float) average local clustering coefficient\n        - transitivity      (float) global transitivity (overall clustering)\n        - degree_assortativity (float) degree assortativity coefficient\n        - num_triangles     (int) number of triangles\n        - degrees           (list[int]) sorted degree sequence\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Size to sparsity ratio\n    size_edge_ratio = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree dispersion: relative spread compared to variation\n    degree_spread = (s['max_degree'] - s['min_degree'] + 1.0)\n    degree_variation = s['std_degree'] + 1.0\n    degree_dispersion = degree_spread / degree_variation\n\n    # 3. Triangle density: triangles per node (shifted to avoid zero)\n    triangle_density = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Local triangle power: square of clustering and transitivity\n    clustering_power = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # 5. Assortativity magnitude: square to make always positive\n    assort_magnitude = s['degree_assortativity'] ** 2 + 1.0\n\n    # ------------------------------------------------------------------\n    # Combine everything into one scalar\n    # The product of the first three components emphasizes sparsity,\n    # degree spread, and triangle abundance – all of which can affect\n    # path lengths.  Dividing by the clustering and assortativity terms\n    # dampens the effect of very high clustering or strong degree\n    # correlations.\n    invariant = (\n        size_edge_ratio\n        * degree_dispersion\n        * triangle_density\n    ) / (\n        clustering_power\n        * assort_magnitude\n    )\n\n    return invariant\n\ndef new_invariant(s):\n    \"\"\"\n    A novel invariant intended to correlate with the average shortest path length\n    using only the pre‑computed structural features provided in *s*.\n\n    The formula blends several independent aspects of the network:\n      • Normalized size versus edge count (comp1)\n      • Degree spread relative to variability (comp2)\n      • Triangle density relative to size (comp3)\n      • Average clustering and global transitivity (comp4)\n      • Degree assortativity magnitude (comp5)\n\n    By multiplying the first three components and dividing by the latter two,\n    we encourage the invariant to increase when the graph is small, sparse, \n    has diverse degrees, many triangles, high clustering, and low assortativity,\n    all of which tend to reduce the typical path length.\n    \"\"\"\n\n    # Core components\n    comp1 = (s['n'] + 1.0) / (s['m'] + 1.0)                     # size–to–edges ratio\n    comp2 = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)  # degree spread vs std\n    comp3 = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)         # triangle density\n\n    # Regularization terms\n    comp4 = (s['avg_clustering']**2 + s['transitivity']**2) / 2.0   # clustering/ transitivity combo\n    comp5 = (s['degree_assortativity']**2 + 1.0)                    # assortativity magnitude\n\n    # Combine into a single scalar\n    return (comp1 * comp2 * comp3) / (comp4 * comp5)\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.025878\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.135793\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    A hand‑crafted composite invariant built only from arithmetic\n    operations on the supplied pre‑computed statistics.\n\n    The formula mixes size, sparsity, degree dispersion, triangle\n    abundance, clustering, and degree assortativity – all quantities\n    known to influence the average shortest‑path length.\n\n    Key assumptions:\n        • s contains the keys listed in the problem statement.\n        • No external modules may be imported; only built‑in\n          operations (addition, subtraction, multiplication,\n          division, pow, min, max, etc.) are used.\n\n    The structure is:\n\n        invariant = (size_factor * degree_factor * triangle_factor)\n                    / (clustering_factor * assortativity_factor)\n\n    The \"+ 1\" terms in denominators guarantee numerical stability\n    for very small or zero values.\n    \"\"\"\n\n    # 1. Size‑to‑edge ratio: captures overall sparsity.\n    size_factor = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree spread relative to its standard deviation.\n    #    Larger spread tends to create longer paths, especially when\n    #    combined with a high variance of degrees.\n    degree_factor = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # 3. Triangle density (shifted to avoid division by zero).\n    triangle_factor = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Clustering influence.  Square both local and global clustering\n    #    before averaging to give more weight to high‑clustering graphs.\n    clustering_factor = (pow(s['avg_clustering'], 2) + pow(s['transitivity'], 2)) / 2.0\n\n    # 5. Assortativity influence.  Strong positive or negative assortativity\n    #    usually creates bottlenecks, so we penalise large absolute values.\n    assortativity_factor = pow(s['degree_assortativity'], 2) + 1.0\n\n    # 6. Combine all pieces.  We multiply the first three terms – each\n    #    known to *shorten* paths – and divide by the last two, which\n    #    typically *enlarge* the average shortest path.\n    invariant = (size_factor * degree_factor * triangle_factor) / (clustering_factor * assortativity_factor)\n\n    return invariant\n```\n\nThis function returns a single scalar value that reflects the interplay of sparsity, degree dispersion, clustering, and assortativity, and it is designed to correlate with the average shortest‑path length without performing any graph traversal.", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    A hand‑crafted composite invariant built only from arithmetic\n    operations on the supplied pre‑computed statistics.\n\n    The formula mixes size, sparsity, degree dispersion, triangle\n    abundance, clustering, and degree assortativity – all quantities\n    known to influence the average shortest‑path length.\n\n    Key assumptions:\n        • s contains the keys listed in the problem statement.\n        • No external modules may be imported; only built‑in\n          operations (addition, subtraction, multiplication,\n          division, pow, min, max, etc.) are used.\n\n    The structure is:\n\n        invariant = (size_factor * degree_factor * triangle_factor)\n                    / (clustering_factor * assortativity_factor)\n\n    The \"+ 1\" terms in denominators guarantee numerical stability\n    for very small or zero values.\n    \"\"\"\n\n    # 1. Size‑to‑edge ratio: captures overall sparsity.\n    size_factor = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree spread relative to its standard deviation.\n    #    Larger spread tends to create longer paths, especially when\n    #    combined with a high variance of degrees.\n    degree_factor = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # 3. Triangle density (shifted to avoid division by zero).\n    triangle_factor = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Clustering influence.  Square both local and global clustering\n    #    before averaging to give more weight to high‑clustering graphs.\n    clustering_factor = (pow(s['avg_clustering'], 2) + pow(s['transitivity'], 2)) / 2.0\n\n    # 5. Assortativity influence.  Strong positive or negative assortativity\n    #    usually creates bottlenecks, so we penalise large absolute values.\n    assortativity_factor = pow(s['degree_assortativity'], 2) + 1.0\n\n    # 6. Combine all pieces.  We multiply the first three terms – each\n    #    known to *shorten* paths – and divide by the last two, which\n    #    typically *enlarge* the average shortest path.\n    invariant = (size_factor * degree_factor * triangle_factor) / (clustering_factor * assortativity_factor)\n\n    return invariant"}}
{"timestamp": "2026-02-13T01:10:23.130776+00:00", "event_type": "candidate_rejected", "payload": {"generation": 5, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.075622", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:12:05.874580+00:00", "event_type": "candidate_rejected", "payload": {"generation": 5, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.022710", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:12:05.879436+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "phase1_20260212T231418Z", "generation": 6, "model_name": "gpt-oss:20b", "best_val_score": 0.5491013268732999, "no_improve_count": 4}}
{"timestamp": "2026-02-13T01:13:59.521552+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i0_p0_330196333", "generation": 6, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7321488595438175, "spearman": 0.643360325268299, "pearson": 0.7189783489399029, "rmse": 32.16476156108652, "mae": 29.687340309864986, "simplicity_score": 0.24656480581498377, "novelty_bonus": 0.3852227835993344, "total_score": 0.4865599588769466, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # already sorted\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n    val *= (1 + trans)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.5 * (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density, clustering and transitivity tend to shorten paths\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.3 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density) * (1 + 1.2 * trans) * (1 + 1.1 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.3 * num_tri / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.3 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.3 * num_tri / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.3 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T01:15:26.572543+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i0_p1_226909348", "generation": 6, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7511644657863146, "spearman": 0.7246728885745987, "pearson": 0.7756983226966729, "rmse": 20.89104731666658, "mae": 19.439967143099476, "simplicity_score": 0.24783440638124699, "novelty_bonus": 0.31979642891023075, "total_score": 0.507842254236618, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # already sorted\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n    val *= (1 + trans)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.5 * (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density, clustering and transitivity tend to shorten paths\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.3 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density) * (1 + 1.2 * trans) * (1 + 1.1 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T01:16:48.200794+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:16:48.201803+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 6, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:18:10.544117+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i0_p2_564499893", "generation": 6, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7615366146458583, "spearman": 0.6708215220961704, "pearson": 0.7511787412627852, "rmse": 20.469720473935215, "mae": 18.944406342300244, "simplicity_score": 0.25062504096016025, "novelty_bonus": 0.3677885587751666, "total_score": 0.4958723368726672, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # already sorted\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n    val *= (1 + trans)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.5 * (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density, clustering and transitivity tend to shorten paths\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.3 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density) * (1 + 1.2 * trans) * (1 + 1.1 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport math\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted combination of structural properties that\n    influence path length: size, density, clustering, transitivity,\n    assortativity, triangles, degree spread and variability.\n    \"\"\"\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n\n    # Base estimate: larger graphs with lower average degree tend to have\n    # longer average shortest paths.\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n\n    # Positive assortativity (similar‑degree nodes clustered) usually shortens paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen their influence with a square root\n    val *= (1 + 0.3 * math.sqrt(num_tri) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    return val\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val"}}
{"timestamp": "2026-02-13T01:18:10.545315+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 6, "island_id": 0, "population_idx": 2, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:20:25.823469+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i0_p3_669813994", "generation": 6, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7527971188475389, "spearman": 0.6678071956076356, "pearson": 0.7347218969253402, "rmse": 28.554741884132035, "mae": 26.64647960681686, "simplicity_score": 0.2458419268201938, "novelty_bonus": 0.3733806540711546, "total_score": 0.49508617938920296, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # already sorted\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n    val *= (1 + trans)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.5 * (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density, clustering and transitivity tend to shorten paths\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.3 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density) * (1 + 1.2 * trans) * (1 + 1.1 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T01:22:19.270406+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i0_p4_940306095", "generation": 6, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7239855942376949, "spearman": 0.7131945973129571, "pearson": 0.6586542487406656, "rmse": 43.01105849402223, "mae": 39.1718814507678, "simplicity_score": 0.24680914964745962, "novelty_bonus": 0.197402522390819, "total_score": 0.4651798853032162, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # already sorted\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.2 * clustering)\n    val *= (1 + trans)\n\n    # Positive assortativity tends to cluster similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.5 * (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.5 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.5 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Density, clustering and transitivity tend to shorten paths\n    val *= (1 + 1.5 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.3 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density) * (1 + 1.2 * trans) * (1 + 1.1 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; use sqrt to dampen large counts\n    val *= (1 + (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = (degrees[mid] if len(degrees) % 2 else\n                  (degrees[mid - 1] + degrees[mid]) / 2)\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths (combined linearly inside a multiplier)\n    val *= (1 + 1.2 * density + 1.1 * clustering + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.3 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg**2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths (combined linearly inside a multiplier)\n    val *= (1 + 1.2 * density + 1.1 * clustering + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; moderate their influence\n    val *= (1 + 0.3 * num_tri / (n**2 + 1))\n\n    # Degree spread can increase path length; moderate its effect\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n\n    # Degree variability often increases path length; moderate its effect\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 1:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.5 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.5 * sum_sq / (n * (avg_deg**2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T01:24:05.006042+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i1_p0_437151918", "generation": 6, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3323409363745498, "spearman": 0.17298213942180002, "pearson": 0.39567991229263216, "rmse": 2.690073240518276, "mae": 2.5606747772904845, "simplicity_score": 0.12245670947119695, "novelty_bonus": 0.3041989930002468, "total_score": 0.20224210950521343, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return base * deg_factor * struct_factor * sqrt_factor * assort_factor * triangle_factor * std_factor * min_factor\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) // 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) // 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )"}}
{"timestamp": "2026-02-13T01:24:53.906724+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i1_p1_160688162", "generation": 6, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3323409363745498, "spearman": 0.17298213942180002, "pearson": 0.39567991229263216, "rmse": 2.690073240518276, "mae": 2.5606747772904845, "simplicity_score": 0.12245670947119695, "novelty_bonus": 0.3041989930002468, "total_score": 0.20224210950521343, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return base * deg_factor * struct_factor * sqrt_factor * assort_factor * triangle_factor * std_factor * min_factor\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1.0, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1.0, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )"}}
{"timestamp": "2026-02-13T01:36:15.378731+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i1_p2_629764301", "generation": 6, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3323409363745498, "spearman": 0.17298213942180002, "pearson": 0.39567991229263216, "rmse": 2.690073240518276, "mae": 2.5606747772904845, "simplicity_score": 0.12245670947119695, "novelty_bonus": 0.3041989930002468, "total_score": 0.20224210950521343, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return base * deg_factor * struct_factor * sqrt_factor * assort_factor * triangle_factor * std_factor * min_factor\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )"}}
{"timestamp": "2026-02-13T01:38:33.305016+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i1_p3_700265101", "generation": 6, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3277310924369748, "spearman": 0.1814596045374779, "pearson": 0.42632632245226104, "rmse": 2.608125658730113, "mae": 2.481958151805334, "simplicity_score": 0.11613663459153037, "novelty_bonus": 0.2981402142950903, "total_score": 0.20339919347557212, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return base * deg_factor * struct_factor * sqrt_factor * assort_factor * triangle_factor * std_factor * min_factor\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = n ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = n ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )"}}
{"timestamp": "2026-02-13T01:41:52.010608+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i1_p4_97226634", "generation": 6, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.38180072028811524, "spearman": 0.26260191352357415, "pearson": 0.49560662794573307, "rmse": 2.5239141797232643, "mae": 2.403821219830924, "simplicity_score": 0.11915354499011185, "novelty_bonus": 0.3467844519407486, "total_score": 0.259167001342034, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    return base * deg_factor * struct_factor * sqrt_factor * assort_factor * triangle_factor * std_factor * min_factor\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)"}}
{"timestamp": "2026-02-13T01:43:27.985586+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i2_p0_312366641", "generation": 6, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8500840336134453, "spearman": 0.8289652849941651, "pearson": 0.7555829097800564, "rmse": 81.75513794352867, "mae": 53.55685081098627, "simplicity_score": 0.17937881696235647, "novelty_bonus": 0.26478370607004686, "total_score": 0.5297935177105679, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term (n / (avg_degree+1)) and several\n    multiplicative adjustments that capture clustering, degree variance,\n    density, assortativity and triangle abundance.  All operations use only\n    built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n   = s.get('n', 1)\n    m   = s.get('m', 1)\n    avg_deg   = s.get('avg_degree', 1.0)\n    avg_deg   = max(avg_deg, 1e-6)           # avoid division by zero\n    density   = s.get('density', 0.0)\n    density   = max(density, 1e-6)           # avoid division by zero\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    std_deg    = s.get('std_degree', 0.0)\n\n    # ---- Base estimate ----------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ----------------------------------\n    # Higher variance tends to shorten paths\n    var_deg = std_deg * std_deg\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment ------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment ----------------------------------------\n    # More triangles relative to edges lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors ----------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length using only pre‑computed\n    graph statistics.  The formula is a product of a simple base term\n    and several multiplicative corrections that capture the effects of\n    clustering, degree heterogeneity, density, assortativity, and\n    triangle abundance.  No external libraries or graph traversal\n    algorithms are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph features.  Expected keys\n        (with safe fallbacks if missing):\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n            = s.get('n', 1)\n    m            = s.get('m', 1)\n    avg_deg      = s.get('avg_degree', 1.0)\n    max_deg      = s.get('max_degree', 1.0)\n    min_deg      = s.get('min_degree', 1.0)\n    std_deg      = s.get('std_degree', 0.0)\n    clustering   = s.get('avg_clustering', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    density      = s.get('density', 0.0)\n    triangles    = s.get('num_triangles', 0)\n\n    # Avoid division by zero\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    if max_deg <= 0:\n        max_deg = 1.0\n    if min_deg <= 0:\n        min_deg = 1.0\n    if density <= 0:\n        density = 1e-6\n\n    # ---------- Base estimate ----------\n    base = n / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering: more triangles → longer paths\n    clustering_adj = 1.0 + clustering\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length using only pre‑computed\n    graph statistics.  The formula is a product of a simple base term\n    and several multiplicative corrections that capture the effects of\n    clustering, degree heterogeneity, density, assortativity, and\n    triangle abundance.  No external libraries or graph traversal\n    algorithms are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph features.  Expected keys\n        (with safe fallbacks if missing):\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n            = s.get('n', 1)\n    m            = s.get('m', 1)\n    avg_deg      = s.get('avg_degree', 1.0)\n    max_deg      = s.get('max_degree', 1.0)\n    min_deg      = s.get('min_degree', 1.0)\n    std_deg      = s.get('std_degree', 0.0)\n    clustering   = s.get('avg_clustering', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    density      = s.get('density', 0.0)\n    triangles    = s.get('num_triangles', 0)\n\n    # Avoid division by zero\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    if max_deg <= 0:\n        max_deg = 1.0\n    if min_deg <= 0:\n        min_deg = 1.0\n    if density <= 0:\n        density = 1e-6\n\n    # ---------- Base estimate ----------\n    base = n / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering: more triangles → longer paths\n    clustering_adj = 1.0 + clustering\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T01:44:38.785230+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i2_p1_767843914", "generation": 6, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.6121968787515005, "spearman": 0.48288925331483684, "pearson": 0.5247720319904184, "rmse": 25.687737104619845, "mae": 20.310626523216207, "simplicity_score": 0.1818542592934614, "novelty_bonus": 0.5218488558709119, "total_score": 0.4343701352773843, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term (n / (avg_degree+1)) and several\n    multiplicative adjustments that capture clustering, degree variance,\n    density, assortativity and triangle abundance.  All operations use only\n    built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n   = s.get('n', 1)\n    m   = s.get('m', 1)\n    avg_deg   = s.get('avg_degree', 1.0)\n    avg_deg   = max(avg_deg, 1e-6)           # avoid division by zero\n    density   = s.get('density', 0.0)\n    density   = max(density, 1e-6)           # avoid division by zero\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    std_deg    = s.get('std_degree', 0.0)\n\n    # ---- Base estimate ----------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ----------------------------------\n    # Higher variance tends to shorten paths\n    var_deg = std_deg * std_deg\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment ------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment ----------------------------------------\n    # More triangles relative to edges lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors ----------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term (n / (avg_degree+1)) and several\n    multiplicative adjustments that capture clustering, degree variance,\n    density, assortativity, triangle abundance and hub presence.\n    All operations use only built‑in Python arithmetic; no external imports\n    are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    density    = s.get('density', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # ---- Base estimate --------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment ------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + trans\n\n    # ---- Degree‑variance adjustment --------------------------------\n    # Higher variance tends to shorten paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment ---------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (1.0 + density)\n\n    # ---- Assortativity adjustment ---------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # ---- Triangle adjustment --------------------------------------\n    # More triangles relative to edges lengthen paths\n    triangle_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Hub adjustment --------------------------------------------\n    # Presence of hubs (max_degree > avg_degree) tends to shorten paths\n    hub_adj = 1.0 + (max_deg - avg_deg) / (avg_deg + 1.0)\n\n    # ---- Combine all factors ---------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                triangle_adj *\n                hub_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term (n / (avg_degree+1)) and several\n    multiplicative adjustments that capture clustering, degree variance,\n    density, assortativity, triangle abundance and hub presence.\n    All operations use only built‑in Python arithmetic; no external imports\n    are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    density    = s.get('density', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # ---- Base estimate --------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment ------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + trans\n\n    # ---- Degree‑variance adjustment --------------------------------\n    # Higher variance tends to shorten paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment ---------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (1.0 + density)\n\n    # ---- Assortativity adjustment ---------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # ---- Triangle adjustment --------------------------------------\n    # More triangles relative to edges lengthen paths\n    triangle_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Hub adjustment --------------------------------------------\n    # Presence of hubs (max_degree > avg_degree) tends to shorten paths\n    hub_adj = 1.0 + (max_deg - avg_deg) / (avg_deg + 1.0)\n\n    # ---- Combine all factors ---------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                triangle_adj *\n                hub_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T01:46:15.019813+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i2_p2_832259801", "generation": 6, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.5721488595438174, "spearman": 0.4776481203210867, "pearson": 0.5786597668974294, "rmse": 7.61241771512563, "mae": 5.8690738718703415, "simplicity_score": 0.18274864716530204, "novelty_bonus": 0.4407095177379434, "total_score": 0.40758664491498675, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term (n / (avg_degree+1)) and several\n    multiplicative adjustments that capture clustering, degree variance,\n    density, assortativity and triangle abundance.  All operations use only\n    built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n   = s.get('n', 1)\n    m   = s.get('m', 1)\n    avg_deg   = s.get('avg_degree', 1.0)\n    avg_deg   = max(avg_deg, 1e-6)           # avoid division by zero\n    density   = s.get('density', 0.0)\n    density   = max(density, 1e-6)           # avoid division by zero\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    std_deg    = s.get('std_degree', 0.0)\n\n    # ---- Base estimate ----------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ----------------------------------\n    # Higher variance tends to shorten paths\n    var_deg = std_deg * std_deg\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment ------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment ----------------------------------------\n    # More triangles relative to edges lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors ----------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    All operations use only built‑in Python functions and safe defaults to\n    avoid division by zero. The estimate is a product of a base term\n    (n / (avg_degree + 1)) and several multiplicative adjustments that\n    capture clustering, degree variance, density, assortativity and\n    triangle abundance.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    clustering = s.get('avg_clustering', 0.0)\n    std_deg    = s.get('std_degree', 0.0)\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n\n    # 1. Base estimate – larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment – more triangles tend to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # 3. Degree‑variance adjustment – higher variance tends to shorten paths\n    variance_adj = 1.0 / (1.0 + (std_deg ** 2) / (avg_deg + 1.0))\n\n    # 4. Density adjustment – denser graphs have shorter average paths\n    density_adj = 1.0 / (1.0 + density)\n\n    # 5. Assortativity adjustment – positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 6. Triangle adjustment – more triangles relative to edges lengthen paths\n    tri_adj = 1.0 + num_tri / (m + 1.0)\n\n    # Combine all factors\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    All operations use only built‑in Python functions and safe defaults to\n    avoid division by zero. The estimate is a product of a base term\n    (n / (avg_degree + 1)) and several multiplicative adjustments that\n    capture clustering, degree variance, density, assortativity and\n    triangle abundance.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    clustering = s.get('avg_clustering', 0.0)\n    std_deg    = s.get('std_degree', 0.0)\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n\n    # 1. Base estimate – larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment – more triangles tend to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # 3. Degree‑variance adjustment – higher variance tends to shorten paths\n    variance_adj = 1.0 / (1.0 + (std_deg ** 2) / (avg_deg + 1.0))\n\n    # 4. Density adjustment – denser graphs have shorter average paths\n    density_adj = 1.0 / (1.0 + density)\n\n    # 5. Assortativity adjustment – positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 6. Triangle adjustment – more triangles relative to edges lengthen paths\n    tri_adj = 1.0 + num_tri / (m + 1.0)\n\n    # Combine all factors\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T01:48:00.960963+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i2_p3_435216667", "generation": 6, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7139015606242496, "spearman": 0.7297227667152567, "pearson": 0.7507400330463588, "rmse": 167.1623962277314, "mae": 124.56980603135584, "simplicity_score": 0.18128955224491675, "novelty_bonus": 0.25378170671962086, "total_score": 0.477253805822498, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term (n / (avg_degree+1)) and several\n    multiplicative adjustments that capture clustering, degree variance,\n    density, assortativity and triangle abundance.  All operations use only\n    built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n   = s.get('n', 1)\n    m   = s.get('m', 1)\n    avg_deg   = s.get('avg_degree', 1.0)\n    avg_deg   = max(avg_deg, 1e-6)           # avoid division by zero\n    density   = s.get('density', 0.0)\n    density   = max(density, 1e-6)           # avoid division by zero\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    std_deg    = s.get('std_degree', 0.0)\n\n    # ---- Base estimate ----------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ----------------------------------\n    # Higher variance tends to shorten paths\n    var_deg = std_deg * std_deg\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment ------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment ----------------------------------------\n    # More triangles relative to edges lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors ----------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a simple base term (n/(avg_degree+1))\n    and multiplicative adjustments that capture clustering, degree variance,\n    density, assortativity and triangle abundance.\n    All operations use only built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    if density <= 0:\n        density = 1e-6\n\n    trans      = s.get('transitivity', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n\n    std_deg    = s.get('std_degree', 0.0)\n    if std_deg <= 0:\n        std_deg = 1e-6\n\n    assort     = s.get('degree_assortativity', 0.0)\n\n    m          = s.get('m', 1)\n    num_tri    = s.get('num_triangles', 0)\n\n    # 1. Base estimate (scales with n and inversely with avg_degree)\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment – more triangles → longer paths\n    cluster_adj = 1.0 + 0.4 * (trans + avg_clust)\n\n    # 3. Degree‑variance adjustment – higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment – denser graphs → shorter paths\n    dens_adj = 1.0 / (density + 1e-6)\n\n    # 5. Assortativity adjustment – positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.3 * assort\n\n    # 6. Triangle adjustment – more triangles relative to edges lengthen paths\n    tri_adj = 1.0 + num_tri / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                cluster_adj *\n                var_adj *\n                dens_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a simple base term (n/(avg_degree+1))\n    and multiplicative adjustments that capture clustering, degree variance,\n    density, assortativity and triangle abundance.\n    All operations use only built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    if density <= 0:\n        density = 1e-6\n\n    trans      = s.get('transitivity', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n\n    std_deg    = s.get('std_degree', 0.0)\n    if std_deg <= 0:\n        std_deg = 1e-6\n\n    assort     = s.get('degree_assortativity', 0.0)\n\n    m          = s.get('m', 1)\n    num_tri    = s.get('num_triangles', 0)\n\n    # 1. Base estimate (scales with n and inversely with avg_degree)\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment – more triangles → longer paths\n    cluster_adj = 1.0 + 0.4 * (trans + avg_clust)\n\n    # 3. Degree‑variance adjustment – higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment – denser graphs → shorter paths\n    dens_adj = 1.0 / (density + 1e-6)\n\n    # 5. Assortativity adjustment – positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.3 * assort\n\n    # 6. Triangle adjustment – more triangles relative to edges lengthen paths\n    tri_adj = 1.0 + num_tri / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                cluster_adj *\n                var_adj *\n                dens_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T01:49:38.492169+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:49:38.493377+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 6, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:51:04.704938+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i2_p4_804764357", "generation": 6, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.5431452581032412, "spearman": 0.41058666863674553, "pearson": 0.4114858212578708, "rmse": 11.640333219138084, "mae": 9.245446642084278, "simplicity_score": 0.18156618084462658, "novelty_bonus": 0.5135093377334432, "total_score": 0.395659371807331, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term (n / (avg_degree+1)) and several\n    multiplicative adjustments that capture clustering, degree variance,\n    density, assortativity and triangle abundance.  All operations use only\n    built‑in Python functions – no imports are required.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n   = s.get('n', 1)\n    m   = s.get('m', 1)\n    avg_deg   = s.get('avg_degree', 1.0)\n    avg_deg   = max(avg_deg, 1e-6)           # avoid division by zero\n    density   = s.get('density', 0.0)\n    density   = max(density, 1e-6)           # avoid division by zero\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    std_deg    = s.get('std_degree', 0.0)\n\n    # ---- Base estimate ----------------------------------------------\n    # Larger n and smaller avg_degree → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # ---- Clustering adjustment --------------------------------------\n    # More clustering tends to increase path lengths\n    clustering_adj = 1.0 + clustering\n\n    # ---- Degree‑variance adjustment ----------------------------------\n    # Higher variance tends to shorten paths\n    var_deg = std_deg * std_deg\n    variance_adj = 1.0 / (1.0 + var_deg / (avg_deg + 1.0))\n\n    # ---- Density adjustment -----------------------------------------\n    # Denser graphs have shorter average paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # ---- Assortativity adjustment ------------------------------------\n    # Positive assortativity can lengthen paths\n    assort_adj = 1.0 + assort\n\n    # ---- Triangle adjustment ----------------------------------------\n    # More triangles relative to edges lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---- Combine all factors ----------------------------------------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport math\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term and several multiplicative adjustments\n    that capture clustering, degree variance, density, assortativity and triangle\n    abundance.  All operations use only built‑in Python functions – no graph\n    traversal is performed.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    if density < 0:\n        density = 0.0\n\n    trans      = s.get('transitivity', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    m          = s.get('m', 1)\n\n    eps = 1e-6\n\n    # 1. Baseline distance estimate (log‑based, with density correction)\n    base = math.log(max(n, 2)) / (math.log(max(avg_deg + 1.0, 2.0)) + 0.1 * density)\n\n    # 2. Clustering adjustment – more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * max(trans, avg_clust)\n\n    # 3. Degree‑variance adjustment – higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment – denser graphs have shorter average paths\n    density_adj = 1.0 / math.sqrt(density + eps)\n\n    # 5. Assortativity adjustment – positive assortativity can lengthen paths\n    assort_adj = math.exp(assort / 2.0)  # keeps factor within a reasonable range\n\n    # 6. Triangle adjustment – more triangles relative to edges lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term and several multiplicative\n    adjustments that capture clustering, degree variance, density,\n    assortativity and triangle abundance.  No external libraries are used.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    if density < 0:\n        density = 0.0\n\n    trans      = s.get('transitivity', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    m          = s.get('m', 1)\n\n    # 1. Baseline distance estimate\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment – more clustering tends to increase path lengths\n    clustering_adj = 1.0 + avg_clust\n\n    # 3. Degree‑variance adjustment – higher variance tends to shorten paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment – denser graphs have shorter average paths\n    density_adj = 1.0 / (1.0 + density)\n\n    # 5. Assortativity adjustment – positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 6. Triangle adjustment – more triangles relative to edges lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term and several multiplicative\n    adjustments that capture clustering, degree variance, density,\n    assortativity and triangle abundance.  No external libraries are used.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    if density < 0:\n        density = 0.0\n\n    trans      = s.get('transitivity', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n    m          = s.get('m', 1)\n\n    # 1. Baseline distance estimate\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment – more clustering tends to increase path lengths\n    clustering_adj = 1.0 + avg_clust\n\n    # 3. Degree‑variance adjustment – higher variance tends to shorten paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment – denser graphs have shorter average paths\n    density_adj = 1.0 / (1.0 + density)\n\n    # 5. Assortativity adjustment – positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 6. Triangle adjustment – more triangles relative to edges lengthen paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T01:51:04.706033+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 6, "island_id": 2, "population_idx": 4, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:52:06.754134+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.078142", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:53:39.310402+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:53:39.312263+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 6, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:55:02.132270+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.077088", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:55:02.133951+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 6, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:56:27.162160+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.078332", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:57:57.994771+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.055391", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T01:59:43.697572+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i3_p4_841691868", "generation": 6, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.5890379278445883, "spearman": -0.4335849587299394, "pearson": -0.36524391197220785, "rmse": 5406.427671362417, "mae": 4131.3921519140085, "simplicity_score": 0.17522258257232803, "novelty_bonus": 0.42363021473211904, "total_score": 0.37892606029907105, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how average path length relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that mixes size, sparsity, degree dispersion,\n    triangle abundance, clustering strength, and degree assortativity.\n    All operations use only built‑in arithmetic to avoid external imports.\n    \"\"\"\n    # Size to edge ratio – captures overall sparsity\n    size_edge = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # Degree dispersion relative to variability – higher spread suggests\n    # longer paths through hubs\n    deg_disp = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # Triangle density – more triangles usually shorten paths\n    tri_dense = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # Combined clustering factor – square to amplify the effect\n    cluster_factor = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # Assortativity magnitude – strong correlation can create bottlenecks\n    assort_factor = (s['degree_assortativity'] ** 2 + 1.0)\n\n    # Final invariant: product of sparsity, dispersion, and triangle terms,\n    # divided by clustering and assortativity terms\n    invariant = (size_edge * deg_disp * tri_dense) / (cluster_factor * assort_factor)\n\n    return invariant\n\ndef new_invariant(s):\n    \"\"\"\n    A hand‑crafted composite invariant built only from arithmetic\n    operations on the supplied pre‑computed statistics.\n\n    The formula mixes size, sparsity, degree dispersion, triangle\n    abundance, clustering, and degree assortativity – all quantities\n    known to influence the average shortest‑path length.\n\n    Key assumptions:\n        • s contains the keys listed in the problem statement.\n        • No external modules may be imported; only built‑in\n          operations (addition, subtraction, multiplication,\n          division, pow, min, max, etc.) are used.\n\n    The structure is:\n\n        invariant = (size_factor * degree_factor * triangle_factor)\n                    / (clustering_factor * assortativity_factor)\n\n    The \"+ 1\" terms in denominators guarantee numerical stability\n    for very small or zero values.\n    \"\"\"\n\n    # 1. Size‑to‑edge ratio: captures overall sparsity.\n    size_factor = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree spread relative to its standard deviation.\n    #    Larger spread tends to create longer paths, especially when\n    #    combined with a high variance of degrees.\n    degree_factor = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # 3. Triangle density (shifted to avoid division by zero).\n    triangle_factor = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Clustering influence.  Square both local and global clustering\n    #    before averaging to give more weight to high‑clustering graphs.\n    clustering_factor = (pow(s['avg_clustering'], 2) + pow(s['transitivity'], 2)) / 2.0\n\n    # 5. Assortativity influence.  Strong positive or negative assortativity\n    #    usually creates bottlenecks, so we penalise large absolute values.\n    assortativity_factor = pow(s['degree_assortativity'], 2) + 1.0\n\n    # 6. Combine all pieces.  We multiply the first three terms – each\n    #    known to *shorten* paths – and divide by the last two, which\n    #    typically *enlarge* the average shortest path.\n    invariant = (size_factor * degree_factor * triangle_factor) / (clustering_factor * assortativity_factor)\n\n    return invariant\n\ndef new_invariant(s):\n    \"\"\"\n    A composite invariant that mixes several pre‑computed graph statistics\n    to produce a value correlated with the average shortest‑path length.\n    It uses only arithmetic, comparisons, and basic Python built‑ins.\n\n    Keys required from the dictionary `s`:\n        - n                 (int) number of nodes\n        - m                 (int) number of edges\n        - density           (float) edge density\n        - avg_degree        (float) average degree\n        - max_degree        (int) maximum degree\n        - min_degree        (int) minimum degree\n        - std_degree        (float) degree standard deviation\n        - avg_clustering    (float) average local clustering coefficient\n        - transitivity      (float) global transitivity (overall clustering)\n        - degree_assortativity (float) degree assortativity coefficient\n        - num_triangles     (int) number of triangles\n        - degrees           (list[int]) sorted degree sequence\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Size to sparsity ratio\n    size_edge_ratio = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree dispersion: relative spread compared to variation\n    degree_spread = (s['max_degree'] - s['min_degree'] + 1.0)\n    degree_variation = s['std_degree'] + 1.0\n    degree_dispersion = degree_spread / degree_variation\n\n    # 3. Triangle density: triangles per node (shifted to avoid zero)\n    triangle_density = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Local triangle power: square of clustering and transitivity\n    clustering_power = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # 5. Assortativity magnitude: square to make always positive\n    assort_magnitude = s['degree_assortativity'] ** 2 + 1.0\n\n    # ------------------------------------------------------------------\n    # Combine everything into one scalar\n    # The product of the first three components emphasizes sparsity,\n    # degree spread, and triangle abundance – all of which can affect\n    # path lengths.  Dividing by the clustering and assortativity terms\n    # dampens the effect of very high clustering or strong degree\n    # correlations.\n    invariant = (\n        size_edge_ratio\n        * degree_dispersion\n        * triangle_density\n    ) / (\n        clustering_power\n        * assort_magnitude\n    )\n\n    return invariant\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.077088\nbelow_novelty_threshold: novelty_bonus=0.078332\nbelow_novelty_threshold: novelty_bonus=0.055391\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant built solely from arithmetic on a\n    dictionary of pre‑computed graph statistics.  The function\n    mixes features that influence the average shortest‑path\n    length: overall sparsity, degree spread, triangle abundance,\n    clustering, assortativity, and an extra degree‑median term.\n\n    Parameters\n    ----------\n    s : dict\n        Must contain the following keys:\n            n                    int   – number of nodes\n            m                    int   – number of edges\n            density              float – edge density (between 0 and 1)\n            avg_degree           float\n            max_degree           int\n            min_degree           int\n            std_degree           float\n            avg_clustering       float\n            transitivity         float\n            degree_assortativity float\n            num_triangles        int\n            degrees              list[int] – sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar that is designed to correlate with the average\n        shortest‑path length.  The expression uses only built‑in\n        Python operations – no external imports, no graph traversal.\n    \"\"\"\n\n    # 1. Size / sparsity factor – larger n relative to m tends to increase path length\n    size_factor = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree spread relative to variability – wide dispersion usually lengthens paths\n    degree_dispersion = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # 3. Triangle density – more triangles typically shorten paths\n    triangle_factor = (s['num_triangles'] + 1.0) / (s['density'] + 1.0)\n\n    # 4. Average degree influence – higher avg degree often reduces path length\n    avg_deg_factor = 1.0 + s['avg_degree'] / (s['n'] + 1.0)\n\n    # 5. Median degree (computed from the sorted degree list)\n    deg_list = s['degrees']\n    l = len(deg_list)\n    if l == 0:\n        median_degree = 0.0\n    elif l % 2 == 1:                    # odd number of elements\n        median_degree = deg_list[l // 2]\n    else:                               # even number – average of two middle values\n        median_degree = (deg_list[l // 2 - 1] + deg_list[l // 2]) / 2.0\n    median_factor = 1.0 + median_degree / (s['max_degree'] + 1.0)\n\n    # 6. Clustering influence – higher clustering generally shortens paths\n    clustering = (s['avg_clustering'] + s['transitivity']) / 2.0\n    clustering_factor = clustering ** 2   # amplify effect\n\n    # 7. Assortativity penalty – strong degree correlation can create bottlenecks\n    assort_factor = abs(s['degree_assortativity']) + 1.0\n\n    # 8. Combine all pieces into a single scalar.\n    #    Numerators contain factors that tend to reduce the average\n    #    shortest‑path length, denominators penalise the opposite.\n    invariant = (\n        size_factor\n        * degree_dispersion\n        * triangle_factor\n        * avg_deg_factor\n        * median_factor\n    ) / (clustering_factor * assort_factor)\n\n    return invariant\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite invariant built solely from arithmetic on a\n    dictionary of pre‑computed graph statistics.  The function\n    mixes features that influence the average shortest‑path\n    length: overall sparsity, degree spread, triangle abundance,\n    clustering, assortativity, and an extra degree‑median term.\n\n    Parameters\n    ----------\n    s : dict\n        Must contain the following keys:\n            n                    int   – number of nodes\n            m                    int   – number of edges\n            density              float – edge density (between 0 and 1)\n            avg_degree           float\n            max_degree           int\n            min_degree           int\n            std_degree           float\n            avg_clustering       float\n            transitivity         float\n            degree_assortativity float\n            num_triangles        int\n            degrees              list[int] – sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar that is designed to correlate with the average\n        shortest‑path length.  The expression uses only built‑in\n        Python operations – no external imports, no graph traversal.\n    \"\"\"\n\n    # 1. Size / sparsity factor – larger n relative to m tends to increase path length\n    size_factor = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree spread relative to variability – wide dispersion usually lengthens paths\n    degree_dispersion = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # 3. Triangle density – more triangles typically shorten paths\n    triangle_factor = (s['num_triangles'] + 1.0) / (s['density'] + 1.0)\n\n    # 4. Average degree influence – higher avg degree often reduces path length\n    avg_deg_factor = 1.0 + s['avg_degree'] / (s['n'] + 1.0)\n\n    # 5. Median degree (computed from the sorted degree list)\n    deg_list = s['degrees']\n    l = len(deg_list)\n    if l == 0:\n        median_degree = 0.0\n    elif l % 2 == 1:                    # odd number of elements\n        median_degree = deg_list[l // 2]\n    else:                               # even number – average of two middle values\n        median_degree = (deg_list[l // 2 - 1] + deg_list[l // 2]) / 2.0\n    median_factor = 1.0 + median_degree / (s['max_degree'] + 1.0)\n\n    # 6. Clustering influence – higher clustering generally shortens paths\n    clustering = (s['avg_clustering'] + s['transitivity']) / 2.0\n    clustering_factor = clustering ** 2   # amplify effect\n\n    # 7. Assortativity penalty – strong degree correlation can create bottlenecks\n    assort_factor = abs(s['degree_assortativity']) + 1.0\n\n    # 8. Combine all pieces into a single scalar.\n    #    Numerators contain factors that tend to reduce the average\n    #    shortest‑path length, denominators penalise the opposite.\n    invariant = (\n        size_factor\n        * degree_dispersion\n        * triangle_factor\n        * avg_deg_factor\n        * median_factor\n    ) / (clustering_factor * assort_factor)\n\n    return invariant"}}
{"timestamp": "2026-02-13T01:59:43.701307+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "phase1_20260212T231418Z", "generation": 7, "model_name": "gpt-oss:20b", "best_val_score": 0.5491013268732999, "no_improve_count": 5}}
{"timestamp": "2026-02-13T02:00:47.822927+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i0_p0_387478378", "generation": 7, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5073229291716687, "spearman": 0.4150222811904144, "pearson": 0.46961269744045087, "rmse": 156.17358506333397, "mae": 144.3951343994114, "simplicity_score": 0.24635279243247865, "novelty_bonus": 0.5499720816070521, "total_score": 0.4217733235638186, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a compact weighted product of factors that tend to\n    shorten or lengthen paths.  All operations use only built‑in Python\n    functions, so no external imports are required.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density)               # overall density\n    val *= (1 + clustering)            # local clustering\n    val *= (1 + trans)                 # transitivity\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + pow(num_tri, 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a compact weighted product of factors that tend to\n    shorten or lengthen paths.  All operations use only built‑in Python\n    functions, so no external imports are required.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density)               # overall density\n    val *= (1 + clustering)            # local clustering\n    val *= (1 + trans)                 # transitivity\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + pow(num_tri, 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T02:02:16.559877+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i0_p1_898087625", "generation": 7, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6145978391356542, "spearman": 0.46699560001338325, "pearson": 0.5474034198526755, "rmse": 60.85691193406195, "mae": 55.83509204375653, "simplicity_score": 0.24623806727974953, "novelty_bonus": 0.4950530778595158, "total_score": 0.4312613368204963, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density) * (1 + trans) * (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T02:03:37.117200+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i0_p2_288328103", "generation": 7, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5634093637454982, "spearman": 0.459656663787876, "pearson": 0.5508394705122999, "rmse": 43.49913130078957, "mae": 40.95914373841136, "simplicity_score": 0.24724760766844345, "novelty_bonus": 0.509884085907965, "total_score": 0.43224307920001614, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a compact product of factors that tend to shorten or lengthen\n    paths, with coefficients chosen to keep the formula simple while capturing\n    the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a compact product of factors that tend to shorten or lengthen\n    paths, with coefficients chosen to keep the formula simple while capturing\n    the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density)\n    val *= (1 + clustering)\n    val *= (1 + trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T02:05:01.638838+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i0_p3_239557784", "generation": 7, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6937334933973589, "spearman": 0.5984139347536365, "pearson": 0.6899706491780693, "rmse": 30.689603036649903, "mae": 28.779145812203588, "simplicity_score": 0.24577833077392158, "novelty_bonus": 0.40958812129657063, "total_score": 0.47123906992057374, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a compact product of factors that tend to shorten or\n    lengthen paths.  Coefficients are chosen to keep the formula simple\n    while capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a compact product of factors that tend to shorten or\n    lengthen paths.  Coefficients are chosen to keep the formula simple\n    while capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T02:06:32.481971+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i0_p4_682495503", "generation": 7, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5488115246098438, "spearman": 0.49999193729544406, "pearson": 0.5967148691949471, "rmse": 60.27622117051265, "mae": 56.86759487310753, "simplicity_score": 0.2484472613346054, "novelty_bonus": 0.48841352526532766, "total_score": 0.4462094784942414, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density)\n    val *= (1 + trans)\n    val *= (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density)\n    val *= (1 + trans)\n    val *= (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T02:07:45.581025+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i1_p0_636761825", "generation": 7, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3277310924369748, "spearman": 0.1814596045374779, "pearson": 0.42632632245226104, "rmse": 2.608125658730113, "mae": 2.481958151805334, "simplicity_score": 0.11693493210030913, "novelty_bonus": 0.2981402142950903, "total_score": 0.20355885297732787, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = n ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degs = s['degrees']\n    mid = len(degs) // 2\n    if len(degs) % 2 == 0:\n        median_deg = (degs[mid - 1] + degs[mid]) / 2.0\n    else:\n        median_deg = degs[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degs = s['degrees']\n    mid = len(degs) // 2\n    if len(degs) % 2 == 0:\n        median_deg = (degs[mid - 1] + degs[mid]) / 2.0\n    else:\n        median_deg = degs[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )"}}
{"timestamp": "2026-02-13T02:09:51.317854+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i1_p1_139752483", "generation": 7, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3277310924369748, "spearman": 0.1814596045374779, "pearson": 0.42632632245226104, "rmse": 2.608125658730113, "mae": 2.481958151805334, "simplicity_score": 0.1161132569655871, "novelty_bonus": 0.2981402142950903, "total_score": 0.20339451795038346, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = n ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )"}}
{"timestamp": "2026-02-13T02:11:27.560848+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i1_p2_832736746", "generation": 7, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3277310924369748, "spearman": 0.1814596045374779, "pearson": 0.42632632245226104, "rmse": 2.608125658730113, "mae": 2.481958151805334, "simplicity_score": 0.11613663459153037, "novelty_bonus": 0.2981402142950903, "total_score": 0.20339919347557212, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = n ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = n ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = n ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )"}}
{"timestamp": "2026-02-13T02:24:05.568270+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i1_p3_199908202", "generation": 7, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3277310924369748, "spearman": 0.1814596045374779, "pearson": 0.42632632245226104, "rmse": 2.608125658730113, "mae": 2.481958151805334, "simplicity_score": 0.11688196888982166, "novelty_bonus": 0.2981402142950903, "total_score": 0.20354826033523038, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = n ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )"}}
{"timestamp": "2026-02-13T02:25:47.054192+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i1_p4_7362269", "generation": 7, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3277310924369748, "spearman": 0.1814596045374779, "pearson": 0.42632632245226104, "rmse": 2.608125658730113, "mae": 2.481958151805334, "simplicity_score": 0.1161132569655871, "novelty_bonus": 0.2981402142950903, "total_score": 0.20339451795038346, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = n ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )"}}
{"timestamp": "2026-02-13T02:27:28.626305+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i2_p0_796842586", "generation": 7, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.838655462184874, "spearman": 0.822381617933613, "pearson": 0.8092943132319474, "rmse": 96.76067711620186, "mae": 68.40336309547178, "simplicity_score": 0.1787415931795217, "novelty_bonus": 0.23580122596704722, "total_score": 0.517679495392825, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length using only pre‑computed\n    graph statistics.  The formula is a product of a simple base term\n    and several multiplicative corrections that capture the effects of\n    clustering, degree heterogeneity, density, assortativity, and\n    triangle abundance.  No external libraries or graph traversal\n    algorithms are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph features.  Expected keys\n        (with safe fallbacks if missing):\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n            = s.get('n', 1)\n    m            = s.get('m', 1)\n    avg_deg      = s.get('avg_degree', 1.0)\n    max_deg      = s.get('max_degree', 1.0)\n    min_deg      = s.get('min_degree', 1.0)\n    std_deg      = s.get('std_degree', 0.0)\n    clustering   = s.get('avg_clustering', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    density      = s.get('density', 0.0)\n    triangles    = s.get('num_triangles', 0)\n\n    # Avoid division by zero\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    if max_deg <= 0:\n        max_deg = 1.0\n    if min_deg <= 0:\n        min_deg = 1.0\n    if density <= 0:\n        density = 1e-6\n\n    # ---------- Base estimate ----------\n    base = n / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering: more triangles → longer paths\n    clustering_adj = 1.0 + clustering\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    The estimate is a product of a simple base term and several multiplicative\n    corrections that capture the effects of clustering, degree heterogeneity,\n    density, assortativity, and triangle abundance.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph features.  Expected keys\n        (with safe fallbacks if missing):\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n            = s.get('n', 1)\n    m            = s.get('m', 1)\n    avg_deg      = s.get('avg_degree', 1.0)\n    max_deg      = s.get('max_degree', 1.0)\n    min_deg      = s.get('min_degree', 1.0)\n    std_deg      = s.get('std_degree', 0.0)\n    clustering   = s.get('avg_clustering', 0.0)\n    trans        = s.get('transitivity', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    density      = s.get('density', 0.0)\n    triangles    = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:      avg_deg = 1.0\n    if max_deg <= 0:      max_deg = 1.0\n    if min_deg <= 0:      min_deg = 1.0\n    if density <= 0:      density = 1e-6\n    if m <= 0:            m = 1\n\n    # ---------- Base estimate ----------\n    base = n / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + clustering)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    The estimate is a product of a simple base term and several multiplicative\n    corrections that capture the effects of clustering, degree heterogeneity,\n    density, assortativity, and triangle abundance.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph features.  Expected keys\n        (with safe fallbacks if missing):\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n            = s.get('n', 1)\n    m            = s.get('m', 1)\n    avg_deg      = s.get('avg_degree', 1.0)\n    max_deg      = s.get('max_degree', 1.0)\n    min_deg      = s.get('min_degree', 1.0)\n    std_deg      = s.get('std_degree', 0.0)\n    clustering   = s.get('avg_clustering', 0.0)\n    trans        = s.get('transitivity', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    density      = s.get('density', 0.0)\n    triangles    = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:      avg_deg = 1.0\n    if max_deg <= 0:      max_deg = 1.0\n    if min_deg <= 0:      min_deg = 1.0\n    if density <= 0:      density = 1e-6\n    if m <= 0:            m = 1\n\n    # ---------- Base estimate ----------\n    base = n / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + clustering)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T02:29:35.452367+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i2_p1_786924377", "generation": 7, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.6326530612244897, "spearman": 0.48319376104172046, "pearson": 0.5971166014080778, "rmse": 4.284567677337845, "mae": 3.0984722541451406, "simplicity_score": 0.17823499808336682, "novelty_bonus": 0.38298057451436285, "total_score": 0.3921380524918424, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length using only pre‑computed\n    graph statistics.  The formula is a product of a simple base term\n    and several multiplicative corrections that capture the effects of\n    clustering, degree heterogeneity, density, assortativity, and\n    triangle abundance.  No external libraries or graph traversal\n    algorithms are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph features.  Expected keys\n        (with safe fallbacks if missing):\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n            = s.get('n', 1)\n    m            = s.get('m', 1)\n    avg_deg      = s.get('avg_degree', 1.0)\n    max_deg      = s.get('max_degree', 1.0)\n    min_deg      = s.get('min_degree', 1.0)\n    std_deg      = s.get('std_degree', 0.0)\n    clustering   = s.get('avg_clustering', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    density      = s.get('density', 0.0)\n    triangles    = s.get('num_triangles', 0)\n\n    # Avoid division by zero\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    if max_deg <= 0:\n        max_deg = 1.0\n    if min_deg <= 0:\n        min_deg = 1.0\n    if density <= 0:\n        density = 1e-6\n\n    # ---------- Base estimate ----------\n    base = n / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering: more triangles → longer paths\n    clustering_adj = 1.0 + clustering\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a simple base term and multiplicative\n    corrections that capture the effects of clustering, degree heterogeneity,\n    density, assortativity, and extreme degree values.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics.  Missing keys are replaced with\n        reasonable defaults.\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n        = s.get('n', 1)                 # number of nodes\n    m        = s.get('m', 1)                 # number of edges\n    avg_deg  = s.get('avg_degree', 1.0)\n    max_deg  = s.get('max_degree', 1.0)\n    min_deg  = s.get('min_degree', 1.0)\n    std_deg  = s.get('std_degree', 0.0)\n    trans    = s.get('transitivity', 0.0)\n    assort   = s.get('degree_assortativity', 0.0)\n    density  = s.get('density', None)\n    tri      = s.get('num_triangles', 0)\n\n    # Guard against invalid or missing values\n    if avg_deg <= 0:\n        avg_deg = 2 * m / n if n > 0 else 1.0\n    if max_deg <= 0:\n        max_deg = 1.0\n    if min_deg <= 0:\n        min_deg = 1.0\n    if density is None or density <= 0:\n        density = 2 * m / (n * (n - 1)) if n > 1 else 0.0\n\n    # ---------- Base estimate ----------\n    # A simple baseline that grows with graph size and shrinks with average degree.\n    base = n / (avg_deg + 1.0)\n\n    # ---------- Adjustment factors ----------\n    # 1. Clustering: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * trans\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (1.0 + density)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle abundance relative to edges\n    tri_adj = 1.0 + tri / (m + 1.0)\n\n    # ---------- Combine all factors ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a simple base term and multiplicative\n    corrections that capture the effects of clustering, degree heterogeneity,\n    density, assortativity, and extreme degree values.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics.  Missing keys are replaced with\n        reasonable defaults.\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n        = s.get('n', 1)                 # number of nodes\n    m        = s.get('m', 1)                 # number of edges\n    avg_deg  = s.get('avg_degree', 1.0)\n    max_deg  = s.get('max_degree', 1.0)\n    min_deg  = s.get('min_degree', 1.0)\n    std_deg  = s.get('std_degree', 0.0)\n    trans    = s.get('transitivity', 0.0)\n    assort   = s.get('degree_assortativity', 0.0)\n    density  = s.get('density', None)\n    tri      = s.get('num_triangles', 0)\n\n    # Guard against invalid or missing values\n    if avg_deg <= 0:\n        avg_deg = 2 * m / n if n > 0 else 1.0\n    if max_deg <= 0:\n        max_deg = 1.0\n    if min_deg <= 0:\n        min_deg = 1.0\n    if density is None or density <= 0:\n        density = 2 * m / (n * (n - 1)) if n > 1 else 0.0\n\n    # ---------- Base estimate ----------\n    # A simple baseline that grows with graph size and shrinks with average degree.\n    base = n / (avg_deg + 1.0)\n\n    # ---------- Adjustment factors ----------\n    # 1. Clustering: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * trans\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (1.0 + density)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle abundance relative to edges\n    tri_adj = 1.0 + tri / (m + 1.0)\n\n    # ---------- Combine all factors ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T02:30:50.587864+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i2_p2_780364318", "generation": 7, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8500840336134453, "spearman": 0.8289652849941651, "pearson": 0.7555829097800564, "rmse": 81.75513794352867, "mae": 53.55685081098627, "simplicity_score": 0.17909397257846857, "novelty_bonus": 0.26478370607004686, "total_score": 0.5297365488337903, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length using only pre‑computed\n    graph statistics.  The formula is a product of a simple base term\n    and several multiplicative corrections that capture the effects of\n    clustering, degree heterogeneity, density, assortativity, and\n    triangle abundance.  No external libraries or graph traversal\n    algorithms are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph features.  Expected keys\n        (with safe fallbacks if missing):\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n            = s.get('n', 1)\n    m            = s.get('m', 1)\n    avg_deg      = s.get('avg_degree', 1.0)\n    max_deg      = s.get('max_degree', 1.0)\n    min_deg      = s.get('min_degree', 1.0)\n    std_deg      = s.get('std_degree', 0.0)\n    clustering   = s.get('avg_clustering', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    density      = s.get('density', 0.0)\n    triangles    = s.get('num_triangles', 0)\n\n    # Avoid division by zero\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    if max_deg <= 0:\n        max_deg = 1.0\n    if min_deg <= 0:\n        min_deg = 1.0\n    if density <= 0:\n        density = 1e-6\n\n    # ---------- Base estimate ----------\n    base = n / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering: more triangles → longer paths\n    clustering_adj = 1.0 + clustering\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length using only pre‑computed graph\n    statistics.  The formula is a product of a simple base term and several\n    multiplicative corrections that capture the effects of clustering,\n    degree heterogeneity, density, assortativity, degree extremes, and\n    triangle abundance.  No external libraries or graph traversal\n    algorithms are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph features.  Expected keys\n        (with safe fallbacks if missing):\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n           = s.get('n', 1)\n    m           = s.get('m', 1)\n    avg_deg     = s.get('avg_degree', 1.0)\n    max_deg     = s.get('max_degree', 1.0)\n    min_deg     = s.get('min_degree', 1.0)\n    std_deg     = s.get('std_degree', 0.0)\n    clustering  = s.get('avg_clustering', 0.0)\n    trans       = s.get('transitivity', 0.0)          # unused but kept for completeness\n    assort      = s.get('degree_assortativity', 0.0)\n    density     = s.get('density', 0.0)\n    triangles   = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    if max_deg <= 0:\n        max_deg = 1.0\n    if min_deg <= 0:\n        min_deg = 1.0\n    if density <= 0:\n        density = 1e-6\n\n    # ---------- Base estimate ----------\n    base = n / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering: more triangles → longer paths\n    clustering_adj = 1.0 + clustering\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Maximum degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length using only pre‑computed graph\n    statistics.  The formula is a product of a simple base term and several\n    multiplicative corrections that capture the effects of clustering,\n    degree heterogeneity, density, assortativity, degree extremes, and\n    triangle abundance.  No external libraries or graph traversal\n    algorithms are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph features.  Expected keys\n        (with safe fallbacks if missing):\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n           = s.get('n', 1)\n    m           = s.get('m', 1)\n    avg_deg     = s.get('avg_degree', 1.0)\n    max_deg     = s.get('max_degree', 1.0)\n    min_deg     = s.get('min_degree', 1.0)\n    std_deg     = s.get('std_degree', 0.0)\n    clustering  = s.get('avg_clustering', 0.0)\n    trans       = s.get('transitivity', 0.0)          # unused but kept for completeness\n    assort      = s.get('degree_assortativity', 0.0)\n    density     = s.get('density', 0.0)\n    triangles   = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    if max_deg <= 0:\n        max_deg = 1.0\n    if min_deg <= 0:\n        min_deg = 1.0\n    if density <= 0:\n        density = 1e-6\n\n    # ---------- Base estimate ----------\n    base = n / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering: more triangles → longer paths\n    clustering_adj = 1.0 + clustering\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Maximum degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T02:32:02.745508+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i2_p3_664850856", "generation": 7, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.4896518607442977, "spearman": 0.349028856607261, "pearson": 0.4584682297882643, "rmse": 4.71608323597588, "mae": 3.2498951376591148, "simplicity_score": 0.17920640820118539, "novelty_bonus": 0.3140643516087901, "total_score": 0.3045750154265046, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length using only pre‑computed\n    graph statistics.  The formula is a product of a simple base term\n    and several multiplicative corrections that capture the effects of\n    clustering, degree heterogeneity, density, assortativity, and\n    triangle abundance.  No external libraries or graph traversal\n    algorithms are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph features.  Expected keys\n        (with safe fallbacks if missing):\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n            = s.get('n', 1)\n    m            = s.get('m', 1)\n    avg_deg      = s.get('avg_degree', 1.0)\n    max_deg      = s.get('max_degree', 1.0)\n    min_deg      = s.get('min_degree', 1.0)\n    std_deg      = s.get('std_degree', 0.0)\n    clustering   = s.get('avg_clustering', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    density      = s.get('density', 0.0)\n    triangles    = s.get('num_triangles', 0)\n\n    # Avoid division by zero\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    if max_deg <= 0:\n        max_deg = 1.0\n    if min_deg <= 0:\n        min_deg = 1.0\n    if density <= 0:\n        density = 1e-6\n\n    # ---------- Base estimate ----------\n    base = n / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering: more triangles → longer paths\n    clustering_adj = 1.0 + clustering\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula is a product of a simple base term and\n    multiplicative corrections that capture the effects of clustering,\n    degree heterogeneity, density, assortativity, extreme degrees and\n    triangle abundance.  No external libraries are used and the function\n    works purely on the feature dictionary.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    if max_deg <= 0:\n        max_deg = 1.0\n    if min_deg <= 0:\n        min_deg = 1.0\n    if density < 0:\n        density = 0.0\n    if m < 0:\n        m = 1\n\n    # 1. Base estimate: scales with n and inversely with average degree\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + clustering\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: denser graphs have shorter paths\n    density_adj = 1.0 / (1.0 + density)\n\n    # 5. Assortativity adjustment: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 6. Max degree adjustment: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 7. Minimum degree adjustment: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1.0)\n\n    # 8. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combine all factors multiplicatively\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula is a product of a simple base term and\n    multiplicative corrections that capture the effects of clustering,\n    degree heterogeneity, density, assortativity, extreme degrees and\n    triangle abundance.  No external libraries are used and the function\n    works purely on the feature dictionary.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    if max_deg <= 0:\n        max_deg = 1.0\n    if min_deg <= 0:\n        min_deg = 1.0\n    if density < 0:\n        density = 0.0\n    if m < 0:\n        m = 1\n\n    # 1. Base estimate: scales with n and inversely with average degree\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + clustering\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: denser graphs have shorter paths\n    density_adj = 1.0 / (1.0 + density)\n\n    # 5. Assortativity adjustment: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 6. Max degree adjustment: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 7. Minimum degree adjustment: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1.0)\n\n    # 8. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combine all factors multiplicatively\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T02:33:41.092148+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i2_p4_471567144", "generation": 7, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8884033613445379, "spearman": 0.8562029761505802, "pearson": 0.8120574905615511, "rmse": 7.62661215948433, "mae": 4.514146493182545, "simplicity_score": 0.17853405031618008, "novelty_bonus": 0.22039635324270634, "total_score": 0.529927204111338, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length using only pre‑computed\n    graph statistics.  The formula is a product of a simple base term\n    and several multiplicative corrections that capture the effects of\n    clustering, degree heterogeneity, density, assortativity, and\n    triangle abundance.  No external libraries or graph traversal\n    algorithms are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph features.  Expected keys\n        (with safe fallbacks if missing):\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n            = s.get('n', 1)\n    m            = s.get('m', 1)\n    avg_deg      = s.get('avg_degree', 1.0)\n    max_deg      = s.get('max_degree', 1.0)\n    min_deg      = s.get('min_degree', 1.0)\n    std_deg      = s.get('std_degree', 0.0)\n    clustering   = s.get('avg_clustering', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    density      = s.get('density', 0.0)\n    triangles    = s.get('num_triangles', 0)\n\n    # Avoid division by zero\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    if max_deg <= 0:\n        max_deg = 1.0\n    if min_deg <= 0:\n        min_deg = 1.0\n    if density <= 0:\n        density = 1e-6\n\n    # ---------- Base estimate ----------\n    base = n / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering: more triangles → longer paths\n    clustering_adj = 1.0 + clustering\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104917\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a simple product of a base term and multiplicative\n    corrections that capture the effects of clustering, degree heterogeneity,\n    density, assortativity, and degree extremes.  No external libraries or\n    graph traversal algorithms are used.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:   avg_deg = 1.0\n    if max_deg <= 0:   max_deg = 1.0\n    if min_deg <= 0:   min_deg = 1.0\n    if density <= 0:   density = 1e-6\n    if m <= 0:         m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a simple product of a base term and multiplicative\n    corrections that capture the effects of clustering, degree heterogeneity,\n    density, assortativity, and degree extremes.  No external libraries or\n    graph traversal algorithms are used.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:   avg_deg = 1.0\n    if max_deg <= 0:   max_deg = 1.0\n    if min_deg <= 0:   min_deg = 1.0\n    if density <= 0:   density = 1e-6\n    if m <= 0:         m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T02:35:16.323046+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i3_p0_705165378", "generation": 7, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.5867252543940795, "spearman": -0.5922153732003401, "pearson": -0.43887592884708837, "rmse": 1.708226690933146, "mae": 1.3323450449725835, "simplicity_score": 0.18088427959769293, "novelty_bonus": 0.26876402168687574, "total_score": 0.4129137490257713, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how average path length relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that mixes size, sparsity, degree dispersion,\n    triangle abundance, clustering strength, and degree assortativity.\n    All operations use only built‑in arithmetic to avoid external imports.\n    \"\"\"\n    # Size to edge ratio – captures overall sparsity\n    size_edge = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # Degree dispersion relative to variability – higher spread suggests\n    # longer paths through hubs\n    deg_disp = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # Triangle density – more triangles usually shorten paths\n    tri_dense = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # Combined clustering factor – square to amplify the effect\n    cluster_factor = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # Assortativity magnitude – strong correlation can create bottlenecks\n    assort_factor = (s['degree_assortativity'] ** 2 + 1.0)\n\n    # Final invariant: product of sparsity, dispersion, and triangle terms,\n    # divided by clustering and assortativity terms\n    invariant = (size_edge * deg_disp * tri_dense) / (cluster_factor * assort_factor)\n\n    return invariant\n\ndef new_invariant(s):\n    \"\"\"\n    A hand‑crafted composite invariant built only from arithmetic\n    operations on the supplied pre‑computed statistics.\n\n    The formula mixes size, sparsity, degree dispersion, triangle\n    abundance, clustering, and degree assortativity – all quantities\n    known to influence the average shortest‑path length.\n\n    Key assumptions:\n        • s contains the keys listed in the problem statement.\n        • No external modules may be imported; only built‑in\n          operations (addition, subtraction, multiplication,\n          division, pow, min, max, etc.) are used.\n\n    The structure is:\n\n        invariant = (size_factor * degree_factor * triangle_factor)\n                    / (clustering_factor * assortativity_factor)\n\n    The \"+ 1\" terms in denominators guarantee numerical stability\n    for very small or zero values.\n    \"\"\"\n\n    # 1. Size‑to‑edge ratio: captures overall sparsity.\n    size_factor = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree spread relative to its standard deviation.\n    #    Larger spread tends to create longer paths, especially when\n    #    combined with a high variance of degrees.\n    degree_factor = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # 3. Triangle density (shifted to avoid division by zero).\n    triangle_factor = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Clustering influence.  Square both local and global clustering\n    #    before averaging to give more weight to high‑clustering graphs.\n    clustering_factor = (pow(s['avg_clustering'], 2) + pow(s['transitivity'], 2)) / 2.0\n\n    # 5. Assortativity influence.  Strong positive or negative assortativity\n    #    usually creates bottlenecks, so we penalise large absolute values.\n    assortativity_factor = pow(s['degree_assortativity'], 2) + 1.0\n\n    # 6. Combine all pieces.  We multiply the first three terms – each\n    #    known to *shorten* paths – and divide by the last two, which\n    #    typically *enlarge* the average shortest path.\n    invariant = (size_factor * degree_factor * triangle_factor) / (clustering_factor * assortativity_factor)\n\n    return invariant\n\ndef new_invariant(s):\n    \"\"\"\n    A composite invariant that mixes several pre‑computed graph statistics\n    to produce a value correlated with the average shortest‑path length.\n    It uses only arithmetic, comparisons, and basic Python built‑ins.\n\n    Keys required from the dictionary `s`:\n        - n                 (int) number of nodes\n        - m                 (int) number of edges\n        - density           (float) edge density\n        - avg_degree        (float) average degree\n        - max_degree        (int) maximum degree\n        - min_degree        (int) minimum degree\n        - std_degree        (float) degree standard deviation\n        - avg_clustering    (float) average local clustering coefficient\n        - transitivity      (float) global transitivity (overall clustering)\n        - degree_assortativity (float) degree assortativity coefficient\n        - num_triangles     (int) number of triangles\n        - degrees           (list[int]) sorted degree sequence\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Size to sparsity ratio\n    size_edge_ratio = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree dispersion: relative spread compared to variation\n    degree_spread = (s['max_degree'] - s['min_degree'] + 1.0)\n    degree_variation = s['std_degree'] + 1.0\n    degree_dispersion = degree_spread / degree_variation\n\n    # 3. Triangle density: triangles per node (shifted to avoid zero)\n    triangle_density = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Local triangle power: square of clustering and transitivity\n    clustering_power = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # 5. Assortativity magnitude: square to make always positive\n    assort_magnitude = s['degree_assortativity'] ** 2 + 1.0\n\n    # ------------------------------------------------------------------\n    # Combine everything into one scalar\n    # The product of the first three components emphasizes sparsity,\n    # degree spread, and triangle abundance – all of which can affect\n    # path lengths.  Dividing by the clustering and assortativity terms\n    # dampens the effect of very high clustering or strong degree\n    # correlations.\n    invariant = (\n        size_edge_ratio\n        * degree_dispersion\n        * triangle_density\n    ) / (\n        clustering_power\n        * assort_magnitude\n    )\n\n    return invariant\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.077088\nbelow_novelty_threshold: novelty_bonus=0.078332\nbelow_novelty_threshold: novelty_bonus=0.055391\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Novel composite invariant for the average shortest‑path length.\n\n    The expression mixes six pre‑computed graph descriptors in a way that\n    reflects several intuitive aspects of graph connectivity:\n\n        * **Size‑to‑edge ratio** – higher when the graph is sparse.\n        * **Density bonus** – grows with overall edge density.\n        * **Degree ratio** – penalises extremely unbalanced degree\n          distributions (high max/min).\n        * **Degree variance term** – stabilises the value for graphs\n          with very little degree spread.\n        * **Triangle bonus** – rewards abundance of triangles.\n        * **Clustering‑assortativity penalty** – dampens the value when\n          clustering is high or degree assortativity is strong.\n\n    All calculations are pure arithmetic; no external modules are used.\n    \"\"\"\n    # 1. Size‑to‑edge ratio (captures sparsity)\n    size_edge_ratio = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Density bonus (tends to grow with edge density)\n    density_bonus = 1.0 + s['density']\n\n    # 3. Degree ratio (high when max/min is large)\n    degree_ratio = (s['max_degree'] + 1.0) / (s['min_degree'] + 1.0)\n\n    # 4. Degree variance stabiliser (avoids division by zero)\n    degree_variance_term = s['std_degree'] + 1.0\n\n    # 5. Triangle bonus (triangles per node, shifted to avoid zero)\n    triangle_bonus = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 6. Clustering‑assortativity penalty\n    clustering_penalty = (s['avg_clustering'] + s['transitivity']) * (abs(s['degree_assortativity']) + 1.0)\n\n    # Combine all components\n    invariant = (\n        size_edge_ratio\n        * density_bonus\n        * degree_ratio\n        * triangle_bonus\n    ) / (\n        degree_variance_term\n        * clustering_penalty\n    )\n\n    return invariant\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Novel composite invariant for the average shortest‑path length.\n\n    The expression mixes six pre‑computed graph descriptors in a way that\n    reflects several intuitive aspects of graph connectivity:\n\n        * **Size‑to‑edge ratio** – higher when the graph is sparse.\n        * **Density bonus** – grows with overall edge density.\n        * **Degree ratio** – penalises extremely unbalanced degree\n          distributions (high max/min).\n        * **Degree variance term** – stabilises the value for graphs\n          with very little degree spread.\n        * **Triangle bonus** – rewards abundance of triangles.\n        * **Clustering‑assortativity penalty** – dampens the value when\n          clustering is high or degree assortativity is strong.\n\n    All calculations are pure arithmetic; no external modules are used.\n    \"\"\"\n    # 1. Size‑to‑edge ratio (captures sparsity)\n    size_edge_ratio = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Density bonus (tends to grow with edge density)\n    density_bonus = 1.0 + s['density']\n\n    # 3. Degree ratio (high when max/min is large)\n    degree_ratio = (s['max_degree'] + 1.0) / (s['min_degree'] + 1.0)\n\n    # 4. Degree variance stabiliser (avoids division by zero)\n    degree_variance_term = s['std_degree'] + 1.0\n\n    # 5. Triangle bonus (triangles per node, shifted to avoid zero)\n    triangle_bonus = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 6. Clustering‑assortativity penalty\n    clustering_penalty = (s['avg_clustering'] + s['transitivity']) * (abs(s['degree_assortativity']) + 1.0)\n\n    # Combine all components\n    invariant = (\n        size_edge_ratio\n        * density_bonus\n        * degree_ratio\n        * triangle_bonus\n    ) / (\n        degree_variance_term\n        * clustering_penalty\n    )\n\n    return invariant"}}
{"timestamp": "2026-02-13T02:37:02.934692+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.060061", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T02:38:40.702359+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.040567", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T02:40:17.715007+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.085085", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T02:41:51.097846+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T02:41:51.098247+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 7, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T02:42:15.852872+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 3, "population_idx": 4, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.076303", "model_name": "gpt-oss:20b", "train_signal": 0.07630252100840335}}
{"timestamp": "2026-02-13T02:42:15.853284+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 7, "island_id": 3, "population_idx": 4, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T02:42:15.855929+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "phase1_20260212T231418Z", "generation": 8, "model_name": "gpt-oss:20b", "best_val_score": 0.5491013268732999, "no_improve_count": 6}}
{"timestamp": "2026-02-13T02:42:45.222323+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i0_p0_277121625", "generation": 8, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7479951980792316, "spearman": 0.6357213814300985, "pearson": 0.6943462521503254, "rmse": 24.232035678167964, "mae": 22.42062579092469, "simplicity_score": 0.24740987154190924, "novelty_bonus": 0.39032200318578625, "total_score": 0.484439265979167, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.077551\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a compact weighted product of factors that influence\n    path length, tuned to capture the main structural effects while keeping\n    the formula simple and free of explicit graph traversal.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 0.8 * density)\n    val *= (1 + 0.9 * trans)\n    val *= (1 + 0.85 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.3 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.35 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.35 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.15 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a compact weighted product of factors that influence\n    path length, tuned to capture the main structural effects while keeping\n    the formula simple and free of explicit graph traversal.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 0.8 * density)\n    val *= (1 + 0.9 * trans)\n    val *= (1 + 0.85 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.3 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.35 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.35 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.15 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T02:43:50.668951+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.056040", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T02:44:36.321583+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i0_p2_780729030", "generation": 8, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7183193277310924, "spearman": 0.6166296469773355, "pearson": 0.694888112746654, "rmse": 29.022880559132034, "mae": 27.218135780330204, "simplicity_score": 0.24582065414661958, "novelty_bonus": 0.4030149025224452, "total_score": 0.4783834250747252, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.056040\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density)\n    val *= (1 + 1.0 * trans)\n    val *= (1 + 0.9 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density)\n    val *= (1 + 1.0 * trans)\n    val *= (1 + 0.9 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T02:45:11.289627+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i0_p3_555646960", "generation": 8, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6996878751500599, "spearman": 0.6168929036574736, "pearson": 0.7145037649046517, "rmse": 22.92412837903762, "mae": 21.708594429251406, "simplicity_score": 0.24675951263099624, "novelty_bonus": 0.39886286818061023, "total_score": 0.4774572148091191, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.056040\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.0 * trans)\n    val *= (1 + 0.9 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.0 * trans)\n    val *= (1 + 0.9 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T02:46:27.011627+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i0_p4_458915775", "generation": 8, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.723409363745498, "spearman": 0.6400557414144834, "pearson": 0.7156125800330229, "rmse": 27.415278855888157, "mae": 25.443181523694822, "simplicity_score": 0.24651706300163662, "novelty_bonus": 0.3948435014789009, "total_score": 0.4877843337512393, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.056040\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T02:47:21.554690+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i1_p0_505606251", "generation": 8, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3277310924369748, "spearman": 0.1814596045374779, "pearson": 0.42632632245226104, "rmse": 2.608125658730113, "mae": 2.481958151805334, "simplicity_score": 0.1161132569655871, "novelty_bonus": 0.2981402142950903, "total_score": 0.20339451795038346, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degs = s['degrees']\n    mid = len(degs) // 2\n    if len(degs) % 2 == 0:\n        median_deg = (degs[mid - 1] + degs[mid]) / 2.0\n    else:\n        median_deg = degs[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    l = len(degrees)\n    mid = l // 2\n    if l % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * median_factor * spread_factor)\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    l = len(degrees)\n    mid = l // 2\n    if l % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * median_factor * spread_factor)"}}
{"timestamp": "2026-02-13T02:48:10.298825+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i1_p1_568741195", "generation": 8, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3277310924369748, "spearman": 0.1814596045374779, "pearson": 0.42632632245226104, "rmse": 2.608125658730113, "mae": 2.481958151805334, "simplicity_score": 0.11688196888982166, "novelty_bonus": 0.2981402142950903, "total_score": 0.20354826033523038, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degs = s['degrees']\n    mid = len(degs) // 2\n    if len(degs) % 2 == 0:\n        median_deg = (degs[mid - 1] + degs[mid]) / 2.0\n    else:\n        median_deg = degs[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )"}}
{"timestamp": "2026-02-13T02:48:51.839205+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i1_p2_37262311", "generation": 8, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3793997599039616, "spearman": 0.25137262858046794, "pearson": 0.5184583117081661, "rmse": 2.3483148213320306, "mae": 2.227428243068378, "simplicity_score": 0.11382269767006811, "novelty_bonus": 0.3271665495129109, "total_score": 0.2466008186781209, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degs = s['degrees']\n    mid = len(degs) // 2\n    if len(degs) % 2 == 0:\n        median_deg = (degs[mid - 1] + degs[mid]) / 2.0\n    else:\n        median_deg = degs[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )"}}
{"timestamp": "2026-02-13T02:49:24.951272+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i1_p3_139796998", "generation": 8, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3277310924369748, "spearman": 0.1814596045374779, "pearson": 0.42632632245226104, "rmse": 2.608125658730113, "mae": 2.481958151805334, "simplicity_score": 0.11688196888982166, "novelty_bonus": 0.2981402142950903, "total_score": 0.20354826033523038, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degs = s['degrees']\n    mid = len(degs) // 2\n    if len(degs) % 2 == 0:\n        median_deg = (degs[mid - 1] + degs[mid]) / 2.0\n    else:\n        median_deg = degs[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )"}}
{"timestamp": "2026-02-13T02:49:58.685360+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i1_p4_245481166", "generation": 8, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3793997599039616, "spearman": 0.25137262858046794, "pearson": 0.5184583117081661, "rmse": 2.3483148213320306, "mae": 2.227428243068378, "simplicity_score": 0.11437803857053233, "novelty_bonus": 0.3271665495129109, "total_score": 0.2467118868582137, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degs = s['degrees']\n    mid = len(degs) // 2\n    if len(degs) % 2 == 0:\n        median_deg = (degs[mid - 1] + degs[mid]) / 2.0\n    else:\n        median_deg = degs[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = s['n'] ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (s['max_degree'] - s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * degree_range_factor\n        * median_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = s['n'] ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (s['max_degree'] - s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * degree_range_factor\n        * median_factor\n    )"}}
{"timestamp": "2026-02-13T02:50:45.607182+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.137126", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T02:51:47.176761+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i2_p1_114530073", "generation": 8, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.5811764705882353, "spearman": 0.44435252544536447, "pearson": 0.5473582178336248, "rmse": 2.143020480512212, "mae": 2.0122593261066104, "simplicity_score": 0.12262660974968084, "novelty_bonus": 0.34093452336308405, "total_score": 0.3489819416815436, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a simple product of a base term and multiplicative\n    corrections that capture the effects of clustering, degree heterogeneity,\n    density, assortativity, and degree extremes.  No external libraries or\n    graph traversal algorithms are used.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:   avg_deg = 1.0\n    if max_deg <= 0:   max_deg = 1.0\n    if min_deg <= 0:   min_deg = 1.0\n    if density <= 0:   density = 1e-6\n    if m <= 0:         m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.137126\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic graph statistics with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 1)\n    avg_deg = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    trans = s.get('transitivity', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    std_deg = s.get('std_degree', 0.0)\n    density = s.get('density', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    triangles = s.get('num_triangles', 0)\n    max_deg = s.get('max_degree', 1.0)\n    min_deg = s.get('min_degree', 1.0)\n\n    # Base estimate: scales with √n and inversely with degree\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # Adjustments capturing various structural effects\n    clustering_adj = 1.0 + 0.4 * (trans + avg_clust)\n    variance_adj   = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n    density_adj    = 1.0 / (1.0 + density)\n    assort_adj     = 1.0 + 0.3 * assort\n    triangle_adj   = 1.0 + triangles / (m + 1.0)\n    max_adj        = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n    min_adj        = 1.0 + 1.0 / (min_deg + 1.0)\n\n    # Combined estimate\n    return (base * clustering_adj * variance_adj * density_adj *\n            assort_adj * triangle_adj * max_adj * min_adj)\n```", "extracted_code": "def new_invariant(s):\n    # Basic graph statistics with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 1)\n    avg_deg = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    trans = s.get('transitivity', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    std_deg = s.get('std_degree', 0.0)\n    density = s.get('density', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    triangles = s.get('num_triangles', 0)\n    max_deg = s.get('max_degree', 1.0)\n    min_deg = s.get('min_degree', 1.0)\n\n    # Base estimate: scales with √n and inversely with degree\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # Adjustments capturing various structural effects\n    clustering_adj = 1.0 + 0.4 * (trans + avg_clust)\n    variance_adj   = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n    density_adj    = 1.0 / (1.0 + density)\n    assort_adj     = 1.0 + 0.3 * assort\n    triangle_adj   = 1.0 + triangles / (m + 1.0)\n    max_adj        = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n    min_adj        = 1.0 + 1.0 / (min_deg + 1.0)\n\n    # Combined estimate\n    return (base * clustering_adj * variance_adj * density_adj *\n            assort_adj * triangle_adj * max_adj * min_adj)"}}
{"timestamp": "2026-02-13T02:52:42.339609+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i2_p2_439613574", "generation": 8, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8336614645858343, "spearman": 0.8124401156679922, "pearson": 0.7462201643332068, "rmse": 5.054487489642385, "mae": 2.946971567818046, "simplicity_score": 0.17830843691681952, "novelty_bonus": 0.2739933085299222, "total_score": 0.5240797377763367, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a simple product of a base term and multiplicative\n    corrections that capture the effects of clustering, degree heterogeneity,\n    density, assortativity, and degree extremes.  No external libraries or\n    graph traversal algorithms are used.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:   avg_deg = 1.0\n    if max_deg <= 0:   max_deg = 1.0\n    if min_deg <= 0:   min_deg = 1.0\n    if density <= 0:   density = 1e-6\n    if m <= 0:         m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.137126\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines a simple base term with multiplicative adjustments\n    for clustering, degree heterogeneity, density, assortativity, and\n    degree extremes.  No external libraries or graph traversal algorithms\n    are used.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Guard against invalid or missing values\n    if avg_deg <= 0:      avg_deg = 1.0\n    if max_deg <= 0:      max_deg = 1.0\n    if min_deg <= 0:      min_deg = 1.0\n    if std_deg < 0:       std_deg = 0.0\n    if density <= 0:      density = 1e-6\n    if m <= 0:            m = 1\n\n    # ---------- Base estimate ----------\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1 + 0.5 * (avg_clust + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    variance_adj = 1 / (1 + (std_deg * std_deg) / (avg_deg + 1))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1 / (1 + max_deg / (avg_deg + 1))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1 + 0.5 / (min_deg + 1)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1 + triangles / (m + 1)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines a simple base term with multiplicative adjustments\n    for clustering, degree heterogeneity, density, assortativity, and\n    degree extremes.  No external libraries or graph traversal algorithms\n    are used.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Guard against invalid or missing values\n    if avg_deg <= 0:      avg_deg = 1.0\n    if max_deg <= 0:      max_deg = 1.0\n    if min_deg <= 0:      min_deg = 1.0\n    if std_deg < 0:       std_deg = 0.0\n    if density <= 0:      density = 1e-6\n    if m <= 0:            m = 1\n\n    # ---------- Base estimate ----------\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1 + 0.5 * (avg_clust + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    variance_adj = 1 / (1 + (std_deg * std_deg) / (avg_deg + 1))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1 / (1 + max_deg / (avg_deg + 1))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1 + 0.5 / (min_deg + 1)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1 + triangles / (m + 1)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T02:53:13.031662+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i2_p3_668402961", "generation": 8, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8884033613445379, "spearman": 0.8562029761505802, "pearson": 0.8120574905615511, "rmse": 7.62661215948433, "mae": 4.514146493182545, "simplicity_score": 0.17853405031618008, "novelty_bonus": 0.22039635324270634, "total_score": 0.529927204111338, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a simple product of a base term and multiplicative\n    corrections that capture the effects of clustering, degree heterogeneity,\n    density, assortativity, and degree extremes.  No external libraries or\n    graph traversal algorithms are used.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:   avg_deg = 1.0\n    if max_deg <= 0:   max_deg = 1.0\n    if min_deg <= 0:   min_deg = 1.0\n    if density <= 0:   density = 1e-6\n    if m <= 0:         m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.137126\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative\n    corrections that capture the effects of clustering, degree variance,\n    density, assortativity, degree extremes and triangle density.\n    No external libraries or graph traversal algorithms are used.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    if max_deg <= 0:\n        max_deg = 1.0\n    if min_deg <= 0:\n        min_deg = 1.0\n    if density <= 0:\n        density = 1e-6\n    if m <= 0:\n        m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle density relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative\n    corrections that capture the effects of clustering, degree variance,\n    density, assortativity, degree extremes and triangle density.\n    No external libraries or graph traversal algorithms are used.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    if max_deg <= 0:\n        max_deg = 1.0\n    if min_deg <= 0:\n        min_deg = 1.0\n    if density <= 0:\n        density = 1e-6\n    if m <= 0:\n        m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle density relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T02:54:00.974145+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i2_p4_654428859", "generation": 8, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.49310924369747894, "spearman": 0.40638881211613603, "pearson": 0.5697157683770129, "rmse": 4.5058097953386, "mae": 3.0798409796598865, "simplicity_score": 0.18018339913067527, "novelty_bonus": 0.3481722043051074, "total_score": 0.3436827471757353, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a simple product of a base term and multiplicative\n    corrections that capture the effects of clustering, degree heterogeneity,\n    density, assortativity, and degree extremes.  No external libraries or\n    graph traversal algorithms are used.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:   avg_deg = 1.0\n    if max_deg <= 0:   max_deg = 1.0\n    if min_deg <= 0:   min_deg = 1.0\n    if density <= 0:   density = 1e-6\n    if m <= 0:         m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.137126\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines a simple baseline with multiplicative adjustments that\n    capture the effects of clustering, degree heterogeneity, density,\n    assortativity, and degree extremes.  Only built‑in operations are used.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Base estimate: grows with n, shrinks with avg degree\n    base = n / (avg_deg + 1.0)\n\n    # Clustering / transitivity adjustment: more triangles → longer paths\n    cluster_adj = 1.0 + avg_clust + trans\n\n    # Degree variance adjustment: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # Density adjustment: denser graphs tend to have shorter paths\n    dens_adj = 1.0 / (1.0 + density)\n\n    # Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # Max degree adjustment: very high max degree tends to shorten paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # Min degree adjustment: very low min degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1.0)\n\n    # Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + tri / (m + 1.0)\n\n    # Combine all adjustments\n    estimate = (base *\n                cluster_adj *\n                var_adj *\n                dens_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines a simple baseline with multiplicative adjustments that\n    capture the effects of clustering, degree heterogeneity, density,\n    assortativity, and degree extremes.  Only built‑in operations are used.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Base estimate: grows with n, shrinks with avg degree\n    base = n / (avg_deg + 1.0)\n\n    # Clustering / transitivity adjustment: more triangles → longer paths\n    cluster_adj = 1.0 + avg_clust + trans\n\n    # Degree variance adjustment: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # Density adjustment: denser graphs tend to have shorter paths\n    dens_adj = 1.0 / (1.0 + density)\n\n    # Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # Max degree adjustment: very high max degree tends to shorten paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # Min degree adjustment: very low min degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1.0)\n\n    # Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + tri / (m + 1.0)\n\n    # Combine all adjustments\n    estimate = (base *\n                cluster_adj *\n                var_adj *\n                dens_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T02:54:35.663437+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i3_p0_471096205", "generation": 8, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.352797118847539, "spearman": -0.44096318944096313, "pearson": -0.2780697137951065, "rmse": 2.42242448271867, "mae": 2.2137155957475554, "simplicity_score": 0.17765488044936778, "novelty_bonus": 0.21731936004282182, "total_score": 0.32120837882320163, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how average path length relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that mixes size, sparsity, degree dispersion,\n    triangle abundance, clustering strength, and degree assortativity.\n    All operations use only built‑in arithmetic to avoid external imports.\n    \"\"\"\n    # Size to edge ratio – captures overall sparsity\n    size_edge = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # Degree dispersion relative to variability – higher spread suggests\n    # longer paths through hubs\n    deg_disp = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # Triangle density – more triangles usually shorten paths\n    tri_dense = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # Combined clustering factor – square to amplify the effect\n    cluster_factor = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # Assortativity magnitude – strong correlation can create bottlenecks\n    assort_factor = (s['degree_assortativity'] ** 2 + 1.0)\n\n    # Final invariant: product of sparsity, dispersion, and triangle terms,\n    # divided by clustering and assortativity terms\n    invariant = (size_edge * deg_disp * tri_dense) / (cluster_factor * assort_factor)\n\n    return invariant\n\ndef new_invariant(s):\n    \"\"\"\n    A hand‑crafted composite invariant built only from arithmetic\n    operations on the supplied pre‑computed statistics.\n\n    The formula mixes size, sparsity, degree dispersion, triangle\n    abundance, clustering, and degree assortativity – all quantities\n    known to influence the average shortest‑path length.\n\n    Key assumptions:\n        • s contains the keys listed in the problem statement.\n        • No external modules may be imported; only built‑in\n          operations (addition, subtraction, multiplication,\n          division, pow, min, max, etc.) are used.\n\n    The structure is:\n\n        invariant = (size_factor * degree_factor * triangle_factor)\n                    / (clustering_factor * assortativity_factor)\n\n    The \"+ 1\" terms in denominators guarantee numerical stability\n    for very small or zero values.\n    \"\"\"\n\n    # 1. Size‑to‑edge ratio: captures overall sparsity.\n    size_factor = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree spread relative to its standard deviation.\n    #    Larger spread tends to create longer paths, especially when\n    #    combined with a high variance of degrees.\n    degree_factor = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # 3. Triangle density (shifted to avoid division by zero).\n    triangle_factor = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Clustering influence.  Square both local and global clustering\n    #    before averaging to give more weight to high‑clustering graphs.\n    clustering_factor = (pow(s['avg_clustering'], 2) + pow(s['transitivity'], 2)) / 2.0\n\n    # 5. Assortativity influence.  Strong positive or negative assortativity\n    #    usually creates bottlenecks, so we penalise large absolute values.\n    assortativity_factor = pow(s['degree_assortativity'], 2) + 1.0\n\n    # 6. Combine all pieces.  We multiply the first three terms – each\n    #    known to *shorten* paths – and divide by the last two, which\n    #    typically *enlarge* the average shortest path.\n    invariant = (size_factor * degree_factor * triangle_factor) / (clustering_factor * assortativity_factor)\n\n    return invariant\n\ndef new_invariant(s):\n    \"\"\"\n    A composite invariant that mixes several pre‑computed graph statistics\n    to produce a value correlated with the average shortest‑path length.\n    It uses only arithmetic, comparisons, and basic Python built‑ins.\n\n    Keys required from the dictionary `s`:\n        - n                 (int) number of nodes\n        - m                 (int) number of edges\n        - density           (float) edge density\n        - avg_degree        (float) average degree\n        - max_degree        (int) maximum degree\n        - min_degree        (int) minimum degree\n        - std_degree        (float) degree standard deviation\n        - avg_clustering    (float) average local clustering coefficient\n        - transitivity      (float) global transitivity (overall clustering)\n        - degree_assortativity (float) degree assortativity coefficient\n        - num_triangles     (int) number of triangles\n        - degrees           (list[int]) sorted degree sequence\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Size to sparsity ratio\n    size_edge_ratio = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree dispersion: relative spread compared to variation\n    degree_spread = (s['max_degree'] - s['min_degree'] + 1.0)\n    degree_variation = s['std_degree'] + 1.0\n    degree_dispersion = degree_spread / degree_variation\n\n    # 3. Triangle density: triangles per node (shifted to avoid zero)\n    triangle_density = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Local triangle power: square of clustering and transitivity\n    clustering_power = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # 5. Assortativity magnitude: square to make always positive\n    assort_magnitude = s['degree_assortativity'] ** 2 + 1.0\n\n    # ------------------------------------------------------------------\n    # Combine everything into one scalar\n    # The product of the first three components emphasizes sparsity,\n    # degree spread, and triangle abundance – all of which can affect\n    # path lengths.  Dividing by the clustering and assortativity terms\n    # dampens the effect of very high clustering or strong degree\n    # correlations.\n    invariant = (\n        size_edge_ratio\n        * degree_dispersion\n        * triangle_density\n    ) / (\n        clustering_power\n        * assort_magnitude\n    )\n\n    return invariant\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.085085\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.076303\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that correlates with the average shortest–path length.\n    It uses only the statistics supplied in the dictionary `s` and pure arithmetic\n    operations, without importing any external modules.\n    \"\"\"\n    # unpack values for clarity\n    n   = s['n']                    # number of nodes\n    m   = s['m']                    # number of edges\n    density          = s['density']             # edge density\n    max_degree       = s['max_degree']          # maximum degree\n    min_degree       = s['min_degree']          # minimum degree\n    std_degree       = s['std_degree']          # degree standard deviation\n    avg_clustering   = s['avg_clustering']      # local clustering coefficient\n    transitivity     = s['transitivity']        # global clustering coefficient\n    degree_assort    = s['degree_assortativity']# degree assortativity coefficient\n    num_triangles    = s['num_triangles']       # number of triangles\n\n    # ---- 1. Sparsity contribution ----\n    size_factor = (n + 1.0) / (m + 1.0)\n\n    # ---- 2. Density (inverted) ----\n    # Sparse graphs typically have longer paths, so we use 1 – density\n    density_factor = 1.0 - density\n\n    # ---- 3. Degree spread ----\n    # Larger spread combined with a high variance usually increases path length\n    degree_spread = (max_degree - min_degree + 1.0)\n\n    # ---- 4. Triangle contribution ----\n    # More triangles generally short‑circuit long paths\n    triangle_factor = (num_triangles + 1.0) / (n + 1.0)\n\n    # ---- 5. Clustering dampener ----\n    # High local and global clustering tend to reduce path length,\n    # so we penalise it multiplicatively\n    clustering_factor = (avg_clustering + transitivity + 1.0)\n\n    # ---- 6. Assortativity dampener ----\n    # Strong positive or negative assortativity can create bottlenecks\n    assortativity_factor = (abs(degree_assort) + 1.0)\n\n    # ---- 7. Degree variance dampener ----\n    # High degree variance often shortens paths via hubs, so we counterbalance it\n    variance_factor = (std_degree ** 2 + 1.0)\n\n    # ---- 8. Assemble invariant ----\n    invariant = (\n        size_factor\n        * density_factor\n        * degree_spread\n        * triangle_factor\n    ) / (\n        clustering_factor\n        * assortativity_factor\n        * variance_factor\n    )\n\n    return invariant\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that correlates with the average shortest–path length.\n    It uses only the statistics supplied in the dictionary `s` and pure arithmetic\n    operations, without importing any external modules.\n    \"\"\"\n    # unpack values for clarity\n    n   = s['n']                    # number of nodes\n    m   = s['m']                    # number of edges\n    density          = s['density']             # edge density\n    max_degree       = s['max_degree']          # maximum degree\n    min_degree       = s['min_degree']          # minimum degree\n    std_degree       = s['std_degree']          # degree standard deviation\n    avg_clustering   = s['avg_clustering']      # local clustering coefficient\n    transitivity     = s['transitivity']        # global clustering coefficient\n    degree_assort    = s['degree_assortativity']# degree assortativity coefficient\n    num_triangles    = s['num_triangles']       # number of triangles\n\n    # ---- 1. Sparsity contribution ----\n    size_factor = (n + 1.0) / (m + 1.0)\n\n    # ---- 2. Density (inverted) ----\n    # Sparse graphs typically have longer paths, so we use 1 – density\n    density_factor = 1.0 - density\n\n    # ---- 3. Degree spread ----\n    # Larger spread combined with a high variance usually increases path length\n    degree_spread = (max_degree - min_degree + 1.0)\n\n    # ---- 4. Triangle contribution ----\n    # More triangles generally short‑circuit long paths\n    triangle_factor = (num_triangles + 1.0) / (n + 1.0)\n\n    # ---- 5. Clustering dampener ----\n    # High local and global clustering tend to reduce path length,\n    # so we penalise it multiplicatively\n    clustering_factor = (avg_clustering + transitivity + 1.0)\n\n    # ---- 6. Assortativity dampener ----\n    # Strong positive or negative assortativity can create bottlenecks\n    assortativity_factor = (abs(degree_assort) + 1.0)\n\n    # ---- 7. Degree variance dampener ----\n    # High degree variance often shortens paths via hubs, so we counterbalance it\n    variance_factor = (std_degree ** 2 + 1.0)\n\n    # ---- 8. Assemble invariant ----\n    invariant = (\n        size_factor\n        * density_factor\n        * degree_spread\n        * triangle_factor\n    ) / (\n        clustering_factor\n        * assortativity_factor\n        * variance_factor\n    )\n\n    return invariant"}}
{"timestamp": "2026-02-13T02:55:07.455462+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.023264", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T02:55:43.354729+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.034675", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T02:56:38.636198+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.043186", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T02:57:17.882415+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.155342", "model_name": "gpt-oss:20b", "train_signal": 0.15534213685474188}}
{"timestamp": "2026-02-13T02:57:17.887733+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "phase1_20260212T231418Z", "generation": 9, "model_name": "gpt-oss:20b", "best_val_score": 0.5491013268732999, "no_improve_count": 7}}
{"timestamp": "2026-02-13T03:01:26.699189+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i0_p0_855080007", "generation": 9, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7311884753901561, "spearman": 0.6499424922907877, "pearson": 0.7351657668201246, "rmse": 24.98280076828773, "mae": 23.275114272236817, "simplicity_score": 0.2457572791538155, "novelty_bonus": 0.3809820470562526, "total_score": 0.48841731609303274, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.056040\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n\n    # positive assortativity tends to shorten paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # triangles provide local shortcuts\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.1 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    # edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + 0.2 * m / (max_edges + 1))\n\n    return val", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n\n    # positive assortativity tends to shorten paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # triangles provide local shortcuts\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.1 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    # edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + 0.2 * m / (max_edges + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T03:02:00.764441+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i0_p1_565236106", "generation": 9, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.733781512605042, "spearman": 0.6454446281574849, "pearson": 0.7290935681259281, "rmse": 27.675461045333424, "mae": 25.698482518889623, "simplicity_score": 0.24559144859917667, "novelty_bonus": 0.3823997396292217, "total_score": 0.4865605256873443, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.056040\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a compact product of factors that capture the main\n    structural influences on path length.  No graph traversal is performed.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + 0.2 * m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.1 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a compact product of factors that capture the main\n    structural influences on path length.  No graph traversal is performed.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + 0.2 * m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.1 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T03:02:43.748689+00:00", "event_type": "candidate_rejected", "payload": {"generation": 9, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:02:43.749287+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 9, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:03:05.168870+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i0_p2_79197403", "generation": 9, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6883553421368548, "spearman": 0.601502513126313, "pearson": 0.699212332054158, "rmse": 27.362484184523165, "mae": 25.75210514830781, "simplicity_score": 0.24569455911846988, "novelty_bonus": 0.4060253781004095, "total_score": 0.47169778181697336, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.252533\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.056040\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport math\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.0 * clustering)\n    val *= (1 + 1.1 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.3 * math.sqrt(num_tri) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.1 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    # Edge density ratio\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    return val\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.0 * clustering)\n    val *= (1 + 1.1 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.1 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    # Edge density ratio\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.0 * clustering)\n    val *= (1 + 1.1 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.1 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    # Edge density ratio\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T03:03:05.172701+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 9, "island_id": 0, "population_idx": 2, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:03:47.240258+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i0_p3_764998857", "generation": 9, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7310924369747898, "spearman": 0.6540435963563035, "pearson": 0.7378371111252702, "rmse": 24.72755026195521, "mae": 23.006748626902993, "simplicity_score": 0.24563248198940796, "novelty_bonus": 0.3796947081529417, "total_score": 0.49005670702191584, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.252533\nbelow_novelty_threshold: novelty_bonus=0.056040\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed graph\n    features.  The expression is a weighted product of factors that tend to\n    shorten or lengthen paths.  All coefficients are chosen to keep the\n    formula compact while capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + 0.2 * m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = 0\n    for d in degrees:\n        sum_sq += d * d\n    val *= (1 + 0.1 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed graph\n    features.  The expression is a weighted product of factors that tend to\n    shorten or lengthen paths.  All coefficients are chosen to keep the\n    formula compact while capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + 0.2 * m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2:\n        median_deg = degrees[mid]\n    else:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = 0\n    for d in degrees:\n        sum_sq += d * d\n    val *= (1 + 0.1 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T03:04:39.250985+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i0_p4_574600623", "generation": 9, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6999759903961584, "spearman": 0.591283503818951, "pearson": 0.6799164363608121, "rmse": 30.55877160492043, "mae": 28.637268804825183, "simplicity_score": 0.24567379589398705, "novelty_bonus": 0.41280762554008144, "total_score": 0.4686187987502973, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.252533\nbelow_novelty_threshold: novelty_bonus=0.056040\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.0 * trans)\n    val *= (1 + 0.9 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.3 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = 0\n    for d in degrees:\n        sum_sq += d * d\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.0 * trans)\n    val *= (1 + 0.9 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.3 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = 0\n    for d in degrees:\n        sum_sq += d * d\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T03:05:48.896729+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i1_p0_634718319", "generation": 9, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3793997599039616, "spearman": 0.25137262858046794, "pearson": 0.5184583117081661, "rmse": 2.3483148213320306, "mae": 2.227428243068378, "simplicity_score": 0.11382269767006811, "novelty_bonus": 0.3271665495129109, "total_score": 0.2466008186781209, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = s['n'] ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (s['max_degree'] - s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * degree_range_factor\n        * median_factor\n    )\n\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )"}}
{"timestamp": "2026-02-13T03:06:22.689514+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i1_p1_565373325", "generation": 9, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3793997599039616, "spearman": 0.25137262858046794, "pearson": 0.5184583117081661, "rmse": 2.3483148213320306, "mae": 2.227428243068378, "simplicity_score": 0.11382269767006811, "novelty_bonus": 0.3271665495129109, "total_score": 0.2466008186781209, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = s['n'] ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (s['max_degree'] - s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * degree_range_factor\n        * median_factor\n    )\n\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )"}}
{"timestamp": "2026-02-13T03:07:12.343318+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i1_p2_553579400", "generation": 9, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3793997599039616, "spearman": 0.25137262858046794, "pearson": 0.5184583117081661, "rmse": 2.3483148213320306, "mae": 2.227428243068378, "simplicity_score": 0.11382269767006811, "novelty_bonus": 0.3271665495129109, "total_score": 0.2466008186781209, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = s['n'] ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (s['max_degree'] - s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * degree_range_factor\n        * median_factor\n    )\n\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )"}}
{"timestamp": "2026-02-13T03:08:03.202766+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i1_p3_90566425", "generation": 9, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3793997599039616, "spearman": 0.25137262858046794, "pearson": 0.5184583117081661, "rmse": 2.3483148213320306, "mae": 2.227428243068378, "simplicity_score": 0.11382269767006811, "novelty_bonus": 0.3271665495129109, "total_score": 0.2466008186781209, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = s['n'] ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (s['max_degree'] - s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * degree_range_factor\n        * median_factor\n    )\n\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )"}}
{"timestamp": "2026-02-13T03:08:38.787458+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i1_p4_559207160", "generation": 9, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3793997599039616, "spearman": 0.25137262858046794, "pearson": 0.5184583117081661, "rmse": 2.3483148213320306, "mae": 2.227428243068378, "simplicity_score": 0.11382269767006811, "novelty_bonus": 0.3271665495129109, "total_score": 0.2466008186781209, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = s['n'] ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (s['max_degree'] - s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * degree_range_factor\n        * median_factor\n    )\n\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list of degrees\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list of degrees\n\n    # Basic node‑to‑edge ratio\n    base = n / (m + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity boost\n    assort_factor = 1 + assort\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encouragement of uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    len_deg = len(degrees)\n    mid = len_deg // 2\n    if len_deg % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor (additional diversity bonus)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * median_factor\n        * spread_factor\n        * degree_range_factor\n    )"}}
{"timestamp": "2026-02-13T03:09:14.253460+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i2_p0_794912616", "generation": 9, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8818727490996399, "spearman": 0.8371607429539114, "pearson": 0.7079814869925748, "rmse": 43.22727762191753, "mae": 28.420841764097123, "simplicity_score": 0.18284455328993982, "novelty_bonus": 0.22281213841057312, "total_score": 0.5219929236581156, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a simple product of a base term and multiplicative\n    corrections that capture the effects of clustering, degree heterogeneity,\n    density, assortativity, and degree extremes.  No external libraries or\n    graph traversal algorithms are used.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:   avg_deg = 1.0\n    if max_deg <= 0:   max_deg = 1.0\n    if min_deg <= 0:   min_deg = 1.0\n    if density <= 0:   density = 1e-6\n    if m <= 0:         m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.137126\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula uses only basic arithmetic and built‑in functions, so no imports\n    are required.  All divisions are guarded against zero and the estimate\n    incorporates several structural properties of the graph.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    std_deg    = s.get('std_degree', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    density    = s.get('density', 0.0)\n\n    # Base estimate – scales with the square root of the node count\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # Multiplicative adjustments\n    adj_clust   = 1.0 + clustering                # more clustering → longer paths\n    adj_assort  = 1.0 + 0.5 * assort              # positive assortativity → longer paths\n    adj_std     = 1.0 + std_deg / (avg_deg + 1.0) # higher variance → shorter paths\n    adj_tri     = 1.0 + num_tri / (m + 1.0)       # more triangles → longer paths\n    adj_dens    = 1.0 / (density + 1e-6)          # denser graphs → shorter paths\n\n    # Combined estimate\n    estimate = base * adj_clust * adj_assort * adj_std * adj_tri * adj_dens\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula uses only basic arithmetic and built‑in functions, so no imports\n    are required.  All divisions are guarded against zero and the estimate\n    incorporates several structural properties of the graph.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    clustering = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    std_deg    = s.get('std_degree', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    density    = s.get('density', 0.0)\n\n    # Base estimate – scales with the square root of the node count\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # Multiplicative adjustments\n    adj_clust   = 1.0 + clustering                # more clustering → longer paths\n    adj_assort  = 1.0 + 0.5 * assort              # positive assortativity → longer paths\n    adj_std     = 1.0 + std_deg / (avg_deg + 1.0) # higher variance → shorter paths\n    adj_tri     = 1.0 + num_tri / (m + 1.0)       # more triangles → longer paths\n    adj_dens    = 1.0 / (density + 1e-6)          # denser graphs → shorter paths\n\n    # Combined estimate\n    estimate = base * adj_clust * adj_assort * adj_std * adj_tri * adj_dens\n    return estimate"}}
{"timestamp": "2026-02-13T03:10:01.503231+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i2_p1_303950097", "generation": 9, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8884033613445379, "spearman": 0.8562029761505802, "pearson": 0.8120574905615511, "rmse": 7.62661215948433, "mae": 4.514146493182545, "simplicity_score": 0.17853405031618008, "novelty_bonus": 0.22039635324270634, "total_score": 0.529927204111338, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a simple product of a base term and multiplicative\n    corrections that capture the effects of clustering, degree heterogeneity,\n    density, assortativity, and degree extremes.  No external libraries or\n    graph traversal algorithms are used.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:   avg_deg = 1.0\n    if max_deg <= 0:   max_deg = 1.0\n    if min_deg <= 0:   min_deg = 1.0\n    if density <= 0:   density = 1e-6\n    if m <= 0:         m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.137126\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative\n    corrections that capture clustering, degree heterogeneity, density,\n    assortativity, and degree extremes.  No external libraries or\n    graph traversal algorithms are used.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # ---- Ensure no division by zero or negative values ----\n    if avg_deg <= 0:   avg_deg = 1.0\n    if max_deg <= 0:   max_deg = 1.0\n    if min_deg <= 0:   min_deg = 1.0\n    if density <= 0:   density = 1e-6\n    if m <= 0:         m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustment factors ----------\n    clustering_adj = 1.0 + 0.5 * (avg_clust + trans)\n    var_adj         = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n    density_adj     = 1.0 / (density + 1e-6)\n    assort_adj      = 1.0 + 0.5 * assort\n    max_adj         = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n    min_adj         = 1.0 + 1.0 / (min_deg + 1e-6)\n    tri_adj         = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative\n    corrections that capture clustering, degree heterogeneity, density,\n    assortativity, and degree extremes.  No external libraries or\n    graph traversal algorithms are used.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # ---- Ensure no division by zero or negative values ----\n    if avg_deg <= 0:   avg_deg = 1.0\n    if max_deg <= 0:   max_deg = 1.0\n    if min_deg <= 0:   min_deg = 1.0\n    if density <= 0:   density = 1e-6\n    if m <= 0:         m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustment factors ----------\n    clustering_adj = 1.0 + 0.5 * (avg_clust + trans)\n    var_adj         = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n    density_adj     = 1.0 / (density + 1e-6)\n    assort_adj      = 1.0 + 0.5 * assort\n    max_adj         = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n    min_adj         = 1.0 + 1.0 / (min_deg + 1e-6)\n    tri_adj         = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T03:10:52.282259+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i2_p2_602838243", "generation": 9, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9159663865546218, "spearman": 0.8621663774718891, "pearson": 0.8248434656802218, "rmse": 2.1035051773555615, "mae": 2.0004422204090906, "simplicity_score": 0.17934976173696474, "novelty_bonus": 0.1723467564891107, "total_score": 0.5186571680300707, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a simple product of a base term and multiplicative\n    corrections that capture the effects of clustering, degree heterogeneity,\n    density, assortativity, and degree extremes.  No external libraries or\n    graph traversal algorithms are used.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:   avg_deg = 1.0\n    if max_deg <= 0:   max_deg = 1.0\n    if min_deg <= 0:   min_deg = 1.0\n    if density <= 0:   density = 1e-6\n    if m <= 0:         m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.137126\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative corrections\n    that capture the effects of clustering, degree heterogeneity, density,\n    assortativity, degree extremes, and triangle abundance.  No external\n    imports are required; it relies on NumPy functions that are assumed to be\n    pre‑imported (np.sqrt, np.maximum, etc.).\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0: avg_deg = 1.0\n\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: scales with sqrt(n) and inversely with average degree\n    base = np.sqrt(max(n, 1)) / (avg_deg + 0.5)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.3 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + 0.5 * std_deg / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (1.0 + density)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.4 * assort\n\n    # 5. Max degree: a very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + 0.5 * max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: a very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 0.5 / (min_deg + 1.0)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + 0.2 * triangles / (m + 1.0)\n\n    # Combine all adjustments multiplicatively\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative corrections\n    that capture the effects of clustering, degree heterogeneity, density,\n    assortativity, degree extremes, and triangle abundance.  No external\n    imports are required; it relies on NumPy functions that are assumed to be\n    pre‑imported (np.sqrt, np.maximum, etc.).\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0: avg_deg = 1.0\n\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: scales with sqrt(n) and inversely with average degree\n    base = np.sqrt(max(n, 1)) / (avg_deg + 0.5)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.3 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + 0.5 * std_deg / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (1.0 + density)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.4 * assort\n\n    # 5. Max degree: a very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + 0.5 * max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: a very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 0.5 / (min_deg + 1.0)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + 0.2 * triangles / (m + 1.0)\n\n    # Combine all adjustments multiplicatively\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T03:11:32.748932+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i2_p3_30817834", "generation": 9, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8884033613445379, "spearman": 0.8562029761505802, "pearson": 0.8120574905615511, "rmse": 7.62661215948433, "mae": 4.514146493182545, "simplicity_score": 0.17909397257846857, "novelty_bonus": 0.22039635324270634, "total_score": 0.5300391885637957, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a simple product of a base term and multiplicative\n    corrections that capture the effects of clustering, degree heterogeneity,\n    density, assortativity, and degree extremes.  No external libraries or\n    graph traversal algorithms are used.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:   avg_deg = 1.0\n    if max_deg <= 0:   max_deg = 1.0\n    if min_deg <= 0:   min_deg = 1.0\n    if density <= 0:   density = 1e-6\n    if m <= 0:         m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.137126\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative\n    adjustments that capture the influence of clustering, degree variance,\n    density, assortativity, and degree extremes.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0: avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0: max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0: min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative\n    adjustments that capture the influence of clustering, degree variance,\n    density, assortativity, and degree extremes.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0: avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0: max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0: min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T03:12:11.896589+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i2_p4_436717389", "generation": 9, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8884033613445379, "spearman": 0.8562029761505802, "pearson": 0.8120574905615511, "rmse": 7.62661215948433, "mae": 4.514146493182545, "simplicity_score": 0.17853405031618008, "novelty_bonus": 0.22039635324270634, "total_score": 0.529927204111338, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a simple product of a base term and multiplicative\n    corrections that capture the effects of clustering, degree heterogeneity,\n    density, assortativity, and degree extremes.  No external libraries or\n    graph traversal algorithms are used.\n    \"\"\"\n    # ---------- Basic statistics with safe defaults ----------\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:   avg_deg = 1.0\n    if max_deg <= 0:   max_deg = 1.0\n    if min_deg <= 0:   min_deg = 1.0\n    if density <= 0:   density = 1e-6\n    if m <= 0:         m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.137126\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and multiplicative adjustments that\n    capture the effects of clustering, degree heterogeneity, density,\n    assortativity, degree extremes, and triangle abundance.\n    No external libraries or graph traversal algorithms are used.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:   avg_deg = 1.0\n    if max_deg <= 0:   max_deg = 1.0\n    if min_deg <= 0:   min_deg = 1.0\n    if density <= 0:   density = 1e-6\n    if m <= 0:         m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and multiplicative adjustments that\n    capture the effects of clustering, degree heterogeneity, density,\n    assortativity, degree extremes, and triangle abundance.\n    No external libraries or graph traversal algorithms are used.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    max_deg    = s.get('max_degree', 1.0)\n    min_deg    = s.get('min_degree', 1.0)\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    density    = s.get('density', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Avoid division by zero or negative values\n    if avg_deg <= 0:   avg_deg = 1.0\n    if max_deg <= 0:   max_deg = 1.0\n    if min_deg <= 0:   min_deg = 1.0\n    if density <= 0:   density = 1e-6\n    if m <= 0:         m = 1\n\n    # ---------- Base estimate ----------\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # ---------- Adjustments ----------\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance → shorter paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity tends to lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_deg_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_deg_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # ---------- Combine ----------\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_deg_adj *\n                min_deg_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T03:12:50.039022+00:00", "event_type": "candidate_rejected", "payload": {"generation": 9, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.013810", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:13:16.647752+00:00", "event_type": "candidate_rejected", "payload": {"generation": 9, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.096137", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:14:03.827668+00:00", "event_type": "candidate_rejected", "payload": {"generation": 9, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.040192", "model_name": "gpt-oss:20b", "train_signal": 0.04019207683073229}}
{"timestamp": "2026-02-13T03:14:28.424772+00:00", "event_type": "candidate_rejected", "payload": {"generation": 9, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.057820", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:14:54.075853+00:00", "event_type": "candidate_rejected", "payload": {"generation": 9, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:14:54.076071+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 9, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:15:17.494191+00:00", "event_type": "candidate_rejected", "payload": {"generation": 9, "island_id": 3, "population_idx": 4, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.017690", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:15:17.494675+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 9, "island_id": 3, "population_idx": 4, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:15:17.497330+00:00", "event_type": "generation_migration", "payload": {"generation": 9, "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:15:17.501445+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "phase1_20260212T231418Z", "generation": 10, "model_name": "gpt-oss:20b", "best_val_score": 0.5491013268732999, "no_improve_count": 8}}
{"timestamp": "2026-02-13T03:15:47.770177+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i0_p0_982738393", "generation": 10, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7378151260504201, "spearman": 0.6670294258717284, "pearson": 0.7538996978204286, "rmse": 21.381171692659198, "mae": 19.94381578159679, "simplicity_score": 0.24766122955523237, "novelty_bonus": 0.3717377350393678, "total_score": 0.49456827935872105, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.252533\nbelow_novelty_threshold: novelty_bonus=0.056040\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a compact product of factors that capture the main\n    structural influences on path length.  All operations use only built‑in\n    Python functions; no external imports are required.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.0 * clustering)\n    val *= (1 + 1.1 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a compact product of factors that capture the main\n    structural influences on path length.  All operations use only built‑in\n    Python functions; no external imports are required.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.0 * clustering)\n    val *= (1 + 1.1 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T03:16:25.889962+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i0_p1_214584672", "generation": 10, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6935414165666266, "spearman": 0.5954543596544181, "pearson": 0.6904948105071087, "rmse": 27.228034563607125, "mae": 25.618920012744255, "simplicity_score": 0.24565310366249313, "novelty_bonus": 0.40834551915562767, "total_score": 0.469361456306396, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_train_threshold: train_signal=0.252533\nbelow_novelty_threshold: novelty_bonus=0.056040\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a compact combination of\n    pre‑computed graph statistics.  The expression is deliberately simple\n    (no external imports) yet captures the main structural influences:\n    - larger graphs and sparser connectivity increase the estimate\n    - higher density, clustering, transitivity, and triangle counts shorten paths\n    - assortativity, degree spread, and variability tend to lengthen paths\n    - edge density and median degree provide additional refinement\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.0 * trans)\n    val *= (1 + 0.9 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.3 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.1 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a compact combination of\n    pre‑computed graph statistics.  The expression is deliberately simple\n    (no external imports) yet captures the main structural influences:\n    - larger graphs and sparser connectivity increase the estimate\n    - higher density, clustering, transitivity, and triangle counts shorten paths\n    - assortativity, degree spread, and variability tend to lengthen paths\n    - edge density and median degree provide additional refinement\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.0 * trans)\n    val *= (1 + 0.9 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.3 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.1 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T03:17:23.281500+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.043167", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:18:46.299962+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i0_p3_276548331", "generation": 10, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5073229291716687, "spearman": 0.4150222811904144, "pearson": 0.4696126974404508, "rmse": 156.17358506333397, "mae": 144.3951343994114, "simplicity_score": 0.2464461285202601, "novelty_bonus": 0.5499720816070521, "total_score": 0.42179199078137486, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.056040\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.043167\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a compact product of multiplicative factors that capture\n    the main structural influences on path length.  All operations are\n    performed with built‑in Python functions – no external imports are used.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Shortening factors: density, clustering, transitivity, triangles\n    val *= (1 + density) * (1 + clustering) * (1 + trans)\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # Lengthening factors: assortativity, degree spread, variability, median\n    val /= (1 + abs(assort))\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n    # Median degree\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Higher‑order degree effect: sum of squared degrees\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg * avg_deg + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a compact product of multiplicative factors that capture\n    the main structural influences on path length.  All operations are\n    performed with built‑in Python functions – no external imports are used.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Shortening factors: density, clustering, transitivity, triangles\n    val *= (1 + density) * (1 + clustering) * (1 + trans)\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # Lengthening factors: assortativity, degree spread, variability, median\n    val /= (1 + abs(assort))\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n    # Median degree\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Higher‑order degree effect: sum of squared degrees\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + sum_sq / (n * (avg_deg * avg_deg + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T03:19:27.767228+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i0_p4_408528643", "generation": 10, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.4597839135654262, "spearman": 0.4090228789555823, "pearson": 0.4954781057025909, "rmse": 68.03163827145606, "mae": 64.50077722449765, "simplicity_score": 0.24746488621996363, "novelty_bonus": 0.5454112458159932, "total_score": 0.4176277904665818, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.056040\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.043167\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density)\n    val *= (1 + trans)\n    val *= (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + density)\n    val *= (1 + trans)\n    val *= (1 + clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + median_deg / (avg_deg + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T03:20:15.691448+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i1_p0_992665618", "generation": 10, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3277310924369748, "spearman": 0.1814596045374779, "pearson": 0.42632632245226104, "rmse": 2.608125658730113, "mae": 2.481958151805334, "simplicity_score": 0.24635279243247865, "novelty_bonus": 0.2981402142950903, "total_score": 0.22944242504376178, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = s['n'] ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (s['max_degree'] - s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * degree_range_factor\n        * median_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic graph quantities\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Base factor: size and degree balance\n    base = n / (m + 1) * (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling\n    sqrt_n = n ** 0.5\n\n    # Assortativity influence\n    assort_factor = 1 + assort\n\n    # Triangle density relative to maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encourage uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Median degree factor\n    deg_len = len(degrees)\n    if deg_len % 2 == 0:\n        mid = deg_len // 2\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[deg_len // 2]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Combine all multiplicatively\n    val = (\n        base\n        * struct_factor\n        * sqrt_n\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * median_factor\n    )\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # Basic graph quantities\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']          # sorted list\n\n    # Base factor: size and degree balance\n    base = n / (m + 1) * (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling\n    sqrt_n = n ** 0.5\n\n    # Assortativity influence\n    assort_factor = 1 + assort\n\n    # Triangle density relative to maximum possible\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + std_deg)\n\n    # Encourage uniform minimum degree\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Median degree factor\n    deg_len = len(degrees)\n    if deg_len % 2 == 0:\n        mid = deg_len // 2\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[deg_len // 2]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Combine all multiplicatively\n    val = (\n        base\n        * struct_factor\n        * sqrt_n\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * median_factor\n    )\n    return val"}}
{"timestamp": "2026-02-13T03:21:36.367819+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i1_p1_34692964", "generation": 10, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6265066026410564, "spearman": 0.7379932265781762, "pearson": 0.6111825976349707, "rmse": 3.523804788737268, "mae": 1.938495780065442, "simplicity_score": 0.24434197266276908, "novelty_bonus": 0.2827537777062503, "total_score": 0.502691141133517, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = s['n'] ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (s['max_degree'] - s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * degree_range_factor\n        * median_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Base factors combining the two top formulas\n    base1 = n / (avg_deg + 1)\n    base2 = n / (m + 1)\n    base = base1 * base2\n\n    # Degree balance\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling\n    sqrt_factor = n ** 0.5\n\n    # Assortativity penalty\n    assort_factor = 1 / (1 + 0.5 * abs(assort))\n\n    # Triangle influence (both raw and normalized)\n    max_triangles = max(1, n * (n - 1) / 2)\n    tri_factor1 = 1 + (triangles ** 0.5) / (n ** 2 + 1)\n    tri_factor2 = 1 + triangles / max_triangles\n    triangle_factor = tri_factor1 * tri_factor2\n\n    # Degree variance penalty\n    std_factor = (1 / (1 + std_deg)) * (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Minimum degree encouragement\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Combine all multiplicatively\n    val = (base * deg_factor * struct_factor * sqrt_factor *\n           assort_factor * triangle_factor * std_factor *\n           min_factor * spread_factor * degree_range_factor *\n           median_factor)\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Base factors combining the two top formulas\n    base1 = n / (avg_deg + 1)\n    base2 = n / (m + 1)\n    base = base1 * base2\n\n    # Degree balance\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling\n    sqrt_factor = n ** 0.5\n\n    # Assortativity penalty\n    assort_factor = 1 / (1 + 0.5 * abs(assort))\n\n    # Triangle influence (both raw and normalized)\n    max_triangles = max(1, n * (n - 1) / 2)\n    tri_factor1 = 1 + (triangles ** 0.5) / (n ** 2 + 1)\n    tri_factor2 = 1 + triangles / max_triangles\n    triangle_factor = tri_factor1 * tri_factor2\n\n    # Degree variance penalty\n    std_factor = (1 / (1 + std_deg)) * (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Minimum degree encouragement\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Combine all multiplicatively\n    val = (base * deg_factor * struct_factor * sqrt_factor *\n           assort_factor * triangle_factor * std_factor *\n           min_factor * spread_factor * degree_range_factor *\n           median_factor)\n\n    return val"}}
{"timestamp": "2026-02-13T03:22:12.217881+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i1_p2_233939485", "generation": 10, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3432893157262905, "spearman": 0.1966377396826583, "pearson": 0.4119659111430695, "rmse": 2.5884169557627357, "mae": 2.4609133699740813, "simplicity_score": 0.11680334210735918, "novelty_bonus": 0.32888412852192417, "total_score": 0.22034477681937822, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = s['n'] ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (s['max_degree'] - s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * degree_range_factor\n        * median_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression combines several structural factors that influence path length:\n    - Node‑to‑edge ratio (base)\n    - Degree balance (deg_factor)\n    - Cohesion from density, clustering and transitivity (struct_factor)\n    - Size scaling (sqrt_factor)\n    - Assortativity effect (assort_factor)\n    - Triangle density (triangle_factor)\n    - Degree variance penalty (std_factor)\n    - Minimum‑degree uniformity (min_factor)\n    - Degree spread (spread_factor)\n    - Median‑degree adjustment (median_factor)\n\n    All factors are multiplicative, keeping the formula compact while\n    capturing the main structural influences on average shortest‑path length.\n    \"\"\"\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost (use absolute value to capture both positive and negative effects)\n    assort_factor = 1 + abs(s['degree_assortativity'])\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * median_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression combines several structural factors that influence path length:\n    - Node‑to‑edge ratio (base)\n    - Degree balance (deg_factor)\n    - Cohesion from density, clustering and transitivity (struct_factor)\n    - Size scaling (sqrt_factor)\n    - Assortativity effect (assort_factor)\n    - Triangle density (triangle_factor)\n    - Degree variance penalty (std_factor)\n    - Minimum‑degree uniformity (min_factor)\n    - Degree spread (spread_factor)\n    - Median‑degree adjustment (median_factor)\n\n    All factors are multiplicative, keeping the formula compact while\n    capturing the main structural influences on average shortest‑path length.\n    \"\"\"\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = pow(s['n'], 0.5)\n\n    # Assortativity boost (use absolute value to capture both positive and negative effects)\n    assort_factor = 1 + abs(s['degree_assortativity'])\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * median_factor\n    )"}}
{"timestamp": "2026-02-13T03:22:36.964829+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i1_p3_821674449", "generation": 10, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6293877551020408, "spearman": 0.531440235296008, "pearson": 0.46232038802247943, "rmse": 1.789665230792773, "mae": 1.1078742880675296, "simplicity_score": 0.24905189471229217, "novelty_bonus": 0.28705490049437177, "total_score": 0.401646966738774, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = s['n'] ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (s['max_degree'] - s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * degree_range_factor\n        * median_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression combines several structural factors multiplicatively, each\n    designed to capture a different aspect of graph connectivity.\n    \"\"\"\n    # Basic size / density factor\n    val = s['n'] / (s['m'] + 1)\n\n    # Structural cohesion factors\n    val *= (1 + s['density'])\n    val *= (1 + s['avg_clustering'])\n    val *= (1 + s['transitivity'])\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    val *= (1 + s['num_triangles'] / max_triangles)\n\n    # Degree spread and variability\n    degree_range = s['max_degree'] - s['min_degree']\n    val *= (1 + degree_range / (s['max_degree'] + 1))\n    val *= (1 + s['std_degree'] / (s['avg_degree'] + 1))\n\n    # Assortativity effect\n    val *= (1 + s['degree_assortativity'])\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (s['avg_degree'] + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression combines several structural factors multiplicatively, each\n    designed to capture a different aspect of graph connectivity.\n    \"\"\"\n    # Basic size / density factor\n    val = s['n'] / (s['m'] + 1)\n\n    # Structural cohesion factors\n    val *= (1 + s['density'])\n    val *= (1 + s['avg_clustering'])\n    val *= (1 + s['transitivity'])\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    val *= (1 + s['num_triangles'] / max_triangles)\n\n    # Degree spread and variability\n    degree_range = s['max_degree'] - s['min_degree']\n    val *= (1 + degree_range / (s['max_degree'] + 1))\n    val *= (1 + s['std_degree'] / (s['avg_degree'] + 1))\n\n    # Assortativity effect\n    val *= (1 + s['degree_assortativity'])\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (s['avg_degree'] + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T03:23:31.968623+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i1_p4_58302741", "generation": 10, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.39476590636254505, "spearman": 0.26660851519109174, "pearson": 0.5228312128590943, "rmse": 1.9748179988665906, "mae": 1.5039486885831055, "simplicity_score": 0.11349211372235778, "novelty_bonus": 0.339798630591426, "total_score": 0.25794226951744526, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    base = n / (m + 1)\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    struct_factor = (density + clustering) * (1 + trans)\n    sqrt_factor = pow(n, 0.5)\n    assort_factor = 1 + assort\n    max_triangles = max(1, n * (n - 1) / 2)\n    triangle_factor = 1 + triangles / max_triangles\n    std_factor = 1 / (1 + std_deg)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    return (base * deg_factor * struct_factor * sqrt_factor *\n            assort_factor * triangle_factor * std_factor *\n            min_factor * degree_range_factor)\n\ndef new_invariant(s):\n    # Basic node‑to‑edge ratio\n    base = s['n'] / (s['m'] + 1)\n\n    # Balance between average and maximum degree\n    deg_factor = (s['avg_degree'] + 1) / (s['max_degree'] + 1)\n\n    # Structural cohesion from density, clustering and transitivity\n    struct_factor = (s['density'] + s['avg_clustering']) * (1 + s['transitivity'])\n\n    # Size scaling (square root of node count)\n    sqrt_factor = s['n'] ** 0.5\n\n    # Assortativity boost\n    assort_factor = 1 + s['degree_assortativity']\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    triangle_factor = 1 + s['num_triangles'] / max_triangles\n\n    # Penalty for high degree variance\n    std_factor = 1 / (1 + s['std_degree'])\n\n    # Encouragement of uniform minimum degree\n    min_factor = (s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (s['max_degree'] - s['min_degree']) / (s['max_degree'] + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (s['max_degree'] - s['min_degree'] + 1) / (s['avg_degree'] + 1)\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (s['avg_degree'] + 1)\n\n    # Combine all factors multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * degree_range_factor\n        * median_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.041056\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Base: geometric mean of two common starting points\n    base = pow((n / (avg_deg + 1)) * (n / (m + 1)), 0.5)\n\n    # Degree‑related factors\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Structural cohesion\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity\n    assort_factor = 1 + abs(assort)\n\n    # Triangle density\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Degree variance penalty\n    std_factor = 1 / (1 + std_deg)\n\n    # Median degree factor\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Combine all multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * degree_range_factor\n        * median_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Base: geometric mean of two common starting points\n    base = pow((n / (avg_deg + 1)) * (n / (m + 1)), 0.5)\n\n    # Degree‑related factors\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Structural cohesion\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling\n    sqrt_factor = pow(n, 0.5)\n\n    # Assortativity\n    assort_factor = 1 + abs(assort)\n\n    # Triangle density\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    triangle_factor = 1 + triangles / max_triangles\n\n    # Degree variance penalty\n    std_factor = 1 / (1 + std_deg)\n\n    # Median degree factor\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Combine all multiplicatively\n    return (\n        base\n        * deg_factor\n        * struct_factor\n        * sqrt_factor\n        * assort_factor\n        * triangle_factor\n        * std_factor\n        * min_factor\n        * spread_factor\n        * degree_range_factor\n        * median_factor\n    )"}}
{"timestamp": "2026-02-13T03:24:09.410281+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i2_p0_855670853", "generation": 10, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8664105642256902, "spearman": 0.7709550629847775, "pearson": 0.8183802871439241, "rmse": 17.02732403707258, "mae": 13.514903935562579, "simplicity_score": 0.17863697240640874, "novelty_bonus": 0.19816526763981457, "total_score": 0.48065450626561484, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative\n    adjustments that capture the influence of clustering, degree variance,\n    density, assortativity, and degree extremes.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0: avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0: max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0: min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.137126\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The expression is a product of a baseline term\n    (based on random‑graph theory) and several multiplicative corrections\n    that capture the influence of clustering, degree heterogeneity,\n    density, assortativity, and degree extremes.\n\n    All operations are guarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:  avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0:  max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0:  min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment – more triangles → longer paths\n    clustering_adj = 1.0 + 0.4 * (trans + clustering)\n\n    # 3. Degree variance adjustment – higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment – sparser graphs tend to have longer paths\n    density_adj = 1.0 / (density + eps)\n\n    # 5. Assortativity adjustment – positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.3 * assort\n\n    # 6. Max degree – very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 7. Minimum degree – very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + eps)\n\n    # 8. Triangle count relative to edges – more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The expression is a product of a baseline term\n    (based on random‑graph theory) and several multiplicative corrections\n    that capture the influence of clustering, degree heterogeneity,\n    density, assortativity, and degree extremes.\n\n    All operations are guarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:  avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0:  max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0:  min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment – more triangles → longer paths\n    clustering_adj = 1.0 + 0.4 * (trans + clustering)\n\n    # 3. Degree variance adjustment – higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment – sparser graphs tend to have longer paths\n    density_adj = 1.0 / (density + eps)\n\n    # 5. Assortativity adjustment – positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.3 * assort\n\n    # 6. Max degree – very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 7. Minimum degree – very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + eps)\n\n    # 8. Triangle count relative to edges – more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T03:24:39.647055+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:24:39.647853+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 10, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:25:27.039195+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i2_p1_281383891", "generation": 10, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.6424489795918368, "spearman": 0.4834607678170174, "pearson": 0.6238454764948136, "rmse": 1.9887460375563344, "mae": 1.8687538555561485, "simplicity_score": 0.1792920388593393, "novelty_bonus": 0.3487752193804844, "total_score": 0.3822213574945219, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative\n    adjustments that capture the influence of clustering, degree variance,\n    density, assortativity, and degree extremes.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0: avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0: max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0: min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.095031\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.137126\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a multiplicative combination of a random‑graph baseline\n    and several adjustment factors that capture the influence of clustering,\n    degree heterogeneity, density, assortativity, and extreme degrees.\n    All operations are guarded against division by zero and missing values.\n    \"\"\"\n    import math\n\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 0.0) or 1e-6          # avoid zero\n    avg_deg    = s.get('avg_degree', 1.0) or 1.0\n    max_deg    = s.get('max_degree', 1.0) or 1.0\n    min_deg    = s.get('min_degree', 1.0) or 1.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    clustering = s.get('avg_clustering', 0.0) or 0.0\n    trans      = s.get('transitivity', 0.0) or 0.0\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n    triangles  = s.get('num_triangles', 0) or 0\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = math.log(max(n, 2)) / math.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = 1.0 / (1.0 + density)\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 6. Max degree adjustment: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 7. Minimum degree adjustment: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 8. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a multiplicative combination of a simple baseline and several\n    adjustment factors that capture the influence of clustering, degree\n    heterogeneity, density, assortativity, and extreme degrees. All operations\n    are guarded against division by zero and missing values.\n    \"\"\"\n    n = s.get('n', 1)\n    m = s.get('m', 1)\n    density = s.get('density', 0.0) or 1e-6\n    avg_deg = s.get('avg_degree', 1.0) or 1.0\n    max_deg = s.get('max_degree', 1.0) or 1.0\n    min_deg = s.get('min_degree', 1.0) or 1.0\n    std_deg = s.get('std_degree', 0.0) or 1.0\n    clustering = s.get('avg_clustering', 0.0) or 0.0\n    trans = s.get('transitivity', 0.0) or 0.0\n    assort = s.get('degree_assortativity', 0.0) or 0.0\n    triangles = s.get('num_triangles', 0) or 0\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # Adjustment factors\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n    density_adj = 1.0 / (1.0 + density)\n    assort_adj = 1.0 + 0.5 * assort\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a multiplicative combination of a simple baseline and several\n    adjustment factors that capture the influence of clustering, degree\n    heterogeneity, density, assortativity, and extreme degrees. All operations\n    are guarded against division by zero and missing values.\n    \"\"\"\n    n = s.get('n', 1)\n    m = s.get('m', 1)\n    density = s.get('density', 0.0) or 1e-6\n    avg_deg = s.get('avg_degree', 1.0) or 1.0\n    max_deg = s.get('max_degree', 1.0) or 1.0\n    min_deg = s.get('min_degree', 1.0) or 1.0\n    std_deg = s.get('std_degree', 0.0) or 1.0\n    clustering = s.get('avg_clustering', 0.0) or 0.0\n    trans = s.get('transitivity', 0.0) or 0.0\n    assort = s.get('degree_assortativity', 0.0) or 0.0\n    triangles = s.get('num_triangles', 0) or 0\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # Adjustment factors\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n    density_adj = 1.0 / (1.0 + density)\n    assort_adj = 1.0 + 0.5 * assort\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    estimate = (base *\n                clustering_adj *\n                variance_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T03:25:27.040722+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 10, "island_id": 2, "population_idx": 1, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:26:00.834278+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:26:00.835127+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 10, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:26:35.613757+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 2, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.135127", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:26:35.614152+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 10, "island_id": 2, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:27:21.692254+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:27:21.693111+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 10, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:27:52.055781+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i2_p3_917652131", "generation": 10, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.529795918367347, "spearman": 0.4014521868492696, "pearson": 0.48813265286819907, "rmse": 2.224354503542899, "mae": 2.088081516434115, "simplicity_score": 0.17920640820118539, "novelty_bonus": 0.32452561314032835, "total_score": 0.3339250590069704, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative\n    adjustments that capture the influence of clustering, degree variance,\n    density, assortativity, and degree extremes.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0: avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0: max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0: min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.137126\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.135127\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport math\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length using a compact, feature‑based model.\n    The estimate is a product of a random‑graph baseline and several\n    multiplicative adjustments that capture clustering, degree variance,\n    density, assortativity, degree extremes and triangle abundance.\n    All operations are protected against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 0.0)\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0:\n        max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0:\n        min_deg = 1.0\n    triangles  = s.get('num_triangles', 0)\n\n    # 1. Random‑graph baseline (logarithmic scaling)\n    base = math.log(n + 1) / math.log(avg_deg + 1.5)\n\n    # 2. Clustering & transitivity adjustment (more triangles → longer paths)\n    cluster_adj = 1.0 + 0.4 * (avg_clust + trans)\n\n    # 3. Degree variance adjustment (higher variance → shorter paths)\n    var_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment (denser graphs → shorter paths)\n    density_adj = 1.0 / (1.0 + density)\n\n    # 5. Assortativity adjustment (positive assortativity can lengthen paths)\n    assort_adj = 1.0 + 0.3 * assort\n\n    # 6. Max degree adjustment (high max degree tends to shorten paths)\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 7. Min degree adjustment (very low min degree can lengthen paths)\n    min_adj = 1.0 + 0.5 / (min_deg + 1.0)\n\n    # 8. Triangle count adjustment (more triangles → longer paths)\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base * cluster_adj * var_adj * density_adj *\n                assort_adj * max_adj * min_adj * tri_adj)\n\n    return estimate\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term and several multiplicative\n    adjustments that capture clustering, degree variance, density,\n    assortativity, degree extremes, and triangle abundance.\n    All operations are protected against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 0.0)\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0:\n        max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0:\n        min_deg = 1.0\n    triangles  = s.get('num_triangles', 0)\n\n    # 1. Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 2. Clustering & transitivity adjustment (more triangles → longer paths)\n    cluster_adj = 1.0 + 0.4 * (avg_clust + trans)\n\n    # 3. Degree variance adjustment (higher variance → shorter paths)\n    var_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment (denser graphs → shorter paths)\n    density_adj = 1.0 / (1.0 + density)\n\n    # 5. Assortativity adjustment (positive assortativity can lengthen paths)\n    assort_adj = 1.0 + 0.3 * assort\n\n    # 6. Max degree adjustment (high max degree tends to shorten paths)\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 7. Min degree adjustment (very low min degree can lengthen paths)\n    min_adj = 1.0 + 0.5 / (min_deg + 1.0)\n\n    # 8. Triangle count adjustment (more triangles → longer paths)\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base * cluster_adj * var_adj * density_adj *\n                assort_adj * max_adj * min_adj * tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term and several multiplicative\n    adjustments that capture clustering, degree variance, density,\n    assortativity, degree extremes, and triangle abundance.\n    All operations are protected against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 0.0)\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0:\n        max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0:\n        min_deg = 1.0\n    triangles  = s.get('num_triangles', 0)\n\n    # 1. Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 2. Clustering & transitivity adjustment (more triangles → longer paths)\n    cluster_adj = 1.0 + 0.4 * (avg_clust + trans)\n\n    # 3. Degree variance adjustment (higher variance → shorter paths)\n    var_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment (denser graphs → shorter paths)\n    density_adj = 1.0 / (1.0 + density)\n\n    # 5. Assortativity adjustment (positive assortativity can lengthen paths)\n    assort_adj = 1.0 + 0.3 * assort\n\n    # 6. Max degree adjustment (high max degree tends to shorten paths)\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 7. Min degree adjustment (very low min degree can lengthen paths)\n    min_adj = 1.0 + 0.5 / (min_deg + 1.0)\n\n    # 8. Triangle count adjustment (more triangles → longer paths)\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base * cluster_adj * var_adj * density_adj *\n                assort_adj * max_adj * min_adj * tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T03:27:52.056125+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 10, "island_id": 2, "population_idx": 3, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:28:31.903087+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.133768", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:29:49.481030+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.151885", "model_name": "gpt-oss:20b", "train_signal": 0.15188475390156062}}
{"timestamp": "2026-02-13T03:30:34.647277+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.288547", "model_name": "gpt-oss:20b", "train_signal": 0.28854741896758695}}
{"timestamp": "2026-02-13T03:31:10.387837+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:31:10.388640+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 10, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:32:25.097525+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i3_p2_293593757", "generation": 10, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.4679471788715486, "spearman": -0.5960093737379004, "pearson": 0.34616666913872995, "rmse": 10036130.841604944, "mae": 1834411.0901371557, "simplicity_score": 0.17765488044936778, "novelty_bonus": 0.16927356039521335, "total_score": 0.38431773107738776, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how average path length relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that mixes size, sparsity, degree dispersion,\n    triangle abundance, clustering strength, and degree assortativity.\n    All operations use only built‑in arithmetic to avoid external imports.\n    \"\"\"\n    # Size to edge ratio – captures overall sparsity\n    size_edge = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # Degree dispersion relative to variability – higher spread suggests\n    # longer paths through hubs\n    deg_disp = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # Triangle density – more triangles usually shorten paths\n    tri_dense = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # Combined clustering factor – square to amplify the effect\n    cluster_factor = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # Assortativity magnitude – strong correlation can create bottlenecks\n    assort_factor = (s['degree_assortativity'] ** 2 + 1.0)\n\n    # Final invariant: product of sparsity, dispersion, and triangle terms,\n    # divided by clustering and assortativity terms\n    invariant = (size_edge * deg_disp * tri_dense) / (cluster_factor * assort_factor)\n\n    return invariant\n\ndef new_invariant(s):\n    \"\"\"\n    A hand‑crafted composite invariant built only from arithmetic\n    operations on the supplied pre‑computed statistics.\n\n    The formula mixes size, sparsity, degree dispersion, triangle\n    abundance, clustering, and degree assortativity – all quantities\n    known to influence the average shortest‑path length.\n\n    Key assumptions:\n        • s contains the keys listed in the problem statement.\n        • No external modules may be imported; only built‑in\n          operations (addition, subtraction, multiplication,\n          division, pow, min, max, etc.) are used.\n\n    The structure is:\n\n        invariant = (size_factor * degree_factor * triangle_factor)\n                    / (clustering_factor * assortativity_factor)\n\n    The \"+ 1\" terms in denominators guarantee numerical stability\n    for very small or zero values.\n    \"\"\"\n\n    # 1. Size‑to‑edge ratio: captures overall sparsity.\n    size_factor = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree spread relative to its standard deviation.\n    #    Larger spread tends to create longer paths, especially when\n    #    combined with a high variance of degrees.\n    degree_factor = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # 3. Triangle density (shifted to avoid division by zero).\n    triangle_factor = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Clustering influence.  Square both local and global clustering\n    #    before averaging to give more weight to high‑clustering graphs.\n    clustering_factor = (pow(s['avg_clustering'], 2) + pow(s['transitivity'], 2)) / 2.0\n\n    # 5. Assortativity influence.  Strong positive or negative assortativity\n    #    usually creates bottlenecks, so we penalise large absolute values.\n    assortativity_factor = pow(s['degree_assortativity'], 2) + 1.0\n\n    # 6. Combine all pieces.  We multiply the first three terms – each\n    #    known to *shorten* paths – and divide by the last two, which\n    #    typically *enlarge* the average shortest path.\n    invariant = (size_factor * degree_factor * triangle_factor) / (clustering_factor * assortativity_factor)\n\n    return invariant\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.017690\nbelow_train_threshold: train_signal=0.151885\nbelow_train_threshold: train_signal=0.288547\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    A composite estimate of the average shortest‑path length built solely\n    from pre‑computed graph statistics.  \n    The formula mixes the following aspects:\n      • Size vs. degree – a random‑graph baseline via log(n)/log(avg_deg).\n      • Triangle abundance (transitivity + clustering) – tends to shorten\n        paths.\n      • Degree dispersion – large max‑/min‑degree range usually shortens\n        paths by creating hubs.\n      • Sparsity – sparser graphs have longer paths; we model this with\n        the inverse square‑root of the density.\n      • Assortativity – strong correlations often increase path length;\n        we penalise by a factor 1+|assort|.\n\n    All operations are purely arithmetic (with `math`), no graph\n    traversal is performed.\n    \"\"\"\n    import math\n\n    # extract and safeguard against zero/division‑by‑zero\n    n            = s.get('n', 0)\n    avg_deg      = s.get('avg_degree', 0.0) + 1e-9\n    std_deg      = s.get('std_degree', 0.0) + 1e-9\n    density      = s.get('density', 0.0) + 1e-12\n    transitivity = s.get('transitivity', 0.0)\n    clust        = s.get('avg_clustering', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    max_deg      = s.get('max_degree', 0.0)\n    min_deg      = s.get('min_degree', 0.0)\n\n    # 1. Random‑graph baseline\n    base = math.log(n + 1) / math.log(avg_deg + 2)\n\n    # 2. Triangle / clustering adjustment\n    cluster_adj = 1 + 0.5 * (transitivity + clust)\n\n    # 3. Degree‑dispersion factor (higher spread → more hubs)\n    disp_adj = (max_deg - min_deg + 1) ** 2 / (std_deg + 1)\n\n    # 4. Sparsity adjustment – sparse graphs have longer paths\n    density_adj = 1 / math.sqrt(density)\n\n    # 5. Assortativity penalty\n    assort_adj = 1 + abs(assort)\n\n    return base * cluster_adj * disp_adj * density_adj / assort_adj\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a purely arithmetic combination of several well‑known\n    structural measures (sparsity, degree spread, triangle density,\n    clustering, and assortativity).  No external libraries are required\n    and all divisions are protected against zero denominators.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary containing the following keys:\n        n, m, avg_degree, max_degree, min_degree, std_degree,\n        avg_clustering, transitivity, degree_assortativity,\n        num_triangles.\n\n    Returns\n    -------\n    float\n        An invariant that correlates with the average shortest‑path length.\n    \"\"\"\n    # ---- Extract features with safe defaults ----\n    n = s.get('n', 1)                  # node count (default 1 to avoid division by zero)\n    m = s.get('m', 0)                  # edge count\n    avg_deg = s.get('avg_degree', 1.0)  # average degree (avoid division by zero)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n\n    # ---- Sparsity factor (size relative to edge count) ----\n    size_factor = (n + 1.0) / (m + 1.0)\n\n    # ---- Degree‑spread factor (larger spread → longer paths) ----\n    degree_factor = (max_deg - min_deg + 1.0) / (std_deg + 1.0)\n\n    # ---- Triangle density factor (more triangles → shorter paths) ----\n    triangle_factor = (num_tri + 1.0) / (n + 1.0)\n\n    # ---- Clustering influence (higher clustering tends to elongate paths) ----\n    clustering_factor = avg_clust + trans + 1e-9  # +ε to avoid division by zero\n\n    # ---- Assortativity penalty (strong correlations lengthen paths) ----\n    assort_factor = abs(assort) + 1.0\n\n    # ---- Composite invariant ----\n    invariant = (size_factor *\n                 degree_factor *\n                 triangle_factor) / (clustering_factor * assort_factor)\n\n    return invariant\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a purely arithmetic combination of several well‑known\n    structural measures (sparsity, degree spread, triangle density,\n    clustering, and assortativity).  No external libraries are required\n    and all divisions are protected against zero denominators.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary containing the following keys:\n        n, m, avg_degree, max_degree, min_degree, std_degree,\n        avg_clustering, transitivity, degree_assortativity,\n        num_triangles.\n\n    Returns\n    -------\n    float\n        An invariant that correlates with the average shortest‑path length.\n    \"\"\"\n    # ---- Extract features with safe defaults ----\n    n = s.get('n', 1)                  # node count (default 1 to avoid division by zero)\n    m = s.get('m', 0)                  # edge count\n    avg_deg = s.get('avg_degree', 1.0)  # average degree (avoid division by zero)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n\n    # ---- Sparsity factor (size relative to edge count) ----\n    size_factor = (n + 1.0) / (m + 1.0)\n\n    # ---- Degree‑spread factor (larger spread → longer paths) ----\n    degree_factor = (max_deg - min_deg + 1.0) / (std_deg + 1.0)\n\n    # ---- Triangle density factor (more triangles → shorter paths) ----\n    triangle_factor = (num_tri + 1.0) / (n + 1.0)\n\n    # ---- Clustering influence (higher clustering tends to elongate paths) ----\n    clustering_factor = avg_clust + trans + 1e-9  # +ε to avoid division by zero\n\n    # ---- Assortativity penalty (strong correlations lengthen paths) ----\n    assort_factor = abs(assort) + 1.0\n\n    # ---- Composite invariant ----\n    invariant = (size_factor *\n                 degree_factor *\n                 triangle_factor) / (clustering_factor * assort_factor)\n\n    return invariant"}}
{"timestamp": "2026-02-13T03:32:25.098746+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 10, "island_id": 3, "population_idx": 2, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:33:11.636827+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.136230", "model_name": "gpt-oss:20b", "train_signal": 0.13623049219687874}}
{"timestamp": "2026-02-13T03:33:54.165689+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i3_p4_434316805", "generation": 10, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.7733580018501388, "spearman": -0.5176074485235316, "pearson": -0.3323906555214724, "rmse": 53.42312398289512, "mae": 41.5169773934602, "simplicity_score": 0.13099168073426157, "novelty_bonus": 0.40562853270443633, "total_score": 0.40669062021994895, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how average path length relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that mixes size, sparsity, degree dispersion,\n    triangle abundance, clustering strength, and degree assortativity.\n    All operations use only built‑in arithmetic to avoid external imports.\n    \"\"\"\n    # Size to edge ratio – captures overall sparsity\n    size_edge = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # Degree dispersion relative to variability – higher spread suggests\n    # longer paths through hubs\n    deg_disp = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # Triangle density – more triangles usually shorten paths\n    tri_dense = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # Combined clustering factor – square to amplify the effect\n    cluster_factor = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # Assortativity magnitude – strong correlation can create bottlenecks\n    assort_factor = (s['degree_assortativity'] ** 2 + 1.0)\n\n    # Final invariant: product of sparsity, dispersion, and triangle terms,\n    # divided by clustering and assortativity terms\n    invariant = (size_edge * deg_disp * tri_dense) / (cluster_factor * assort_factor)\n\n    return invariant\n\ndef new_invariant(s):\n    \"\"\"\n    A hand‑crafted composite invariant built only from arithmetic\n    operations on the supplied pre‑computed statistics.\n\n    The formula mixes size, sparsity, degree dispersion, triangle\n    abundance, clustering, and degree assortativity – all quantities\n    known to influence the average shortest‑path length.\n\n    Key assumptions:\n        • s contains the keys listed in the problem statement.\n        • No external modules may be imported; only built‑in\n          operations (addition, subtraction, multiplication,\n          division, pow, min, max, etc.) are used.\n\n    The structure is:\n\n        invariant = (size_factor * degree_factor * triangle_factor)\n                    / (clustering_factor * assortativity_factor)\n\n    The \"+ 1\" terms in denominators guarantee numerical stability\n    for very small or zero values.\n    \"\"\"\n\n    # 1. Size‑to‑edge ratio: captures overall sparsity.\n    size_factor = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree spread relative to its standard deviation.\n    #    Larger spread tends to create longer paths, especially when\n    #    combined with a high variance of degrees.\n    degree_factor = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # 3. Triangle density (shifted to avoid division by zero).\n    triangle_factor = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Clustering influence.  Square both local and global clustering\n    #    before averaging to give more weight to high‑clustering graphs.\n    clustering_factor = (pow(s['avg_clustering'], 2) + pow(s['transitivity'], 2)) / 2.0\n\n    # 5. Assortativity influence.  Strong positive or negative assortativity\n    #    usually creates bottlenecks, so we penalise large absolute values.\n    assortativity_factor = pow(s['degree_assortativity'], 2) + 1.0\n\n    # 6. Combine all pieces.  We multiply the first three terms – each\n    #    known to *shorten* paths – and divide by the last two, which\n    #    typically *enlarge* the average shortest path.\n    invariant = (size_factor * degree_factor * triangle_factor) / (clustering_factor * assortativity_factor)\n\n    return invariant\nRecent failures:\nbelow_train_threshold: train_signal=0.288547\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.136230\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant built only from basic arithmetic on the\n    supplied pre‑computed statistics.  It combines\n      * overall sparsity,\n      * degree dispersion,\n      * triangle abundance,\n      * clustering (global + local),\n      * and degree assortativity.\n\n    All operations use built‑in operators, so no external modules are needed.\n    \"\"\"\n\n    # Size‑to‑edge ratio: captures overall sparsity.\n    size_factor = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # Degree spread relative to its standard deviation.\n    degree_factor = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # Triangle density (shifted to avoid division by zero).\n    triangle_factor = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # Clustering influence: average of squared global and local clustering.\n    clustering_factor = (pow(s['avg_clustering'], 2) + pow(s['transitivity'], 2)) / 2.0\n\n    # Assortativity influence: penalise large absolute values.\n    assort_factor = pow(s['degree_assortativity'], 2) + 1.0\n\n    # Final invariant: product of the first three factors divided by\n    # the last two.\n    return (size_factor * degree_factor * triangle_factor) / (clustering_factor * assort_factor)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant built only from basic arithmetic on the\n    supplied pre‑computed statistics.  It combines\n      * overall sparsity,\n      * degree dispersion,\n      * triangle abundance,\n      * clustering (global + local),\n      * and degree assortativity.\n\n    All operations use built‑in operators, so no external modules are needed.\n    \"\"\"\n\n    # Size‑to‑edge ratio: captures overall sparsity.\n    size_factor = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # Degree spread relative to its standard deviation.\n    degree_factor = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # Triangle density (shifted to avoid division by zero).\n    triangle_factor = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # Clustering influence: average of squared global and local clustering.\n    clustering_factor = (pow(s['avg_clustering'], 2) + pow(s['transitivity'], 2)) / 2.0\n\n    # Assortativity influence: penalise large absolute values.\n    assort_factor = pow(s['degree_assortativity'], 2) + 1.0\n\n    # Final invariant: product of the first three factors divided by\n    # the last two.\n    return (size_factor * degree_factor * triangle_factor) / (clustering_factor * assort_factor)"}}
{"timestamp": "2026-02-13T03:33:54.169376+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "phase1_20260212T231418Z", "generation": 11, "model_name": "gpt-oss:20b", "best_val_score": 0.5491013268732999, "no_improve_count": 9}}
{"timestamp": "2026-02-13T03:35:45.009614+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i0_p0_661916514", "generation": 11, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.7339735894357742, "spearman": 0.6535403335860107, "pearson": 0.7387911021160836, "rmse": 23.034078908331598, "mae": 21.474293495418568, "simplicity_score": 0.24567379589398705, "novelty_bonus": 0.3773892222440166, "total_score": 0.4891216926450077, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.056040\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.043167\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density) * (1 + 1.0 * trans) * (1 + 0.9 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.3 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + 0.1 * m / (max_edges + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = 0\n    for d in degrees:\n        sum_sq += d * d\n    val *= (1 + 0.05 * sum_sq / (n * (avg_deg * avg_deg + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    degrees = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density) * (1 + 1.0 * trans) * (1 + 0.9 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.3 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + 0.1 * m / (max_edges + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = 0\n    for d in degrees:\n        sum_sq += d * d\n    val *= (1 + 0.05 * sum_sq / (n * (avg_deg * avg_deg + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T03:38:56.060524+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i0_p1_126280735", "generation": 11, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6921968787515005, "spearman": 0.5900789732539878, "pearson": 0.6830600256076108, "rmse": 33.947508137122284, "mae": 31.719014281869804, "simplicity_score": 0.24582065414661958, "novelty_bonus": 0.41261865128525155, "total_score": 0.4679892128418933, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.056040\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.043167\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T03:42:30.860593+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i0_p2_557032152", "generation": 11, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6937334933973589, "spearman": 0.5984139347536365, "pearson": 0.6899706491780695, "rmse": 30.689603036649906, "mae": 28.779145812203588, "simplicity_score": 0.24582065414661958, "novelty_bonus": 0.40958812129657063, "total_score": 0.4712475345951133, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.056040\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.043167\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n\n    # Positive assortativity tends to shorten paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    return val", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n\n    # Positive assortativity tends to shorten paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T03:43:36.185122+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i0_p3_505015495", "generation": 11, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.701704681872749, "spearman": 0.6167113990517943, "pearson": 0.6690570395176295, "rmse": 26.962698673957107, "mae": 25.287886160304797, "simplicity_score": 0.24569455911846988, "novelty_bonus": 0.414524591626822, "total_score": 0.48185198883763775, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.056040\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.043167\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 0.9 * density)\n    val *= (1 + 0.8 * trans)\n    val *= (1 + 0.7 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.5 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 0.9 * density)\n    val *= (1 + 0.8 * trans)\n    val *= (1 + 0.7 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.5 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T03:44:22.348790+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i0_p4_783898208", "generation": 11, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.3677791116446578, "spearman": 0.23343742347463708, "pearson": 0.27572643688571363, "rmse": 37.21102737496154, "mae": 34.31869746329004, "simplicity_score": 0.2477472396632161, "novelty_bonus": 0.5566445173425695, "total_score": 0.3332615148727326, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n\n    val = n / (avg_deg + 1)\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * trans)\n    val *= (1 + 1.0 * clustering)\n    val /= (1 + 0.4 * abs(assort))\n    val *= (1 + 0.3 * (num_tri ** 0.5) / (n + 1))\n    val *= (1 + 0.4 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.4 * std_deg / (avg_deg + 1))\n    return val\n\ndef new_invariant(s):\n    # unpack features\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.1 * density) * (1 + 1.1 * trans) * (1 + 1.0 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.4 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with sqrt\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n**2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    max_edges = n * (n - 1) // 2\n    val *= (1 + m / (max_edges + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.2 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.056040\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.043167\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a weighted product of structural factors that tend to\n    shorten or lengthen paths.  Coefficients are chosen to keep the formula\n    compact while capturing the main influences on path length.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.0 * trans)\n    val *= (1 + 0.9 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    val *= (1 + 0.2 * m / (n + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.1 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression is a weighted product of structural factors that tend to\n    shorten or lengthen paths.  Coefficients are chosen to keep the formula\n    compact while capturing the main influences on path length.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.2 * density)\n    val *= (1 + 1.0 * trans)\n    val *= (1 + 0.9 * clustering)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + 0.4 * (num_tri ** 0.5) / (n + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Edge density expressed as ratio of actual to possible edges\n    val *= (1 + 0.2 * m / (n + 1))\n\n    # Sum of squared degrees captures higher‑order degree effects\n    sum_sq = sum(d * d for d in degrees)\n    val *= (1 + 0.1 * sum_sq / (n * (avg_deg ** 2 + 1)))\n\n    return val"}}
{"timestamp": "2026-02-13T03:45:06.160370+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.107083", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:45:35.992804+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i1_p1_996106906", "generation": 11, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6305402160864346, "spearman": 0.570975238496717, "pearson": 0.5083390730277598, "rmse": 0.9940379477352599, "mae": 0.7429068033149566, "simplicity_score": 0.24884422855652805, "novelty_bonus": 0.2787261494590507, "total_score": 0.4188743097973794, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Base factors combining the two top formulas\n    base1 = n / (avg_deg + 1)\n    base2 = n / (m + 1)\n    base = base1 * base2\n\n    # Degree balance\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling\n    sqrt_factor = n ** 0.5\n\n    # Assortativity penalty\n    assort_factor = 1 / (1 + 0.5 * abs(assort))\n\n    # Triangle influence (both raw and normalized)\n    max_triangles = max(1, n * (n - 1) / 2)\n    tri_factor1 = 1 + (triangles ** 0.5) / (n ** 2 + 1)\n    tri_factor2 = 1 + triangles / max_triangles\n    triangle_factor = tri_factor1 * tri_factor2\n\n    # Degree variance penalty\n    std_factor = (1 / (1 + std_deg)) * (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Minimum degree encouragement\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Combine all multiplicatively\n    val = (base * deg_factor * struct_factor * sqrt_factor *\n           assort_factor * triangle_factor * std_factor *\n           min_factor * spread_factor * degree_range_factor *\n           median_factor)\n\n    return val\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression combines several structural factors multiplicatively, each\n    designed to capture a different aspect of graph connectivity.\n    \"\"\"\n    # Basic size / density factor\n    val = s['n'] / (s['m'] + 1)\n\n    # Structural cohesion factors\n    val *= (1 + s['density'])\n    val *= (1 + s['avg_clustering'])\n    val *= (1 + s['transitivity'])\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    val *= (1 + s['num_triangles'] / max_triangles)\n\n    # Degree spread and variability\n    degree_range = s['max_degree'] - s['min_degree']\n    val *= (1 + degree_range / (s['max_degree'] + 1))\n    val *= (1 + s['std_degree'] / (s['avg_degree'] + 1))\n\n    # Assortativity effect\n    val *= (1 + s['degree_assortativity'])\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (s['avg_degree'] + 1))\n\n    return val\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nbelow_novelty_threshold: novelty_bonus=0.107083\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression combines several structural factors multiplicatively, each\n    designed to capture a different aspect of graph connectivity.\n    \"\"\"\n    # Basic size / density factor\n    val = s['n'] / (s['m'] + 1)\n\n    # Structural cohesion factors\n    val *= (1 + s['density'])\n    val *= (1 + s['avg_clustering'])\n    val *= (1 + s['transitivity'])\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    val *= (1 + s['num_triangles'] / max_triangles)\n\n    # Degree spread and variability\n    degree_range = s['max_degree'] - s['min_degree']\n    val *= (1 + degree_range / (s['max_degree'] + 1))\n    val *= (1 + s['std_degree'] / (s['avg_degree'] + 1))\n\n    # Assortativity effect (penalise large absolute values)\n    val *= (1 / (1 + abs(s['degree_assortativity'])))\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (s['avg_degree'] + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression combines several structural factors multiplicatively, each\n    designed to capture a different aspect of graph connectivity.\n    \"\"\"\n    # Basic size / density factor\n    val = s['n'] / (s['m'] + 1)\n\n    # Structural cohesion factors\n    val *= (1 + s['density'])\n    val *= (1 + s['avg_clustering'])\n    val *= (1 + s['transitivity'])\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    val *= (1 + s['num_triangles'] / max_triangles)\n\n    # Degree spread and variability\n    degree_range = s['max_degree'] - s['min_degree']\n    val *= (1 + degree_range / (s['max_degree'] + 1))\n    val *= (1 + s['std_degree'] / (s['avg_degree'] + 1))\n\n    # Assortativity effect (penalise large absolute values)\n    val *= (1 / (1 + abs(s['degree_assortativity'])))\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (s['avg_degree'] + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T03:46:05.834101+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i1_p2_664313540", "generation": 11, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.665594237695078, "spearman": 0.5204262058150092, "pearson": 0.5303335853165496, "rmse": 1.8533421235980216, "mae": 1.1338592397729896, "simplicity_score": 0.24894726141771692, "novelty_bonus": 0.3145440983224703, "total_score": 0.40436578468778905, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Base factors combining the two top formulas\n    base1 = n / (avg_deg + 1)\n    base2 = n / (m + 1)\n    base = base1 * base2\n\n    # Degree balance\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling\n    sqrt_factor = n ** 0.5\n\n    # Assortativity penalty\n    assort_factor = 1 / (1 + 0.5 * abs(assort))\n\n    # Triangle influence (both raw and normalized)\n    max_triangles = max(1, n * (n - 1) / 2)\n    tri_factor1 = 1 + (triangles ** 0.5) / (n ** 2 + 1)\n    tri_factor2 = 1 + triangles / max_triangles\n    triangle_factor = tri_factor1 * tri_factor2\n\n    # Degree variance penalty\n    std_factor = (1 / (1 + std_deg)) * (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Minimum degree encouragement\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Combine all multiplicatively\n    val = (base * deg_factor * struct_factor * sqrt_factor *\n           assort_factor * triangle_factor * std_factor *\n           min_factor * spread_factor * degree_range_factor *\n           median_factor)\n\n    return val\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression combines several structural factors multiplicatively, each\n    designed to capture a different aspect of graph connectivity.\n    \"\"\"\n    # Basic size / density factor\n    val = s['n'] / (s['m'] + 1)\n\n    # Structural cohesion factors\n    val *= (1 + s['density'])\n    val *= (1 + s['avg_clustering'])\n    val *= (1 + s['transitivity'])\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    val *= (1 + s['num_triangles'] / max_triangles)\n\n    # Degree spread and variability\n    degree_range = s['max_degree'] - s['min_degree']\n    val *= (1 + degree_range / (s['max_degree'] + 1))\n    val *= (1 + s['std_degree'] / (s['avg_degree'] + 1))\n\n    # Assortativity effect\n    val *= (1 + s['degree_assortativity'])\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (s['avg_degree'] + 1))\n\n    return val\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nbelow_novelty_threshold: novelty_bonus=0.107083\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression combines several structural factors multiplicatively, each\n    designed to capture a different aspect of graph connectivity.\n    \"\"\"\n    # Basic size / density factor\n    val = s['n'] / (s['m'] + 1)\n\n    # Structural cohesion factors\n    val *= (1 + s['density'])\n    val *= (1 + s['avg_clustering'])\n    val *= (1 + s['transitivity'])\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    val *= (1 + s['num_triangles'] / max_triangles)\n\n    # Degree spread and variability\n    degree_range = s['max_degree'] - s['min_degree']\n    val *= (1 + degree_range / (s['max_degree'] + 1))\n    val *= (1 + s['std_degree'] / (s['avg_degree'] + 1))\n\n    # Assortativity effect\n    val *= (1 + abs(s['degree_assortativity']))\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (s['avg_degree'] + 1))\n\n    return val\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression combines several structural factors multiplicatively, each\n    designed to capture a different aspect of graph connectivity.\n    \"\"\"\n    # Basic size / density factor\n    val = s['n'] / (s['m'] + 1)\n\n    # Structural cohesion factors\n    val *= (1 + s['density'])\n    val *= (1 + s['avg_clustering'])\n    val *= (1 + s['transitivity'])\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    val *= (1 + s['num_triangles'] / max_triangles)\n\n    # Degree spread and variability\n    degree_range = s['max_degree'] - s['min_degree']\n    val *= (1 + degree_range / (s['max_degree'] + 1))\n    val *= (1 + s['std_degree'] / (s['avg_degree'] + 1))\n\n    # Assortativity effect\n    val *= (1 + abs(s['degree_assortativity']))\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (s['avg_degree'] + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T03:49:22.069698+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i1_p3_409186442", "generation": 11, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7202400960384154, "spearman": 0.5505387199200568, "pearson": 0.4310323805676535, "rmse": 141.121697637269, "mae": 99.83923993642503, "simplicity_score": 0.24658881504507985, "novelty_bonus": 0.3777972523697515, "total_score": 0.4379262986799698, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The formula is a weighted product of factors that tend to shorten or lengthen\n    paths, with coefficients tuned to keep the expression compact while\n    capturing the main structural influences.\n    \"\"\"\n    # Basic quantities\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    degrees    = s['degrees']          # sorted list\n\n    # Base estimate: larger n and smaller avg_degree → longer paths\n    val = n / (avg_deg + 1)\n\n    # Factors that tend to shorten paths\n    val *= (1 + 1.3 * density)\n    val *= (1 + 1.1 * clustering)\n    val *= (1 + 1.2 * trans)\n\n    # Positive assortativity clusters similar‑degree nodes, often shortening paths\n    val /= (1 + 0.5 * abs(assort))\n\n    # Triangles provide local shortcuts; dampen large counts with a square root\n    val *= (1 + (num_tri ** 0.5) / (n ** 2 + 1))\n\n    # Degree spread and variability can increase path length\n    val *= (1 + 0.3 * (max_deg - min_deg) / (max_deg + 1))\n    val *= (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Median degree captures the central tendency of the degree distribution\n    mid = len(degrees) // 2\n    median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2\n    val *= (1 + 0.2 * median_deg / (avg_deg + 1))\n\n    return val\n\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Base factors combining the two top formulas\n    base1 = n / (avg_deg + 1)\n    base2 = n / (m + 1)\n    base = base1 * base2\n\n    # Degree balance\n    deg_factor = (avg_deg + 1) / (max_deg + 1)\n\n    # Structural cohesion\n    struct_factor = (density + clustering) * (1 + trans)\n\n    # Size scaling\n    sqrt_factor = n ** 0.5\n\n    # Assortativity penalty\n    assort_factor = 1 / (1 + 0.5 * abs(assort))\n\n    # Triangle influence (both raw and normalized)\n    max_triangles = max(1, n * (n - 1) / 2)\n    tri_factor1 = 1 + (triangles ** 0.5) / (n ** 2 + 1)\n    tri_factor2 = 1 + triangles / max_triangles\n    triangle_factor = tri_factor1 * tri_factor2\n\n    # Degree variance penalty\n    std_factor = (1 / (1 + std_deg)) * (1 + 0.3 * std_deg / (avg_deg + 1))\n\n    # Minimum degree encouragement\n    min_factor = (min_deg + 1) / (avg_deg + 1)\n\n    # Degree spread factor\n    spread_factor = 1 + (max_deg - min_deg) / (max_deg + 1)\n\n    # Degree range factor\n    degree_range_factor = 1 + (max_deg - min_deg + 1) / (avg_deg + 1)\n\n    # Median degree factor\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    median_factor = (median_deg + 1) / (avg_deg + 1)\n\n    # Combine all multiplicatively\n    val = (base * deg_factor * struct_factor * sqrt_factor *\n           assort_factor * triangle_factor * std_factor *\n           min_factor * spread_factor * degree_range_factor *\n           median_factor)\n\n    return val\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features.\n    The expression combines several structural factors multiplicatively, each\n    designed to capture a different aspect of graph connectivity.\n    \"\"\"\n    # Basic size / density factor\n    val = s['n'] / (s['m'] + 1)\n\n    # Structural cohesion factors\n    val *= (1 + s['density'])\n    val *= (1 + s['avg_clustering'])\n    val *= (1 + s['transitivity'])\n\n    # Triangle density relative to the maximum possible\n    max_triangles = max(1, s['n'] * (s['n'] - 1) / 2.0)\n    val *= (1 + s['num_triangles'] / max_triangles)\n\n    # Degree spread and variability\n    degree_range = s['max_degree'] - s['min_degree']\n    val *= (1 + degree_range / (s['max_degree'] + 1))\n    val *= (1 + s['std_degree'] / (s['avg_degree'] + 1))\n\n    # Assortativity effect\n    val *= (1 + s['degree_assortativity'])\n\n    # Median degree factor\n    degrees = s['degrees']\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (s['avg_degree'] + 1))\n\n    return val\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.090900\nbelow_novelty_threshold: novelty_bonus=0.107083\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_degree = s['avg_degree']\n    max_degree = s['max_degree']\n    min_degree = s['min_degree']\n    std_degree = s['std_degree']\n    avg_clustering = s['avg_clustering']\n    transitivity = s['transitivity']\n    degree_assortativity = s['degree_assortativity']\n    num_triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Base size factor\n    val = n / (m + 1)\n\n    # Size scaling\n    val *= n ** 0.5\n\n    # Cohesion factors\n    val *= (1 + density)\n    val *= (1 + avg_clustering)\n    val *= (1 + transitivity)\n\n    # Triangle factor\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    val *= (1 + num_triangles / max_triangles)\n\n    # Degree spread and variability\n    degree_range = max_degree - min_degree\n    val *= (1 + degree_range / (max_degree + 1))\n    val *= (1 + std_degree / (avg_degree + 1))\n\n    # Assortativity effect\n    val *= (1 + abs(degree_assortativity))\n\n    # Median degree\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_degree + 1))\n\n    # Minimum and maximum degree encouragement\n    val *= (1 + min_degree / (avg_degree + 1))\n    val *= (1 + max_degree / (avg_degree + 1))\n\n    return val", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_degree = s['avg_degree']\n    max_degree = s['max_degree']\n    min_degree = s['min_degree']\n    std_degree = s['std_degree']\n    avg_clustering = s['avg_clustering']\n    transitivity = s['transitivity']\n    degree_assortativity = s['degree_assortativity']\n    num_triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Base size factor\n    val = n / (m + 1)\n\n    # Size scaling\n    val *= n ** 0.5\n\n    # Cohesion factors\n    val *= (1 + density)\n    val *= (1 + avg_clustering)\n    val *= (1 + transitivity)\n\n    # Triangle factor\n    max_triangles = max(1, n * (n - 1) / 2.0)\n    val *= (1 + num_triangles / max_triangles)\n\n    # Degree spread and variability\n    degree_range = max_degree - min_degree\n    val *= (1 + degree_range / (max_degree + 1))\n    val *= (1 + std_degree / (avg_degree + 1))\n\n    # Assortativity effect\n    val *= (1 + abs(degree_assortativity))\n\n    # Median degree\n    mid = len(degrees) // 2\n    if len(degrees) % 2 == 0:\n        median_deg = (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = degrees[mid]\n    val *= (1 + median_deg / (avg_degree + 1))\n\n    # Minimum and maximum degree encouragement\n    val *= (1 + min_degree / (avg_degree + 1))\n    val *= (1 + max_degree / (avg_degree + 1))\n\n    return val"}}
{"timestamp": "2026-02-13T03:51:35.343013+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 1, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.121359", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:52:28.706079+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i2_p0_406386861", "generation": 11, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8884033613445379, "spearman": 0.8562029761505802, "pearson": 0.8120574905615511, "rmse": 7.62661215948433, "mae": 4.514146493182545, "simplicity_score": 0.17909397257846857, "novelty_bonus": 0.22039635324270634, "total_score": 0.5300391885637957, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative\n    adjustments that capture the influence of clustering, degree variance,\n    density, assortativity, and degree extremes.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0: avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0: max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0: min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.135127\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.133768\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term and multiplicative adjustments that\n    capture the effects of clustering, degree variance, density, assortativity,\n    degree extremes, and triangle abundance.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0:\n        max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0:\n        min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term and multiplicative adjustments that\n    capture the effects of clustering, degree variance, density, assortativity,\n    degree extremes, and triangle abundance.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0:\n        max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0:\n        min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T03:53:31.471056+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i2_p1_417958745", "generation": 11, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8884033613445379, "spearman": 0.8562029761505802, "pearson": 0.8120574905615511, "rmse": 7.62661215948433, "mae": 4.514146493182545, "simplicity_score": 0.17906616771954115, "novelty_bonus": 0.22039635324270634, "total_score": 0.5300336275920102, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative\n    adjustments that capture the influence of clustering, degree variance,\n    density, assortativity, and degree extremes.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0: avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0: max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0: min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.135127\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.133768\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative adjustments\n    that capture the influence of clustering, degree variance, density,\n    assortativity, degree extremes, and triangle abundance.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0:\n        max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0:\n        min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative adjustments\n    that capture the influence of clustering, degree variance, density,\n    assortativity, degree extremes, and triangle abundance.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0:\n        max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0:\n        min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = pow(n, 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T03:54:13.660218+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i2_p2_814020384", "generation": 11, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8884033613445379, "spearman": 0.8562029761505802, "pearson": 0.8120574905615511, "rmse": 7.62661215948433, "mae": 4.514146493182545, "simplicity_score": 0.17909397257846857, "novelty_bonus": 0.22039635324270634, "total_score": 0.5300391885637957, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative\n    adjustments that capture the influence of clustering, degree variance,\n    density, assortativity, and degree extremes.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0: avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0: max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0: min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.135127\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.133768\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed graph\n    features.  The expression is a product of a simple base term and several\n    multiplicative adjustments that capture the influence of clustering,\n    degree heterogeneity, density, assortativity, and degree extremes.\n    All divisions are guarded against zero and missing values.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:          # avoid division by zero\n        avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0:\n        max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0:\n        min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # 1. Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 2. Clustering & transitivity adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 3. Degree variance adjustment: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 4. Density adjustment: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 6. Max degree adjustment: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 7. Minimum degree adjustment: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 8. Triangle count adjustment: more triangles relative to edges → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combine all factors\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed graph\n    features.  The expression is a product of a simple base term and several\n    multiplicative adjustments that capture the influence of clustering,\n    degree heterogeneity, density, assortativity, and degree extremes.\n    All divisions are guarded against zero and missing values.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:          # avoid division by zero\n        avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0:\n        max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0:\n        min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # 1. Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 2. Clustering & transitivity adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 3. Degree variance adjustment: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 4. Density adjustment: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 6. Max degree adjustment: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 7. Minimum degree adjustment: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 8. Triangle count adjustment: more triangles relative to edges → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combine all factors\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T03:55:24.669588+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i2_p3_321215732", "generation": 11, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8884033613445379, "spearman": 0.8562029761505802, "pearson": 0.8120574905615511, "rmse": 7.62661215948433, "mae": 4.514146493182545, "simplicity_score": 0.17909397257846857, "novelty_bonus": 0.22039635324270634, "total_score": 0.5300391885637957, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative\n    adjustments that capture the influence of clustering, degree variance,\n    density, assortativity, and degree extremes.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0: avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0: max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0: min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.135127\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.133768\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term and several multiplicative\n    adjustments that capture the influence of clustering, degree variance,\n    density, assortativity, and degree extremes.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0:\n        max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0:\n        min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a base term and several multiplicative\n    adjustments that capture the influence of clustering, degree variance,\n    density, assortativity, and degree extremes.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0:\n        max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0:\n        min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T03:56:18.240787+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i2_p4_166972919", "generation": 11, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.855174069627851, "spearman": 0.8266799770044747, "pearson": 0.7579594129891316, "rmse": 81.26777792865637, "mae": 53.292676445291306, "simplicity_score": 0.17901091630774404, "novelty_bonus": 0.26701591624750753, "total_score": 0.5292469466380384, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n\n    trans      = s.get('transitivity', 0.0)\n    std_deg    = s.get('std_degree', 1.0)\n    if std_deg <= 0:\n        std_deg = 1.0\n\n    density    = s.get('density', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n\n    # 1. Baseline distance estimate (scales with sqrt(n))\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Adjust for clustering – more triangles → longer paths\n    clustering_adj = 1 + trans\n\n    # 3. Adjust for degree variance – higher variance → shorter paths\n    variance_adj = 1 / (1 + std_deg / (avg_deg + 1))\n\n    # 4. Adjust for density – denser graphs → shorter paths\n    density_adj = 1 / (1 + density)\n\n    # 5. Adjust for assortativity – positive assortativity can lengthen paths\n    assort_adj = 1 + 0.5 * assort\n\n    # Combined estimate\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a product of a base term and several multiplicative\n    adjustments that capture the influence of clustering, degree variance,\n    density, assortativity, and degree extremes.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0: avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0: max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0: min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    # Base estimate: grows with sqrt(n) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # 1. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 2. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 3. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + 1e-6)\n\n    # 4. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 5. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 6. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + 1e-6)\n\n    # 7. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.135127\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.133768\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a simple base term and several multiplicative\n    adjustments that capture the influence of clustering, degree variance,\n    density, assortativity, degree extremes, and triangle abundance.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0:\n        max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0:\n        min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    eps = 1e-6  # small constant to avoid division by zero\n\n    # 1. Base estimate: grows with n, shrinks with average degree\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 3. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 4. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + eps)\n\n    # 5. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 6. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 7. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + eps)\n\n    # 8. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a simple base term and several multiplicative\n    adjustments that capture the influence of clustering, degree variance,\n    density, assortativity, degree extremes, and triangle abundance.\n    \"\"\"\n    # Basic statistics with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 1)\n    density    = s.get('density', 1e-6)\n    avg_deg    = s.get('avg_degree', 1.0)\n    if avg_deg <= 0:\n        avg_deg = 1.0\n    max_deg    = s.get('max_degree', 1.0)\n    if max_deg <= 0:\n        max_deg = 1.0\n    min_deg    = s.get('min_degree', 1.0)\n    if min_deg <= 0:\n        min_deg = 1.0\n    std_deg    = s.get('std_degree', 0.0)\n    clustering = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    triangles  = s.get('num_triangles', 0)\n\n    eps = 1e-6  # small constant to avoid division by zero\n\n    # 1. Base estimate: grows with n, shrinks with average degree\n    base = n / (avg_deg + 1.0)\n\n    # 2. Clustering & transitivity: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (clustering + trans)\n\n    # 3. Degree variance: higher variance tends to shorten paths\n    var_adj = 1.0 / (1.0 + (std_deg * std_deg) / (avg_deg + 1.0))\n\n    # 4. Density: denser graphs have shorter paths\n    density_adj = 1.0 / (density + eps)\n\n    # 5. Assortativity: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort\n\n    # 6. Max degree: very high maximum degree usually shortens paths\n    max_adj = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # 7. Minimum degree: very low minimum degree can lengthen paths\n    min_adj = 1.0 + 1.0 / (min_deg + eps)\n\n    # 8. Triangle count relative to edges: more triangles → longer paths\n    tri_adj = 1.0 + triangles / (m + 1.0)\n\n    # Combined estimate\n    estimate = (base *\n                clustering_adj *\n                var_adj *\n                density_adj *\n                assort_adj *\n                max_adj *\n                min_adj *\n                tri_adj)\n\n    return estimate"}}
{"timestamp": "2026-02-13T03:57:18.084245+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i3_p0_334291442", "generation": 11, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.6162118408880666, "spearman": -0.2692440429715039, "pearson": -0.14646435367778193, "rmse": 169.98684714961388, "mae": 126.40486333224092, "simplicity_score": 0.17643221399517606, "novelty_bonus": 0.289380909139469, "total_score": 0.25672273702662785, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how average path length relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that mixes size, sparsity, degree dispersion,\n    triangle abundance, clustering strength, and degree assortativity.\n    All operations use only built‑in arithmetic to avoid external imports.\n    \"\"\"\n    # Size to edge ratio – captures overall sparsity\n    size_edge = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # Degree dispersion relative to variability – higher spread suggests\n    # longer paths through hubs\n    deg_disp = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # Triangle density – more triangles usually shorten paths\n    tri_dense = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # Combined clustering factor – square to amplify the effect\n    cluster_factor = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # Assortativity magnitude – strong correlation can create bottlenecks\n    assort_factor = (s['degree_assortativity'] ** 2 + 1.0)\n\n    # Final invariant: product of sparsity, dispersion, and triangle terms,\n    # divided by clustering and assortativity terms\n    invariant = (size_edge * deg_disp * tri_dense) / (cluster_factor * assort_factor)\n\n    return invariant\n\ndef new_invariant(s):\n    \"\"\"\n    A hand‑crafted composite invariant built only from arithmetic\n    operations on the supplied pre‑computed statistics.\n\n    The formula mixes size, sparsity, degree dispersion, triangle\n    abundance, clustering, and degree assortativity – all quantities\n    known to influence the average shortest‑path length.\n\n    Key assumptions:\n        • s contains the keys listed in the problem statement.\n        • No external modules may be imported; only built‑in\n          operations (addition, subtraction, multiplication,\n          division, pow, min, max, etc.) are used.\n\n    The structure is:\n\n        invariant = (size_factor * degree_factor * triangle_factor)\n                    / (clustering_factor * assortativity_factor)\n\n    The \"+ 1\" terms in denominators guarantee numerical stability\n    for very small or zero values.\n    \"\"\"\n\n    # 1. Size‑to‑edge ratio: captures overall sparsity.\n    size_factor = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree spread relative to its standard deviation.\n    #    Larger spread tends to create longer paths, especially when\n    #    combined with a high variance of degrees.\n    degree_factor = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # 3. Triangle density (shifted to avoid division by zero).\n    triangle_factor = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Clustering influence.  Square both local and global clustering\n    #    before averaging to give more weight to high‑clustering graphs.\n    clustering_factor = (pow(s['avg_clustering'], 2) + pow(s['transitivity'], 2)) / 2.0\n\n    # 5. Assortativity influence.  Strong positive or negative assortativity\n    #    usually creates bottlenecks, so we penalise large absolute values.\n    assortativity_factor = pow(s['degree_assortativity'], 2) + 1.0\n\n    # 6. Combine all pieces.  We multiply the first three terms – each\n    #    known to *shorten* paths – and divide by the last two, which\n    #    typically *enlarge* the average shortest path.\n    invariant = (size_factor * degree_factor * triangle_factor) / (clustering_factor * assortativity_factor)\n\n    return invariant\nRecent failures:\nbelow_train_threshold: train_signal=0.288547\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.136230\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features\n    using only arithmetic, power, and built‑in operations.  The formula\n    blends sparsity, degree dispersion, triangle density, clustering,\n    assortativity, and overall density – all quantities that influence\n    path lengths.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics.  Expected keys are:\n\n        n                 - number of nodes\n        m                 - number of edges\n        density           - edge density (0‑1)\n        avg_degree        - average degree\n        max_degree        - maximum degree\n        min_degree        - minimum degree\n        std_degree        - standard deviation of degrees\n        avg_clustering    - average clustering coefficient\n        transitivity      - global transitivity\n        degree_assortativity - degree assortativity coefficient\n        num_triangles     - number of triangles\n        degrees           - sorted list of degrees (unused here)\n\n    Returns\n    -------\n    float\n        An estimate of the average shortest‑path length.\n    \"\"\"\n    # Retrieve values with safe defaults\n    n  = s.get('n',       1)\n    m  = s.get('m',       1)\n    density          = s.get('density',          1e-6)\n    max_d            = s.get('max_degree',        1)\n    min_d            = s.get('min_degree',        1)\n    std_d            = s.get('std_degree',        1)\n    num_tri          = s.get('num_triangles',     0)\n    avg_clust        = s.get('avg_clustering',    0.0)\n    trans            = s.get('transitivity',      0.0)\n    assort           = s.get('degree_assortativity', 0.0)\n\n    # 1. Size / sparsity factor (larger for sparser graphs)\n    size_factor = (n + 1.0) / (m + 1.0)\n\n    # 2. Degree dispersion factor\n    deg_disp = (max_d - min_d + 1.0) / (std_d + 1.0)\n\n    # 3. Triangle density (more triangles tend to shorten paths)\n    tri_factor = (num_tri + 1.0) / (n + 1.0)\n\n    # 4. Clustering influence (higher clustering typically increases path length)\n    cluster_factor = (pow(avg_clust, 2) + pow(trans, 2)) / 2.0\n\n    # 5. Assortativity penalty (strong assortativity can create bottlenecks)\n    assort_factor = pow(assort, 2) + 1.0\n\n    # 6. Density adjustment (sparser graphs have longer paths)\n    density_adj = pow(1.0 / (density + 1e-9), 0.5)\n\n    # 7. Combine all pieces\n    invariant = (size_factor * deg_disp * tri_factor *\n                 density_adj) / (cluster_factor * assort_factor)\n\n    return invariant\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features\n    using only arithmetic, power, and built‑in operations.  The formula\n    blends sparsity, degree dispersion, triangle density, clustering,\n    assortativity, and overall density – all quantities that influence\n    path lengths.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics.  Expected keys are:\n\n        n                 - number of nodes\n        m                 - number of edges\n        density           - edge density (0‑1)\n        avg_degree        - average degree\n        max_degree        - maximum degree\n        min_degree        - minimum degree\n        std_degree        - standard deviation of degrees\n        avg_clustering    - average clustering coefficient\n        transitivity      - global transitivity\n        degree_assortativity - degree assortativity coefficient\n        num_triangles     - number of triangles\n        degrees           - sorted list of degrees (unused here)\n\n    Returns\n    -------\n    float\n        An estimate of the average shortest‑path length.\n    \"\"\"\n    # Retrieve values with safe defaults\n    n  = s.get('n',       1)\n    m  = s.get('m',       1)\n    density          = s.get('density',          1e-6)\n    max_d            = s.get('max_degree',        1)\n    min_d            = s.get('min_degree',        1)\n    std_d            = s.get('std_degree',        1)\n    num_tri          = s.get('num_triangles',     0)\n    avg_clust        = s.get('avg_clustering',    0.0)\n    trans            = s.get('transitivity',      0.0)\n    assort           = s.get('degree_assortativity', 0.0)\n\n    # 1. Size / sparsity factor (larger for sparser graphs)\n    size_factor = (n + 1.0) / (m + 1.0)\n\n    # 2. Degree dispersion factor\n    deg_disp = (max_d - min_d + 1.0) / (std_d + 1.0)\n\n    # 3. Triangle density (more triangles tend to shorten paths)\n    tri_factor = (num_tri + 1.0) / (n + 1.0)\n\n    # 4. Clustering influence (higher clustering typically increases path length)\n    cluster_factor = (pow(avg_clust, 2) + pow(trans, 2)) / 2.0\n\n    # 5. Assortativity penalty (strong assortativity can create bottlenecks)\n    assort_factor = pow(assort, 2) + 1.0\n\n    # 6. Density adjustment (sparser graphs have longer paths)\n    density_adj = pow(1.0 / (density + 1e-9), 0.5)\n\n    # 7. Combine all pieces\n    invariant = (size_factor * deg_disp * tri_factor *\n                 density_adj) / (cluster_factor * assort_factor)\n\n    return invariant"}}
{"timestamp": "2026-02-13T03:58:14.195161+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i3_p1_106142582", "generation": 11, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.547563025210084, "spearman": -0.5700984662486213, "pearson": 0.33824661906623416, "rmse": 16398.958937469786, "mae": 3351.1456539451333, "simplicity_score": 0.17560239116938964, "novelty_bonus": 0.32422104143419117, "total_score": 0.4174360237884459, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how average path length relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula combines random‑graph theory with corrections for clustering,\n    degree heterogeneity, density, and assortativity.  All operations are\n    safeguarded against division by zero and missing values.\n    \"\"\"\n    # Basic graph statistics (safe defaults)\n    n          = s.get('n', 0)\n    avg_deg    = s.get('avg_degree', 0.0) or 1.0          # avoid zero\n    trans      = s.get('transitivity', 0.0) or 0.0\n    avg_clust  = s.get('avg_clustering', 0.0) or 0.0\n    std_deg    = s.get('std_degree', 0.0) or 1.0\n    density    = s.get('density', 0.0) or 1e-6            # avoid zero\n    assort     = s.get('degree_assortativity', 0.0) or 0.0\n\n    eps = 1e-6\n\n    # 1. Random‑graph baseline: log(n)/log(avg_deg+1)\n    base = np.log(max(n, 2)) / np.log(max(avg_deg + 1.0, 2.0))\n\n    # 2. Clustering adjustment: more triangles → longer paths\n    clustering_adj = 1.0 + 0.5 * (trans + avg_clust)\n\n    # 3. Degree variance adjustment: higher variance → shorter paths\n    variance_adj = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))\n\n    # 4. Density adjustment: sparser graphs tend to have longer paths\n    density_adj = np.sqrt(1.0 / (density + eps))\n\n    # 5. Assortativity adjustment: positive assortativity can lengthen paths\n    assort_adj = 1.0 + 0.5 * assort  # range roughly [0.5, 1.5]\n\n    return base * clustering_adj * variance_adj * density_adj * assort_adj\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that mixes size, sparsity, degree dispersion,\n    triangle abundance, clustering strength, and degree assortativity.\n    All operations use only built‑in arithmetic to avoid external imports.\n    \"\"\"\n    # Size to edge ratio – captures overall sparsity\n    size_edge = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # Degree dispersion relative to variability – higher spread suggests\n    # longer paths through hubs\n    deg_disp = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # Triangle density – more triangles usually shorten paths\n    tri_dense = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # Combined clustering factor – square to amplify the effect\n    cluster_factor = (s['avg_clustering'] ** 2 + s['transitivity'] ** 2) / 2.0\n\n    # Assortativity magnitude – strong correlation can create bottlenecks\n    assort_factor = (s['degree_assortativity'] ** 2 + 1.0)\n\n    # Final invariant: product of sparsity, dispersion, and triangle terms,\n    # divided by clustering and assortativity terms\n    invariant = (size_edge * deg_disp * tri_dense) / (cluster_factor * assort_factor)\n\n    return invariant\n\ndef new_invariant(s):\n    \"\"\"\n    A hand‑crafted composite invariant built only from arithmetic\n    operations on the supplied pre‑computed statistics.\n\n    The formula mixes size, sparsity, degree dispersion, triangle\n    abundance, clustering, and degree assortativity – all quantities\n    known to influence the average shortest‑path length.\n\n    Key assumptions:\n        • s contains the keys listed in the problem statement.\n        • No external modules may be imported; only built‑in\n          operations (addition, subtraction, multiplication,\n          division, pow, min, max, etc.) are used.\n\n    The structure is:\n\n        invariant = (size_factor * degree_factor * triangle_factor)\n                    / (clustering_factor * assortativity_factor)\n\n    The \"+ 1\" terms in denominators guarantee numerical stability\n    for very small or zero values.\n    \"\"\"\n\n    # 1. Size‑to‑edge ratio: captures overall sparsity.\n    size_factor = (s['n'] + 1.0) / (s['m'] + 1.0)\n\n    # 2. Degree spread relative to its standard deviation.\n    #    Larger spread tends to create longer paths, especially when\n    #    combined with a high variance of degrees.\n    degree_factor = (s['max_degree'] - s['min_degree'] + 1.0) / (s['std_degree'] + 1.0)\n\n    # 3. Triangle density (shifted to avoid division by zero).\n    triangle_factor = (s['num_triangles'] + 1.0) / (s['n'] + 1.0)\n\n    # 4. Clustering influence.  Square both local and global clustering\n    #    before averaging to give more weight to high‑clustering graphs.\n    clustering_factor = (pow(s['avg_clustering'], 2) + pow(s['transitivity'], 2)) / 2.0\n\n    # 5. Assortativity influence.  Strong positive or negative assortativity\n    #    usually creates bottlenecks, so we penalise large absolute values.\n    assortativity_factor = pow(s['degree_assortativity'], 2) + 1.0\n\n    # 6. Combine all pieces.  We multiply the first three terms – each\n    #    known to *shorten* paths – and divide by the last two, which\n    #    typically *enlarge* the average shortest path.\n    invariant = (size_factor * degree_factor * triangle_factor) / (clustering_factor * assortativity_factor)\n\n    return invariant\nRecent failures:\nbelow_train_threshold: train_signal=0.288547\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.136230\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant built only from arithmetic on the supplied\n    pre‑computed statistics.\n\n    The formula mixes sparsity (n/m), degree dispersion, triangle\n    density, clustering, assortativity, and the harmonic mean of the\n    degree sequence – all known to influence the average shortest‑path\n    length.\n\n    All operations are safe from division‑by‑zero errors by adding a\n    tiny epsilon where necessary.\n    \"\"\"\n    eps = 1e-6  # small constant for numerical stability\n\n    # Basic counts\n    n = s['n']\n    m = s['m']\n\n    # Degree‑related statistics\n    avg_deg = s['avg_degree']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    degrees = s['degrees']      # sorted list of degrees\n\n    # Triangle and clustering measures\n    num_tri = s['num_triangles']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Assortativity\n    assort = s['degree_assortativity']\n\n    # 1. Sparsity factor – how many nodes per edge (plus 1 to avoid 0/0)\n    size_factor = (n + 1.0) / (m + 1.0)\n\n    # 2. Degree‑spread factor – captures heterogeneity in connectivity\n    spread_factor = (max_deg - min_deg + 1.0) / (std_deg + 1.0)\n\n    # 3. Triangle density – more triangles usually reduce average path length\n    tri_factor = (num_tri + 1.0) / (n + 1.0)\n\n    # 4. Clustering penalty – large clustering tends to increase path lengths\n    cluster_factor = (avg_clust ** 2 + trans ** 2) / 2.0\n\n    # 5. Assortativity penalty – strong assortative or disassortative mixing can\n    #    create bottlenecks, so penalise large absolute values.\n    assort_factor = (assort ** 2) + 1.0\n\n    # 6. Harmonic mean of degrees – higher harmonic mean usually means\n    #    more uniformly high degrees, which shortens paths.\n    sum_inv = 0.0\n    for d in degrees:\n        if d > 0:\n            sum_inv += 1.0 / d\n    harmonic = (len(degrees) / (sum_inv + eps)) if degrees else 1.0\n\n    # 7. Final composite invariant\n    invariant = (size_factor * spread_factor * tri_factor * harmonic) \\\n                / (cluster_factor * assort_factor + eps)\n\n    return invariant\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite invariant built only from arithmetic on the supplied\n    pre‑computed statistics.\n\n    The formula mixes sparsity (n/m), degree dispersion, triangle\n    density, clustering, assortativity, and the harmonic mean of the\n    degree sequence – all known to influence the average shortest‑path\n    length.\n\n    All operations are safe from division‑by‑zero errors by adding a\n    tiny epsilon where necessary.\n    \"\"\"\n    eps = 1e-6  # small constant for numerical stability\n\n    # Basic counts\n    n = s['n']\n    m = s['m']\n\n    # Degree‑related statistics\n    avg_deg = s['avg_degree']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    degrees = s['degrees']      # sorted list of degrees\n\n    # Triangle and clustering measures\n    num_tri = s['num_triangles']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n\n    # Assortativity\n    assort = s['degree_assortativity']\n\n    # 1. Sparsity factor – how many nodes per edge (plus 1 to avoid 0/0)\n    size_factor = (n + 1.0) / (m + 1.0)\n\n    # 2. Degree‑spread factor – captures heterogeneity in connectivity\n    spread_factor = (max_deg - min_deg + 1.0) / (std_deg + 1.0)\n\n    # 3. Triangle density – more triangles usually reduce average path length\n    tri_factor = (num_tri + 1.0) / (n + 1.0)\n\n    # 4. Clustering penalty – large clustering tends to increase path lengths\n    cluster_factor = (avg_clust ** 2 + trans ** 2) / 2.0\n\n    # 5. Assortativity penalty – strong assortative or disassortative mixing can\n    #    create bottlenecks, so penalise large absolute values.\n    assort_factor = (assort ** 2) + 1.0\n\n    # 6. Harmonic mean of degrees – higher harmonic mean usually means\n    #    more uniformly high degrees, which shortens paths.\n    sum_inv = 0.0\n    for d in degrees:\n        if d > 0:\n            sum_inv += 1.0 / d\n    harmonic = (len(degrees) / (sum_inv + eps)) if degrees else 1.0\n\n    # 7. Final composite invariant\n    invariant = (size_factor * spread_factor * tri_factor * harmonic) \\\n                / (cluster_factor * assort_factor + eps)\n\n    return invariant"}}
{"timestamp": "2026-02-13T03:59:11.835604+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:59:11.837644+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 11, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:59:56.596866+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 3, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.015219", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T03:59:56.597484+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 11, "island_id": 3, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T04:00:47.933118+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.046182", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-13T04:01:36.367280+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.149772", "model_name": "gpt-oss:20b", "train_signal": 0.1497719087635054}}
{"timestamp": "2026-02-13T04:01:36.373609+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "phase1_20260212T231418Z", "generation": 12, "model_name": "gpt-oss:20b", "best_val_score": 0.5491013268732999, "no_improve_count": 10}}
