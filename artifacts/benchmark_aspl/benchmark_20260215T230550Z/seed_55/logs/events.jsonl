{"timestamp": "2026-02-17T02:47:06.494908+00:00", "event_type": "phase1_started", "payload": {"experiment_id": "seed_55", "resume": null, "model_name": "gpt-oss:20b", "dataset_fingerprint": "9d8c3443143d034c29f9a0cf9b7cc4a409f17a0e6661ac5b3cafbb9c132fa22b"}}
{"timestamp": "2026-02-17T02:47:39.387926+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 0, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:47:39.388328+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 0, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:47:49.982592+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 0, "population_idx": 0, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:47:49.983229+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 0, "population_idx": 0, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:48:59.749301+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.037445", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:48:59.749850+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.037445", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:49:22.733367+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 0, "population_idx": 1, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:49:22.733969+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 0, "population_idx": 1, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:51:34.518798+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: code must define exactly one function named `new_invariant`", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:51:34.520282+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: code must define exactly one function named `new_invariant`", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:52:10.965858+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 0, "population_idx": 2, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: code must define exactly one function named `new_invariant`", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:52:10.966741+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 0, "population_idx": 2, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:53:25.377744+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g0_i0_p3_963605186", "generation": 0, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.39927971188475386, "fitness_mode": "correlation", "simplicity_score": 0.22377762324679887, "novelty_bonus": 0.2588109381116982, "total_score": 0.25850020861793266, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\nNone yet.\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.037445\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: static_invalid: code must define exactly one function named `new_invariant`\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_degree = s['avg_degree']\n    max_degree = s['max_degree']\n    min_degree = s['min_degree']\n    std_degree = s['std_degree']\n    avg_clustering = s['avg_clustering']\n    transitivity = s['transitivity']\n    degree_assortativity = s['degree_assortativity']\n    num_triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Approximate logarithms by string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(avg_degree)) if avg_degree > 0 else 1\n\n    # Base estimate: log(n) / log(avg_degree)\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for graph density – denser graphs have shorter paths\n    base *= (1 - density) + 0.5\n\n    # Adjust for clustering – higher clustering slightly inflates path length\n    base *= (1 + avg_clustering)\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_degree > 0:\n        base *= (1 + std_degree / max_degree)\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_triangles / n)\n\n    # Optional: incorporate degree assortativity (absolute value to keep factor positive)\n    base *= (1 + abs(degree_assortativity))\n\n    return base", "extracted_code": "def new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_degree = s['avg_degree']\n    max_degree = s['max_degree']\n    min_degree = s['min_degree']\n    std_degree = s['std_degree']\n    avg_clustering = s['avg_clustering']\n    transitivity = s['transitivity']\n    degree_assortativity = s['degree_assortativity']\n    num_triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Approximate logarithms by string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(avg_degree)) if avg_degree > 0 else 1\n\n    # Base estimate: log(n) / log(avg_degree)\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for graph density – denser graphs have shorter paths\n    base *= (1 - density) + 0.5\n\n    # Adjust for clustering – higher clustering slightly inflates path length\n    base *= (1 + avg_clustering)\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_degree > 0:\n        base *= (1 + std_degree / max_degree)\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_triangles / n)\n\n    # Optional: incorporate degree assortativity (absolute value to keep factor positive)\n    base *= (1 + abs(degree_assortativity))\n\n    return base", "spearman": -0.2722028050701268, "pearson": -0.18520577421906487, "rmse": 6.720397710587224, "mae": 3.214934941247998}}
{"timestamp": "2026-02-17T02:54:26.653066+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g0_i0_p4_832252183", "generation": 0, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6336134453781512, "fitness_mode": "correlation", "simplicity_score": 0.23081515560713875, "novelty_bonus": 0.1540611064871057, "total_score": 0.43151909586427445, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\nNone yet.\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.037445\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: static_invalid: code must define exactly one function named `new_invariant`\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base", "extracted_code": "def new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base", "spearman": 0.6782754655934299, "pearson": 0.506248257962618, "rmse": 1.1041638856158253, "mae": 0.7889224660943924}}
{"timestamp": "2026-02-17T02:54:45.076703+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:54:45.077646+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:55:15.274588+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 1, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.063980", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:55:15.275240+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 1, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:55:39.260790+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 1, "population_idx": 1, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.164850", "model_name": "gpt-oss:20b", "train_signal": 0.1648499399759904}}
{"timestamp": "2026-02-17T02:56:39.603603+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g0_i1_p2_727600573", "generation": 0, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.34751500600240093, "fitness_mode": "correlation", "simplicity_score": 0.12714924444448233, "novelty_bonus": 0.21074731243220424, "total_score": 0.34466394286606394, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\nNone yet.\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.063980\nbelow_train_threshold: train_signal=0.164850\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degs = s['degrees']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort))\n    )\n```", "extracted_code": "def new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degs = s['degrees']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort))\n    )", "spearman": 0.5120198004950124, "pearson": 0.37782037010306435, "rmse": 2.8879868494878385, "mae": 2.740310316736073}}
{"timestamp": "2026-02-17T02:57:10.610644+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 1, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.047723", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:57:10.611312+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 1, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.047723", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:57:38.074555+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 1, "population_idx": 3, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.287587", "model_name": "gpt-oss:20b", "train_signal": 0.28758703481392556}}
{"timestamp": "2026-02-17T02:57:38.075310+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 1, "population_idx": 3, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:57:54.051613+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 1, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:57:54.052357+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 1, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:58:28.165670+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 1, "population_idx": 4, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.020216", "model_name": "gpt-oss:20b", "train_signal": 0.020216086434573826}}
{"timestamp": "2026-02-17T02:58:28.166284+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 1, "population_idx": 4, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:58:52.937186+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:58:52.937828+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:59:22.730104+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 2, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.004052", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T02:59:22.730263+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 2, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:00:06.048600+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.127799", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:00:06.048930+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.127799", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:00:28.135007+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 2, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.124341", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:00:28.135394+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 2, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:00:50.632528+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:00:50.633176+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:01:29.859332+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 2, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.018869", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:01:29.859889+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 2, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:02:21.590765+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:02:21.591397+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:02:50.532207+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g0_i2_p3_870645611", "generation": 0, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8601680672268907, "fitness_mode": "correlation", "simplicity_score": 0.22757206167059985, "novelty_bonus": 0.16431528390917616, "total_score": 0.47433723571282804, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\nNone yet.\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.124341\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.018869\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport math\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length of a graph from\n    pre‑computed structural features.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys:\n            n                : number of nodes\n            m                : number of edges\n            avg_degree       : average node degree\n            transitivity     : global clustering coefficient\n            degree_assortativity : degree assortativity coefficient\n            num_triangles    : total number of triangles\n\n    Returns\n    -------\n    float\n        A heuristic estimate of the average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    k = max(s.get('avg_degree', 0.0), 0.0)          # average degree\n    t = s.get('transitivity', 0.0)                 # clustering\n    r = s.get('degree_assortativity', 0.0)          # assortativity\n    m = max(s.get('m', 0), 0)                       # edge count\n    tri = s.get('num_triangles', 0)                # triangle count\n\n    # Base estimate based on random graph intuition\n    est = math.log(n) / math.log(k + 1)\n\n    # Adjust for clustering (high clustering tends to keep paths short)\n    est *= (1 + t)\n\n    # Adjust for assortativity (negative assortativity can create hubs that shorten paths)\n    est *= (1 + abs(r))\n\n    # Incorporate triangle density as an additional shortening factor\n    if m > 0:\n        est *= (1 + tri / m)\n\n    return est\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Heuristic estimate of the average shortest path length based on\n    pre‑computed structural features.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys:\n            n                     : number of nodes\n            m                     : number of edges\n            density               : edge density\n            avg_degree            : average node degree\n            transitivity          : global clustering coefficient\n            degree_assortativity  : degree assortativity coefficient\n            num_triangles         : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_d = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n\n    # Base estimate inversely related to average degree and density\n    base = n / (max(avg_d, 1.0) * max(density, 1e-6))\n\n    # Adjust for clustering: higher clustering tends to shorten paths\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity: negative assortativity can create hubs that shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Heuristic estimate of the average shortest path length based on\n    pre‑computed structural features.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys:\n            n                     : number of nodes\n            m                     : number of edges\n            density               : edge density\n            avg_degree            : average node degree\n            transitivity          : global clustering coefficient\n            degree_assortativity  : degree assortativity coefficient\n            num_triangles         : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_d = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n\n    # Base estimate inversely related to average degree and density\n    base = n / (max(avg_d, 1.0) * max(density, 1e-6))\n\n    # Adjust for clustering: higher clustering tends to shorten paths\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity: negative assortativity can create hubs that shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    return base", "spearman": 0.7590564764119104, "pearson": 0.6300218456450044, "rmse": 543.2141622255064, "mae": 308.868269165467}}
{"timestamp": "2026-02-17T03:02:50.532762+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 2, "population_idx": 3, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:03:29.746945+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g0_i2_p4_221525849", "generation": 0, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.6269867947178872, "fitness_mode": "correlation", "simplicity_score": 0.16344925734773658, "novelty_bonus": 0.41863168084272306, "total_score": 0.4644865109012437, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\nNone yet.\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.124341\nbelow_novelty_threshold: novelty_bonus=0.018869\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, and degree assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features with keys:\n        - n (int): number of nodes\n        - avg_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s['n']\n    d = s['avg_degree']\n    c = s['avg_clustering']\n    t = s['transitivity']\n    a = s['degree_assortativity']\n\n    # Construct a positive denominator that incorporates several aspects\n    # of the graph.  Each term is designed to be small when the graph\n    # is well connected and large when the graph has sparse or highly\n    # clustered structure.\n    denom = np.log(d + 1) + (1 - c) + (1 - t) + (1 - a)\n\n    # Guard against numerical issues (unlikely but safe)\n    if denom <= 0:\n        denom = 1e-6\n\n    # Logarithm of the node count captures the overall scale of the\n    # network, while the denominator normalises for connectivity.\n    return np.log(n) / denom\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, and degree assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features with keys:\n        - n (int): number of nodes\n        - avg_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s['n']\n    d = s['avg_degree']\n    c = s['avg_clustering']\n    t = s['transitivity']\n    a = s['degree_assortativity']\n\n    # Construct a positive denominator that incorporates several aspects\n    # of the graph.  Each term is designed to be small when the graph\n    # is well connected and large when the graph has sparse or highly\n    # clustered structure.\n    denom = np.log(d + 1) + (1 - c) + (1 - t) + (1 - a)\n\n    # Guard against numerical issues (unlikely but safe)\n    if denom <= 0:\n        denom = 1e-6\n\n    # Logarithm of the node count captures the overall scale of the\n    # network, while the denominator normalises for connectivity.\n    return np.log(n) / denom", "spearman": 0.612414310357759, "pearson": 0.7109974317748536, "rmse": 2.0263533043252058, "mae": 1.8492797897701416}}
{"timestamp": "2026-02-17T03:04:07.811499+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:04:07.812184+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:04:51.891231+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.022144", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:04:51.891764+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 3, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:05:42.116497+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.108611", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:05:42.117055+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.108611", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:06:40.287757+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.139174", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:06:40.288300+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:07:11.292576+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:07:11.293385+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:07:43.871560+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 2, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:07:43.872813+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 3, "population_idx": 2, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:08:29.477037+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:08:29.477722+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 0, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:08:57.749726+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g0_i3_p3_218361898", "generation": 0, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.3342617046818727, "fitness_mode": "correlation", "simplicity_score": 0.13344489772490953, "novelty_bonus": 0.16544172280846436, "total_score": 0.27042334893383496, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\nNone yet.\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.108611\nbelow_novelty_threshold: novelty_bonus=0.139174\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\n# Novel formula for estimating the average shortest‑path length (ASPL)\n# from pre‑computed graph features.  \n# It mixes density, clustering, assortativity and triangle density\n# with degree dispersion, all in a multiplicative‑additive structure\n# that has not been used before.  No direct feature is returned.\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the ASPL from a dictionary of graph features.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed features (see problem statement).\n\n    Returns\n    -------\n    float\n        A scalar that is intended to correlate with the true\n        average shortest path length.  The formula is:\n\n        ASPL_est = (n/(m+1)) * (1+density) * (1-avg_clustering)\n                  * (1-degree_assortativity) + (std_degree/max_degree)\n                  * logit(triangle_fraction)\n\n        where triangle_fraction = num_triangles / (n choose 3) and\n        logit(p) = log(p/(1-p)) (regularized to avoid division by zero).\n    \"\"\"\n    import math\n\n    # ---------- Helper calculations ----------\n    # Avoid division by zero in all ratios\n    eps = 1e-12\n\n    # Triangle density (fraction of possible triangles that exist)\n    if s['n'] >= 3:\n        possible_triangles = s['n'] * (s['n'] - 1) * (s['n'] - 2) / 6.0\n        triangle_frac = s['num_triangles'] / (possible_triangles + eps)\n    else:\n        triangle_frac = 0.0\n\n    # Regularised logistic transform of triangle fraction\n    logit_tri = math.log((triangle_frac + eps) /\n                         (1.0 - triangle_frac + eps))\n\n    # Standardised degree dispersion\n    std_deg = s['std_degree']\n    max_deg = max(s['max_degree'], eps)\n    deg_disp = std_deg / max_deg\n\n    # ---------- Combine all components ----------\n    part1 = (s['n'] / (s['m'] + 1.0))\n    part2 = (1.0 + s['density'])\n    part3 = (1.0 - s['avg_clustering'])\n    part4 = (1.0 - s['degree_assortativity'])\n\n    return part1 * part2 * part3 * part4 + deg_disp * logit_tri\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features\n    without accessing any external libraries.  The expression mixes\n    density, clustering, assortativity, degree dispersion and the\n    triangle density in a way that has not appeared before in\n    conventional estimators.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed features.  Keys used:\n        n, m, density, avg_clustering, degree_assortativity,\n        max_degree, std_degree, num_triangles.\n\n    Returns\n    -------\n    float\n        A scalar value that is intended to correlate with the true\n        average shortest‑path length of the graph.\n    \"\"\"\n    eps = 1e-12\n\n    n = s['n']\n    m = s['m']\n    dens = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    num_tri = s['num_triangles']\n\n    # Triangle density (fraction of possible triangles that actually exist)\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # A simple monotonic transform of the triangle fraction\n    tri_transform = tri_frac / (1.0 - tri_frac + eps)\n\n    # Degree dispersion normalised by the maximum degree\n    deg_disp = std_deg / (max_deg + eps)\n\n    # Core multiplicative term combining structural features\n    part1 = n / (m + 1.0)\n    part2 = 1.0 + dens\n    part3 = 1.0 - clustering\n    part4 = 1.0 - assort\n\n    return part1 * part2 * part3 * part4 + deg_disp * tri_transform", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features\n    without accessing any external libraries.  The expression mixes\n    density, clustering, assortativity, degree dispersion and the\n    triangle density in a way that has not appeared before in\n    conventional estimators.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed features.  Keys used:\n        n, m, density, avg_clustering, degree_assortativity,\n        max_degree, std_degree, num_triangles.\n\n    Returns\n    -------\n    float\n        A scalar value that is intended to correlate with the true\n        average shortest‑path length of the graph.\n    \"\"\"\n    eps = 1e-12\n\n    n = s['n']\n    m = s['m']\n    dens = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    num_tri = s['num_triangles']\n\n    # Triangle density (fraction of possible triangles that actually exist)\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # A simple monotonic transform of the triangle fraction\n    tri_transform = tri_frac / (1.0 - tri_frac + eps)\n\n    # Degree dispersion normalised by the maximum degree\n    deg_disp = std_deg / (max_deg + eps)\n\n    # Core multiplicative term combining structural features\n    part1 = n / (m + 1.0)\n    part2 = 1.0 + dens\n    part3 = 1.0 - clustering\n    part4 = 1.0 - assort\n\n    return part1 * part2 * part3 * part4 + deg_disp * tri_transform", "spearman": 0.3882037050926274, "pearson": 0.32679913269314603, "rmse": 2.5684435810070574, "mae": 2.417714328925085}}
{"timestamp": "2026-02-17T03:08:57.750238+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 0, "island_id": 3, "population_idx": 3, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:09:32.747620+00:00", "event_type": "candidate_rejected", "payload": {"generation": 0, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.237551", "model_name": "gpt-oss:20b", "train_signal": 0.23755102040816325}}
{"timestamp": "2026-02-17T03:09:32.750303+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 1, "model_name": "gpt-oss:20b", "best_val_score": 0.47433723571282804, "no_improve_count": 0}}
{"timestamp": "2026-02-17T03:10:28.293756+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 0, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.082805", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:10:28.294644+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 1, "island_id": 0, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.082805", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:11:03.209705+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 0, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.109413", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:11:03.210353+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 1, "island_id": 0, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:11:29.960976+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:11:29.961776+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 1, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:12:01.323657+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i0_p1_781134760", "generation": 1, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6205522208883553, "fitness_mode": "correlation", "simplicity_score": 0.22451121995660644, "novelty_bonus": 0.17145639492344067, "total_score": 0.3767194219748412, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_degree = s['avg_degree']\n    max_degree = s['max_degree']\n    min_degree = s['min_degree']\n    std_degree = s['std_degree']\n    avg_clustering = s['avg_clustering']\n    transitivity = s['transitivity']\n    degree_assortativity = s['degree_assortativity']\n    num_triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Approximate logarithms by string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(avg_degree)) if avg_degree > 0 else 1\n\n    # Base estimate: log(n) / log(avg_degree)\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for graph density – denser graphs have shorter paths\n    base *= (1 - density) + 0.5\n\n    # Adjust for clustering – higher clustering slightly inflates path length\n    base *= (1 + avg_clustering)\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_degree > 0:\n        base *= (1 + std_degree / max_degree)\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_triangles / n)\n\n    # Optional: incorporate degree assortativity (absolute value to keep factor positive)\n    base *= (1 + abs(degree_assortativity))\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: code must define exactly one function named `new_invariant`\nbelow_novelty_threshold: novelty_bonus=0.082805\nbelow_novelty_threshold: novelty_bonus=0.109413\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport math\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula is a lightweight combination of random‑graph theory and\n    empirical adjustments for density, clustering, degree variance, triangles\n    and assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph features. Expected keys:\n        - n (int): number of nodes\n        - m (int): number of edges\n        - density (float): edge density in [0, 1]\n        - avg_degree (float)\n        - max_degree (int)\n        - min_degree (int)\n        - std_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n        - num_triangles (int)\n        - degrees (list[int]): sorted degree list\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n\n    # Basic random‑graph estimate: log(n) / log(avg_degree)\n    # Guard against zero or very small avg_degree\n    base = math.log(n) / (math.log(max(avg_deg, 1.0)) + 1e-6)\n\n    # 1. Density: denser graphs have shorter paths\n    #    (1 - density) shrinks the estimate when density is high\n    base *= math.sqrt(max(1.0 - density, 0.0))\n\n    # 2. Clustering: higher clustering slightly reduces path length in\n    #    small‑world networks\n    base *= (1.0 + avg_clust) ** -0.25\n\n    # 3. Degree variance: high variance can increase path length\n    if max_deg > 0:\n        base *= 1.0 + std_deg / max_deg\n\n    # 4. Triangles: more triangles tend to reduce path length\n    if n > 0:\n        base *= (1.0 + num_tri / n) ** -0.15\n\n    # 5. Assortativity: positive assortativity can increase path length\n    base *= (1.0 + abs(assort)) ** 0.1\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n\n    # approximate logarithms using string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # adjust for density: denser graphs have shorter paths\n    base *= (1 - density) + 0.5  # scales between 0.5 and 1.5\n\n    # adjust for clustering: higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # adjust for degree variance: high variance can increase path length\n    if max_deg > 0:\n        base *= 1 + std_deg / max_deg\n\n    # adjust for triangles: more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.15\n\n    # adjust for assortativity: positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.1\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n\n    # approximate logarithms using string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # adjust for density: denser graphs have shorter paths\n    base *= (1 - density) + 0.5  # scales between 0.5 and 1.5\n\n    # adjust for clustering: higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # adjust for degree variance: high variance can increase path length\n    if max_deg > 0:\n        base *= 1 + std_deg / max_deg\n\n    # adjust for triangles: more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.15\n\n    # adjust for assortativity: positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.1\n\n    return base", "spearman": 0.5607605190129754, "pearson": 0.398577386468617, "rmse": 0.9893629431201648, "mae": 0.7023731466769854}}
{"timestamp": "2026-02-17T03:12:01.324424+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 1, "island_id": 0, "population_idx": 1, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:12:31.149916+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.140878", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:12:31.150325+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 1, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.140878", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:13:04.457927+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 0, "population_idx": 2, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:13:04.458809+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 1, "island_id": 0, "population_idx": 2, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:14:02.023090+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 0, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.135362", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:14:02.024023+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 1, "island_id": 0, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.135362", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:14:27.725127+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 0, "population_idx": 3, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:14:27.726102+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 1, "island_id": 0, "population_idx": 3, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:15:29.833020+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 0, "population_idx": 4, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.179640", "model_name": "gpt-oss:20b", "train_signal": 0.17963985594237694}}
{"timestamp": "2026-02-17T03:15:58.167688+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.132389", "model_name": "gpt-oss:20b", "train_signal": 0.13238895558223288}}
{"timestamp": "2026-02-17T03:16:19.626360+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 1, "population_idx": 1, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.159760", "model_name": "gpt-oss:20b", "train_signal": 0.15975990396158463}}
{"timestamp": "2026-02-17T03:16:37.541061+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 1, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:16:37.541499+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 1, "island_id": 1, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:18:06.943678+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i1_p2_230097150", "generation": 1, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.5104921968787515, "fitness_mode": "correlation", "simplicity_score": 0.1412324861085894, "novelty_bonus": 0.31376024857927143, "total_score": 0.35490138496582857, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degs = s['degrees']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort))\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.020216\nbelow_train_threshold: train_signal=0.132389\nbelow_train_threshold: train_signal=0.159760\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    import numpy as np\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – logarithmic degree scaling\n    degree_scaling = np.log(n + 1) * avg_deg / max(max_deg, 1)\n\n    # Component 3 – clustering dampening\n    clustering_damp = np.sqrt(n) / (1 + avg_cluster)\n\n    # Combine the components multiplicatively for a richer invariant\n    return size_edge_ratio * degree_scaling * clustering_damp\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "def new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree scaling (avoid external imports)\n    degree_scaling = (n + 1) ** 0.5 * avg_deg / (max_deg + 1)\n\n    # Component 3 – clustering dampening\n    clustering_damp = (n + 1) ** 0.5 / (1 + avg_cluster)\n\n    # Combine the components multiplicatively for a richer invariant\n    return size_edge_ratio * degree_scaling * clustering_damp", "extracted_code": "def new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree scaling (avoid external imports)\n    degree_scaling = (n + 1) ** 0.5 * avg_deg / (max_deg + 1)\n\n    # Component 3 – clustering dampening\n    clustering_damp = (n + 1) ** 0.5 / (1 + avg_cluster)\n\n    # Combine the components multiplicatively for a richer invariant\n    return size_edge_ratio * degree_scaling * clustering_damp", "spearman": 0.46505362634065855, "pearson": 0.28717980860862896, "rmse": 5.6579741940636525, "mae": 4.5793060389244}}
{"timestamp": "2026-02-17T03:18:06.944731+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 1, "island_id": 1, "population_idx": 2, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:18:50.245431+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i1_p3_588897071", "generation": 1, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.47447779111644656, "fitness_mode": "correlation", "simplicity_score": 0.126552291213293, "novelty_bonus": 0.2957274993584148, "total_score": 0.3963020148828539, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degs = s['degrees']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort))\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.132389\nbelow_train_threshold: train_signal=0.159760\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    # (n/(m+1))   : normalises by edge count\n    # (avg_deg/(max_deg+1)) : captures degree spread\n    # (1+avg_cluster) : accounts for local clustering\n    # (triangle_ratio+0.1) : adds global triangle density\n    # (1+abs(assort)) : incorporates assortativity\n    # (n**0.5) : scales with graph size\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort)) *\n        (n ** 0.5)\n    )\n```", "extracted_code": "def new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    # (n/(m+1))   : normalises by edge count\n    # (avg_deg/(max_deg+1)) : captures degree spread\n    # (1+avg_cluster) : accounts for local clustering\n    # (triangle_ratio+0.1) : adds global triangle density\n    # (1+abs(assort)) : incorporates assortativity\n    # (n**0.5) : scales with graph size\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort)) *\n        (n ** 0.5)\n    )", "spearman": 0.5645466136653416, "pearson": 0.5720693440294479, "rmse": 2.73224323647583, "mae": 2.587541917244336}}
{"timestamp": "2026-02-17T03:19:20.536639+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 1, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.088616", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:19:20.537245+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 1, "island_id": 1, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.088616", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:19:48.983088+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i1_p4_492743099", "generation": 1, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.46061480675052247, "fitness_mode": "correlation", "simplicity_score": 0.12801546686567425, "novelty_bonus": 0.15259108286932166, "total_score": 0.2657734492008395, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degs = s['degrees']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort))\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.132389\nbelow_train_threshold: train_signal=0.159760\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: novelty_bonus=0.088616\nPrevious candidate code:\n```python\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / (possible_triangles + 1)\n\n    # Combine multiple aspects into a single invariant\n    part1 = n / (m + 1)                     # size vs. connectivity\n    part2 = n ** 0.5 / (1 + avg_cluster)    # size vs. clustering\n    part3 = avg_deg / (max_deg + 1)          # average vs. maximum degree\n    part4 = 1 + abs(assort)                  # assortativity influence\n\n    return part1 * part2 * part3 * part4 * triangle_ratio\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / (possible_triangles + 1)\n\n    # Heterogeneity factor (captures degree spread)\n    hetero = 1 + std_deg / (max_deg + 1)\n\n    # Connectivity factor (larger for sparse graphs)\n    conn = n / (m + 1)\n\n    # Clustering factor (reduces value when clustering is high)\n    cluster_factor = 1 / (1 + avg_cluster)\n\n    # Transitivity factor (reduces value when transitivity is high)\n    trans_factor = 1 / (1 + trans)\n\n    # Assortativity factor (increases value when assortativity is strong)\n    assort_factor = 1 + abs(assort)\n\n    # Combine all components into a single invariant\n    return conn * cluster_factor * trans_factor * assort_factor * hetero * triangle_ratio\n```", "extracted_code": "def new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / (possible_triangles + 1)\n\n    # Heterogeneity factor (captures degree spread)\n    hetero = 1 + std_deg / (max_deg + 1)\n\n    # Connectivity factor (larger for sparse graphs)\n    conn = n / (m + 1)\n\n    # Clustering factor (reduces value when clustering is high)\n    cluster_factor = 1 / (1 + avg_cluster)\n\n    # Transitivity factor (reduces value when transitivity is high)\n    trans_factor = 1 / (1 + trans)\n\n    # Assortativity factor (increases value when assortativity is strong)\n    assort_factor = 1 + abs(assort)\n\n    # Combine all components into a single invariant\n    return conn * cluster_factor * trans_factor * assort_factor * hetero * triangle_ratio", "spearman": -0.3887860619338163, "pearson": -0.10136235364988885, "rmse": 2.911650283413921, "mae": 2.7633672387311843}}
{"timestamp": "2026-02-17T03:19:48.983534+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 1, "island_id": 1, "population_idx": 4, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:20:24.135731+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i2_p0_339636371", "generation": 1, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.5635054021608643, "fitness_mode": "correlation", "simplicity_score": 0.22801826355282728, "novelty_bonus": 0.1538948473711842, "total_score": 0.4614488488404687, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Heuristic estimate of the average shortest path length based on\n    pre‑computed structural features.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys:\n            n                     : number of nodes\n            m                     : number of edges\n            density               : edge density\n            avg_degree            : average node degree\n            transitivity          : global clustering coefficient\n            degree_assortativity  : degree assortativity coefficient\n            num_triangles         : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_d = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n\n    # Base estimate inversely related to average degree and density\n    base = n / (max(avg_d, 1.0) * max(density, 1e-6))\n\n    # Adjust for clustering: higher clustering tends to shorten paths\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity: negative assortativity can create hubs that shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, and degree assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features with keys:\n        - n (int): number of nodes\n        - avg_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s['n']\n    d = s['avg_degree']\n    c = s['avg_clustering']\n    t = s['transitivity']\n    a = s['degree_assortativity']\n\n    # Construct a positive denominator that incorporates several aspects\n    # of the graph.  Each term is designed to be small when the graph\n    # is well connected and large when the graph has sparse or highly\n    # clustered structure.\n    denom = np.log(d + 1) + (1 - c) + (1 - t) + (1 - a)\n\n    # Guard against numerical issues (unlikely but safe)\n    if denom <= 0:\n        denom = 1e-6\n\n    # Logarithm of the node count captures the overall scale of the\n    # network, while the denominator normalises for connectivity.\n    return np.log(n) / denom\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.124341\nbelow_novelty_threshold: novelty_bonus=0.018869\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is deliberately simple: it combines a\n    connectivity term (based on the edge count), a clustering adjustment,\n    an assortativity factor, and a triangle‑density correction, all scaled\n    by the maximum degree to keep the estimate in a reasonable range.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            avg_degree (float)\n            avg_clustering (float)\n            degree_assortativity (float)\n            num_triangles (int)\n            max_degree (int)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Connectivity term – more edges → shorter paths\n    base = n / (max(m, 1))\n\n    # Clustering tends to create shortcuts, so increase the estimate\n    base *= (1.0 + clust)\n\n    # Negative assortativity (hub‑rich networks) shortens paths; use abs\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment – more triangles → shorter paths\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by the maximum degree to keep the scale reasonable\n    base /= max(max_deg, 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is deliberately simple: it combines a\n    connectivity term (based on the edge count), a clustering adjustment,\n    an assortativity factor, and a triangle‑density correction, all scaled\n    by the maximum degree to keep the estimate in a reasonable range.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            avg_degree (float)\n            avg_clustering (float)\n            degree_assortativity (float)\n            num_triangles (int)\n            max_degree (int)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Connectivity term – more edges → shorter paths\n    base = n / (max(m, 1))\n\n    # Clustering tends to create shortcuts, so increase the estimate\n    base *= (1.0 + clust)\n\n    # Negative assortativity (hub‑rich networks) shortens paths; use abs\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment – more triangles → shorter paths\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by the maximum degree to keep the scale reasonable\n    base /= max(max_deg, 1)\n\n    return base", "spearman": 0.739353483837096, "pearson": 0.5231863694634629, "rmse": 2.829072591887465, "mae": 2.6888806435309687}}
{"timestamp": "2026-02-17T03:20:48.471262+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:20:48.472249+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 1, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:21:26.834690+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 2, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.040600", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:21:26.836001+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 1, "island_id": 2, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:22:21.366497+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i2_p2_753222903", "generation": 1, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8214645858343338, "fitness_mode": "correlation", "simplicity_score": 0.22261611918032703, "novelty_bonus": 0.20659254694291174, "total_score": 0.45371241820469604, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Heuristic estimate of the average shortest path length based on\n    pre‑computed structural features.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys:\n            n                     : number of nodes\n            m                     : number of edges\n            density               : edge density\n            avg_degree            : average node degree\n            transitivity          : global clustering coefficient\n            degree_assortativity  : degree assortativity coefficient\n            num_triangles         : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_d = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n\n    # Base estimate inversely related to average degree and density\n    base = n / (max(avg_d, 1.0) * max(density, 1e-6))\n\n    # Adjust for clustering: higher clustering tends to shorten paths\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity: negative assortativity can create hubs that shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, and degree assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features with keys:\n        - n (int): number of nodes\n        - avg_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s['n']\n    d = s['avg_degree']\n    c = s['avg_clustering']\n    t = s['transitivity']\n    a = s['degree_assortativity']\n\n    # Construct a positive denominator that incorporates several aspects\n    # of the graph.  Each term is designed to be small when the graph\n    # is well connected and large when the graph has sparse or highly\n    # clustered structure.\n    denom = np.log(d + 1) + (1 - c) + (1 - t) + (1 - a)\n\n    # Guard against numerical issues (unlikely but safe)\n    if denom <= 0:\n        denom = 1e-6\n\n    # Logarithm of the node count captures the overall scale of the\n    # network, while the denominator normalises for connectivity.\n    return np.log(n) / denom\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.018869\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.040600\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula is a weighted combination of several\n    structural features that influence path lengths:\n\n    - Size of the graph (n)\n    - Connectivity (average degree and edge density)\n    - Clustering (transitivity)\n    - Degree heterogeneity (std, min, max degrees)\n    - Degree assortativity\n    - Triangle density\n\n    The expression is intentionally simple and uses only built‑in\n    arithmetic operations, so no external libraries are required.\n    \"\"\"\n    # Basic graph metrics\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_d = s.get('avg_degree', 0.0)\n    std_d = s.get('std_degree', 0.0)\n    min_d = s.get('min_degree', 0.0)\n    max_d = s.get('max_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Guard against division by zero\n    avg_d = max(avg_d, 1.0)\n    density = max(density, 1e-6)\n\n    # Base estimate: size divided by connectivity\n    base = n / (avg_d * density)\n\n    # Adjust for clustering – higher clustering tends to shorten paths\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity – hubs (negative assortativity) shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Adjust for triangle density – more triangles reduce path lengths\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – high std means hubs, which shorten paths\n    if avg_d > 0:\n        base *= (1.0 + std_d / avg_d)\n\n    # Effect of maximum degree – a very high degree node can act as a hub\n    if avg_d > 0:\n        base *= (1.0 + max_d / avg_d)\n\n    # Effect of minimum degree – a very low min degree can increase distances\n    if avg_d > 0:\n        base /= (1.0 + min_d / avg_d)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula is a weighted combination of several\n    structural features that influence path lengths:\n\n    - Size of the graph (n)\n    - Connectivity (average degree and edge density)\n    - Clustering (transitivity)\n    - Degree heterogeneity (std, min, max degrees)\n    - Degree assortativity\n    - Triangle density\n\n    The expression is intentionally simple and uses only built‑in\n    arithmetic operations, so no external libraries are required.\n    \"\"\"\n    # Basic graph metrics\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_d = s.get('avg_degree', 0.0)\n    std_d = s.get('std_degree', 0.0)\n    min_d = s.get('min_degree', 0.0)\n    max_d = s.get('max_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Guard against division by zero\n    avg_d = max(avg_d, 1.0)\n    density = max(density, 1e-6)\n\n    # Base estimate: size divided by connectivity\n    base = n / (avg_d * density)\n\n    # Adjust for clustering – higher clustering tends to shorten paths\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity – hubs (negative assortativity) shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Adjust for triangle density – more triangles reduce path lengths\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – high std means hubs, which shorten paths\n    if avg_d > 0:\n        base *= (1.0 + std_d / avg_d)\n\n    # Effect of maximum degree – a very high degree node can act as a hub\n    if avg_d > 0:\n        base *= (1.0 + max_d / avg_d)\n\n    # Effect of minimum degree – a very low min degree can increase distances\n    if avg_d > 0:\n        base /= (1.0 + min_d / avg_d)\n\n    return base", "spearman": 0.6944228605715143, "pearson": 0.38567303337550485, "rmse": 7338.979021636019, "mae": 2119.0816775792755}}
{"timestamp": "2026-02-17T03:23:10.826171+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.101273", "model_name": "gpt-oss:20b", "train_signal": 0.10127250900360144}}
{"timestamp": "2026-02-17T03:23:50.504116+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.113372", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:23:50.504252+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 1, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.113372", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:24:27.462717+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 2, "population_idx": 4, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.112202", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:24:27.463487+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 1, "island_id": 2, "population_idx": 4, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:25:00.752833+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i3_p0_509867362", "generation": 1, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.3342617046818727, "fitness_mode": "correlation", "simplicity_score": 0.14283043671265785, "novelty_bonus": 0.16544172280846436, "total_score": 0.2723004567313846, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features\n    without accessing any external libraries.  The expression mixes\n    density, clustering, assortativity, degree dispersion and the\n    triangle density in a way that has not appeared before in\n    conventional estimators.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed features.  Keys used:\n        n, m, density, avg_clustering, degree_assortativity,\n        max_degree, std_degree, num_triangles.\n\n    Returns\n    -------\n    float\n        A scalar value that is intended to correlate with the true\n        average shortest‑path length of the graph.\n    \"\"\"\n    eps = 1e-12\n\n    n = s['n']\n    m = s['m']\n    dens = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    num_tri = s['num_triangles']\n\n    # Triangle density (fraction of possible triangles that actually exist)\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # A simple monotonic transform of the triangle fraction\n    tri_transform = tri_frac / (1.0 - tri_frac + eps)\n\n    # Degree dispersion normalised by the maximum degree\n    deg_disp = std_deg / (max_deg + eps)\n\n    # Core multiplicative term combining structural features\n    part1 = n / (m + 1.0)\n    part2 = 1.0 + dens\n    part3 = 1.0 - clustering\n    part4 = 1.0 - assort\n\n    return part1 * part2 * part3 * part4 + deg_disp * tri_transform\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.139174\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.237551\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Novel estimator of the average shortest‑path length that combines\n    density, clustering, assortativity, degree dispersion, and triangle\n    density.  The formula is intentionally constructed to avoid any\n    graph traversal or library calls and to provide a nonlinear\n    coupling of several structural descriptors.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features.  Expected keys:\n\n        - n (int): number of nodes\n        - m (int): number of edges\n        - density (float)\n        - avg_degree (float)\n        - max_degree (int)\n        - min_degree (int)\n        - std_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n        - num_triangles (int)\n        - degrees (list of int): sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar estimate that tends to grow with the true average\n        shortest‑path length.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # Basic numeric stability\n    # ------------------------------------------------------------------\n    eps = 1e-12\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    clustering = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    # ------------------------------------------------------------------\n    # Triangle density (fraction of possible triangles that actually exist)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ------------------------------------------------------------------\n    # Degree‑based dispersion term (scaled by maximum degree)\n    # ------------------------------------------------------------------\n    deg_disp = std_deg / (max_deg + eps)\n\n    # ------------------------------------------------------------------\n    # Core multiplicative factor capturing global connectivity\n    # ------------------------------------------------------------------\n    #   1. n / (m + 1)    : inversely related to average degree\n    #   2. 1 + density    : higher density reduces path lengths\n    #   3. 1 - clustering : more clustering often shortens paths\n    #   4. 1 - assort      : disassortative networks typically have shorter paths\n    #\n    # Each component is wrapped in (1 + |x|) to ensure monotonicity and\n    # to avoid large cancellations.\n    # ------------------------------------------------------------------\n    part1 = n / (m + 1.0)\n    part2 = 1.0 + density\n    part3 = 1.0 - clustering\n    part4 = 1.0 - assort\n\n    core = part1 * part2 * part3 * part4\n\n    # ------------------------------------------------------------------\n    # Secondary adjustment capturing local triangle concentration\n    # ------------------------------------------------------------------\n    tri_adjust = tri_frac / (1.0 - tri_frac + eps)\n\n    # ------------------------------------------------------------------\n    # Final estimator: additive combination of global core and\n    # local triangle adjustment weighted by degree dispersion.\n    # ------------------------------------------------------------------\n    return core + deg_disp * tri_adjust\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Novel estimator of the average shortest‑path length that combines\n    density, clustering, assortativity, degree dispersion, and triangle\n    density.  The formula is intentionally constructed to avoid any\n    graph traversal or library calls and to provide a nonlinear\n    coupling of several structural descriptors.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features.  Expected keys:\n\n        - n (int): number of nodes\n        - m (int): number of edges\n        - density (float)\n        - avg_degree (float)\n        - max_degree (int)\n        - min_degree (int)\n        - std_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n        - num_triangles (int)\n        - degrees (list of int): sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar estimate that tends to grow with the true average\n        shortest‑path length.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # Basic numeric stability\n    # ------------------------------------------------------------------\n    eps = 1e-12\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    clustering = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    # ------------------------------------------------------------------\n    # Triangle density (fraction of possible triangles that actually exist)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ------------------------------------------------------------------\n    # Degree‑based dispersion term (scaled by maximum degree)\n    # ------------------------------------------------------------------\n    deg_disp = std_deg / (max_deg + eps)\n\n    # ------------------------------------------------------------------\n    # Core multiplicative factor capturing global connectivity\n    # ------------------------------------------------------------------\n    #   1. n / (m + 1)    : inversely related to average degree\n    #   2. 1 + density    : higher density reduces path lengths\n    #   3. 1 - clustering : more clustering often shortens paths\n    #   4. 1 - assort      : disassortative networks typically have shorter paths\n    #\n    # Each component is wrapped in (1 + |x|) to ensure monotonicity and\n    # to avoid large cancellations.\n    # ------------------------------------------------------------------\n    part1 = n / (m + 1.0)\n    part2 = 1.0 + density\n    part3 = 1.0 - clustering\n    part4 = 1.0 - assort\n\n    core = part1 * part2 * part3 * part4\n\n    # ------------------------------------------------------------------\n    # Secondary adjustment capturing local triangle concentration\n    # ------------------------------------------------------------------\n    tri_adjust = tri_frac / (1.0 - tri_frac + eps)\n\n    # ------------------------------------------------------------------\n    # Final estimator: additive combination of global core and\n    # local triangle adjustment weighted by degree dispersion.\n    # ------------------------------------------------------------------\n    return core + deg_disp * tri_adjust", "spearman": 0.3882037050926274, "pearson": 0.32679913269314603, "rmse": 2.5684435810070574, "mae": 2.417714328925085}}
{"timestamp": "2026-02-17T03:25:43.883488+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i3_p1_704232425", "generation": 1, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.3342617046818727, "fitness_mode": "correlation", "simplicity_score": 0.1403773976088029, "novelty_bonus": 0.16544172280846436, "total_score": 0.2718098489106136, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features\n    without accessing any external libraries.  The expression mixes\n    density, clustering, assortativity, degree dispersion and the\n    triangle density in a way that has not appeared before in\n    conventional estimators.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed features.  Keys used:\n        n, m, density, avg_clustering, degree_assortativity,\n        max_degree, std_degree, num_triangles.\n\n    Returns\n    -------\n    float\n        A scalar value that is intended to correlate with the true\n        average shortest‑path length of the graph.\n    \"\"\"\n    eps = 1e-12\n\n    n = s['n']\n    m = s['m']\n    dens = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    num_tri = s['num_triangles']\n\n    # Triangle density (fraction of possible triangles that actually exist)\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # A simple monotonic transform of the triangle fraction\n    tri_transform = tri_frac / (1.0 - tri_frac + eps)\n\n    # Degree dispersion normalised by the maximum degree\n    deg_disp = std_deg / (max_deg + eps)\n\n    # Core multiplicative term combining structural features\n    part1 = n / (m + 1.0)\n    part2 = 1.0 + dens\n    part3 = 1.0 - clustering\n    part4 = 1.0 - assort\n\n    return part1 * part2 * part3 * part4 + deg_disp * tri_transform\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.139174\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.237551\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a novel combination of\n    structural graph features. The formula blends:\n    - Inverse density effect: n / (m + 1)\n    - Density amplification: 1 + density\n    - Clustering suppression: 1 - avg_clustering\n    - Assortativity damping: 1 - degree_assortativity\n    - Triangle‐based nonlinearity: triangle density/(1‑triangle density)\n    - Degree dispersion weighting: std_degree / max_degree\n    All calculations avoid any external imports and use only built‑in\n    arithmetic operations.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features. Required keys:\n        'n', 'm', 'density', 'avg_clustering',\n        'degree_assortativity', 'max_degree', 'std_degree',\n        'num_triangles'.\n\n    Returns\n    -------\n    float\n        Scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12\n\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assortativity = s['degree_assortativity']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    num_triangles = s['num_triangles']\n\n    # Triangle density fraction (bounded between 0 and 1)\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_triangles / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # Transform triangle fraction into a monotonic scale\n    tri_transform = tri_frac / (1.0 - tri_frac + eps)\n\n    # Normalize degree dispersion\n    deg_disp = std_deg / (max_deg + eps)\n\n    # Core multiplicative term capturing global connectivity\n    base_term = (n / (m + 1.0)) * (1.0 + density) * (1.0 - clustering) * (1.0 - assortativity)\n\n    # Final estimate combining core term with triangle and degree dispersion effects\n    return base_term + deg_disp * tri_transform\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a novel combination of\n    structural graph features. The formula blends:\n    - Inverse density effect: n / (m + 1)\n    - Density amplification: 1 + density\n    - Clustering suppression: 1 - avg_clustering\n    - Assortativity damping: 1 - degree_assortativity\n    - Triangle‐based nonlinearity: triangle density/(1‑triangle density)\n    - Degree dispersion weighting: std_degree / max_degree\n    All calculations avoid any external imports and use only built‑in\n    arithmetic operations.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features. Required keys:\n        'n', 'm', 'density', 'avg_clustering',\n        'degree_assortativity', 'max_degree', 'std_degree',\n        'num_triangles'.\n\n    Returns\n    -------\n    float\n        Scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12\n\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assortativity = s['degree_assortativity']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    num_triangles = s['num_triangles']\n\n    # Triangle density fraction (bounded between 0 and 1)\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_triangles / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # Transform triangle fraction into a monotonic scale\n    tri_transform = tri_frac / (1.0 - tri_frac + eps)\n\n    # Normalize degree dispersion\n    deg_disp = std_deg / (max_deg + eps)\n\n    # Core multiplicative term capturing global connectivity\n    base_term = (n / (m + 1.0)) * (1.0 + density) * (1.0 - clustering) * (1.0 - assortativity)\n\n    # Final estimate combining core term with triangle and degree dispersion effects\n    return base_term + deg_disp * tri_transform", "spearman": 0.3882037050926274, "pearson": 0.32679913269314603, "rmse": 2.5684435810070574, "mae": 2.417714328925085}}
{"timestamp": "2026-02-17T03:26:14.045047+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g1_i3_p2_117411836", "generation": 1, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.38641056422569026, "fitness_mode": "correlation", "simplicity_score": 0.1711411006832482, "novelty_bonus": 0.15844776604091548, "total_score": 0.3300007559040732, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph features\n    without accessing any external libraries.  The expression mixes\n    density, clustering, assortativity, degree dispersion and the\n    triangle density in a way that has not appeared before in\n    conventional estimators.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed features.  Keys used:\n        n, m, density, avg_clustering, degree_assortativity,\n        max_degree, std_degree, num_triangles.\n\n    Returns\n    -------\n    float\n        A scalar value that is intended to correlate with the true\n        average shortest‑path length of the graph.\n    \"\"\"\n    eps = 1e-12\n\n    n = s['n']\n    m = s['m']\n    dens = s['density']\n    clustering = s['avg_clustering']\n    assort = s['degree_assortativity']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    num_tri = s['num_triangles']\n\n    # Triangle density (fraction of possible triangles that actually exist)\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # A simple monotonic transform of the triangle fraction\n    tri_transform = tri_frac / (1.0 - tri_frac + eps)\n\n    # Degree dispersion normalised by the maximum degree\n    deg_disp = std_deg / (max_deg + eps)\n\n    # Core multiplicative term combining structural features\n    part1 = n / (m + 1.0)\n    part2 = 1.0 + dens\n    part3 = 1.0 - clustering\n    part4 = 1.0 - assort\n\n    return part1 * part2 * part3 * part4 + deg_disp * tri_transform\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.139174\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.237551\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a mixture of global\n    graph characteristics that have never been combined in the same way.\n    The function only operates on pre‑computed features supplied in *s*.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degs = s['degrees']\n\n    # Triangle fraction, safely handled for very small graphs\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri if possible_tri else 1.0)\n    else:\n        tri_frac = 0.0\n\n    # Mean of squared degrees\n    avg_deg_sq = sum(d * d for d in degs) / n if n else 0.0\n\n    # Core multiplicative component that balances size, density, clustering,\n    # triangle richness, and assortativity in a non‑linear fashion\n    part = (n / (m + 1.0) ** 0.3)          # larger graphs grow slowly\n    part *= (1.0 + density) ** 0.5          # denser graphs shrink distance\n    part *= (1.0 + tri_frac) ** 0.5         # richer triangles imply shorter paths\n    part *= (1.0 - avg_clust) ** 0.5        # high clustering tends to elongate paths\n    part *= (1.0 - assort) ** 0.2           # disassortativity can reduce distances\n\n    # Additive correction driven by degree dispersion and degree heterogeneity\n    add = std_deg * avg_deg_sq / (max_deg + 1.0)\n\n    return part + add\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a mixture of global\n    graph characteristics that have never been combined in the same way.\n    The function only operates on pre‑computed features supplied in *s*.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degs = s['degrees']\n\n    # Triangle fraction, safely handled for very small graphs\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri if possible_tri else 1.0)\n    else:\n        tri_frac = 0.0\n\n    # Mean of squared degrees\n    avg_deg_sq = sum(d * d for d in degs) / n if n else 0.0\n\n    # Core multiplicative component that balances size, density, clustering,\n    # triangle richness, and assortativity in a non‑linear fashion\n    part = (n / (m + 1.0) ** 0.3)          # larger graphs grow slowly\n    part *= (1.0 + density) ** 0.5          # denser graphs shrink distance\n    part *= (1.0 + tri_frac) ** 0.5         # richer triangles imply shorter paths\n    part *= (1.0 - avg_clust) ** 0.5        # high clustering tends to elongate paths\n    part *= (1.0 - assort) ** 0.2           # disassortativity can reduce distances\n\n    # Additive correction driven by degree dispersion and degree heterogeneity\n    add = std_deg * avg_deg_sq / (max_deg + 1.0)\n\n    return part + add", "spearman": -0.49647641191029784, "pearson": -0.27413583230658795, "rmse": 38.217969936400735, "mae": 24.278399335635804}}
{"timestamp": "2026-02-17T03:26:50.082710+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.100830", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:26:50.082989+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 1, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.100830", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:27:29.812963+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 3, "population_idx": 3, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.173878", "model_name": "gpt-oss:20b", "train_signal": 0.17387755102040817}}
{"timestamp": "2026-02-17T03:27:29.813593+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 1, "island_id": 3, "population_idx": 3, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:28:01.958382+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:28:01.959137+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 1, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:28:37.535505+00:00", "event_type": "candidate_rejected", "payload": {"generation": 1, "island_id": 3, "population_idx": 4, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.000000", "model_name": "gpt-oss:20b", "train_signal": 0.0}}
{"timestamp": "2026-02-17T03:28:37.535989+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 1, "island_id": 3, "population_idx": 4, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:28:37.537857+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 2, "model_name": "gpt-oss:20b", "best_val_score": 0.47433723571282804, "no_improve_count": 1}}
{"timestamp": "2026-02-17T03:31:38.449739+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 0, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.131807", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:31:38.450551+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 2, "island_id": 0, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.131807", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:32:06.112974+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 0, "population_idx": 0, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:32:06.113450+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 2, "island_id": 0, "population_idx": 0, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:33:10.213286+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.126396", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:33:10.213929+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 2, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.126396", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:33:38.073128+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 0, "population_idx": 1, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:33:38.073927+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 2, "island_id": 0, "population_idx": 1, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:36:18.628860+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.147171", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:36:18.629578+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 2, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.147171", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:37:01.006023+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i0_p2_947085989", "generation": 2, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6083553421368547, "fitness_mode": "correlation", "simplicity_score": 0.22156029980918096, "novelty_bonus": 0.20821575173885343, "total_score": 0.38223692198690484, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n\n    # approximate logarithms using string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # adjust for density: denser graphs have shorter paths\n    base *= (1 - density) + 0.5  # scales between 0.5 and 1.5\n\n    # adjust for clustering: higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # adjust for degree variance: high variance can increase path length\n    if max_deg > 0:\n        base *= 1 + std_deg / max_deg\n\n    # adjust for triangles: more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.15\n\n    # adjust for assortativity: positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.1\n\n    return base\n\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_degree = s['avg_degree']\n    max_degree = s['max_degree']\n    min_degree = s['min_degree']\n    std_degree = s['std_degree']\n    avg_clustering = s['avg_clustering']\n    transitivity = s['transitivity']\n    degree_assortativity = s['degree_assortativity']\n    num_triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Approximate logarithms by string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(avg_degree)) if avg_degree > 0 else 1\n\n    # Base estimate: log(n) / log(avg_degree)\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for graph density – denser graphs have shorter paths\n    base *= (1 - density) + 0.5\n\n    # Adjust for clustering – higher clustering slightly inflates path length\n    base *= (1 + avg_clustering)\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_degree > 0:\n        base *= (1 + std_degree / max_degree)\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_triangles / n)\n\n    # Optional: incorporate degree assortativity (absolute value to keep factor positive)\n    base *= (1 + abs(degree_assortativity))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.131807\nbelow_novelty_threshold: novelty_bonus=0.126396\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: novelty_bonus=0.147171\nPrevious candidate code:\n```python\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n\n    # Rough logarithm approximations (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) + 0.5\n\n    # Adjust for clustering and transitivity – higher values tend to reduce path length\n    base *= (1 + avg_clust) ** -0.25\n    base *= (1 + trans) ** -0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_deg > 0:\n        base *= 1 + std_deg / max_deg\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.15\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.1\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= 1 + (1 / min_deg)\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n\n    # Rough logarithm approximations (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering and transitivity – higher values tend to reduce path length\n    base *= (1 + avg_clust + trans) ** -0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n\n    # Rough logarithm approximations (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering and transitivity – higher values tend to reduce path length\n    base *= (1 + avg_clust + trans) ** -0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    return base", "spearman": 0.5509202730068252, "pearson": 0.3669326351385293, "rmse": 1.578225831439785, "mae": 1.3246333135910917}}
{"timestamp": "2026-02-17T03:37:01.006638+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 2, "island_id": 0, "population_idx": 2, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:37:48.764234+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 0, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.122351", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:37:48.764873+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 2, "island_id": 0, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.122351", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:38:18.556249+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 0, "population_idx": 3, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.130352", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:38:18.556779+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 2, "island_id": 0, "population_idx": 3, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:39:00.270635+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 0, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:39:00.271142+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 2, "island_id": 0, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:39:53.474438+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i0_p4_781812457", "generation": 2, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5810804321728692, "fitness_mode": "correlation", "simplicity_score": 0.22413502645053612, "novelty_bonus": 0.19032093506039016, "total_score": 0.36705791417393346, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n\n    # approximate logarithms using string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # adjust for density: denser graphs have shorter paths\n    base *= (1 - density) + 0.5  # scales between 0.5 and 1.5\n\n    # adjust for clustering: higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # adjust for degree variance: high variance can increase path length\n    if max_deg > 0:\n        base *= 1 + std_deg / max_deg\n\n    # adjust for triangles: more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.15\n\n    # adjust for assortativity: positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.1\n\n    return base\n\ndef new_invariant(s):\n    # Extract features\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_degree = s['avg_degree']\n    max_degree = s['max_degree']\n    min_degree = s['min_degree']\n    std_degree = s['std_degree']\n    avg_clustering = s['avg_clustering']\n    transitivity = s['transitivity']\n    degree_assortativity = s['degree_assortativity']\n    num_triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Approximate logarithms by string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(avg_degree)) if avg_degree > 0 else 1\n\n    # Base estimate: log(n) / log(avg_degree)\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for graph density – denser graphs have shorter paths\n    base *= (1 - density) + 0.5\n\n    # Adjust for clustering – higher clustering slightly inflates path length\n    base *= (1 + avg_clustering)\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_degree > 0:\n        base *= (1 + std_degree / max_degree)\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_triangles / n)\n\n    # Optional: incorporate degree assortativity (absolute value to keep factor positive)\n    base *= (1 + abs(degree_assortativity))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147171\nbelow_novelty_threshold: novelty_bonus=0.122351\nbelow_novelty_threshold: novelty_bonus=0.130352\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    import math\n\n    # Basic graph statistics\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    clustering = s['avg_clustering']\n    std_deg    = s['std_degree']\n    max_deg    = s['max_degree']\n    num_tri    = s['num_triangles']\n    assort     = s['degree_assortativity']\n\n    # Logarithmic terms (use natural log for simplicity)\n    log_n       = math.log(n) if n > 0 else 0.0\n    log_avg_deg = math.log(avg_deg) if avg_deg > 0 else 1.0\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1.0)\n\n    # Adjust for graph density – denser graphs tend to have shorter paths\n    # The factor is bounded roughly between 0.7 and 1.0 for 0 ≤ density ≤ 1\n    base *= (1.0 - density)**0.3 + 0.7\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1.0 + clustering)**-0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_deg > 0:\n        base *= (1.0 + std_deg / max_deg)**0.15\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1.0 + num_tri / n)**-0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1.0 + abs(assort))**0.05\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n\n    # Guard against empty graphs\n    if n <= 0:\n        return 0.0\n\n    # Approximate logarithms using string lengths (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for graph density – denser graphs tend to have shorter paths\n    base *= (1.0 - density)**0.3 + 0.7\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1.0 + clustering)**-0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_deg > 0:\n        base *= (1.0 + std_deg / max_deg)**0.15\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1.0 + num_tri / n)**-0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1.0 + abs(assort))**0.05\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n\n    # Guard against empty graphs\n    if n <= 0:\n        return 0.0\n\n    # Approximate logarithms using string lengths (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for graph density – denser graphs tend to have shorter paths\n    base *= (1.0 - density)**0.3 + 0.7\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1.0 + clustering)**-0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_deg > 0:\n        base *= (1.0 + std_deg / max_deg)**0.15\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1.0 + num_tri / n)**-0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1.0 + abs(assort))**0.05\n\n    return base", "spearman": 0.5302692567314183, "pearson": 0.35604227729798255, "rmse": 0.9653735557847515, "mae": 0.7419849222751245}}
{"timestamp": "2026-02-17T03:39:53.475227+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 2, "island_id": 0, "population_idx": 4, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:40:16.671081+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.067081", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:40:16.671737+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 2, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.067081", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:41:43.021369+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 1, "population_idx": 0, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.020941", "model_name": "gpt-oss:20b", "train_signal": 0.02094140310148361}}
{"timestamp": "2026-02-17T03:41:43.022315+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 2, "island_id": 1, "population_idx": 0, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:42:11.534411+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 1, "population_idx": 1, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.149772", "model_name": "gpt-oss:20b", "train_signal": 0.1497719087635054}}
{"timestamp": "2026-02-17T03:42:44.583345+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i1_p2_67785276", "generation": 2, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224735024490937, "novelty_bonus": 0.185688142203555, "total_score": 0.4606234037073992, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    # (n/(m+1))   : normalises by edge count\n    # (avg_deg/(max_deg+1)) : captures degree spread\n    # (1+avg_cluster) : accounts for local clustering\n    # (triangle_ratio+0.1) : adds global triangle density\n    # (1+abs(assort)) : incorporates assortativity\n    # (n**0.5) : scales with graph size\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort)) *\n        (n ** 0.5)\n    )\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree scaling (avoid external imports)\n    degree_scaling = (n + 1) ** 0.5 * avg_deg / (max_deg + 1)\n\n    # Component 3 – clustering dampening\n    clustering_damp = (n + 1) ** 0.5 / (1 + avg_cluster)\n\n    # Combine the components multiplicatively for a richer invariant\n    return size_edge_ratio * degree_scaling * clustering_damp\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degs = s['degrees']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort))\n    )\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.067081\nbelow_train_threshold: train_signal=0.020941\nbelow_train_threshold: train_signal=0.149772\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T03:43:36.758051+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 1, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:43:36.759967+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 2, "island_id": 1, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:43:51.788698+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 1, "population_idx": 3, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.152461", "model_name": "gpt-oss:20b", "train_signal": 0.1524609843937575}}
{"timestamp": "2026-02-17T03:43:51.789214+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 2, "island_id": 1, "population_idx": 3, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:44:18.889025+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i1_p4_491095216", "generation": 2, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6650180072028812, "fitness_mode": "correlation", "simplicity_score": 0.1261696684279261, "novelty_bonus": 0.29650073295103696, "total_score": 0.4264387099348054, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    # (n/(m+1))   : normalises by edge count\n    # (avg_deg/(max_deg+1)) : captures degree spread\n    # (1+avg_cluster) : accounts for local clustering\n    # (triangle_ratio+0.1) : adds global triangle density\n    # (1+abs(assort)) : incorporates assortativity\n    # (n**0.5) : scales with graph size\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort)) *\n        (n ** 0.5)\n    )\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree scaling (avoid external imports)\n    degree_scaling = (n + 1) ** 0.5 * avg_deg / (max_deg + 1)\n\n    # Component 3 – clustering dampening\n    clustering_damp = (n + 1) ** 0.5 / (1 + avg_cluster)\n\n    # Combine the components multiplicatively for a richer invariant\n    return size_edge_ratio * degree_scaling * clustering_damp\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degs = s['degrees']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort))\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.149772\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.152461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree scaling (avoid external imports)\n    degree_scaling = (n + 1) ** 0.5 * avg_deg / (max_deg + 1)\n\n    # Component 3 – clustering dampening\n    clustering_damp = (n + 1) ** 0.5 / (1 + avg_cluster)\n\n    # Combine the components multiplicatively for a richer invariant\n    return (\n        size_edge_ratio *\n        degree_scaling *\n        clustering_damp *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort))\n    )\n```", "extracted_code": "def new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree scaling (avoid external imports)\n    degree_scaling = (n + 1) ** 0.5 * avg_deg / (max_deg + 1)\n\n    # Component 3 – clustering dampening\n    clustering_damp = (n + 1) ** 0.5 / (1 + avg_cluster)\n\n    # Combine the components multiplicatively for a richer invariant\n    return (\n        size_edge_ratio *\n        degree_scaling *\n        clustering_damp *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort))\n    )", "spearman": 0.6245091127278182, "pearson": 0.45470884384152466, "rmse": 2.060162598455069, "mae": 1.8903021884252933}}
{"timestamp": "2026-02-17T03:44:52.061672+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:44:52.062692+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 2, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:45:19.662981+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i2_p0_355049613", "generation": 2, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.5014645858343336, "fitness_mode": "correlation", "simplicity_score": 0.17274320141874255, "novelty_bonus": 0.2679183297202935, "total_score": 0.43764745728278864, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Heuristic estimate of the average shortest path length based on\n    pre‑computed structural features.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys:\n            n                     : number of nodes\n            m                     : number of edges\n            density               : edge density\n            avg_degree            : average node degree\n            transitivity          : global clustering coefficient\n            degree_assortativity  : degree assortativity coefficient\n            num_triangles         : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_d = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n\n    # Base estimate inversely related to average degree and density\n    base = n / (max(avg_d, 1.0) * max(density, 1e-6))\n\n    # Adjust for clustering: higher clustering tends to shorten paths\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity: negative assortativity can create hubs that shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, and degree assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features with keys:\n        - n (int): number of nodes\n        - avg_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s['n']\n    d = s['avg_degree']\n    c = s['avg_clustering']\n    t = s['transitivity']\n    a = s['degree_assortativity']\n\n    # Construct a positive denominator that incorporates several aspects\n    # of the graph.  Each term is designed to be small when the graph\n    # is well connected and large when the graph has sparse or highly\n    # clustered structure.\n    denom = np.log(d + 1) + (1 - c) + (1 - t) + (1 - a)\n\n    # Guard against numerical issues (unlikely but safe)\n    if denom <= 0:\n        denom = 1e-6\n\n    # Logarithm of the node count captures the overall scale of the\n    # network, while the denominator normalises for connectivity.\n    return np.log(n) / denom\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is deliberately simple: it combines a\n    connectivity term (based on the edge count), a clustering adjustment,\n    an assortativity factor, and a triangle‑density correction, all scaled\n    by the maximum degree to keep the estimate in a reasonable range.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            avg_degree (float)\n            avg_clustering (float)\n            degree_assortativity (float)\n            num_triangles (int)\n            max_degree (int)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Connectivity term – more edges → shorter paths\n    base = n / (max(m, 1))\n\n    # Clustering tends to create shortcuts, so increase the estimate\n    base *= (1.0 + clust)\n\n    # Negative assortativity (hub‑rich networks) shortens paths; use abs\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment – more triangles → shorter paths\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by the maximum degree to keep the scale reasonable\n    base /= max(max_deg, 1)\n\n    return base\nRecent failures:\nbelow_train_threshold: train_signal=0.101273\nbelow_novelty_threshold: novelty_bonus=0.113372\nbelow_novelty_threshold: novelty_bonus=0.112202\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport numpy as np\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula is a compact weighted product of several\n    connectivity and structural indicators, with a final logarithmic\n    scaling that captures the overall size of the network.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features.  Expected keys:\n        - n, m\n        - avg_degree, std_degree, max_degree\n        - avg_clustering, transitivity\n        - degree_assortativity\n        - num_triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic connectivity term – more edges → shorter paths\n    base = s['n'] / max(s['m'], 1)\n\n    # Clustering tends to provide local shortcuts\n    base *= (1.0 + s['avg_clustering'])\n\n    # Transitivity (global clustering) also shortens paths\n    base *= (1.0 + s['transitivity'])\n\n    # Degree assortativity: negative assortativity (hub‑rich) shortens paths\n    base *= (1.0 + abs(s['degree_assortativity']))\n\n    # Triangle density adjustment – more triangles → shorter paths\n    if s['m'] > 0:\n        base *= (1.0 + s['num_triangles'] / s['m'])\n\n    # Degree variance: a high variance (hub‑rich network) typically reduces\n    # the average path length, so we dampen the estimate accordingly.\n    if s['avg_degree'] > 0:\n        base /= (1.0 + s['std_degree'] / s['avg_degree'])\n\n    # Normalise by the maximum degree to keep the scale reasonable\n    base /= max(s['max_degree'], 1)\n\n    # Final scaling by the logarithm of the node count captures the\n    # overall network size while preserving the influence of the other\n    # structural factors.\n    base *= np.log(max(s['n'], 2))\n\n    return float(base)\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula combines connectivity, clustering, assortativity,\n    triangle density, degree variance, and a size scaling term.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n\n    # Basic connectivity term – more edges → shorter paths\n    base = n / max(m, 1)\n\n    # Clustering tends to provide local shortcuts\n    base *= (1.0 + s['avg_clustering'])\n\n    # Transitivity (global clustering) also shortens paths\n    base *= (1.0 + s['transitivity'])\n\n    # Degree assortativity: negative assortativity (hub‑rich) shortens paths\n    base *= (1.0 + abs(s['degree_assortativity']))\n\n    # Triangle density adjustment – more triangles → shorter paths\n    if m > 0:\n        base *= (1.0 + s['num_triangles'] / m)\n\n    # Degree variance: a high variance (hub‑rich network) typically reduces\n    # the average path length, so we dampen the estimate accordingly.\n    if s['avg_degree'] > 0:\n        base /= (1.0 + s['std_degree'] / s['avg_degree'])\n\n    # Normalise by the maximum degree to keep the scale reasonable\n    base /= max(s['max_degree'], 1)\n\n    # Size scaling: multiply by the square root of the node count\n    base *= n ** 0.5\n\n    return float(base)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula combines connectivity, clustering, assortativity,\n    triangle density, degree variance, and a size scaling term.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n\n    # Basic connectivity term – more edges → shorter paths\n    base = n / max(m, 1)\n\n    # Clustering tends to provide local shortcuts\n    base *= (1.0 + s['avg_clustering'])\n\n    # Transitivity (global clustering) also shortens paths\n    base *= (1.0 + s['transitivity'])\n\n    # Degree assortativity: negative assortativity (hub‑rich) shortens paths\n    base *= (1.0 + abs(s['degree_assortativity']))\n\n    # Triangle density adjustment – more triangles → shorter paths\n    if m > 0:\n        base *= (1.0 + s['num_triangles'] / m)\n\n    # Degree variance: a high variance (hub‑rich network) typically reduces\n    # the average path length, so we dampen the estimate accordingly.\n    if s['avg_degree'] > 0:\n        base /= (1.0 + s['std_degree'] / s['avg_degree'])\n\n    # Normalise by the maximum degree to keep the scale reasonable\n    base /= max(s['max_degree'], 1)\n\n    # Size scaling: multiply by the square root of the node count\n    base *= n ** 0.5\n\n    return float(base)", "spearman": 0.6454466361659043, "pearson": 0.6603742267177637, "rmse": 2.3717772956606025, "mae": 2.262978237776285}}
{"timestamp": "2026-02-17T03:45:19.663608+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 2, "island_id": 2, "population_idx": 0, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:46:05.434998+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i2_p1_398795410", "generation": 2, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.47985594237695073, "fitness_mode": "correlation", "simplicity_score": 0.22470692676220022, "novelty_bonus": 0.24399309982749562, "total_score": 0.4486703285760206, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Heuristic estimate of the average shortest path length based on\n    pre‑computed structural features.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys:\n            n                     : number of nodes\n            m                     : number of edges\n            density               : edge density\n            avg_degree            : average node degree\n            transitivity          : global clustering coefficient\n            degree_assortativity  : degree assortativity coefficient\n            num_triangles         : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_d = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n\n    # Base estimate inversely related to average degree and density\n    base = n / (max(avg_d, 1.0) * max(density, 1e-6))\n\n    # Adjust for clustering: higher clustering tends to shorten paths\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity: negative assortativity can create hubs that shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, and degree assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features with keys:\n        - n (int): number of nodes\n        - avg_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s['n']\n    d = s['avg_degree']\n    c = s['avg_clustering']\n    t = s['transitivity']\n    a = s['degree_assortativity']\n\n    # Construct a positive denominator that incorporates several aspects\n    # of the graph.  Each term is designed to be small when the graph\n    # is well connected and large when the graph has sparse or highly\n    # clustered structure.\n    denom = np.log(d + 1) + (1 - c) + (1 - t) + (1 - a)\n\n    # Guard against numerical issues (unlikely but safe)\n    if denom <= 0:\n        denom = 1e-6\n\n    # Logarithm of the node count captures the overall scale of the\n    # network, while the denominator normalises for connectivity.\n    return np.log(n) / denom\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is deliberately simple: it combines a\n    connectivity term (based on the edge count), a clustering adjustment,\n    an assortativity factor, and a triangle‑density correction, all scaled\n    by the maximum degree to keep the estimate in a reasonable range.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            avg_degree (float)\n            avg_clustering (float)\n            degree_assortativity (float)\n            num_triangles (int)\n            max_degree (int)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Connectivity term – more edges → shorter paths\n    base = n / (max(m, 1))\n\n    # Clustering tends to create shortcuts, so increase the estimate\n    base *= (1.0 + clust)\n\n    # Negative assortativity (hub‑rich networks) shortens paths; use abs\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment – more triangles → shorter paths\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by the maximum degree to keep the scale reasonable\n    base /= max(max_deg, 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.113372\nbelow_novelty_threshold: novelty_bonus=0.112202\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary containing at least the following keys:\n        - n (int): number of nodes\n        - m (int): number of edges\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n        - num_triangles (int)\n        - max_degree (int)\n        - min_degree (int)\n        - std_degree (float)\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n\n    # Base inversely proportional to edge count (more edges → shorter paths)\n    base = n / (m + 1)\n\n    # Clustering and transitivity create shortcuts\n    base *= (1 + avg_clust + trans)\n\n    # Negative assortativity (hub‑rich) shortens paths\n    base *= (1 + abs(assort))\n\n    # Triangle density also shortens paths\n    if m > 0:\n        base *= (1 + tri / m)\n\n    # Degree spread: higher spread tends to reduce distances\n    if max_deg > 0:\n        base *= (1 + min_deg / max_deg)\n        base *= (1 + std_deg / max_deg)\n\n    # Normalise by max degree to keep the estimate in a reasonable range\n    base /= (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary containing at least the following keys:\n        - n (int): number of nodes\n        - m (int): number of edges\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n        - num_triangles (int)\n        - max_degree (int)\n        - min_degree (int)\n        - std_degree (float)\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n\n    # Base inversely proportional to edge count (more edges → shorter paths)\n    base = n / (m + 1)\n\n    # Clustering and transitivity create shortcuts\n    base *= (1 + avg_clust + trans)\n\n    # Negative assortativity (hub‑rich) shortens paths\n    base *= (1 + abs(assort))\n\n    # Triangle density also shortens paths\n    if m > 0:\n        base *= (1 + tri / m)\n\n    # Degree spread: higher spread tends to reduce distances\n    if max_deg > 0:\n        base *= (1 + min_deg / max_deg)\n        base *= (1 + std_deg / max_deg)\n\n    # Normalise by max degree to keep the estimate in a reasonable range\n    base /= (max_deg + 1)\n\n    return base", "spearman": 0.6610620265506638, "pearson": 0.4963469702016582, "rmse": 2.7835507782295568, "mae": 2.6465663542550852}}
{"timestamp": "2026-02-17T03:46:43.587191+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i2_p2_601916892", "generation": 2, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.4417286914765906, "fitness_mode": "correlation", "simplicity_score": 0.2253817469883273, "novelty_bonus": 0.19251141756957235, "total_score": 0.2518780008741923, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Heuristic estimate of the average shortest path length based on\n    pre‑computed structural features.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys:\n            n                     : number of nodes\n            m                     : number of edges\n            density               : edge density\n            avg_degree            : average node degree\n            transitivity          : global clustering coefficient\n            degree_assortativity  : degree assortativity coefficient\n            num_triangles         : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_d = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n\n    # Base estimate inversely related to average degree and density\n    base = n / (max(avg_d, 1.0) * max(density, 1e-6))\n\n    # Adjust for clustering: higher clustering tends to shorten paths\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity: negative assortativity can create hubs that shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, and degree assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features with keys:\n        - n (int): number of nodes\n        - avg_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s['n']\n    d = s['avg_degree']\n    c = s['avg_clustering']\n    t = s['transitivity']\n    a = s['degree_assortativity']\n\n    # Construct a positive denominator that incorporates several aspects\n    # of the graph.  Each term is designed to be small when the graph\n    # is well connected and large when the graph has sparse or highly\n    # clustered structure.\n    denom = np.log(d + 1) + (1 - c) + (1 - t) + (1 - a)\n\n    # Guard against numerical issues (unlikely but safe)\n    if denom <= 0:\n        denom = 1e-6\n\n    # Logarithm of the node count captures the overall scale of the\n    # network, while the denominator normalises for connectivity.\n    return np.log(n) / denom\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is deliberately simple: it combines a\n    connectivity term (based on the edge count), a clustering adjustment,\n    an assortativity factor, and a triangle‑density correction, all scaled\n    by the maximum degree to keep the estimate in a reasonable range.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            avg_degree (float)\n            avg_clustering (float)\n            degree_assortativity (float)\n            num_triangles (int)\n            max_degree (int)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Connectivity term – more edges → shorter paths\n    base = n / (max(m, 1))\n\n    # Clustering tends to create shortcuts, so increase the estimate\n    base *= (1.0 + clust)\n\n    # Negative assortativity (hub‑rich networks) shortens paths; use abs\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment – more triangles → shorter paths\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by the maximum degree to keep the scale reasonable\n    base /= max(max_deg, 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.113372\nbelow_novelty_threshold: novelty_bonus=0.112202\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula is intentionally compact, avoiding any\n    graph traversal or external libraries.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys (with safe defaults\n        if missing):\n        - n                 (int)    : number of nodes\n        - m                 (int)    : number of edges\n        - density           (float)  : edge density\n        - avg_degree        (float)  : average node degree\n        - max_degree        (int)    : maximum degree\n        - min_degree        (int)    : minimum degree\n        - avg_clustering    (float)  : average clustering coefficient\n        - transitivity      (float)  : global transitivity\n        - degree_assortativity (float) : degree assortativity\n        - num_triangles     (int)    : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe fallbacks\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 1)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    # --- Core scaling ----------------------------------------------------\n    # Use sqrt(n) as a rough size indicator\n    base = pow(n, 0.5)\n\n    # Connectivity: higher density shortens paths\n    if density > 0.0:\n        base /= (1.0 + density)\n\n    # Clustering: more triangles tend to create shortcuts\n    base /= (1.0 + trans)\n\n    # Assortativity: hubs (negative assortativity) help shorten paths\n    base /= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base /= (1.0 + tri / m)\n\n    # Degree spread: a large ratio max/min indicates hubs, which help\n    # reduce distances.  Scale accordingly.\n    if max_deg > 0:\n        base *= (max_deg / max(min_deg, 1))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula is intentionally compact, avoiding any\n    graph traversal or external libraries.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys (with safe defaults\n        if missing):\n        - n                 (int)    : number of nodes\n        - m                 (int)    : number of edges\n        - density           (float)  : edge density\n        - avg_degree        (float)  : average node degree\n        - max_degree        (int)    : maximum degree\n        - min_degree        (int)    : minimum degree\n        - avg_clustering    (float)  : average clustering coefficient\n        - transitivity      (float)  : global transitivity\n        - degree_assortativity (float) : degree assortativity\n        - num_triangles     (int)    : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe fallbacks\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 1)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    # --- Core scaling ----------------------------------------------------\n    # Use sqrt(n) as a rough size indicator\n    base = pow(n, 0.5)\n\n    # Connectivity: higher density shortens paths\n    if density > 0.0:\n        base /= (1.0 + density)\n\n    # Clustering: more triangles tend to create shortcuts\n    base /= (1.0 + trans)\n\n    # Assortativity: hubs (negative assortativity) help shorten paths\n    base /= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base /= (1.0 + tri / m)\n\n    # Degree spread: a large ratio max/min indicates hubs, which help\n    # reduce distances.  Scale accordingly.\n    if max_deg > 0:\n        base *= (max_deg / max(min_deg, 1))\n\n    return base", "spearman": 0.29809645241131033, "pearson": 0.29317459550131103, "rmse": 33.64823222268118, "mae": 21.398434379012215}}
{"timestamp": "2026-02-17T03:47:26.145231+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i2_p3_15181125", "generation": 2, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.962641056422569, "fitness_mode": "correlation", "simplicity_score": 0.2233139507913656, "novelty_bonus": 0.19517431682141706, "total_score": 0.5659399033251513, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Heuristic estimate of the average shortest path length based on\n    pre‑computed structural features.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys:\n            n                     : number of nodes\n            m                     : number of edges\n            density               : edge density\n            avg_degree            : average node degree\n            transitivity          : global clustering coefficient\n            degree_assortativity  : degree assortativity coefficient\n            num_triangles         : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_d = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n\n    # Base estimate inversely related to average degree and density\n    base = n / (max(avg_d, 1.0) * max(density, 1e-6))\n\n    # Adjust for clustering: higher clustering tends to shorten paths\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity: negative assortativity can create hubs that shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, and degree assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features with keys:\n        - n (int): number of nodes\n        - avg_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s['n']\n    d = s['avg_degree']\n    c = s['avg_clustering']\n    t = s['transitivity']\n    a = s['degree_assortativity']\n\n    # Construct a positive denominator that incorporates several aspects\n    # of the graph.  Each term is designed to be small when the graph\n    # is well connected and large when the graph has sparse or highly\n    # clustered structure.\n    denom = np.log(d + 1) + (1 - c) + (1 - t) + (1 - a)\n\n    # Guard against numerical issues (unlikely but safe)\n    if denom <= 0:\n        denom = 1e-6\n\n    # Logarithm of the node count captures the overall scale of the\n    # network, while the denominator normalises for connectivity.\n    return np.log(n) / denom\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is deliberately simple: it combines a\n    connectivity term (based on the edge count), a clustering adjustment,\n    an assortativity factor, and a triangle‑density correction, all scaled\n    by the maximum degree to keep the estimate in a reasonable range.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            avg_degree (float)\n            avg_clustering (float)\n            degree_assortativity (float)\n            num_triangles (int)\n            max_degree (int)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Connectivity term – more edges → shorter paths\n    base = n / (max(m, 1))\n\n    # Clustering tends to create shortcuts, so increase the estimate\n    base *= (1.0 + clust)\n\n    # Negative assortativity (hub‑rich networks) shortens paths; use abs\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment – more triangles → shorter paths\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by the maximum degree to keep the scale reasonable\n    base /= max(max_deg, 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.113372\nbelow_novelty_threshold: novelty_bonus=0.112202\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base", "spearman": 0.9254496362409061, "pearson": 0.7992340618744114, "rmse": 15.562873536567396, "mae": 9.08070591527503}}
{"timestamp": "2026-02-17T03:48:17.827595+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.069778", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:48:17.828372+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 2, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.069778", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:48:53.077857+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 2, "population_idx": 4, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.058540", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:48:53.078603+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 2, "island_id": 2, "population_idx": 4, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:49:25.225322+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i3_p0_42285690", "generation": 2, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.3342617046818727, "fitness_mode": "correlation", "simplicity_score": 0.1479439902091538, "novelty_bonus": 0.16544172280846436, "total_score": 0.2733231674306838, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a mixture of global\n    graph characteristics that have never been combined in the same way.\n    The function only operates on pre‑computed features supplied in *s*.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degs = s['degrees']\n\n    # Triangle fraction, safely handled for very small graphs\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri if possible_tri else 1.0)\n    else:\n        tri_frac = 0.0\n\n    # Mean of squared degrees\n    avg_deg_sq = sum(d * d for d in degs) / n if n else 0.0\n\n    # Core multiplicative component that balances size, density, clustering,\n    # triangle richness, and assortativity in a non‑linear fashion\n    part = (n / (m + 1.0) ** 0.3)          # larger graphs grow slowly\n    part *= (1.0 + density) ** 0.5          # denser graphs shrink distance\n    part *= (1.0 + tri_frac) ** 0.5         # richer triangles imply shorter paths\n    part *= (1.0 - avg_clust) ** 0.5        # high clustering tends to elongate paths\n    part *= (1.0 - assort) ** 0.2           # disassortativity can reduce distances\n\n    # Additive correction driven by degree dispersion and degree heterogeneity\n    add = std_deg * avg_deg_sq / (max_deg + 1.0)\n\n    return part + add\n\ndef new_invariant(s):\n    \"\"\"\n    Novel estimator of the average shortest‑path length that combines\n    density, clustering, assortativity, degree dispersion, and triangle\n    density.  The formula is intentionally constructed to avoid any\n    graph traversal or library calls and to provide a nonlinear\n    coupling of several structural descriptors.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features.  Expected keys:\n\n        - n (int): number of nodes\n        - m (int): number of edges\n        - density (float)\n        - avg_degree (float)\n        - max_degree (int)\n        - min_degree (int)\n        - std_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n        - num_triangles (int)\n        - degrees (list of int): sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar estimate that tends to grow with the true average\n        shortest‑path length.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # Basic numeric stability\n    # ------------------------------------------------------------------\n    eps = 1e-12\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    clustering = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    # ------------------------------------------------------------------\n    # Triangle density (fraction of possible triangles that actually exist)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ------------------------------------------------------------------\n    # Degree‑based dispersion term (scaled by maximum degree)\n    # ------------------------------------------------------------------\n    deg_disp = std_deg / (max_deg + eps)\n\n    # ------------------------------------------------------------------\n    # Core multiplicative factor capturing global connectivity\n    # ------------------------------------------------------------------\n    #   1. n / (m + 1)    : inversely related to average degree\n    #   2. 1 + density    : higher density reduces path lengths\n    #   3. 1 - clustering : more clustering often shortens paths\n    #   4. 1 - assort      : disassortative networks typically have shorter paths\n    #\n    # Each component is wrapped in (1 + |x|) to ensure monotonicity and\n    # to avoid large cancellations.\n    # ------------------------------------------------------------------\n    part1 = n / (m + 1.0)\n    part2 = 1.0 + density\n    part3 = 1.0 - clustering\n    part4 = 1.0 - assort\n\n    core = part1 * part2 * part3 * part4\n\n    # ------------------------------------------------------------------\n    # Secondary adjustment capturing local triangle concentration\n    # ------------------------------------------------------------------\n    tri_adjust = tri_frac / (1.0 - tri_frac + eps)\n\n    # ------------------------------------------------------------------\n    # Final estimator: additive combination of global core and\n    # local triangle adjustment weighted by degree dispersion.\n    # ------------------------------------------------------------------\n    return core + deg_disp * tri_adjust\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a novel combination of\n    structural graph features. The formula blends:\n    - Inverse density effect: n / (m + 1)\n    - Density amplification: 1 + density\n    - Clustering suppression: 1 - avg_clustering\n    - Assortativity damping: 1 - degree_assortativity\n    - Triangle‐based nonlinearity: triangle density/(1‑triangle density)\n    - Degree dispersion weighting: std_degree / max_degree\n    All calculations avoid any external imports and use only built‑in\n    arithmetic operations.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features. Required keys:\n        'n', 'm', 'density', 'avg_clustering',\n        'degree_assortativity', 'max_degree', 'std_degree',\n        'num_triangles'.\n\n    Returns\n    -------\n    float\n        Scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12\n\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assortativity = s['degree_assortativity']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    num_triangles = s['num_triangles']\n\n    # Triangle density fraction (bounded between 0 and 1)\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_triangles / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # Transform triangle fraction into a monotonic scale\n    tri_transform = tri_frac / (1.0 - tri_frac + eps)\n\n    # Normalize degree dispersion\n    deg_disp = std_deg / (max_deg + eps)\n\n    # Core multiplicative term capturing global connectivity\n    base_term = (n / (m + 1.0)) * (1.0 + density) * (1.0 - clustering) * (1.0 - assortativity)\n\n    # Final estimate combining core term with triangle and degree dispersion effects\n    return base_term + deg_disp * tri_transform\nRecent failures:\nbelow_train_threshold: train_signal=0.173878\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.000000\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate average shortest path length from pre‑computed graph features\n    without any graph traversal.  Combines global connectivity, clustering,\n    assortativity, triangle density and degree dispersion.\n    \"\"\"\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_clustering = float(s['avg_clustering'])\n    assort = float(s['degree_assortativity'])\n    std_deg = float(s['std_degree'])\n    max_deg = float(s['max_degree'])\n    num_tri = float(s['num_triangles'])\n\n    # Triangle density fraction (0–1)\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + 1e-12)\n    else:\n        tri_frac = 0.0\n\n    # Core factor capturing global connectivity\n    core = (n / (m + 1.0)) * (1.0 + density) * (1.0 - avg_clustering) * (1.0 - assort)\n\n    # Local triangle adjustment\n    tri_adj = tri_frac / (1.0 - tri_frac + 1e-12)\n\n    # Degree dispersion weighting\n    deg_disp = std_deg / (max_deg + 1e-12)\n\n    return core + deg_disp * tri_adj\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate average shortest path length from pre‑computed graph features\n    without any graph traversal.  Combines global connectivity, clustering,\n    assortativity, triangle density and degree dispersion.\n    \"\"\"\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_clustering = float(s['avg_clustering'])\n    assort = float(s['degree_assortativity'])\n    std_deg = float(s['std_degree'])\n    max_deg = float(s['max_degree'])\n    num_tri = float(s['num_triangles'])\n\n    # Triangle density fraction (0–1)\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + 1e-12)\n    else:\n        tri_frac = 0.0\n\n    # Core factor capturing global connectivity\n    core = (n / (m + 1.0)) * (1.0 + density) * (1.0 - avg_clustering) * (1.0 - assort)\n\n    # Local triangle adjustment\n    tri_adj = tri_frac / (1.0 - tri_frac + 1e-12)\n\n    # Degree dispersion weighting\n    deg_disp = std_deg / (max_deg + 1e-12)\n\n    return core + deg_disp * tri_adj", "spearman": 0.3882037050926274, "pearson": 0.32679913269314603, "rmse": 2.5684435810070574, "mae": 2.417714328925085}}
{"timestamp": "2026-02-17T03:50:01.781686+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i3_p1_417728367", "generation": 2, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.4703481392557023, "fitness_mode": "correlation", "simplicity_score": 0.22146646413886412, "novelty_bonus": 0.45593974619345234, "total_score": 0.38559332963863235, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a mixture of global\n    graph characteristics that have never been combined in the same way.\n    The function only operates on pre‑computed features supplied in *s*.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degs = s['degrees']\n\n    # Triangle fraction, safely handled for very small graphs\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri if possible_tri else 1.0)\n    else:\n        tri_frac = 0.0\n\n    # Mean of squared degrees\n    avg_deg_sq = sum(d * d for d in degs) / n if n else 0.0\n\n    # Core multiplicative component that balances size, density, clustering,\n    # triangle richness, and assortativity in a non‑linear fashion\n    part = (n / (m + 1.0) ** 0.3)          # larger graphs grow slowly\n    part *= (1.0 + density) ** 0.5          # denser graphs shrink distance\n    part *= (1.0 + tri_frac) ** 0.5         # richer triangles imply shorter paths\n    part *= (1.0 - avg_clust) ** 0.5        # high clustering tends to elongate paths\n    part *= (1.0 - assort) ** 0.2           # disassortativity can reduce distances\n\n    # Additive correction driven by degree dispersion and degree heterogeneity\n    add = std_deg * avg_deg_sq / (max_deg + 1.0)\n\n    return part + add\n\ndef new_invariant(s):\n    \"\"\"\n    Novel estimator of the average shortest‑path length that combines\n    density, clustering, assortativity, degree dispersion, and triangle\n    density.  The formula is intentionally constructed to avoid any\n    graph traversal or library calls and to provide a nonlinear\n    coupling of several structural descriptors.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features.  Expected keys:\n\n        - n (int): number of nodes\n        - m (int): number of edges\n        - density (float)\n        - avg_degree (float)\n        - max_degree (int)\n        - min_degree (int)\n        - std_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n        - num_triangles (int)\n        - degrees (list of int): sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar estimate that tends to grow with the true average\n        shortest‑path length.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # Basic numeric stability\n    # ------------------------------------------------------------------\n    eps = 1e-12\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    clustering = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    # ------------------------------------------------------------------\n    # Triangle density (fraction of possible triangles that actually exist)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ------------------------------------------------------------------\n    # Degree‑based dispersion term (scaled by maximum degree)\n    # ------------------------------------------------------------------\n    deg_disp = std_deg / (max_deg + eps)\n\n    # ------------------------------------------------------------------\n    # Core multiplicative factor capturing global connectivity\n    # ------------------------------------------------------------------\n    #   1. n / (m + 1)    : inversely related to average degree\n    #   2. 1 + density    : higher density reduces path lengths\n    #   3. 1 - clustering : more clustering often shortens paths\n    #   4. 1 - assort      : disassortative networks typically have shorter paths\n    #\n    # Each component is wrapped in (1 + |x|) to ensure monotonicity and\n    # to avoid large cancellations.\n    # ------------------------------------------------------------------\n    part1 = n / (m + 1.0)\n    part2 = 1.0 + density\n    part3 = 1.0 - clustering\n    part4 = 1.0 - assort\n\n    core = part1 * part2 * part3 * part4\n\n    # ------------------------------------------------------------------\n    # Secondary adjustment capturing local triangle concentration\n    # ------------------------------------------------------------------\n    tri_adjust = tri_frac / (1.0 - tri_frac + eps)\n\n    # ------------------------------------------------------------------\n    # Final estimator: additive combination of global core and\n    # local triangle adjustment weighted by degree dispersion.\n    # ------------------------------------------------------------------\n    return core + deg_disp * tri_adjust\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a novel combination of\n    structural graph features. The formula blends:\n    - Inverse density effect: n / (m + 1)\n    - Density amplification: 1 + density\n    - Clustering suppression: 1 - avg_clustering\n    - Assortativity damping: 1 - degree_assortativity\n    - Triangle‐based nonlinearity: triangle density/(1‑triangle density)\n    - Degree dispersion weighting: std_degree / max_degree\n    All calculations avoid any external imports and use only built‑in\n    arithmetic operations.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features. Required keys:\n        'n', 'm', 'density', 'avg_clustering',\n        'degree_assortativity', 'max_degree', 'std_degree',\n        'num_triangles'.\n\n    Returns\n    -------\n    float\n        Scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12\n\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assortativity = s['degree_assortativity']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    num_triangles = s['num_triangles']\n\n    # Triangle density fraction (bounded between 0 and 1)\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_triangles / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # Transform triangle fraction into a monotonic scale\n    tri_transform = tri_frac / (1.0 - tri_frac + eps)\n\n    # Normalize degree dispersion\n    deg_disp = std_deg / (max_deg + eps)\n\n    # Core multiplicative term capturing global connectivity\n    base_term = (n / (m + 1.0)) * (1.0 + density) * (1.0 - clustering) * (1.0 - assortativity)\n\n    # Final estimate combining core term with triangle and degree dispersion effects\n    return base_term + deg_disp * tri_transform\nRecent failures:\nbelow_train_threshold: train_signal=0.173878\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.000000\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a novel combination of\n    structural features.  The estimator is purely algebraic, requiring no\n    external libraries or graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n            n                 (int)          # number of vertices\n            m                 (int)          # number of edges\n            density           (float)\n            avg_degree        (float)\n            max_degree        (int)\n            min_degree        (int)\n            std_degree        (float)\n            avg_clustering    (float)\n            transitivity      (float)\n            degree_assortativity (float)\n            num_triangles     (int)\n            degrees           (list[int])   # sorted degree list\n\n    Returns\n    -------\n    float\n        An estimate that grows with the true average shortest‑path length.\n    \"\"\"\n    eps = 1e-12\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_clustering = float(s['avg_clustering'])\n    assortativity = float(s['degree_assortativity'])\n    max_deg = float(s['max_degree'])\n    std_deg = float(s['std_degree'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    # Basic base term: inverse of mean degree times density effects\n    base = n / (m + 1.0)                     # inversely proportional to avg degree\n    base *= (1.0 + density)                  # denser graphs shrink distances\n    base *= (1.0 - avg_clustering)           # high clustering can stretch paths\n    base *= (1.0 - assortativity)            # disassortativity typically shortens paths\n\n    # Triangle density contribution (non‑linear scaling)\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    # Amplify the effect: a bell‑shaped contribution centred at ~0.3\n    tri_term = tri_frac * (1.0 - tri_frac) * 12.0\n    base += tri_term\n\n    # Degree dispersion and heterogeneity adjustment\n    # Compute mean of squared degrees\n    if degrees:\n        avg_sq_deg = sum(d * d for d in degrees) / n\n    else:\n        avg_sq_deg = 0.0\n    deg_disp = std_deg / (max_deg + eps)\n    dispersion_term = deg_disp * avg_sq_deg / (max_deg + eps)\n    base += dispersion_term\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a novel combination of\n    structural features.  The estimator is purely algebraic, requiring no\n    external libraries or graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n            n                 (int)          # number of vertices\n            m                 (int)          # number of edges\n            density           (float)\n            avg_degree        (float)\n            max_degree        (int)\n            min_degree        (int)\n            std_degree        (float)\n            avg_clustering    (float)\n            transitivity      (float)\n            degree_assortativity (float)\n            num_triangles     (int)\n            degrees           (list[int])   # sorted degree list\n\n    Returns\n    -------\n    float\n        An estimate that grows with the true average shortest‑path length.\n    \"\"\"\n    eps = 1e-12\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_clustering = float(s['avg_clustering'])\n    assortativity = float(s['degree_assortativity'])\n    max_deg = float(s['max_degree'])\n    std_deg = float(s['std_degree'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    # Basic base term: inverse of mean degree times density effects\n    base = n / (m + 1.0)                     # inversely proportional to avg degree\n    base *= (1.0 + density)                  # denser graphs shrink distances\n    base *= (1.0 - avg_clustering)           # high clustering can stretch paths\n    base *= (1.0 - assortativity)            # disassortativity typically shortens paths\n\n    # Triangle density contribution (non‑linear scaling)\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    # Amplify the effect: a bell‑shaped contribution centred at ~0.3\n    tri_term = tri_frac * (1.0 - tri_frac) * 12.0\n    base += tri_term\n\n    # Degree dispersion and heterogeneity adjustment\n    # Compute mean of squared degrees\n    if degrees:\n        avg_sq_deg = sum(d * d for d in degrees) / n\n    else:\n        avg_sq_deg = 0.0\n    deg_disp = std_deg / (max_deg + eps)\n    dispersion_term = deg_disp * avg_sq_deg / (max_deg + eps)\n    base += dispersion_term\n\n    return base", "spearman": -0.40903622590564764, "pearson": -0.26905316501293464, "rmse": 2.012099716557451, "mae": 1.7185788128970694}}
{"timestamp": "2026-02-17T03:50:39.171365+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.060663", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:50:39.171997+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 2, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.060663", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:51:17.377793+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 3, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.072208", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:51:17.378330+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 2, "island_id": 3, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:52:08.993188+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:52:08.994038+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 2, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:52:30.453948+00:00", "event_type": "candidate_rejected", "payload": {"generation": 2, "island_id": 3, "population_idx": 3, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.147083", "model_name": "gpt-oss:20b", "train_signal": 0.1470828331332533}}
{"timestamp": "2026-02-17T03:52:30.454502+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 2, "island_id": 3, "population_idx": 3, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:52:59.339019+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g2_i3_p4_339997949", "generation": 2, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.38641056422569026, "fitness_mode": "correlation", "simplicity_score": 0.17009710934385577, "novelty_bonus": 0.15844776604091548, "total_score": 0.3297919576361947, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a mixture of global\n    graph characteristics that have never been combined in the same way.\n    The function only operates on pre‑computed features supplied in *s*.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degs = s['degrees']\n\n    # Triangle fraction, safely handled for very small graphs\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri if possible_tri else 1.0)\n    else:\n        tri_frac = 0.0\n\n    # Mean of squared degrees\n    avg_deg_sq = sum(d * d for d in degs) / n if n else 0.0\n\n    # Core multiplicative component that balances size, density, clustering,\n    # triangle richness, and assortativity in a non‑linear fashion\n    part = (n / (m + 1.0) ** 0.3)          # larger graphs grow slowly\n    part *= (1.0 + density) ** 0.5          # denser graphs shrink distance\n    part *= (1.0 + tri_frac) ** 0.5         # richer triangles imply shorter paths\n    part *= (1.0 - avg_clust) ** 0.5        # high clustering tends to elongate paths\n    part *= (1.0 - assort) ** 0.2           # disassortativity can reduce distances\n\n    # Additive correction driven by degree dispersion and degree heterogeneity\n    add = std_deg * avg_deg_sq / (max_deg + 1.0)\n\n    return part + add\n\ndef new_invariant(s):\n    \"\"\"\n    Novel estimator of the average shortest‑path length that combines\n    density, clustering, assortativity, degree dispersion, and triangle\n    density.  The formula is intentionally constructed to avoid any\n    graph traversal or library calls and to provide a nonlinear\n    coupling of several structural descriptors.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features.  Expected keys:\n\n        - n (int): number of nodes\n        - m (int): number of edges\n        - density (float)\n        - avg_degree (float)\n        - max_degree (int)\n        - min_degree (int)\n        - std_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n        - num_triangles (int)\n        - degrees (list of int): sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar estimate that tends to grow with the true average\n        shortest‑path length.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # Basic numeric stability\n    # ------------------------------------------------------------------\n    eps = 1e-12\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    clustering = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    # ------------------------------------------------------------------\n    # Triangle density (fraction of possible triangles that actually exist)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ------------------------------------------------------------------\n    # Degree‑based dispersion term (scaled by maximum degree)\n    # ------------------------------------------------------------------\n    deg_disp = std_deg / (max_deg + eps)\n\n    # ------------------------------------------------------------------\n    # Core multiplicative factor capturing global connectivity\n    # ------------------------------------------------------------------\n    #   1. n / (m + 1)    : inversely related to average degree\n    #   2. 1 + density    : higher density reduces path lengths\n    #   3. 1 - clustering : more clustering often shortens paths\n    #   4. 1 - assort      : disassortative networks typically have shorter paths\n    #\n    # Each component is wrapped in (1 + |x|) to ensure monotonicity and\n    # to avoid large cancellations.\n    # ------------------------------------------------------------------\n    part1 = n / (m + 1.0)\n    part2 = 1.0 + density\n    part3 = 1.0 - clustering\n    part4 = 1.0 - assort\n\n    core = part1 * part2 * part3 * part4\n\n    # ------------------------------------------------------------------\n    # Secondary adjustment capturing local triangle concentration\n    # ------------------------------------------------------------------\n    tri_adjust = tri_frac / (1.0 - tri_frac + eps)\n\n    # ------------------------------------------------------------------\n    # Final estimator: additive combination of global core and\n    # local triangle adjustment weighted by degree dispersion.\n    # ------------------------------------------------------------------\n    return core + deg_disp * tri_adjust\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a novel combination of\n    structural graph features. The formula blends:\n    - Inverse density effect: n / (m + 1)\n    - Density amplification: 1 + density\n    - Clustering suppression: 1 - avg_clustering\n    - Assortativity damping: 1 - degree_assortativity\n    - Triangle‐based nonlinearity: triangle density/(1‑triangle density)\n    - Degree dispersion weighting: std_degree / max_degree\n    All calculations avoid any external imports and use only built‑in\n    arithmetic operations.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features. Required keys:\n        'n', 'm', 'density', 'avg_clustering',\n        'degree_assortativity', 'max_degree', 'std_degree',\n        'num_triangles'.\n\n    Returns\n    -------\n    float\n        Scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12\n\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    clustering = s['avg_clustering']\n    assortativity = s['degree_assortativity']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    num_triangles = s['num_triangles']\n\n    # Triangle density fraction (bounded between 0 and 1)\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_triangles / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # Transform triangle fraction into a monotonic scale\n    tri_transform = tri_frac / (1.0 - tri_frac + eps)\n\n    # Normalize degree dispersion\n    deg_disp = std_deg / (max_deg + eps)\n\n    # Core multiplicative term capturing global connectivity\n    base_term = (n / (m + 1.0)) * (1.0 + density) * (1.0 - clustering) * (1.0 - assortativity)\n\n    # Final estimate combining core term with triangle and degree dispersion effects\n    return base_term + deg_disp * tri_transform\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.072208\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.147083\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a handful of\n    pre‑computed structural descriptors.  The expression is a\n    handcrafted non‑linear combination of size, density, clustering,\n    triangle richness, assortativity, degree dispersion and degree\n    heterogeneity.  It involves no graph traversal and requires only\n    built‑in arithmetic operations.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features with the keys\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', and 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # Triangle density (fraction of possible triangles that exist)\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri if possible_tri else 1.0)\n    else:\n        tri_frac = 0.0\n\n    # Mean of squared degrees\n    mean_sq_deg = sum(d * d for d in degs) / n if n else 0.0\n\n    # Core multiplicative factor that balances global connectivity,\n    # density, clustering, triangles and assortativity\n    part = (n / (m + 1.0) ** 0.3)\n    part *= (1.0 + density) ** 0.5\n    part *= (1.0 + tri_frac) ** 0.5\n    part *= (1.0 - avg_clust) ** 0.5\n    part *= (1.0 - assort) ** 0.2\n\n    # Additive correction driven by degree dispersion and heterogeneity\n    add = std_deg * mean_sq_deg / (max_deg + 1.0)\n\n    return part + add\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a handful of\n    pre‑computed structural descriptors.  The expression is a\n    handcrafted non‑linear combination of size, density, clustering,\n    triangle richness, assortativity, degree dispersion and degree\n    heterogeneity.  It involves no graph traversal and requires only\n    built‑in arithmetic operations.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features with the keys\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', and 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # Triangle density (fraction of possible triangles that exist)\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri if possible_tri else 1.0)\n    else:\n        tri_frac = 0.0\n\n    # Mean of squared degrees\n    mean_sq_deg = sum(d * d for d in degs) / n if n else 0.0\n\n    # Core multiplicative factor that balances global connectivity,\n    # density, clustering, triangles and assortativity\n    part = (n / (m + 1.0) ** 0.3)\n    part *= (1.0 + density) ** 0.5\n    part *= (1.0 + tri_frac) ** 0.5\n    part *= (1.0 - avg_clust) ** 0.5\n    part *= (1.0 - assort) ** 0.2\n\n    # Additive correction driven by degree dispersion and heterogeneity\n    add = std_deg * mean_sq_deg / (max_deg + 1.0)\n\n    return part + add", "spearman": -0.49647641191029784, "pearson": -0.27413583230658795, "rmse": 38.217969936400735, "mae": 24.278399335635804}}
{"timestamp": "2026-02-17T03:52:59.341479+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 3, "model_name": "gpt-oss:20b", "best_val_score": 0.5659399033251513, "no_improve_count": 0}}
{"timestamp": "2026-02-17T03:54:16.844758+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 0, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.130541", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:54:16.845838+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 3, "island_id": 0, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.130541", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:54:54.453771+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 0, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.056943", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:54:54.454175+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 3, "island_id": 0, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:55:39.304653+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.130956", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:55:39.305047+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 3, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.130956", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:56:06.866873+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 0, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.108654", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:56:06.867563+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 3, "island_id": 0, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:56:45.629884+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:56:45.630585+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 3, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:57:49.490931+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i0_p2_692262416", "generation": 3, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6083553421368547, "fitness_mode": "correlation", "simplicity_score": 0.22175206469573494, "novelty_bonus": 0.20821575173885343, "total_score": 0.38227527496421565, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n\n    # Rough logarithm approximations (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering and transitivity – higher values tend to reduce path length\n    base *= (1 + avg_clust + trans) ** -0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    return base\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n\n    # approximate logarithms using string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # adjust for density: denser graphs have shorter paths\n    base *= (1 - density) + 0.5  # scales between 0.5 and 1.5\n\n    # adjust for clustering: higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # adjust for degree variance: high variance can increase path length\n    if max_deg > 0:\n        base *= 1 + std_deg / max_deg\n\n    # adjust for triangles: more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.15\n\n    # adjust for assortativity: positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.1\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.056943\nbelow_novelty_threshold: novelty_bonus=0.130956\nbelow_novelty_threshold: novelty_bonus=0.108654\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    import math\n\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n\n    if n <= 1:\n        return 0.0\n\n    # Basic random‑graph estimate\n    log_n = math.log(n)\n    log_avg_deg = math.log(avg_deg) if avg_deg > 0 else 1.0\n    base = log_n / max(log_avg_deg, 1.0)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering and transitivity – higher values tend to reduce ASPL\n    base *= (1 + avg_clust + trans) ** -0.2\n\n    # Adjust for degree variance – high variance can increase ASPL\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Adjust for triangles – more triangles tend to reduce ASPL\n    base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for assortativity – positive assortativity can increase ASPL\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate ASPL\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten ASPL\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n\n    if n <= 1:\n        return 0.0\n\n    # approximate logarithms using string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # adjust for clustering and transitivity – higher values tend to reduce ASPL\n    base *= (1 + avg_clust + trans) ** -0.2\n\n    # adjust for degree variance – high variance can increase ASPL\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # adjust for triangles – more triangles tend to reduce ASPL\n    base *= (1 + num_tri / n) ** -0.1\n\n    # adjust for assortativity – positive assortativity can increase ASPL\n    base *= (1 + abs(assort)) ** 0.05\n\n    # adjust for minimum degree – very low min degree can inflate ASPL\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # adjust for maximum degree relative to average – very high max degree can shorten ASPL\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n\n    if n <= 1:\n        return 0.0\n\n    # approximate logarithms using string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # adjust for clustering and transitivity – higher values tend to reduce ASPL\n    base *= (1 + avg_clust + trans) ** -0.2\n\n    # adjust for degree variance – high variance can increase ASPL\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # adjust for triangles – more triangles tend to reduce ASPL\n    base *= (1 + num_tri / n) ** -0.1\n\n    # adjust for assortativity – positive assortativity can increase ASPL\n    base *= (1 + abs(assort)) ** 0.05\n\n    # adjust for minimum degree – very low min degree can inflate ASPL\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # adjust for maximum degree relative to average – very high max degree can shorten ASPL\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    return base", "spearman": 0.5509202730068252, "pearson": 0.3669326351385293, "rmse": 1.578225831439785, "mae": 1.3246333135910917}}
{"timestamp": "2026-02-17T03:57:49.491906+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 3, "island_id": 0, "population_idx": 2, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:59:13.857182+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 0, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.129664", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:59:13.858173+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 3, "island_id": 0, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.129664", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:59:55.057356+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 0, "population_idx": 3, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T03:59:55.058622+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 3, "island_id": 0, "population_idx": 3, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:01:26.320381+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i0_p4_491102914", "generation": 3, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6298679471788714, "fitness_mode": "correlation", "simplicity_score": 0.2206775829744107, "novelty_bonus": 0.19238162838984718, "total_score": 0.385182338420169, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n\n    # Rough logarithm approximations (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering and transitivity – higher values tend to reduce path length\n    base *= (1 + avg_clust + trans) ** -0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    return base\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n\n    # approximate logarithms using string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # adjust for density: denser graphs have shorter paths\n    base *= (1 - density) + 0.5  # scales between 0.5 and 1.5\n\n    # adjust for clustering: higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # adjust for degree variance: high variance can increase path length\n    if max_deg > 0:\n        base *= 1 + std_deg / max_deg\n\n    # adjust for triangles: more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.15\n\n    # adjust for assortativity: positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.1\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.108654\nbelow_novelty_threshold: novelty_bonus=0.129664\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base", "spearman": 0.5666646666166655, "pearson": 0.39514065159658396, "rmse": 1.550161178344951, "mae": 1.2997755255400834}}
{"timestamp": "2026-02-17T04:01:58.144658+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i1_p0_971238904", "generation": 3, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6164225690276111, "fitness_mode": "correlation", "simplicity_score": 0.12497309083708594, "novelty_bonus": 0.16165758588050727, "total_score": 0.4175202446403371, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree scaling (avoid external imports)\n    degree_scaling = (n + 1) ** 0.5 * avg_deg / (max_deg + 1)\n\n    # Component 3 – clustering dampening\n    clustering_damp = (n + 1) ** 0.5 / (1 + avg_cluster)\n\n    # Combine the components multiplicatively for a richer invariant\n    return (\n        size_edge_ratio *\n        degree_scaling *\n        clustering_damp *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort))\n    )\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    # (n/(m+1))   : normalises by edge count\n    # (avg_deg/(max_deg+1)) : captures degree spread\n    # (1+avg_cluster) : accounts for local clustering\n    # (triangle_ratio+0.1) : adds global triangle density\n    # (1+abs(assort)) : incorporates assortativity\n    # (n**0.5) : scales with graph size\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort)) *\n        (n ** 0.5)\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.149772\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.152461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Components\n    size_edge_ratio = n / (m + 1)\n    degree_factor = avg_deg / (max_deg + 1)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n    triangle_factor = triangle_ratio + 0.1\n    assort_factor = 1 + abs(assort)\n    size_factor = n ** 0.5\n\n    # Composite invariant\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Components\n    size_edge_ratio = n / (m + 1)\n    degree_factor = avg_deg / (max_deg + 1)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n    triangle_factor = triangle_ratio + 0.1\n    assort_factor = 1 + abs(assort)\n    size_factor = n ** 0.5\n\n    # Composite invariant\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.6880567014175355, "pearson": 0.576637052265951, "rmse": 2.7722513442812797, "mae": 2.625258290279277}}
{"timestamp": "2026-02-17T04:02:24.586698+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i1_p1_978711397", "generation": 3, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12236940754061881, "novelty_bonus": 0.185688142203555, "total_score": 0.4606025847257042, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree scaling (avoid external imports)\n    degree_scaling = (n + 1) ** 0.5 * avg_deg / (max_deg + 1)\n\n    # Component 3 – clustering dampening\n    clustering_damp = (n + 1) ** 0.5 / (1 + avg_cluster)\n\n    # Combine the components multiplicatively for a richer invariant\n    return (\n        size_edge_ratio *\n        degree_scaling *\n        clustering_damp *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort))\n    )\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    # (n/(m+1))   : normalises by edge count\n    # (avg_deg/(max_deg+1)) : captures degree spread\n    # (1+avg_cluster) : accounts for local clustering\n    # (triangle_ratio+0.1) : adds global triangle density\n    # (1+abs(assort)) : incorporates assortativity\n    # (n**0.5) : scales with graph size\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort)) *\n        (n ** 0.5)\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.149772\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.152461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends several structural properties\n    (size, density, degree distribution, clustering, triangle density,\n    and assortativity) into a single scalar value.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees.\n\n    Returns\n    -------\n    float\n        The invariant value.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1.0) / (max_deg + 1.0)\n    degree_variability = 1.0 + std_deg / (max_deg + 1.0)\n    degree_factor = (avg_deg / (max_deg + 1.0)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends several structural properties\n    (size, density, degree distribution, clustering, triangle density,\n    and assortativity) into a single scalar value.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees.\n\n    Returns\n    -------\n    float\n        The invariant value.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1.0) / (max_deg + 1.0)\n    degree_variability = 1.0 + std_deg / (max_deg + 1.0)\n    degree_factor = (avg_deg / (max_deg + 1.0)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T04:02:57.174614+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i1_p2_588779643", "generation": 3, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree scaling (avoid external imports)\n    degree_scaling = (n + 1) ** 0.5 * avg_deg / (max_deg + 1)\n\n    # Component 3 – clustering dampening\n    clustering_damp = (n + 1) ** 0.5 / (1 + avg_cluster)\n\n    # Combine the components multiplicatively for a richer invariant\n    return (\n        size_edge_ratio *\n        degree_scaling *\n        clustering_damp *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort))\n    )\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    # (n/(m+1))   : normalises by edge count\n    # (avg_deg/(max_deg+1)) : captures degree spread\n    # (1+avg_cluster) : accounts for local clustering\n    # (triangle_ratio+0.1) : adds global triangle density\n    # (1+abs(assort)) : incorporates assortativity\n    # (n**0.5) : scales with graph size\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort)) *\n        (n ** 0.5)\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.149772\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.152461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T04:03:20.772742+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i1_p3_250908856", "generation": 3, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6226650660264105, "fitness_mode": "correlation", "simplicity_score": 0.1240319827679004, "novelty_bonus": 0.16908804449770332, "total_score": 0.4187811411111714, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree scaling (avoid external imports)\n    degree_scaling = (n + 1) ** 0.5 * avg_deg / (max_deg + 1)\n\n    # Component 3 – clustering dampening\n    clustering_damp = (n + 1) ** 0.5 / (1 + avg_cluster)\n\n    # Combine the components multiplicatively for a richer invariant\n    return (\n        size_edge_ratio *\n        degree_scaling *\n        clustering_damp *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort))\n    )\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    # (n/(m+1))   : normalises by edge count\n    # (avg_deg/(max_deg+1)) : captures degree spread\n    # (1+avg_cluster) : accounts for local clustering\n    # (triangle_ratio+0.1) : adds global triangle density\n    # (1+abs(assort)) : incorporates assortativity\n    # (n**0.5) : scales with graph size\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort)) *\n        (n ** 0.5)\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.149772\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.152461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant combining size, degree distribution, clustering,\n    triangle density, assortativity, and graph size scaling.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6\n    else:\n        possible_triangles = 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree scaling (average over maximum)\n    degree_factor = (avg_deg / (max_deg + 1)) * (1 + std_deg / (max_deg + 1))\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_damp = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_damp *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite invariant combining size, degree distribution, clustering,\n    triangle density, assortativity, and graph size scaling.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6\n    else:\n        possible_triangles = 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree scaling (average over maximum)\n    degree_factor = (avg_deg / (max_deg + 1)) * (1 + std_deg / (max_deg + 1))\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_damp = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_damp *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.6864966624165606, "pearson": 0.5963589562935734, "rmse": 2.750063321236041, "mae": 2.6034382356499424}}
{"timestamp": "2026-02-17T04:03:42.761970+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i1_p4_507677092", "generation": 3, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6226650660264105, "fitness_mode": "correlation", "simplicity_score": 0.1235552163905093, "novelty_bonus": 0.16908804449770332, "total_score": 0.41868578783569316, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree scaling (avoid external imports)\n    degree_scaling = (n + 1) ** 0.5 * avg_deg / (max_deg + 1)\n\n    # Component 3 – clustering dampening\n    clustering_damp = (n + 1) ** 0.5 / (1 + avg_cluster)\n\n    # Combine the components multiplicatively for a richer invariant\n    return (\n        size_edge_ratio *\n        degree_scaling *\n        clustering_damp *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort))\n    )\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    avg_cluster = s['avg_clustering']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Combine multiple aspects into a single invariant\n    # (n/(m+1))   : normalises by edge count\n    # (avg_deg/(max_deg+1)) : captures degree spread\n    # (1+avg_cluster) : accounts for local clustering\n    # (triangle_ratio+0.1) : adds global triangle density\n    # (1+abs(assort)) : incorporates assortativity\n    # (n**0.5) : scales with graph size\n    return (\n        (n / (m + 1)) *\n        (avg_deg / (max_deg + 1)) *\n        (1 + avg_cluster) *\n        (triangle_ratio + 0.1) *\n        (1 + abs(assort)) *\n        (n ** 0.5)\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.149772\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.152461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite invariant combining size, edge density, degree spread,\n    clustering, triangle density, assortativity and graph size scaling.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree scaling (captures spread and variability)\n    degree_scaling = (avg_deg / (max_deg + 1)) * (1 + std_deg / (max_deg + 1))\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_damp = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_scaling *\n        clustering_damp *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite invariant combining size, edge density, degree spread,\n    clustering, triangle density, assortativity and graph size scaling.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree scaling (captures spread and variability)\n    degree_scaling = (avg_deg / (max_deg + 1)) * (1 + std_deg / (max_deg + 1))\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_damp = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_scaling *\n        clustering_damp *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.6864966624165606, "pearson": 0.5963589562935734, "rmse": 2.750063321236041, "mae": 2.6034382356499424}}
{"timestamp": "2026-02-17T04:04:18.586691+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i2_p0_766796678", "generation": 3, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.962641056422569, "fitness_mode": "correlation", "simplicity_score": 0.2233139507913656, "novelty_bonus": 0.19517431682141706, "total_score": 0.5659399033251513, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Heuristic estimate of the average shortest path length based on\n    pre‑computed structural features.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys:\n            n                     : number of nodes\n            m                     : number of edges\n            density               : edge density\n            avg_degree            : average node degree\n            transitivity          : global clustering coefficient\n            degree_assortativity  : degree assortativity coefficient\n            num_triangles         : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_d = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n\n    # Base estimate inversely related to average degree and density\n    base = n / (max(avg_d, 1.0) * max(density, 1e-6))\n\n    # Adjust for clustering: higher clustering tends to shorten paths\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity: negative assortativity can create hubs that shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, and degree assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features with keys:\n        - n (int): number of nodes\n        - avg_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s['n']\n    d = s['avg_degree']\n    c = s['avg_clustering']\n    t = s['transitivity']\n    a = s['degree_assortativity']\n\n    # Construct a positive denominator that incorporates several aspects\n    # of the graph.  Each term is designed to be small when the graph\n    # is well connected and large when the graph has sparse or highly\n    # clustered structure.\n    denom = np.log(d + 1) + (1 - c) + (1 - t) + (1 - a)\n\n    # Guard against numerical issues (unlikely but safe)\n    if denom <= 0:\n        denom = 1e-6\n\n    # Logarithm of the node count captures the overall scale of the\n    # network, while the denominator normalises for connectivity.\n    return np.log(n) / denom\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.069778\nbelow_novelty_threshold: novelty_bonus=0.058540\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length using pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n\n    # Base estimate inversely related to average degree and density\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Adjust for clustering (higher clustering tends to shorten paths)\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity (negative assortativity can create hubs that shorten paths)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree spread (more heterogeneous degrees usually give shorter paths)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length using pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n\n    # Base estimate inversely related to average degree and density\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Adjust for clustering (higher clustering tends to shorten paths)\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity (negative assortativity can create hubs that shorten paths)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree spread (more heterogeneous degrees usually give shorter paths)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base", "spearman": 0.9254496362409061, "pearson": 0.7992340618744114, "rmse": 15.562873536567396, "mae": 9.08070591527503}}
{"timestamp": "2026-02-17T04:04:57.866456+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i2_p1_980749530", "generation": 3, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9646578631452579, "fitness_mode": "correlation", "simplicity_score": 0.22335485883721273, "novelty_bonus": 0.1994874448704833, "total_score": 0.5663240003984669, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Heuristic estimate of the average shortest path length based on\n    pre‑computed structural features.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys:\n            n                     : number of nodes\n            m                     : number of edges\n            density               : edge density\n            avg_degree            : average node degree\n            transitivity          : global clustering coefficient\n            degree_assortativity  : degree assortativity coefficient\n            num_triangles         : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_d = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n\n    # Base estimate inversely related to average degree and density\n    base = n / (max(avg_d, 1.0) * max(density, 1e-6))\n\n    # Adjust for clustering: higher clustering tends to shorten paths\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity: negative assortativity can create hubs that shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, and degree assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features with keys:\n        - n (int): number of nodes\n        - avg_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s['n']\n    d = s['avg_degree']\n    c = s['avg_clustering']\n    t = s['transitivity']\n    a = s['degree_assortativity']\n\n    # Construct a positive denominator that incorporates several aspects\n    # of the graph.  Each term is designed to be small when the graph\n    # is well connected and large when the graph has sparse or highly\n    # clustered structure.\n    denom = np.log(d + 1) + (1 - c) + (1 - t) + (1 - a)\n\n    # Guard against numerical issues (unlikely but safe)\n    if denom <= 0:\n        denom = 1e-6\n\n    # Logarithm of the node count captures the overall scale of the\n    # network, while the denominator normalises for connectivity.\n    return np.log(n) / denom\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.069778\nbelow_novelty_threshold: novelty_bonus=0.058540\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base", "spearman": 0.9236135903397585, "pearson": 0.804977620128539, "rmse": 13.852416981972354, "mae": 8.040305045467084}}
{"timestamp": "2026-02-17T04:05:29.066565+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i2_p2_655046361", "generation": 3, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.962641056422569, "fitness_mode": "correlation", "simplicity_score": 0.223192647377777, "novelty_bonus": 0.19517431682141706, "total_score": 0.5659156426424335, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Heuristic estimate of the average shortest path length based on\n    pre‑computed structural features.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys:\n            n                     : number of nodes\n            m                     : number of edges\n            density               : edge density\n            avg_degree            : average node degree\n            transitivity          : global clustering coefficient\n            degree_assortativity  : degree assortativity coefficient\n            num_triangles         : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_d = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n\n    # Base estimate inversely related to average degree and density\n    base = n / (max(avg_d, 1.0) * max(density, 1e-6))\n\n    # Adjust for clustering: higher clustering tends to shorten paths\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity: negative assortativity can create hubs that shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, and degree assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features with keys:\n        - n (int): number of nodes\n        - avg_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s['n']\n    d = s['avg_degree']\n    c = s['avg_clustering']\n    t = s['transitivity']\n    a = s['degree_assortativity']\n\n    # Construct a positive denominator that incorporates several aspects\n    # of the graph.  Each term is designed to be small when the graph\n    # is well connected and large when the graph has sparse or highly\n    # clustered structure.\n    denom = np.log(d + 1) + (1 - c) + (1 - t) + (1 - a)\n\n    # Guard against numerical issues (unlikely but safe)\n    if denom <= 0:\n        denom = 1e-6\n\n    # Logarithm of the node count captures the overall scale of the\n    # network, while the denominator normalises for connectivity.\n    return np.log(n) / denom\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.069778\nbelow_novelty_threshold: novelty_bonus=0.058540\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    The formula balances graph size, connectivity, clustering, assortativity,\n    triangle density, and degree heterogeneity.  No external libraries are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n        - n (int)                     : number of nodes\n        - m (int)                     : number of edges\n        - density (float)             : edge density\n        - avg_degree (float)          : average degree\n        - max_degree (int)            : maximum degree\n        - min_degree (int)            : minimum degree\n        - std_degree (float)          : standard deviation of degrees\n        - avg_clustering (float)      : average clustering coefficient\n        - transitivity (float)        : global transitivity\n        - degree_assortativity (float): degree assortativity coefficient\n        - num_triangles (int)         : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_d = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_d, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree spread (heterogeneity)\n    base /= (1.0 + std_deg / max(1.0, avg_d))\n    base /= (1.0 + min_deg / max(1.0, avg_d))\n\n    # Final scaling by maximum degree\n    base /= max_deg if max_deg > 0 else 1\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    The formula balances graph size, connectivity, clustering, assortativity,\n    triangle density, and degree heterogeneity.  No external libraries are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n        - n (int)                     : number of nodes\n        - m (int)                     : number of edges\n        - density (float)             : edge density\n        - avg_degree (float)          : average degree\n        - max_degree (int)            : maximum degree\n        - min_degree (int)            : minimum degree\n        - std_degree (float)          : standard deviation of degrees\n        - avg_clustering (float)      : average clustering coefficient\n        - transitivity (float)        : global transitivity\n        - degree_assortativity (float): degree assortativity coefficient\n        - num_triangles (int)         : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_d = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_d, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree spread (heterogeneity)\n    base /= (1.0 + std_deg / max(1.0, avg_d))\n    base /= (1.0 + min_deg / max(1.0, avg_d))\n\n    # Final scaling by maximum degree\n    base /= max_deg if max_deg > 0 else 1\n\n    return base", "spearman": 0.9254496362409061, "pearson": 0.7992340618744114, "rmse": 15.562873536567396, "mae": 9.08070591527503}}
{"timestamp": "2026-02-17T04:06:20.993033+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g3_i2_p3_370331271", "generation": 3, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9646578631452579, "fitness_mode": "correlation", "simplicity_score": 0.22335485883721273, "novelty_bonus": 0.1994874448704833, "total_score": 0.5663240003984669, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Heuristic estimate of the average shortest path length based on\n    pre‑computed structural features.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys:\n            n                     : number of nodes\n            m                     : number of edges\n            density               : edge density\n            avg_degree            : average node degree\n            transitivity          : global clustering coefficient\n            degree_assortativity  : degree assortativity coefficient\n            num_triangles         : total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_d = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n\n    # Base estimate inversely related to average degree and density\n    base = n / (max(avg_d, 1.0) * max(density, 1e-6))\n\n    # Adjust for clustering: higher clustering tends to shorten paths\n    base *= (1.0 + trans)\n\n    # Adjust for assortativity: negative assortativity can create hubs that shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, and degree assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features with keys:\n        - n (int): number of nodes\n        - avg_degree (float)\n        - avg_clustering (float)\n        - transitivity (float)\n        - degree_assortativity (float)\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s['n']\n    d = s['avg_degree']\n    c = s['avg_clustering']\n    t = s['transitivity']\n    a = s['degree_assortativity']\n\n    # Construct a positive denominator that incorporates several aspects\n    # of the graph.  Each term is designed to be small when the graph\n    # is well connected and large when the graph has sparse or highly\n    # clustered structure.\n    denom = np.log(d + 1) + (1 - c) + (1 - t) + (1 - a)\n\n    # Guard against numerical issues (unlikely but safe)\n    if denom <= 0:\n        denom = 1e-6\n\n    # Logarithm of the node count captures the overall scale of the\n    # network, while the denominator normalises for connectivity.\n    return np.log(n) / denom\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.069778\nbelow_novelty_threshold: novelty_bonus=0.058540\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base", "spearman": 0.9236135903397585, "pearson": 0.804977620128539, "rmse": 13.852416981972354, "mae": 8.040305045467084}}
{"timestamp": "2026-02-17T04:06:53.069591+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:06:53.070113+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 3, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:07:18.870553+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 2, "population_idx": 4, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.134019", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:07:18.871164+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 3, "island_id": 2, "population_idx": 4, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:07:46.622280+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.032918", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:07:46.622565+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 3, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.032918", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:08:18.693268+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 3, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.032720", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:08:18.693817+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 3, "island_id": 3, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:08:49.154145+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:08:49.155413+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 3, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:09:16.962406+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.029617", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:09:16.962861+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 3, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:09:50.664652+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.034847", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:09:50.665289+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 3, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.034847", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:10:16.195520+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 3, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.032077", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:10:16.195950+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 3, "island_id": 3, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:10:52.137558+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:10:52.138099+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 3, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:11:18.985840+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 3, "population_idx": 3, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.032177", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:11:18.986492+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 3, "island_id": 3, "population_idx": 3, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:12:14.626418+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.078479", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:12:14.626986+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 3, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.078479", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:12:55.944813+00:00", "event_type": "candidate_rejected", "payload": {"generation": 3, "island_id": 3, "population_idx": 4, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.048547", "model_name": "gpt-oss:20b", "train_signal": 0.04854741896758703}}
{"timestamp": "2026-02-17T04:12:55.945067+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 3, "island_id": 3, "population_idx": 4, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:12:55.948006+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 4, "model_name": "gpt-oss:20b", "best_val_score": 0.5663240003984669, "no_improve_count": 0}}
{"timestamp": "2026-02-17T04:13:37.816173+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i0_p0_563106088", "generation": 4, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.58953181272509, "fitness_mode": "correlation", "simplicity_score": 0.22040825984618836, "novelty_bonus": 0.19135694084224852, "total_score": 0.3659183449621808, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n\n    if n <= 1:\n        return 0.0\n\n    # approximate logarithms using string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # adjust for clustering and transitivity – higher values tend to reduce ASPL\n    base *= (1 + avg_clust + trans) ** -0.2\n\n    # adjust for degree variance – high variance can increase ASPL\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # adjust for triangles – more triangles tend to reduce ASPL\n    base *= (1 + num_tri / n) ** -0.1\n\n    # adjust for assortativity – positive assortativity can increase ASPL\n    base *= (1 + abs(assort)) ** 0.05\n\n    # adjust for minimum degree – very low min degree can inflate ASPL\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # adjust for maximum degree relative to average – very high max degree can shorten ASPL\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.108654\nbelow_novelty_threshold: novelty_bonus=0.129664\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # approximate logarithms with string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.3\n\n    # adjust for clustering and transitivity – higher values tend to reduce ASPL\n    base *= (1 + avg_clust + trans) ** -0.15\n\n    # adjust for degree variance – high variance can increase ASPL\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.08\n\n    # adjust for triangles – more triangles tend to reduce ASPL\n    base *= (1 + num_tri / n) ** -0.08\n\n    # adjust for assortativity – positive assortativity can increase ASPL\n    base *= (1 + abs(assort)) ** 0.04\n\n    # adjust for minimum degree – very low min degree can inflate ASPL\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    # adjust for maximum degree relative to average – very high max degree can shorten ASPL\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    # adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.04\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # approximate logarithms with string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.3\n\n    # adjust for clustering and transitivity – higher values tend to reduce ASPL\n    base *= (1 + avg_clust + trans) ** -0.15\n\n    # adjust for degree variance – high variance can increase ASPL\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.08\n\n    # adjust for triangles – more triangles tend to reduce ASPL\n    base *= (1 + num_tri / n) ** -0.08\n\n    # adjust for assortativity – positive assortativity can increase ASPL\n    base *= (1 + abs(assort)) ** 0.04\n\n    # adjust for minimum degree – very low min degree can inflate ASPL\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    # adjust for maximum degree relative to average – very high max degree can shorten ASPL\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    # adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.04\n\n    return base", "spearman": 0.5288592214805371, "pearson": 0.36936439296614476, "rmse": 1.5122115936648022, "mae": 1.2486309059134704}}
{"timestamp": "2026-02-17T04:14:19.647941+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.130830", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:14:19.648714+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 4, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.130830", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:14:43.047590+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 0, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.117935", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:14:43.048056+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 4, "island_id": 0, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:15:17.768736+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.124404", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:15:17.769322+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 4, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.124404", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:15:56.519883+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 0, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.135226", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:15:56.520317+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 4, "island_id": 0, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:16:29.824492+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 0, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:16:29.825247+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 4, "island_id": 0, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:17:04.360342+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i0_p3_431620835", "generation": 4, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6008643457382953, "fitness_mode": "correlation", "simplicity_score": 0.22051463019207068, "novelty_bonus": 0.18344813763485746, "total_score": 0.36414374248825043, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n\n    if n <= 1:\n        return 0.0\n\n    # approximate logarithms using string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # adjust for clustering and transitivity – higher values tend to reduce ASPL\n    base *= (1 + avg_clust + trans) ** -0.2\n\n    # adjust for degree variance – high variance can increase ASPL\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # adjust for triangles – more triangles tend to reduce ASPL\n    base *= (1 + num_tri / n) ** -0.1\n\n    # adjust for assortativity – positive assortativity can increase ASPL\n    base *= (1 + abs(assort)) ** 0.05\n\n    # adjust for minimum degree – very low min degree can inflate ASPL\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # adjust for maximum degree relative to average – very high max degree can shorten ASPL\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.117935\nbelow_novelty_threshold: novelty_bonus=0.124404\nbelow_novelty_threshold: novelty_bonus=0.135226\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport math\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    The formula combines logarithmic scaling, density, clustering, degree\n    dispersion, triangle density, assortativity, and degree extremes.\n    \"\"\"\n    # Basic counts\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Guard against degenerate graphs\n    if n <= 1 or avg_deg <= 0:\n        return 0.0\n\n    # Median degree (robust central tendency)\n    median_deg = degrees[len(degrees) // 2]\n\n    # Logarithmic base estimate (random‑graph intuition)\n    base = math.log(n + 1) / (math.log(avg_deg + 1) + 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering and transitivity – higher values reduce ASPL\n    base *= (1 + avg_clust + trans) ** -0.2\n\n    # Adjust for degree variance – high variance can increase ASPL\n    base *= (1 + std_deg / (avg_deg + 1)) ** 0.08\n\n    # Adjust for triangle density – more triangles reduce ASPL\n    base *= (1 + num_tri / n) ** -0.08\n\n    # Adjust for assortativity – positive assortativity can increase ASPL\n    base *= (1 + abs(assort)) ** 0.04\n\n    # Adjust for minimum degree – very low min degree inflates ASPL\n    base *= (1 + 1 / (min_deg + 1)) ** 0.04\n\n    # Adjust for maximum degree relative to average – high max degree shortens ASPL\n    base *= (1 + max_deg / (avg_deg + 1)) ** -0.04\n\n    # Adjust for median degree relative to average – robust central tendency\n    base *= (1 + median_deg / (avg_deg + 1)) ** -0.04\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    if n <= 1 or avg_deg <= 0:\n        return 0.0\n\n    # approximate logarithms (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering and transitivity – higher values reduce ASPL\n    base *= (1 + avg_clust + trans) ** -0.2\n\n    # Adjust for degree variance – high variance can increase ASPL\n    base *= (1 + std_deg / (avg_deg + 1)) ** 0.08\n\n    # Adjust for triangle density – more triangles reduce ASPL\n    base *= (1 + num_tri / n) ** -0.08\n\n    # Adjust for assortativity – positive assortativity can increase ASPL\n    base *= (1 + abs(assort)) ** 0.04\n\n    # Adjust for minimum degree – very low min degree inflates ASPL\n    base *= (1 + 1 / (min_deg + 1)) ** 0.04\n\n    # Adjust for maximum degree relative to average – high max degree shortens ASPL\n    base *= (1 + max_deg / (avg_deg + 1)) ** -0.04\n\n    # Adjust for median degree relative to average – robust central tendency\n    median_deg = degrees[len(degrees) // 2]\n    base *= (1 + median_deg / (avg_deg + 1)) ** -0.04\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    if n <= 1 or avg_deg <= 0:\n        return 0.0\n\n    # approximate logarithms (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering and transitivity – higher values reduce ASPL\n    base *= (1 + avg_clust + trans) ** -0.2\n\n    # Adjust for degree variance – high variance can increase ASPL\n    base *= (1 + std_deg / (avg_deg + 1)) ** 0.08\n\n    # Adjust for triangle density – more triangles reduce ASPL\n    base *= (1 + num_tri / n) ** -0.08\n\n    # Adjust for assortativity – positive assortativity can increase ASPL\n    base *= (1 + abs(assort)) ** 0.04\n\n    # Adjust for minimum degree – very low min degree inflates ASPL\n    base *= (1 + 1 / (min_deg + 1)) ** 0.04\n\n    # Adjust for maximum degree relative to average – high max degree shortens ASPL\n    base *= (1 + max_deg / (avg_deg + 1)) ** -0.04\n\n    # Adjust for median degree relative to average – robust central tendency\n    median_deg = degrees[len(degrees) // 2]\n    base *= (1 + median_deg / (avg_deg + 1)) ** -0.04\n\n    return base", "spearman": 0.530012750318758, "pearson": 0.36625707817466946, "rmse": 1.567075753573523, "mae": 1.3119619627071857}}
{"timestamp": "2026-02-17T04:17:04.360819+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 4, "island_id": 0, "population_idx": 3, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:21:05.047077+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 0, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.131431", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:21:05.048336+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 4, "island_id": 0, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.131431", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:21:34.341011+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i0_p4_537278868", "generation": 4, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5177911164465786, "fitness_mode": "correlation", "simplicity_score": 0.21961625809647964, "novelty_bonus": 0.23229977305307115, "total_score": 0.3917238863027865, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\n\ndef new_invariant(s):\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n\n    if n <= 1:\n        return 0.0\n\n    # approximate logarithms using string length (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # adjust for clustering and transitivity – higher values tend to reduce ASPL\n    base *= (1 + avg_clust + trans) ** -0.2\n\n    # adjust for degree variance – high variance can increase ASPL\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # adjust for triangles – more triangles tend to reduce ASPL\n    base *= (1 + num_tri / n) ** -0.1\n\n    # adjust for assortativity – positive assortativity can increase ASPL\n    base *= (1 + abs(assort)) ** 0.05\n\n    # adjust for minimum degree – very low min degree can inflate ASPL\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # adjust for maximum degree relative to average – very high max degree can shorten ASPL\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.124404\nbelow_novelty_threshold: novelty_bonus=0.135226\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: novelty_bonus=0.131431\nPrevious candidate code:\n```python\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    num_tri = s['num_triangles']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    # Guard against zero average degree\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.1\n\n    # Adjust for maximum degree – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    num_tri = s['num_triangles']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_m = m.bit_length() - 1 if m > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_m, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.4\n\n    # Adjust for average degree ratio (m/n)\n    base *= (m / n) ** 0.1\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.15\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.08\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.08\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.04\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    num_tri = s['num_triangles']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_m = m.bit_length() - 1 if m > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_m, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.4\n\n    # Adjust for average degree ratio (m/n)\n    base *= (m / n) ** 0.1\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.15\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.08\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.08\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.04\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    return base", "spearman": 0.5562214055351384, "pearson": 0.3887578347103096, "rmse": 2.2429259804157518, "mae": 2.064804484592415}}
{"timestamp": "2026-02-17T04:21:34.341989+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 4, "island_id": 0, "population_idx": 4, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:22:40.126603+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i1_p0_523121938", "generation": 4, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.44614645858343327, "fitness_mode": "correlation", "simplicity_score": 0.11610725416341869, "novelty_bonus": 0.32315037833918414, "total_score": 0.3775114979577796, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends several structural properties\n    (size, density, degree distribution, clustering, triangle density,\n    and assortativity) into a single scalar value.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees.\n\n    Returns\n    -------\n    float\n        The invariant value.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1.0) / (max_deg + 1.0)\n    degree_variability = 1.0 + std_deg / (max_deg + 1.0)\n    degree_factor = (avg_deg / (max_deg + 1.0)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.149772\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.152461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"Composite invariant combining multiple graph statistics.\"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Triangle density\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = pow(n, 0.5)\n\n    # Density factor\n    density_factor = 1.0 + density\n\n    # Median degree factor\n    deg_len = len(degrees)\n    if deg_len % 2 == 1:\n        median_deg = degrees[deg_len // 2]\n    else:\n        median_deg = (degrees[deg_len // 2 - 1] + degrees[deg_len // 2]) / 2.0\n    median_factor = 1.0 + median_deg / denom\n\n    # Combine all components multiplicatively\n    return (size_edge_ratio *\n            degree_factor *\n            clustering_factor *\n            triangle_factor *\n            assort_factor *\n            size_factor *\n            density_factor *\n            median_factor)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"Composite invariant combining multiple graph statistics.\"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Triangle density\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = pow(n, 0.5)\n\n    # Density factor\n    density_factor = 1.0 + density\n\n    # Median degree factor\n    deg_len = len(degrees)\n    if deg_len % 2 == 1:\n        median_deg = degrees[deg_len // 2]\n    else:\n        median_deg = (degrees[deg_len // 2 - 1] + degrees[deg_len // 2]) / 2.0\n    median_factor = 1.0 + median_deg / denom\n\n    # Combine all components multiplicatively\n    return (size_edge_ratio *\n            degree_factor *\n            clustering_factor *\n            triangle_factor *\n            assort_factor *\n            size_factor *\n            density_factor *\n            median_factor)", "spearman": 0.5146898672466813, "pearson": 0.4749493849456128, "rmse": 2.704400887538064, "mae": 2.5563006283367957}}
{"timestamp": "2026-02-17T04:23:44.554181+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i1_p1_6750190", "generation": 4, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6001920768307323, "fitness_mode": "correlation", "simplicity_score": 0.11979356293275192, "novelty_bonus": 0.2404110102752568, "total_score": 0.4336009536425767, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends several structural properties\n    (size, density, degree distribution, clustering, triangle density,\n    and assortativity) into a single scalar value.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees.\n\n    Returns\n    -------\n    float\n        The invariant value.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1.0) / (max_deg + 1.0)\n    degree_variability = 1.0 + std_deg / (max_deg + 1.0)\n    degree_factor = (avg_deg / (max_deg + 1.0)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.149772\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.152461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends several structural properties\n    (size, density, degree distribution, clustering, triangle density,\n    and assortativity) into a single scalar value.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles.\n\n    Returns\n    -------\n    float\n        The invariant value.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n    density    = s['density']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density scaling\n    density_factor = 1.0 + density\n\n    # Combine all components multiplicatively\n    return (size_edge_ratio *\n            degree_factor *\n            clustering_factor *\n            triangle_factor *\n            assort_factor *\n            size_factor *\n            density_factor)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends several structural properties\n    (size, density, degree distribution, clustering, triangle density,\n    and assortativity) into a single scalar value.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles.\n\n    Returns\n    -------\n    float\n        The invariant value.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n    density    = s['density']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density scaling\n    density_factor = 1.0 + density\n\n    # Combine all components multiplicatively\n    return (size_edge_ratio *\n            degree_factor *\n            clustering_factor *\n            triangle_factor *\n            assort_factor *\n            size_factor *\n            density_factor)", "spearman": 0.6750378759468987, "pearson": 0.6377208676115874, "rmse": 2.768144803056992, "mae": 2.622268323424163}}
{"timestamp": "2026-02-17T04:24:16.241717+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i1_p2_57376479", "generation": 4, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends several structural properties\n    (size, density, degree distribution, clustering, triangle density,\n    and assortativity) into a single scalar value.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees.\n\n    Returns\n    -------\n    float\n        The invariant value.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1.0) / (max_deg + 1.0)\n    degree_variability = 1.0 + std_deg / (max_deg + 1.0)\n    degree_factor = (avg_deg / (max_deg + 1.0)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.149772\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.152461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T04:24:58.699075+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i1_p3_701103014", "generation": 4, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends several structural properties\n    (size, density, degree distribution, clustering, triangle density,\n    and assortativity) into a single scalar value.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees.\n\n    Returns\n    -------\n    float\n        The invariant value.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1.0) / (max_deg + 1.0)\n    degree_variability = 1.0 + std_deg / (max_deg + 1.0)\n    degree_factor = (avg_deg / (max_deg + 1.0)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.149772\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.152461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends several structural properties\n    (size, density, degree distribution, clustering, triangle density,\n    and assortativity) into a single scalar value.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        n, m, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles.\n\n    Returns\n    -------\n    float\n        The invariant value.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends several structural properties\n    (size, density, degree distribution, clustering, triangle density,\n    and assortativity) into a single scalar value.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        n, m, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles.\n\n    Returns\n    -------\n    float\n        The invariant value.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T04:25:34.661715+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i1_p4_24133543", "generation": 4, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.44614645858343327, "fitness_mode": "correlation", "simplicity_score": 0.11638009270571165, "novelty_bonus": 0.32315037833918414, "total_score": 0.3775660656662382, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends several structural properties\n    (size, density, degree distribution, clustering, triangle density,\n    and assortativity) into a single scalar value.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees.\n\n    Returns\n    -------\n    float\n        The invariant value.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1.0) / (max_deg + 1.0)\n    degree_variability = 1.0 + std_deg / (max_deg + 1.0)\n    degree_factor = (avg_deg / (max_deg + 1.0)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.149772\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.152461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends several structural properties\n    (size, density, degree distribution, clustering, triangle density,\n    assortativity, and median degree) into a single scalar value.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees.\n\n    Returns\n    -------\n    float\n        The invariant value.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n    density    = s['density']\n    degrees    = s['degrees']\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread      = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor      = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio     = triangles / possible_triangles\n    triangle_factor    = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density boost\n    density_factor = 1 + density\n\n    # Component 8 – median degree influence\n    mid = n // 2\n    median_deg = degrees[mid] if n % 2 == 1 else (degrees[mid - 1] + degrees[mid]) / 2.0\n    median_factor = 1 + median_deg / (max_deg + 1)\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor *\n        median_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends several structural properties\n    (size, density, degree distribution, clustering, triangle density,\n    assortativity, and median degree) into a single scalar value.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        n, m, density, avg_degree, max_degree, min_degree,\n        std_degree, avg_clustering, transitivity,\n        degree_assortativity, num_triangles, degrees.\n\n    Returns\n    -------\n    float\n        The invariant value.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n    density    = s['density']\n    degrees    = s['degrees']\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread      = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor      = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio     = triangles / possible_triangles\n    triangle_factor    = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density boost\n    density_factor = 1 + density\n\n    # Component 8 – median degree influence\n    mid = n // 2\n    median_deg = degrees[mid] if n % 2 == 1 else (degrees[mid - 1] + degrees[mid]) / 2.0\n    median_factor = 1 + median_deg / (max_deg + 1)\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor *\n        median_factor\n    )", "spearman": 0.5146898672466813, "pearson": 0.4749493849456128, "rmse": 2.704400887538064, "mae": 2.5563006283367957}}
{"timestamp": "2026-02-17T04:26:29.089558+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.118693", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:26:29.090078+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 4, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.118693", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:27:06.433459+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 2, "population_idx": 0, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:27:06.437245+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 4, "island_id": 2, "population_idx": 0, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:27:53.369525+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i2_p1_571401595", "generation": 4, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9655222088835534, "fitness_mode": "correlation", "simplicity_score": 0.21956993949421266, "novelty_bonus": 0.19513498035315835, "total_score": 0.5658393166256557, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.134019\nbelow_novelty_threshold: novelty_bonus=0.118693\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The estimate starts from the graph size divided\n    by a connectivity term and is then adjusted multiplicatively for\n    clustering, assortativity, triangle density, degree heterogeneity,\n    and the presence of hubs.  A small skewness correction using the\n    sorted degree list is applied if the list is available.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list (optional)\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity denominator – more edges and higher density shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering and assortativity create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalize very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Optional skewness adjustment using the sorted degree list\n    if degrees:\n        mean_deg = sum(degrees) / len(degrees)\n        sorted_deg = sorted(degrees)\n        mid = len(sorted_deg) // 2\n        median_deg = (\n            sorted_deg[mid]\n            if len(sorted_deg) % 2 == 1\n            else (sorted_deg[mid - 1] + sorted_deg[mid]) / 2\n        )\n        skew = (mean_deg - median_deg) / (std_deg if std_deg > 0 else 1e-6)\n        base *= (1.0 + abs(skew) * 0.1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The estimate starts from the graph size divided\n    by a connectivity term and is then adjusted multiplicatively for\n    clustering, assortativity, triangle density, degree heterogeneity,\n    and the presence of hubs.  A small skewness correction using the\n    sorted degree list is applied if the list is available.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list (optional)\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity denominator – more edges and higher density shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering and assortativity create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalize very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Optional skewness adjustment using the sorted degree list\n    if degrees:\n        mean_deg = sum(degrees) / len(degrees)\n        sorted_deg = sorted(degrees)\n        mid = len(sorted_deg) // 2\n        median_deg = (\n            sorted_deg[mid]\n            if len(sorted_deg) % 2 == 1\n            else (sorted_deg[mid - 1] + sorted_deg[mid]) / 2\n        )\n        skew = (mean_deg - median_deg) / (std_deg if std_deg > 0 else 1e-6)\n        base *= (1.0 + abs(skew) * 0.1)\n\n    return base", "spearman": 0.9267696692417312, "pearson": 0.8121232112462469, "rmse": 14.161130808966583, "mae": 8.225047125362577}}
{"timestamp": "2026-02-17T04:28:38.095720+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i2_p2_307171747", "generation": 4, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9313325330132053, "fitness_mode": "correlation", "simplicity_score": 0.2218830559467793, "novelty_bonus": 0.20578436500506414, "total_score": 0.5472872000728597, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.134019\nbelow_novelty_threshold: novelty_bonus=0.118693\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n    It also includes a small correction that favours networks with\n    hubs (high max_degree relative to avg_degree).\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list (optional)\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering, assortativity and average clustering tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n    base *= (1.0 + avg_clust)\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Penalise very large maximum degree (few hubs) but reward hubs relative to avg\n    hub_factor = 1.0 + avg_deg / (max_deg + 1.0)\n    base *= hub_factor\n    base /= (max_deg + 1.0)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n    It also includes a small correction that favours networks with\n    hubs (high max_degree relative to avg_degree).\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list (optional)\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering, assortativity and average clustering tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n    base *= (1.0 + avg_clust)\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Penalise very large maximum degree (few hubs) but reward hubs relative to avg\n    hub_factor = 1.0 + avg_deg / (max_deg + 1.0)\n    base *= hub_factor\n    base /= (max_deg + 1.0)\n\n    return base", "spearman": 0.8823505587639692, "pearson": 0.7854117856244823, "rmse": 28.11668358446291, "mae": 16.964078282790876}}
{"timestamp": "2026-02-17T04:29:26.000166+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.143898", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:29:26.001118+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 4, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.143898", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:30:01.747376+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 2, "population_idx": 3, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:30:01.748491+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 4, "island_id": 2, "population_idx": 3, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:30:55.931195+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i2_p4_798722002", "generation": 4, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.6793277310924369, "fitness_mode": "correlation", "simplicity_score": 0.2223984364555807, "novelty_bonus": 0.47010923433391083, "total_score": 0.5058642163852594, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.118693\nbelow_novelty_threshold: novelty_bonus=0.143898\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is deliberately simple: it starts from\n    a size / connectivity baseline and applies multiplicative corrections\n    for clustering, assortativity, triangle density and degree heterogeneity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Baseline: size divided by a connectivity term\n    denom_conn = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Corrections for clustering, assortativity and triangles\n    base *= (1.0 + trans)          # transitivity (local loops)\n    base *= (1.0 + abs(assort))    # assortativity (hub mixing)\n    base *= (1.0 + tri / max(m, 1))  # triangle density\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n\n    # Effect of minimum degree (sparse local connectivity)\n    base *= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Effect of maximum degree (hub richness)\n    base /= (1.0 + max_deg / max(avg_deg, 1.0))\n\n    # Additional adjustment using average clustering coefficient\n    base *= (1.0 + avg_clust)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is deliberately simple: it starts from\n    a size / connectivity baseline and applies multiplicative corrections\n    for clustering, assortativity, triangle density and degree heterogeneity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Baseline: size divided by a connectivity term\n    denom_conn = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Corrections for clustering, assortativity and triangles\n    base *= (1.0 + trans)          # transitivity (local loops)\n    base *= (1.0 + abs(assort))    # assortativity (hub mixing)\n    base *= (1.0 + tri / max(m, 1))  # triangle density\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n\n    # Effect of minimum degree (sparse local connectivity)\n    base *= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Effect of maximum degree (hub richness)\n    base /= (1.0 + max_deg / max(avg_deg, 1.0))\n\n    # Additional adjustment using average clustering coefficient\n    base *= (1.0 + avg_clust)\n\n    return base", "spearman": 0.6407035175879399, "pearson": 0.6202254835351082, "rmse": 147.8809370561888, "mae": 105.40582005402688}}
{"timestamp": "2026-02-17T04:31:28.728310+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:31:28.729289+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 4, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:32:07.705388+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 3, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.125096", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:32:07.707358+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 4, "island_id": 3, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:32:45.637176+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.030713", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:32:45.637794+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 4, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.030713", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:33:44.722301+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.114348", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:33:44.722892+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 4, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:34:17.086450+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:34:17.086921+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 4, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:35:08.129848+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g4_i3_p2_871199412", "generation": 4, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.37997599039615837, "fitness_mode": "correlation", "simplicity_score": 0.15313840219771296, "novelty_bonus": 0.33439435985899624, "total_score": 0.38489258706220814, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a novel combination of\n    structural features.  The estimator is purely algebraic, requiring no\n    external libraries or graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n            n                 (int)          # number of vertices\n            m                 (int)          # number of edges\n            density           (float)\n            avg_degree        (float)\n            max_degree        (int)\n            min_degree        (int)\n            std_degree        (float)\n            avg_clustering    (float)\n            transitivity      (float)\n            degree_assortativity (float)\n            num_triangles     (int)\n            degrees           (list[int])   # sorted degree list\n\n    Returns\n    -------\n    float\n        An estimate that grows with the true average shortest‑path length.\n    \"\"\"\n    eps = 1e-12\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_clustering = float(s['avg_clustering'])\n    assortativity = float(s['degree_assortativity'])\n    max_deg = float(s['max_degree'])\n    std_deg = float(s['std_degree'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    # Basic base term: inverse of mean degree times density effects\n    base = n / (m + 1.0)                     # inversely proportional to avg degree\n    base *= (1.0 + density)                  # denser graphs shrink distances\n    base *= (1.0 - avg_clustering)           # high clustering can stretch paths\n    base *= (1.0 - assortativity)            # disassortativity typically shortens paths\n\n    # Triangle density contribution (non‑linear scaling)\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    # Amplify the effect: a bell‑shaped contribution centred at ~0.3\n    tri_term = tri_frac * (1.0 - tri_frac) * 12.0\n    base += tri_term\n\n    # Degree dispersion and heterogeneity adjustment\n    # Compute mean of squared degrees\n    if degrees:\n        avg_sq_deg = sum(d * d for d in degrees) / n\n    else:\n        avg_sq_deg = 0.0\n    deg_disp = std_deg / (max_deg + eps)\n    dispersion_term = deg_disp * avg_sq_deg / (max_deg + eps)\n    base += dispersion_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a mixture of global\n    graph characteristics that have never been combined in the same way.\n    The function only operates on pre‑computed features supplied in *s*.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degs = s['degrees']\n\n    # Triangle fraction, safely handled for very small graphs\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri if possible_tri else 1.0)\n    else:\n        tri_frac = 0.0\n\n    # Mean of squared degrees\n    avg_deg_sq = sum(d * d for d in degs) / n if n else 0.0\n\n    # Core multiplicative component that balances size, density, clustering,\n    # triangle richness, and assortativity in a non‑linear fashion\n    part = (n / (m + 1.0) ** 0.3)          # larger graphs grow slowly\n    part *= (1.0 + density) ** 0.5          # denser graphs shrink distance\n    part *= (1.0 + tri_frac) ** 0.5         # richer triangles imply shorter paths\n    part *= (1.0 - avg_clust) ** 0.5        # high clustering tends to elongate paths\n    part *= (1.0 - assort) ** 0.2           # disassortativity can reduce distances\n\n    # Additive correction driven by degree dispersion and degree heterogeneity\n    add = std_deg * avg_deg_sq / (max_deg + 1.0)\n\n    return part + add\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a handful of\n    pre‑computed structural descriptors.  The expression is a\n    handcrafted non‑linear combination of size, density, clustering,\n    triangle richness, assortativity, degree dispersion and degree\n    heterogeneity.  It involves no graph traversal and requires only\n    built‑in arithmetic operations.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features with the keys\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', and 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # Triangle density (fraction of possible triangles that exist)\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri if possible_tri else 1.0)\n    else:\n        tri_frac = 0.0\n\n    # Mean of squared degrees\n    mean_sq_deg = sum(d * d for d in degs) / n if n else 0.0\n\n    # Core multiplicative factor that balances global connectivity,\n    # density, clustering, triangles and assortativity\n    part = (n / (m + 1.0) ** 0.3)\n    part *= (1.0 + density) ** 0.5\n    part *= (1.0 + tri_frac) ** 0.5\n    part *= (1.0 - avg_clust) ** 0.5\n    part *= (1.0 - assort) ** 0.2\n\n    # Additive correction driven by degree dispersion and heterogeneity\n    add = std_deg * mean_sq_deg / (max_deg + 1.0)\n\n    return part + add\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.125096\nbelow_novelty_threshold: novelty_bonus=0.030713\nbelow_novelty_threshold: novelty_bonus=0.114348\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport math\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a novel, purely algebraic\n    combination of global graph descriptors.\n\n    The expression exploits several non‑linear effects:\n        * The *harmonic mean of degrees* captures how many low‑degree vertices\n          exist – sparse hubs tend to increase typical distances.\n        * A logarithmic term models the classic random‑graph scaling\n          `log(n)/log(avg_degree)` but is modulated by density and\n          clustering.\n        * Triangle density and transitivity are combined multiplicatively to\n          reflect the fact that dense local cliques generally shorten paths.\n        * Degree dispersion is added as a corrective factor, because large\n          heterogeneity can either facilitate shortcuts or create bottlenecks.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics.\n        Expected keys:\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles, degrees.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract variables\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    eps = 1e-12\n\n    # -------- Harmonic mean of the degrees (ignoring zeros) ----------\n    if degs:\n        inv_sum = sum(1.0 / (d + eps) for d in degs if d > 0)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # -------- Triangle fraction ------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # -------- Core multiplicative factor -----------------------------\n    # Base scaling inspired by classic random‑graph behavior\n    base = math.log(1.0 + n * density + eps) / (math.log(1.0 + avg_deg + harmonic_mean + eps))\n\n    # Modulate by clustering, triangle density and transitivity\n    base *= (1.0 + tri_frac) ** 0.5\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n\n    # Influence of assortativity (disassortative networks often shorten paths)\n    base *= (1.0 - assort) ** 0.2\n\n    # -------- Additive correction for degree dispersion --------------\n    disp_term = std_deg * (harmonic_mean - min_deg) / (max_deg + 1.0 + eps)\n\n    return base + disp_term\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from global graph descriptors\n    without performing any traversal.  The expression is a hand‑crafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, and degree heterogeneity.  No external libraries or\n    `import` statements are used.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract variables and cast to float for consistency\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    eps = 1e-12\n\n    # ----------------- Harmonic mean of degrees --------------------\n    if degs:\n        inv_sum = sum(1.0 / (d + eps) for d in degs if d > 0)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ----------------- Triangle fraction ----------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ----------------- Core multiplicative factor -------------------\n    # Ratio of simple linear terms replaces the logarithmic scaling\n    base = (1.0 + n * density + eps) / (1.0 + avg_deg + harmonic_mean + eps)\n\n    # Modulate by clustering, triangle density and transitivity\n    base *= (1.0 + tri_frac) ** 0.5\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n\n    # Influence of assortativity (disassortative networks often shorten paths)\n    base *= (1.0 - assort) ** 0.2\n\n    # ----------------- Additive correction for degree dispersion ----\n    disp_term = std_deg * (harmonic_mean - min_deg) / (max_deg + 1.0 + eps)\n\n    return base + disp_term", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from global graph descriptors\n    without performing any traversal.  The expression is a hand‑crafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, and degree heterogeneity.  No external libraries or\n    `import` statements are used.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract variables and cast to float for consistency\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    eps = 1e-12\n\n    # ----------------- Harmonic mean of degrees --------------------\n    if degs:\n        inv_sum = sum(1.0 / (d + eps) for d in degs if d > 0)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ----------------- Triangle fraction ----------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ----------------- Core multiplicative factor -------------------\n    # Ratio of simple linear terms replaces the logarithmic scaling\n    base = (1.0 + n * density + eps) / (1.0 + avg_deg + harmonic_mean + eps)\n\n    # Modulate by clustering, triangle density and transitivity\n    base *= (1.0 + tri_frac) ** 0.5\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n\n    # Influence of assortativity (disassortative networks often shorten paths)\n    base *= (1.0 - assort) ** 0.2\n\n    # ----------------- Additive correction for degree dispersion ----\n    disp_term = std_deg * (harmonic_mean - min_deg) / (max_deg + 1.0 + eps)\n\n    return base + disp_term", "spearman": -0.5078931973299333, "pearson": -0.32158919335959807, "rmse": 2.0891736726066577, "mae": 1.7939387824418993}}
{"timestamp": "2026-02-17T04:35:08.130933+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 4, "island_id": 3, "population_idx": 2, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:35:52.509442+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.031300", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:35:52.510947+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 4, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.031300", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:36:40.083649+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 3, "population_idx": 3, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.028871", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:36:40.084661+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 4, "island_id": 3, "population_idx": 3, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:37:20.273079+00:00", "event_type": "candidate_rejected", "payload": {"generation": 4, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.046627", "model_name": "gpt-oss:20b", "train_signal": 0.046626650660264106}}
{"timestamp": "2026-02-17T04:37:20.276571+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 5, "model_name": "gpt-oss:20b", "best_val_score": 0.5663240003984669, "no_improve_count": 1}}
{"timestamp": "2026-02-17T04:39:35.372581+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i0_p0_582520546", "generation": 5, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6267947178871548, "fitness_mode": "correlation", "simplicity_score": 0.21912495952497338, "novelty_bonus": 0.16180829631863847, "total_score": 0.42263373745700267, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    num_tri = s['num_triangles']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_m = m.bit_length() - 1 if m > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_m, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.4\n\n    # Adjust for average degree ratio (m/n)\n    base *= (m / n) ** 0.1\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.15\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.08\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.08\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.04\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.135226\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.131431\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjustments based on structural properties\n    base *= (1 - density) ** 0.4\n    base *= (1 + avg_clust) ** -0.15\n    base *= (1 + trans) ** -0.1\n    base *= (1 + num_tri / n) ** -0.08\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.08\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    base *= (1 + abs(assort)) ** 0.04\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    base *= (m / n) ** 0.1\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjustments based on structural properties\n    base *= (1 - density) ** 0.4\n    base *= (1 + avg_clust) ** -0.15\n    base *= (1 + trans) ** -0.1\n    base *= (1 + num_tri / n) ** -0.08\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.08\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    base *= (1 + abs(assort)) ** 0.04\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    base *= (m / n) ** 0.1\n\n    return base", "spearman": 0.6605325133128329, "pearson": 0.4837916203091739, "rmse": 1.150720758538782, "mae": 0.8212177031592836}}
{"timestamp": "2026-02-17T04:40:58.855106+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i0_p1_693417319", "generation": 5, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.47803121248499403, "fitness_mode": "correlation", "simplicity_score": 0.21885219349336266, "novelty_bonus": 0.21123209411739086, "total_score": 0.3668085586461826, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    num_tri = s['num_triangles']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_m = m.bit_length() - 1 if m > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_m, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.4\n\n    # Adjust for average degree ratio (m/n)\n    base *= (m / n) ** 0.1\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.15\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.08\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.08\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.04\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.135226\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.131431\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_m = m.bit_length() - 1 if m > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_m, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base = base * pow(1 - density, 0.3)\n\n    # Adjust for average degree ratio (m/n)\n    base = base * pow(m / n, 0.1)\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base = base * pow(1 + avg_clust, -0.2)\n\n    # Adjust for transitivity – similar effect to clustering\n    base = base * pow(1 + s['transitivity'], -0.15)\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base = base * pow(1 + num_tri / n, -0.1)\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base = base * pow(1 + std_deg / avg_deg, 0.1)\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base = base * pow(1 + max_deg / avg_deg, -0.05)\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base = base * pow(1 + 1 / min_deg, 0.05)\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base = base * pow(1 + abs(assort), 0.05)\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base = base * pow(1 + median_deg / avg_deg, -0.05)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_m = m.bit_length() - 1 if m > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_m, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base = base * pow(1 - density, 0.3)\n\n    # Adjust for average degree ratio (m/n)\n    base = base * pow(m / n, 0.1)\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base = base * pow(1 + avg_clust, -0.2)\n\n    # Adjust for transitivity – similar effect to clustering\n    base = base * pow(1 + s['transitivity'], -0.15)\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base = base * pow(1 + num_tri / n, -0.1)\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base = base * pow(1 + std_deg / avg_deg, 0.1)\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base = base * pow(1 + max_deg / avg_deg, -0.05)\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base = base * pow(1 + 1 / min_deg, 0.05)\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base = base * pow(1 + abs(assort), 0.05)\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base = base * pow(1 + median_deg / avg_deg, -0.05)\n\n    return base", "spearman": 0.5193369834245857, "pearson": 0.3713112649491463, "rmse": 2.2528617232400854, "mae": 2.0763782207422175}}
{"timestamp": "2026-02-17T04:44:04.783588+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i0_p2_176890324", "generation": 5, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6369747899159662, "fitness_mode": "correlation", "simplicity_score": 0.2163783798776253, "novelty_bonus": 0.1572770231176902, "total_score": 0.4193075041288626, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    num_tri = s['num_triangles']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_m = m.bit_length() - 1 if m > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_m, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.4\n\n    # Adjust for average degree ratio (m/n)\n    base *= (m / n) ** 0.1\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.15\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.08\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.08\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.04\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.135226\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.131431\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Clamp values to sane ranges\n    if density < 0.0:\n        density = 0.0\n    if density > 1.0:\n        density = 1.0\n    if avg_clust < 0.0:\n        avg_clust = 0.0\n    if avg_clust > 1.0:\n        avg_clust = 1.0\n    if trans < 0.0:\n        trans = 0.0\n    if trans > 1.0:\n        trans = 1.0\n    if assort < -1.0:\n        assort = -1.0\n    if assort > 1.0:\n        assort = 1.0\n    if num_tri < 0:\n        num_tri = 0\n    if std_deg < 0:\n        std_deg = 0\n    if max_deg < 0:\n        max_deg = 0\n    if min_deg < 0:\n        min_deg = 0\n    if m < 0:\n        m = 0\n    if avg_deg < 0:\n        avg_deg = 0\n\n    # Logarithmic approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = float(log_n) / max(float(log_avg_deg), 1.0)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1.0 - density) ** 0.5\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1.0 + avg_clust) ** -0.2\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1.0 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1.0 + num_tri / n) ** -0.1\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1.0 + std_deg / avg_deg) ** 0.1\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1.0 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1.0 + 1.0 / min_deg) ** 0.05\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1.0 + abs(assort)) ** 0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1.0 + median_deg / avg_deg) ** -0.05\n\n    # Adjust for edge density ratio (m/n) – higher ratio generally shortens paths\n    ratio_m_n = m / n if n > 0 else 1.0\n    if ratio_m_n <= 0.0:\n        ratio_m_n = 1.0\n    base *= ratio_m_n ** 0.1\n\n    # Ensure a non‑negative result\n    if base <= 0.0:\n        base = 0.0\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Clamp values to sane ranges\n    if density < 0.0:\n        density = 0.0\n    if density > 1.0:\n        density = 1.0\n    if avg_clust < 0.0:\n        avg_clust = 0.0\n    if avg_clust > 1.0:\n        avg_clust = 1.0\n    if trans < 0.0:\n        trans = 0.0\n    if trans > 1.0:\n        trans = 1.0\n    if assort < -1.0:\n        assort = -1.0\n    if assort > 1.0:\n        assort = 1.0\n    if num_tri < 0:\n        num_tri = 0\n    if std_deg < 0:\n        std_deg = 0\n    if max_deg < 0:\n        max_deg = 0\n    if min_deg < 0:\n        min_deg = 0\n    if m < 0:\n        m = 0\n    if avg_deg < 0:\n        avg_deg = 0\n\n    # Logarithmic approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = float(log_n) / max(float(log_avg_deg), 1.0)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1.0 - density) ** 0.5\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1.0 + avg_clust) ** -0.2\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1.0 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1.0 + num_tri / n) ** -0.1\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1.0 + std_deg / avg_deg) ** 0.1\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1.0 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1.0 + 1.0 / min_deg) ** 0.05\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1.0 + abs(assort)) ** 0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1.0 + median_deg / avg_deg) ** -0.05\n\n    # Adjust for edge density ratio (m/n) – higher ratio generally shortens paths\n    ratio_m_n = m / n if n > 0 else 1.0\n    if ratio_m_n <= 0.0:\n        ratio_m_n = 1.0\n    base *= ratio_m_n ** 0.1\n\n    # Ensure a non‑negative result\n    if base <= 0.0:\n        base = 0.0\n\n    return base", "spearman": 0.6576974424360609, "pearson": 0.4809499527573012, "rmse": 1.179967559874903, "mae": 0.860163709620617}}
{"timestamp": "2026-02-17T04:45:00.715759+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i0_p3_630788142", "generation": 5, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6237214885954381, "fitness_mode": "correlation", "simplicity_score": 0.21954690955517187, "novelty_bonus": 0.15463603254099445, "total_score": 0.4243772936008809, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    num_tri = s['num_triangles']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_m = m.bit_length() - 1 if m > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_m, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.4\n\n    # Adjust for average degree ratio (m/n)\n    base *= (m / n) ** 0.1\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.15\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.08\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.08\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.04\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.135226\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.131431\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.3\n\n    # Adjust for edge density (m/n)\n    base *= (m / n) ** 0.05\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.05\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.3\n\n    # Adjust for edge density (m/n)\n    base *= (m / n) ** 0.05\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.05\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base", "spearman": 0.6681542038550964, "pearson": 0.4941791554647819, "rmse": 1.12160704146485, "mae": 0.8145047296886488}}
{"timestamp": "2026-02-17T04:45:49.472263+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i0_p4_310702520", "generation": 5, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5144297719087634, "fitness_mode": "correlation", "simplicity_score": 0.21947833032914538, "novelty_bonus": 0.1949317833042975, "total_score": 0.39474076019609683, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    num_tri = s['num_triangles']\n    std_deg = s['std_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_m = m.bit_length() - 1 if m > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_m, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.4\n\n    # Adjust for average degree ratio (m/n)\n    base *= (m / n) ** 0.1\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.15\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.08\n\n    # Adjust for degree variance – high variance can increase path length\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.08\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.04\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑10 proxy)\n    log_n = len(str(n))\n    log_avg_deg = len(str(int(avg_deg))) if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.5\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    if n > 0:\n        base *= (1 + num_tri / n) ** -0.1\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.135226\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.131431\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_m = m.bit_length() - 1 if m > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_m, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.3\n\n    # Adjust for average degree ratio (m/n)\n    if m > 0:\n        base *= (m / n) ** 0.05\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.12\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.08\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.06\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.03\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.02\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.02\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.02\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    num_tri = s['num_triangles']\n    assort = s['degree_assortativity']\n    degrees = s['degrees']\n\n    # Logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_m = m.bit_length() - 1 if m > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_m, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.3\n\n    # Adjust for average degree ratio (m/n)\n    if m > 0:\n        base *= (m / n) ** 0.05\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.12\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.08\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.06\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.03\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.02\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.02\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.02\n\n    return base", "spearman": 0.5847311182779571, "pearson": 0.4231369189760801, "rmse": 2.2359755822317116, "mae": 2.0595281669895247}}
{"timestamp": "2026-02-17T04:46:27.279791+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i1_p0_81009178", "generation": 5, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.149772\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.152461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T04:46:56.495879+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i1_p1_770278299", "generation": 5, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.149772\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.152461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T04:47:41.271823+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i1_p2_346113021", "generation": 5, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.149772\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.152461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T04:50:49.423684+00:00", "event_type": "candidate_rejected", "payload": {"generation": 5, "island_id": 1, "population_idx": 3, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.211717", "model_name": "gpt-oss:20b", "train_signal": 0.21171668667466984}}
{"timestamp": "2026-02-17T04:51:45.883131+00:00", "event_type": "candidate_rejected", "payload": {"generation": 5, "island_id": 1, "population_idx": 4, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.140840", "model_name": "gpt-oss:20b", "train_signal": 0.1408403361344538}}
{"timestamp": "2026-02-17T04:53:00.031885+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i2_p0_81216181", "generation": 5, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.40302521008403364, "fitness_mode": "correlation", "simplicity_score": 0.22257935204184484, "novelty_bonus": 0.36970066980002014, "total_score": 0.3305051983265495, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.118693\nbelow_novelty_threshold: novelty_bonus=0.143898\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.  The formula starts with a\n    connectivity term based on the graph size and average degree,\n    then applies multiplicative corrections for density, clustering,\n    assortativity, triangle density, and degree heterogeneity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n   = s.get('n', 1)\n    m   = s.get('m', 0)\n    density   = s.get('density', 0.0)\n    avg_deg   = s.get('avg_degree', 0.0)\n    max_deg   = s.get('max_degree', 1)\n    min_deg   = s.get('min_degree', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    tri       = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom_conn = (max(avg_deg, 1e-6) + 1.0) * (1.0 + max(density, 0.0))\n    base = n / denom_conn\n\n    # Triangle density correction\n    tri_ratio = tri / m if m > 0 else 0.0\n\n    # Normalise by various structural factors\n    base /= (1.0 + trans)                     # clustering\n    base /= (1.0 + abs(assort))               # assortativity\n    base /= (1.0 + tri_ratio)                # triangle density\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))   # degree heterogeneity\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))   # minimum degree\n    base /= (1.0 + max_deg / max(avg_deg, 1e-6))   # maximum degree\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.  The formula starts with a\n    connectivity term based on the graph size and average degree,\n    then applies multiplicative corrections for density, clustering,\n    assortativity, triangle density, and degree heterogeneity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n   = s.get('n', 1)\n    m   = s.get('m', 0)\n    density   = s.get('density', 0.0)\n    avg_deg   = s.get('avg_degree', 0.0)\n    max_deg   = s.get('max_degree', 1)\n    min_deg   = s.get('min_degree', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    tri       = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom_conn = (max(avg_deg, 1e-6) + 1.0) * (1.0 + max(density, 0.0))\n    base = n / denom_conn\n\n    # Triangle density correction\n    tri_ratio = tri / m if m > 0 else 0.0\n\n    # Normalise by various structural factors\n    base /= (1.0 + trans)                     # clustering\n    base /= (1.0 + abs(assort))               # assortativity\n    base /= (1.0 + tri_ratio)                # triangle density\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))   # degree heterogeneity\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))   # minimum degree\n    base /= (1.0 + max_deg / max(avg_deg, 1e-6))   # maximum degree\n\n    return base", "spearman": 0.350158253956349, "pearson": 0.1449178718396339, "rmse": 2.3244471389938006, "mae": 2.1163472813568402}}
{"timestamp": "2026-02-17T04:53:29.924519+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i2_p1_463251964", "generation": 5, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7372388955582232, "fitness_mode": "correlation", "simplicity_score": 0.22243423636554488, "novelty_bonus": 0.4094485437625762, "total_score": 0.49232403546750847, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.118693\nbelow_novelty_threshold: novelty_bonus=0.143898\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is deliberately compact: it starts from\n    the graph size divided by a connectivity term and then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    avg_clust = s.get('avg_clustering', 0.0)\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans + avg_clust)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / (m + 1e-6))\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (1.0 + max_deg / (avg_deg + 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is deliberately compact: it starts from\n    the graph size divided by a connectivity term and then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    avg_clust = s.get('avg_clustering', 0.0)\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans + avg_clust)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / (m + 1e-6))\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (1.0 + max_deg / (avg_deg + 1e-6))\n\n    return base", "spearman": 0.6500052501312533, "pearson": 0.6810314698336888, "rmse": 70.57048726637586, "mae": 47.861769347697994}}
{"timestamp": "2026-02-17T04:54:01.921178+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i2_p2_786157774", "generation": 5, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9646578631452579, "fitness_mode": "correlation", "simplicity_score": 0.22323284751129324, "novelty_bonus": 0.1994874448704833, "total_score": 0.5662995981332829, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.118693\nbelow_novelty_threshold: novelty_bonus=0.143898\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    The formula combines graph size, connectivity, clustering, degree\n    heterogeneity, assortativity, triangle density, and maximum degree.\n    It is intentionally simple and avoids any explicit graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Safe extraction of features with reasonable defaults\n    n   = s.get('n', 1)\n    m   = s.get('m', 0)\n    density      = s.get('density', 0.0)\n    avg_deg      = s.get('avg_degree', 0.0)\n    max_deg      = s.get('max_degree', 1)\n    min_deg      = s.get('min_degree', 0)\n    std_deg      = s.get('std_degree', 0.0)\n    trans        = s.get('transitivity', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    tri          = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # ---------- Base estimate ----------\n    # Connectivity term: larger avg_deg and density shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / (denom_conn + 1e-6)\n\n    # ---------- Multiplicative adjustments ----------\n    # Clustering creates shortcuts\n    base *= (1.0 + trans)\n\n    # Degree assortativity can affect path length\n    base *= (1.0 + abs(assort))\n\n    # Triangle density (tri/m) boosts shortcut potential\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ---------- Normalisation ----------\n    # Heterogeneous degrees (large std) usually reduce path length\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Very small minimum degree can increase path length\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    The formula combines graph size, connectivity, clustering, degree\n    heterogeneity, assortativity, triangle density, and maximum degree.\n    It is intentionally simple and avoids any explicit graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Safe extraction of features with reasonable defaults\n    n   = s.get('n', 1)\n    m   = s.get('m', 0)\n    density      = s.get('density', 0.0)\n    avg_deg      = s.get('avg_degree', 0.0)\n    max_deg      = s.get('max_degree', 1)\n    min_deg      = s.get('min_degree', 0)\n    std_deg      = s.get('std_degree', 0.0)\n    trans        = s.get('transitivity', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    tri          = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # ---------- Base estimate ----------\n    # Connectivity term: larger avg_deg and density shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / (denom_conn + 1e-6)\n\n    # ---------- Multiplicative adjustments ----------\n    # Clustering creates shortcuts\n    base *= (1.0 + trans)\n\n    # Degree assortativity can affect path length\n    base *= (1.0 + abs(assort))\n\n    # Triangle density (tri/m) boosts shortcut potential\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ---------- Normalisation ----------\n    # Heterogeneous degrees (large std) usually reduce path length\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Very small minimum degree can increase path length\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base", "spearman": 0.9236135903397585, "pearson": 0.8049782332844566, "rmse": 13.852291353732435, "mae": 8.040249282911786}}
{"timestamp": "2026-02-17T04:54:47.679228+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i2_p3_324426737", "generation": 5, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9319087635054021, "fitness_mode": "correlation", "simplicity_score": 0.2207328343862078, "novelty_bonus": 0.24165459442199677, "total_score": 0.551445315263092, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.118693\nbelow_novelty_threshold: novelty_bonus=0.143898\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula starts with the graph size divided by a\n    connectivity term, then applies multiplicative adjustments for\n    clustering, assortativity, triangle density, and normalises by degree\n    spread, median degree, and the maximum degree (via a square‑root\n    penalty).  All operations are simple arithmetic and use only the\n    features provided in the dictionary `s`.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    std_deg    = s.get('std_degree', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    if n <= 1:\n        return 0.0\n\n    # Prevent division by zero\n    eps = 1e-6\n    denom_conn = max(avg_deg, eps) * max(density, eps)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity and median degree\n    if avg_deg > eps:\n        base /= (1.0 + std_deg / avg_deg)\n        # Compute median degree from the sorted list\n        if degrees:\n            mid = len(degrees) // 2\n            median_deg = degrees[mid] if len(degrees) % 2 == 1 else \\\n                         (degrees[mid - 1] + degrees[mid]) / 2\n            base /= (1.0 + median_deg / avg_deg)\n\n    # Square‑root penalty for large maximum degree\n    base /= (max_deg + 1) ** 0.5\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula starts with the graph size divided by a\n    connectivity term, then applies multiplicative adjustments for\n    clustering, assortativity, triangle density, and normalises by degree\n    spread, median degree, and the maximum degree (via a square‑root\n    penalty).  All operations are simple arithmetic and use only the\n    features provided in the dictionary `s`.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    std_deg    = s.get('std_degree', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    if n <= 1:\n        return 0.0\n\n    # Prevent division by zero\n    eps = 1e-6\n    denom_conn = max(avg_deg, eps) * max(density, eps)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity and median degree\n    if avg_deg > eps:\n        base /= (1.0 + std_deg / avg_deg)\n        # Compute median degree from the sorted list\n        if degrees:\n            mid = len(degrees) // 2\n            median_deg = degrees[mid] if len(degrees) % 2 == 1 else \\\n                         (degrees[mid - 1] + degrees[mid]) / 2\n            base /= (1.0 + median_deg / avg_deg)\n\n    # Square‑root penalty for large maximum degree\n    base /= (max_deg + 1) ** 0.5\n\n    return base", "spearman": 0.869604740118503, "pearson": 0.8045065347958953, "rmse": 53.232621072665225, "mae": 33.84776359598934}}
{"timestamp": "2026-02-17T04:55:26.571867+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i2_p4_26965764", "generation": 5, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9677310924369749, "fitness_mode": "correlation", "simplicity_score": 0.22335485883721273, "novelty_bonus": 0.20045697311756405, "total_score": 0.5676243841107219, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula is intentionally simple: it starts\n    from the graph size divided by a connectivity term, then applies\n    multiplicative adjustments for clustering, assortativity, triangle\n    density, and normalises by degree spread and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic attributes with safe defaults\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    if n <= 1:\n        return 0.0\n\n    # Connectivity denominator: more edges and higher density shorten paths\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Clustering and assortativity tend to create shortcuts\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density correction\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree spread: very heterogeneous degrees usually give\n    # shorter paths (hub‑rich networks)\n    base /= (1.0 + std_deg / max(1.0, avg_deg))\n    base /= (1.0 + min_deg / max(1.0, avg_deg))\n\n    # Keep the estimate in a reasonable range using the maximum degree\n    base /= max(max_deg, 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.118693\nbelow_novelty_threshold: novelty_bonus=0.143898\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base", "spearman": 0.9256326408160205, "pearson": 0.7974349185729827, "rmse": 13.89062781328298, "mae": 8.099590493842701}}
{"timestamp": "2026-02-17T04:56:12.333605+00:00", "event_type": "candidate_rejected", "payload": {"generation": 5, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.090804", "model_name": "gpt-oss:20b", "train_signal": 0.09080432172869149}}
{"timestamp": "2026-02-17T04:56:55.732072+00:00", "event_type": "candidate_rejected", "payload": {"generation": 5, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.184058", "model_name": "gpt-oss:20b", "train_signal": 0.18405762304921966}}
{"timestamp": "2026-02-17T04:57:26.615542+00:00", "event_type": "candidate_rejected", "payload": {"generation": 5, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:57:26.615743+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 5, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:57:55.957399+00:00", "event_type": "candidate_rejected", "payload": {"generation": 5, "island_id": 3, "population_idx": 2, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.003121", "model_name": "gpt-oss:20b", "train_signal": 0.00312124849939976}}
{"timestamp": "2026-02-17T04:57:55.957952+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 5, "island_id": 3, "population_idx": 2, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T04:58:37.562738+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g5_i3_p3_840087448", "generation": 5, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.46180072028811525, "fitness_mode": "correlation", "simplicity_score": 0.22054150232247327, "novelty_bonus": 0.4755385817088963, "total_score": 0.38965594712896734, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a novel combination of\n    structural features.  The estimator is purely algebraic, requiring no\n    external libraries or graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n            n                 (int)          # number of vertices\n            m                 (int)          # number of edges\n            density           (float)\n            avg_degree        (float)\n            max_degree        (int)\n            min_degree        (int)\n            std_degree        (float)\n            avg_clustering    (float)\n            transitivity      (float)\n            degree_assortativity (float)\n            num_triangles     (int)\n            degrees           (list[int])   # sorted degree list\n\n    Returns\n    -------\n    float\n        An estimate that grows with the true average shortest‑path length.\n    \"\"\"\n    eps = 1e-12\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_clustering = float(s['avg_clustering'])\n    assortativity = float(s['degree_assortativity'])\n    max_deg = float(s['max_degree'])\n    std_deg = float(s['std_degree'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    # Basic base term: inverse of mean degree times density effects\n    base = n / (m + 1.0)                     # inversely proportional to avg degree\n    base *= (1.0 + density)                  # denser graphs shrink distances\n    base *= (1.0 - avg_clustering)           # high clustering can stretch paths\n    base *= (1.0 - assortativity)            # disassortativity typically shortens paths\n\n    # Triangle density contribution (non‑linear scaling)\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    # Amplify the effect: a bell‑shaped contribution centred at ~0.3\n    tri_term = tri_frac * (1.0 - tri_frac) * 12.0\n    base += tri_term\n\n    # Degree dispersion and heterogeneity adjustment\n    # Compute mean of squared degrees\n    if degrees:\n        avg_sq_deg = sum(d * d for d in degrees) / n\n    else:\n        avg_sq_deg = 0.0\n    deg_disp = std_deg / (max_deg + eps)\n    dispersion_term = deg_disp * avg_sq_deg / (max_deg + eps)\n    base += dispersion_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from global graph descriptors\n    without performing any traversal.  The expression is a hand‑crafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, and degree heterogeneity.  No external libraries or\n    `import` statements are used.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract variables and cast to float for consistency\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    eps = 1e-12\n\n    # ----------------- Harmonic mean of degrees --------------------\n    if degs:\n        inv_sum = sum(1.0 / (d + eps) for d in degs if d > 0)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ----------------- Triangle fraction ----------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ----------------- Core multiplicative factor -------------------\n    # Ratio of simple linear terms replaces the logarithmic scaling\n    base = (1.0 + n * density + eps) / (1.0 + avg_deg + harmonic_mean + eps)\n\n    # Modulate by clustering, triangle density and transitivity\n    base *= (1.0 + tri_frac) ** 0.5\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n\n    # Influence of assortativity (disassortative networks often shorten paths)\n    base *= (1.0 - assort) ** 0.2\n\n    # ----------------- Additive correction for degree dispersion ----\n    disp_term = std_deg * (harmonic_mean - min_deg) / (max_deg + 1.0 + eps)\n\n    return base + disp_term\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a mixture of global\n    graph characteristics that have never been combined in the same way.\n    The function only operates on pre‑computed features supplied in *s*.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degs = s['degrees']\n\n    # Triangle fraction, safely handled for very small graphs\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri if possible_tri else 1.0)\n    else:\n        tri_frac = 0.0\n\n    # Mean of squared degrees\n    avg_deg_sq = sum(d * d for d in degs) / n if n else 0.0\n\n    # Core multiplicative component that balances size, density, clustering,\n    # triangle richness, and assortativity in a non‑linear fashion\n    part = (n / (m + 1.0) ** 0.3)          # larger graphs grow slowly\n    part *= (1.0 + density) ** 0.5          # denser graphs shrink distance\n    part *= (1.0 + tri_frac) ** 0.5         # richer triangles imply shorter paths\n    part *= (1.0 - avg_clust) ** 0.5        # high clustering tends to elongate paths\n    part *= (1.0 - assort) ** 0.2           # disassortativity can reduce distances\n\n    # Additive correction driven by degree dispersion and degree heterogeneity\n    add = std_deg * avg_deg_sq / (max_deg + 1.0)\n\n    return part + add\nRecent failures:\nbelow_train_threshold: train_signal=0.184058\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.003121\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The function combines size, density, clustering, triangle richness,\n    assortativity, and degree dispersion in a novel algebraic form.\n    It does not perform any graph traversal and uses only built‑in Python operations.\n    \n    Parameters\n    ----------\n    s : dict\n        Pre‑computed statistics of a graph.  Expected keys are:\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', 'degrees'.\n    \n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values and cast to float for arithmetic consistency\n    n       = float(s['n'])\n    m       = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Base term – inversely related to the mean degree\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)                    # larger n gives larger baseline\n    base *= (1.0 + density)                # denser graphs shrink path lengths\n    base *= (1.0 - avg_clust)              # high clustering can stretch distances\n    base *= (1.0 - assort)                 # disassortative networks tend to be closer\n\n    # ------------------------------------------------------------------\n    # 2. Triangle fraction with a bell‑shaped amplification\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + 1e-12)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac) * 10.0   # peak around tri_frac≈0.5\n    base += tri_term\n\n    # ------------------------------------------------------------------\n    # 3. Degree dispersion adjustment\n    # ------------------------------------------------------------------\n    if degs:\n        sum_sq = 0.0\n        for d in degs:\n            sum_sq += d * d\n        avg_sq = sum_sq / n\n    else:\n        avg_sq = 0.0\n\n    deg_disp = std_deg / (max_deg + 1e-12)\n    dispersion_term = deg_disp * avg_sq / (max_deg + 1e-12)\n    base += dispersion_term\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The function combines size, density, clustering, triangle richness,\n    assortativity, and degree dispersion in a novel algebraic form.\n    It does not perform any graph traversal and uses only built‑in Python operations.\n    \n    Parameters\n    ----------\n    s : dict\n        Pre‑computed statistics of a graph.  Expected keys are:\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', 'degrees'.\n    \n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values and cast to float for arithmetic consistency\n    n       = float(s['n'])\n    m       = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Base term – inversely related to the mean degree\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)                    # larger n gives larger baseline\n    base *= (1.0 + density)                # denser graphs shrink path lengths\n    base *= (1.0 - avg_clust)              # high clustering can stretch distances\n    base *= (1.0 - assort)                 # disassortative networks tend to be closer\n\n    # ------------------------------------------------------------------\n    # 2. Triangle fraction with a bell‑shaped amplification\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + 1e-12)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac) * 10.0   # peak around tri_frac≈0.5\n    base += tri_term\n\n    # ------------------------------------------------------------------\n    # 3. Degree dispersion adjustment\n    # ------------------------------------------------------------------\n    if degs:\n        sum_sq = 0.0\n        for d in degs:\n            sum_sq += d * d\n        avg_sq = sum_sq / n\n    else:\n        avg_sq = 0.0\n\n    deg_disp = std_deg / (max_deg + 1e-12)\n    dispersion_term = deg_disp * avg_sq / (max_deg + 1e-12)\n    base += dispersion_term\n\n    return base", "spearman": -0.4057721443036076, "pearson": -0.2675547522787929, "rmse": 2.012337793616399, "mae": 1.7197705006542043}}
{"timestamp": "2026-02-17T04:59:17.969973+00:00", "event_type": "candidate_rejected", "payload": {"generation": 5, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.162737", "model_name": "gpt-oss:20b", "train_signal": 0.16273709483793514}}
{"timestamp": "2026-02-17T04:59:17.973358+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 6, "model_name": "gpt-oss:20b", "best_val_score": 0.5676243841107219, "no_improve_count": 0}}
{"timestamp": "2026-02-17T05:00:00.755869+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i0_p0_435611420", "generation": 6, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.628235294117647, "fitness_mode": "correlation", "simplicity_score": 0.2190821898695896, "novelty_bonus": 0.15665994118078175, "total_score": 0.4249470236432354, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.3\n\n    # Adjust for edge density (m/n)\n    base *= (m / n) ** 0.05\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.05\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\n\ndef new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjustments based on structural properties\n    base *= (1 - density) ** 0.4\n    base *= (1 + avg_clust) ** -0.15\n    base *= (1 + trans) ** -0.1\n    base *= (1 + num_tri / n) ** -0.08\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.08\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    base *= (1 + abs(assort)) ** 0.04\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    base *= (m / n) ** 0.1\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.135226\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.131431\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base", "spearman": 0.6682652066301659, "pearson": 0.4902046785855589, "rmse": 1.1433950313854035, "mae": 0.8264347427050578}}
{"timestamp": "2026-02-17T05:00:44.253834+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i0_p1_313706618", "generation": 6, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6179591836734694, "fitness_mode": "correlation", "simplicity_score": 0.21912495952497338, "novelty_bonus": 0.1626866246229972, "total_score": 0.42178195806636326, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.3\n\n    # Adjust for edge density (m/n)\n    base *= (m / n) ** 0.05\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.05\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\n\ndef new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjustments based on structural properties\n    base *= (1 - density) ** 0.4\n    base *= (1 + avg_clust) ** -0.15\n    base *= (1 + trans) ** -0.1\n    base *= (1 + num_tri / n) ** -0.08\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.08\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    base *= (1 + abs(assort)) ** 0.04\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    base *= (m / n) ** 0.1\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.135226\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.131431\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjustments based on structural properties\n    base *= (1 - density) ** 0.35\n    base *= (1 + avg_clust) ** -0.18\n    base *= (1 + trans) ** -0.12\n    base *= (1 + num_tri / n) ** -0.07\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.07\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    base *= (1 + abs(assort)) ** 0.04\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    base *= (m / n) ** 0.09\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjustments based on structural properties\n    base *= (1 - density) ** 0.35\n    base *= (1 + avg_clust) ** -0.18\n    base *= (1 + trans) ** -0.12\n    base *= (1 + num_tri / n) ** -0.07\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.07\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    base *= (1 + abs(assort)) ** 0.04\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    base *= (m / n) ** 0.09\n\n    return base", "spearman": 0.6583019575489388, "pearson": 0.4805687246301843, "rmse": 1.1473001586215819, "mae": 0.8198722417209138}}
{"timestamp": "2026-02-17T05:03:19.930409+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i0_p2_609925320", "generation": 6, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6265066026410564, "fitness_mode": "correlation", "simplicity_score": 0.21912495952497338, "novelty_bonus": 0.16509189290262583, "total_score": 0.4219657751061658, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.3\n\n    # Adjust for edge density (m/n)\n    base *= (m / n) ** 0.05\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.05\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\n\ndef new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjustments based on structural properties\n    base *= (1 - density) ** 0.4\n    base *= (1 + avg_clust) ** -0.15\n    base *= (1 + trans) ** -0.1\n    base *= (1 + num_tri / n) ** -0.08\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.08\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    base *= (1 + abs(assort)) ** 0.04\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    base *= (m / n) ** 0.1\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.135226\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.131431\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjustments based on structural properties\n    base *= (1 - density) ** 0.35\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.06\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.07\n        base *= (1 + max_deg / avg_deg) ** -0.03\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n\n    base *= (1 + abs(assort)) ** 0.04\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    base *= (m / n) ** 0.09\n\n    return base", "extracted_code": "def new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjustments based on structural properties\n    base *= (1 - density) ** 0.35\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.06\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.07\n        base *= (1 + max_deg / avg_deg) ** -0.03\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n\n    base *= (1 + abs(assort)) ** 0.04\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    base *= (m / n) ** 0.09\n\n    return base", "spearman": 0.6572264306607667, "pearson": 0.49109935934604704, "rmse": 1.1332986750561627, "mae": 0.7987702412246327}}
{"timestamp": "2026-02-17T05:05:05.984098+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i0_p3_409006797", "generation": 6, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6461944777911164, "fitness_mode": "correlation", "simplicity_score": 0.218137467882336, "novelty_bonus": 0.1508351981777738, "total_score": 0.4273442646850908, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.3\n\n    # Adjust for edge density (m/n)\n    base *= (m / n) ** 0.05\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.05\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\n\ndef new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjustments based on structural properties\n    base *= (1 - density) ** 0.4\n    base *= (1 + avg_clust) ** -0.15\n    base *= (1 + trans) ** -0.1\n    base *= (1 + num_tri / n) ** -0.08\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.08\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    base *= (1 + abs(assort)) ** 0.04\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    base *= (m / n) ** 0.1\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.135226\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.131431\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base", "spearman": 0.6769324233105829, "pearson": 0.49763552560309, "rmse": 1.1524237490950855, "mae": 0.8350765090777584}}
{"timestamp": "2026-02-17T05:06:02.336098+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i0_p4_271499247", "generation": 6, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6192076830732293, "fitness_mode": "correlation", "simplicity_score": 0.1561723438201606, "novelty_bonus": 0.1697034918544854, "total_score": 0.40881018293704324, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Rough logarithm approximations (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density – denser graphs have shorter paths\n    base *= (1 - density) ** 0.3\n\n    # Adjust for edge density (m/n)\n    base *= (m / n) ** 0.05\n\n    # Adjust for clustering – higher clustering slightly reduces path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for transitivity – similar effect to clustering\n    base *= (1 + trans) ** -0.1\n\n    # Adjust for triangles – more triangles tend to reduce path length\n    base *= (1 + num_tri / n) ** -0.05\n\n    # Adjust for degree variance – high variance can increase path length\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05\n\n    # Adjust for assortativity – positive assortativity can increase path length\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Adjust for minimum degree – very low min degree can inflate path length\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Adjust for maximum degree relative to average – very high max degree can shorten paths\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.05\n\n    # Adjust for median degree – median relative to average gives a robust central tendency\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.05\n\n    return base\n\ndef new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjustments based on structural properties\n    base *= (1 - density) ** 0.4\n    base *= (1 + avg_clust) ** -0.15\n    base *= (1 + trans) ** -0.1\n    base *= (1 + num_tri / n) ** -0.08\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.08\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    base *= (1 + abs(assort)) ** 0.04\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    base *= (m / n) ** 0.1\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.135226\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.131431\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjustments based on structural properties\n    base *= (max(0.0, 1 - density)) ** 0.35\n    base *= (1 + avg_clust) ** -0.18\n    base *= (1 + trans) ** -0.12\n    base *= (1 + num_tri / n) ** -0.06\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.06\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    base *= (1 + abs(assort)) ** 0.04\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    if m > 0:\n        base *= (m / n) ** 0.1\n\n    return max(base, 0.0)\n```", "extracted_code": "def new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjustments based on structural properties\n    base *= (max(0.0, 1 - density)) ** 0.35\n    base *= (1 + avg_clust) ** -0.18\n    base *= (1 + trans) ** -0.12\n    base *= (1 + num_tri / n) ** -0.06\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.06\n        base *= (1 + max_deg / avg_deg) ** -0.04\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04\n\n    base *= (1 + abs(assort)) ** 0.04\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    if m > 0:\n        base *= (m / n) ** 0.1\n\n    return max(base, 0.0)", "spearman": 0.653329333233331, "pearson": 0.47997299636424373, "rmse": 1.1303545189970985, "mae": 0.7996932410478741}}
{"timestamp": "2026-02-17T05:06:42.333906+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:06:42.334847+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 6, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:07:17.519503+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i1_p0_244214900", "generation": 6, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.4650660264105642, "fitness_mode": "correlation", "simplicity_score": 0.11532724326247604, "novelty_bonus": 0.3862536563414084, "total_score": 0.3470687487349972, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.152461\nbelow_train_threshold: train_signal=0.211717\nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport numpy as np\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends multiple structural features\n    into a single scalar.  It uses the pre‑computed statistics in `s`\n    (see the problem statement for the available keys).\n\n    The invariant is a multiplicative combination of the following\n    components:\n\n    1. size_edge_ratio   – captures how many nodes per edge.\n    2. degree_factor     – normalises the average degree by the maximum\n                           degree and incorporates degree spread and\n                           variability.\n    3. clustering_factor – dampens the influence of local clustering\n                           relative to global transitivity.\n    4. triangle_factor   – boosts the value when many triangles are\n                           present.\n    5. assort_factor     – accounts for degree assortativity.\n    6. size_factor       – scales with the square root of the node count.\n    7. density_factor    – incorporates overall edge density.\n    8. degree_cv_factor  – adds a term for the coefficient of variation\n                           of the degree distribution.\n    9. degree_skew_factor– captures the skewness of the degree\n                           distribution (max/min ratio).\n\n    The product of these components yields a single invariant that\n    reflects a wide range of graph properties while remaining\n    computationally inexpensive.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    density = s['density']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density scaling\n    density_factor = np.sqrt(density + 1e-6)\n\n    # Component 8 – coefficient of variation of degrees\n    degree_cv_factor = 1.0 + (std_deg / (avg_deg + 1e-6))\n\n    # Component 9 – degree skewness (max/min ratio)\n    degree_skew_factor = 1.0 + (max_deg / (min_deg + 1e-6))\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor *\n        degree_cv_factor *\n        degree_skew_factor\n    )\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    density = s['density']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density scaling\n    density_factor = (density + 1e-6) ** 0.5\n\n    # Component 8 – coefficient of variation of degrees\n    degree_cv_factor = 1.0 + (std_deg / (avg_deg + 1e-6))\n\n    # Component 9 – degree skewness (max/min ratio)\n    degree_skew_factor = 1.0 + (max_deg / (min_deg + 1e-6))\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor *\n        degree_cv_factor *\n        degree_skew_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    density = s['density']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density scaling\n    density_factor = (density + 1e-6) ** 0.5\n\n    # Component 8 – coefficient of variation of degrees\n    degree_cv_factor = 1.0 + (std_deg / (avg_deg + 1e-6))\n\n    # Component 9 – degree skewness (max/min ratio)\n    degree_skew_factor = 1.0 + (max_deg / (min_deg + 1e-6))\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor *\n        degree_cv_factor *\n        degree_skew_factor\n    )", "spearman": 0.416254406360159, "pearson": 0.45388438946400267, "rmse": 2.4492665666311666, "mae": 2.3146509789781486}}
{"timestamp": "2026-02-17T05:07:17.521016+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 6, "island_id": 1, "population_idx": 0, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:07:45.667090+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 1, "population_idx": 1, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.166867", "model_name": "gpt-oss:20b", "train_signal": 0.16686674669867946}}
{"timestamp": "2026-02-17T05:10:51.591179+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i1_p2_774740538", "generation": 6, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6001920768307323, "fitness_mode": "correlation", "simplicity_score": 0.11979356293275192, "novelty_bonus": 0.2404110102752568, "total_score": 0.4336009536425767, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.140840\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.166867\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    \"\"\"\n    Composite invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density influence\n    density_factor = 1.0 + density\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor\n    )", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density influence\n    density_factor = 1.0 + density\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor\n    )", "spearman": 0.6750378759468987, "pearson": 0.6377208676115874, "rmse": 2.768144803056992, "mae": 2.622268323424163}}
{"timestamp": "2026-02-17T05:11:54.996251+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i1_p3_671418961", "generation": 6, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12100496779361278, "novelty_bonus": 0.185688142203555, "total_score": 0.46032969677630303, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.140840\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.166867\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = float(n) / (float(m) + 1.0)\n\n    # Degree spread and variability\n    denom = float(max_deg) + 1.0\n    degree_spread = (float(max_deg) - float(min_deg) + 1.0) / denom\n    degree_variability = 1.0 + float(std_deg) / denom\n    degree_factor = (float(avg_deg) / denom) * degree_spread * degree_variability\n\n    # Clustering dampening (local vs global)\n    clustering_factor = (1.0 + float(avg_cluster)) / (1.0 + float(trans))\n\n    # Triangle density boost\n    if n > 2:\n        possible_triangles = float(n) * (float(n) - 1.0) * (float(n) - 2.0) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = float(triangles) / possible_triangles\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(float(assort))\n\n    # Size scaling\n    size_factor = float(n) ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = float(n) / (float(m) + 1.0)\n\n    # Degree spread and variability\n    denom = float(max_deg) + 1.0\n    degree_spread = (float(max_deg) - float(min_deg) + 1.0) / denom\n    degree_variability = 1.0 + float(std_deg) / denom\n    degree_factor = (float(avg_deg) / denom) * degree_spread * degree_variability\n\n    # Clustering dampening (local vs global)\n    clustering_factor = (1.0 + float(avg_cluster)) / (1.0 + float(trans))\n\n    # Triangle density boost\n    if n > 2:\n        possible_triangles = float(n) * (float(n) - 1.0) * (float(n) - 2.0) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = float(triangles) / possible_triangles\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(float(assort))\n\n    # Size scaling\n    size_factor = float(n) ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T05:12:25.187824+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i1_p4_596843314", "generation": 6, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.140840\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.166867\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    The function uses only built‑in operations and the pre‑computed features\n    supplied in the dictionary `s`.  No graph traversal or external imports\n    are required.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0          # avoid division by zero\n    degree_spread     = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor      = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    The function uses only built‑in operations and the pre‑computed features\n    supplied in the dictionary `s`.  No graph traversal or external imports\n    are required.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0          # avoid division by zero\n    degree_spread     = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor      = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T05:13:10.695021+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i2_p0_725968418", "generation": 6, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9646578631452579, "fitness_mode": "correlation", "simplicity_score": 0.22335485883721273, "novelty_bonus": 0.1994874448704833, "total_score": 0.5663240003984669, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.118693\nbelow_novelty_threshold: novelty_bonus=0.143898\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from pre‑computed graph\n    statistics.  The estimate is a simple rational expression that\n    combines the size of the graph, its connectivity, clustering,\n    assortativity, triangle density and degree heterogeneity.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic connectivity terms\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    tri       = s.get('num_triangles', 0)\n    m         = s.get('m', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Avoid division by zero\n    denom = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from pre‑computed graph\n    statistics.  The estimate is a simple rational expression that\n    combines the size of the graph, its connectivity, clustering,\n    assortativity, triangle density and degree heterogeneity.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic connectivity terms\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    tri       = s.get('num_triangles', 0)\n    m         = s.get('m', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Avoid division by zero\n    denom = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base", "spearman": 0.9236135903397585, "pearson": 0.804977620128539, "rmse": 13.852416981972354, "mae": 8.040305045467084}}
{"timestamp": "2026-02-17T05:13:49.945846+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i2_p1_61981901", "generation": 6, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9687875150060024, "fitness_mode": "correlation", "simplicity_score": 0.22140464171531832, "novelty_bonus": 0.17789249509978344, "total_score": 0.5585749500298276, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.118693\nbelow_novelty_threshold: novelty_bonus=0.143898\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Fallback: compute average degree from the list if not provided\n    if avg_deg == 0.0 and degrees:\n        avg_deg = sum(degrees) / len(degrees)\n\n    # Base connectivity estimate: larger n and lower avg degree/density → longer paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude matters)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalize an excessively large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Fallback: compute average degree from the list if not provided\n    if avg_deg == 0.0 and degrees:\n        avg_deg = sum(degrees) / len(degrees)\n\n    # Base connectivity estimate: larger n and lower avg degree/density → longer paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude matters)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalize an excessively large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base", "spearman": 0.921852546313658, "pearson": 0.8278927633986597, "rmse": 18.635334323629447, "mae": 10.83454993053741}}
{"timestamp": "2026-02-17T05:14:41.672913+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.085798", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:14:41.673445+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 6, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.085798", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:15:08.121238+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 2, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.128567", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:15:08.121825+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 6, "island_id": 2, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:16:10.432810+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.136587", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:16:10.433352+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 6, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.136587", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:16:52.488352+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 2, "population_idx": 3, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.136587", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:16:52.488760+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 6, "island_id": 2, "population_idx": 3, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:17:30.882072+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g6_i2_p4_782137058", "generation": 6, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.967154861944778, "fitness_mode": "correlation", "simplicity_score": 0.2218830559467793, "novelty_bonus": 0.1868527255264647, "total_score": 0.5631812475677633, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.085798\nbelow_novelty_threshold: novelty_bonus=0.128567\nbelow_novelty_threshold: novelty_bonus=0.136587\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed graph\n    statistics.  The estimate is a compact, algebraic combination of the\n    following features:\n\n    * Effective average degree – the harmonic mean of the non‑zero degrees.\n    * Graph size – the number of nodes.\n    * Connectivity – product of effective degree and edge density.\n    * Structural shortcuts – clustering (transitivity) and triangle density.\n    * Degree heterogeneity – standard deviation and minimum degree.\n    * Hub penalty – maximum degree.\n\n    The formula is deliberately simple, uses only arithmetic operations,\n    and does not invoke any graph traversal algorithms.\n    \"\"\"\n    # Basic graph attributes with safe defaults\n    n        = s.get('n', 1)\n    m        = s.get('m', 0)\n    density  = s.get('density', 0.0)\n    trans    = s.get('transitivity', 0.0)\n    assort   = s.get('degree_assortativity', 0.0)\n    tri      = s.get('num_triangles', 0)\n    std_deg  = s.get('std_degree', 0.0)\n    min_deg  = s.get('min_degree', 0)\n    max_deg  = s.get('max_degree', 1)\n    degrees  = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # 1. Effective average degree – harmonic mean of non‑zero degrees\n    # ------------------------------------------------------------------\n    pos_degs = [d for d in degrees if d > 0]\n    if pos_degs:\n        harmonic = len(pos_degs) / sum(1.0 / d for d in pos_degs)\n    else:\n        harmonic = 1.0                     # fallback when no positive degree\n\n    # ------------------------------------------------------------------\n    # 2. Base estimate: size divided by connectivity\n    # ------------------------------------------------------------------\n    denom_conn = max(harmonic, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # 3. Shortcuts from clustering and assortativity\n    # ------------------------------------------------------------------\n    base *= (1.0 + trans)                     # transitivity as a shortcut factor\n    base *= (1.0 + abs(assort))               # assortativity influences path length\n\n    # ------------------------------------------------------------------\n    # 4. Triangle density adjustment\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)               # more triangles → shorter paths\n\n    # ------------------------------------------------------------------\n    # 5. Normalize by degree heterogeneity\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(harmonic, 1e-6))\n    base /= (1.0 + min_deg / max(harmonic, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 6. Penalize very large maximum degree (few hubs)\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1.0)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed graph\n    statistics.  The estimate is a compact, algebraic combination of the\n    following features:\n\n    * Effective average degree – the harmonic mean of the non‑zero degrees.\n    * Graph size – the number of nodes.\n    * Connectivity – product of effective degree and edge density.\n    * Structural shortcuts – clustering (transitivity) and triangle density.\n    * Degree heterogeneity – standard deviation and minimum degree.\n    * Hub penalty – maximum degree.\n\n    The formula is deliberately simple, uses only arithmetic operations,\n    and does not invoke any graph traversal algorithms.\n    \"\"\"\n    # Basic graph attributes with safe defaults\n    n        = s.get('n', 1)\n    m        = s.get('m', 0)\n    density  = s.get('density', 0.0)\n    trans    = s.get('transitivity', 0.0)\n    assort   = s.get('degree_assortativity', 0.0)\n    tri      = s.get('num_triangles', 0)\n    std_deg  = s.get('std_degree', 0.0)\n    min_deg  = s.get('min_degree', 0)\n    max_deg  = s.get('max_degree', 1)\n    degrees  = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # 1. Effective average degree – harmonic mean of non‑zero degrees\n    # ------------------------------------------------------------------\n    pos_degs = [d for d in degrees if d > 0]\n    if pos_degs:\n        harmonic = len(pos_degs) / sum(1.0 / d for d in pos_degs)\n    else:\n        harmonic = 1.0                     # fallback when no positive degree\n\n    # ------------------------------------------------------------------\n    # 2. Base estimate: size divided by connectivity\n    # ------------------------------------------------------------------\n    denom_conn = max(harmonic, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # 3. Shortcuts from clustering and assortativity\n    # ------------------------------------------------------------------\n    base *= (1.0 + trans)                     # transitivity as a shortcut factor\n    base *= (1.0 + abs(assort))               # assortativity influences path length\n\n    # ------------------------------------------------------------------\n    # 4. Triangle density adjustment\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)               # more triangles → shorter paths\n\n    # ------------------------------------------------------------------\n    # 5. Normalize by degree heterogeneity\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(harmonic, 1e-6))\n    base /= (1.0 + min_deg / max(harmonic, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 6. Penalize very large maximum degree (few hubs)\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1.0)\n\n    return base", "spearman": 0.925497637440936, "pearson": 0.8208775529376366, "rmse": 14.785419734898321, "mae": 8.633148115017644}}
{"timestamp": "2026-02-17T05:18:21.327461+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.118842", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:18:21.328007+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 6, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.118842", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:18:55.811089+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 3, "population_idx": 0, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.172917", "model_name": "gpt-oss:20b", "train_signal": 0.17291716686674669}}
{"timestamp": "2026-02-17T05:18:55.811930+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 6, "island_id": 3, "population_idx": 0, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:19:31.785970+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:19:31.787235+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 6, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:20:03.486005+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.084836", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:20:03.486511+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 6, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:20:37.692336+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.163217", "model_name": "gpt-oss:20b", "train_signal": 0.1632172869147659}}
{"timestamp": "2026-02-17T05:21:27.328379+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.034537", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:21:27.332843+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 6, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.034537", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:22:11.965199+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 3, "population_idx": 3, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.043357", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:22:11.966065+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 6, "island_id": 3, "population_idx": 3, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:22:49.403478+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:22:49.404520+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 6, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:23:18.227535+00:00", "event_type": "candidate_rejected", "payload": {"generation": 6, "island_id": 3, "population_idx": 4, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.094739", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:23:18.228206+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 6, "island_id": 3, "population_idx": 4, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:23:18.231183+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 7, "model_name": "gpt-oss:20b", "best_val_score": 0.5676243841107219, "no_improve_count": 1}}
{"timestamp": "2026-02-17T05:24:06.103012+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 0, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.148962", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:24:06.103924+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 7, "island_id": 0, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.148962", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:24:35.944914+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 0, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.148619", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:24:35.945771+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 7, "island_id": 0, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:25:14.224578+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:25:14.226367+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 7, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:25:34.606986+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i0_p1_733357881", "generation": 7, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6136374549819928, "fitness_mode": "correlation", "simplicity_score": 0.2188317116485725, "novelty_bonus": 0.1568341054257486, "total_score": 0.418622769112318, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.131431\nbelow_novelty_threshold: novelty_bonus=0.148962\nbelow_novelty_threshold: novelty_bonus=0.148619\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    import math\n\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.25             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.15                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.07          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.07   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.04  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.04            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.06                     # edge density adjustment\n    base *= (log_n + 1) ** 0.02                 # mild scaling with graph size\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.25             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.15                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.07          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.07   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.04  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.04            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.06                     # edge density adjustment\n    base *= (log_n + 1) ** 0.02                 # mild scaling with graph size\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.25             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.15                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.07          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.07   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.04  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.04            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.06                     # edge density adjustment\n    base *= (log_n + 1) ** 0.02                 # mild scaling with graph size\n\n    return base", "spearman": 0.6556123903097578, "pearson": 0.47935695425444746, "rmse": 1.2004965175234774, "mae": 0.8677981098900358}}
{"timestamp": "2026-02-17T05:25:34.607543+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 7, "island_id": 0, "population_idx": 1, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:26:29.987975+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.146974", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:26:29.988793+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 7, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.146974", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:26:59.493090+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 0, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.141697", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:26:59.493728+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 7, "island_id": 0, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:28:02.121918+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i0_p3_807795968", "generation": 7, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.628235294117647, "fitness_mode": "correlation", "simplicity_score": 0.2187102608464588, "novelty_bonus": 0.15665994118078175, "total_score": 0.42487263783860924, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.146974\nbelow_novelty_threshold: novelty_bonus=0.141697\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from pre‑computed graph features.\n    The formula combines a logarithmic baseline (motivated by random‑graph theory)\n    with multiplicative adjustments for density, clustering, transitivity,\n    triangle density, degree heterogeneity, hubs, low‑degree vertices,\n    assortativity, median degree, and edge density.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic baseline (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= pow(max(1 - density, 1e-6), 0.4)          # denser → shorter paths\n    base *= pow(1 + avg_clust, -0.2)                 # higher clustering → shorter paths\n    base *= pow(1 + trans, -0.1)                     # transitivity effect\n    base *= pow(1 + num_tri / n, -0.05)              # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= pow(1 + std_deg / avg_deg, 0.05)     # high degree variance → longer paths\n        base *= pow(1 + max_deg / avg_deg, -0.03)    # hubs shorten paths\n\n    if min_deg > 0:\n        base *= pow(1 + 1 / min_deg, 0.03)           # very low min degree → longer paths\n\n    base *= pow(1 + abs(assort), 0.03)                # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= pow(1 + median_deg / avg_deg, -0.03)\n\n    base *= pow(m / max(n, 1), 0.05)                  # edge density adjustment\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from pre‑computed graph features.\n    The formula combines a logarithmic baseline (motivated by random‑graph theory)\n    with multiplicative adjustments for density, clustering, transitivity,\n    triangle density, degree heterogeneity, hubs, low‑degree vertices,\n    assortativity, median degree, and edge density.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic baseline (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= pow(max(1 - density, 1e-6), 0.4)          # denser → shorter paths\n    base *= pow(1 + avg_clust, -0.2)                 # higher clustering → shorter paths\n    base *= pow(1 + trans, -0.1)                     # transitivity effect\n    base *= pow(1 + num_tri / n, -0.05)              # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= pow(1 + std_deg / avg_deg, 0.05)     # high degree variance → longer paths\n        base *= pow(1 + max_deg / avg_deg, -0.03)    # hubs shorten paths\n\n    if min_deg > 0:\n        base *= pow(1 + 1 / min_deg, 0.03)           # very low min degree → longer paths\n\n    base *= pow(1 + abs(assort), 0.03)                # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= pow(1 + median_deg / avg_deg, -0.03)\n\n    base *= pow(m / max(n, 1), 0.05)                  # edge density adjustment\n\n    return base", "spearman": 0.6682652066301659, "pearson": 0.4902046785855589, "rmse": 1.1433950313854035, "mae": 0.8264347427050578}}
{"timestamp": "2026-02-17T05:28:43.002044+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i0_p4_592331101", "generation": 7, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.628235294117647, "fitness_mode": "correlation", "simplicity_score": 0.21899754220321135, "novelty_bonus": 0.15665994118078175, "total_score": 0.42493009410995974, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.146974\nbelow_novelty_threshold: novelty_bonus=0.141697\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula combines a logarithmic baseline with structural adjustments inspired\n    by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / max(n, 1)) ** 0.05             # edge density adjustment\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula combines a logarithmic baseline with structural adjustments inspired\n    by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / max(n, 1)) ** 0.05             # edge density adjustment\n\n    return base", "spearman": 0.6682652066301659, "pearson": 0.4902046785855589, "rmse": 1.1433950313854035, "mae": 0.8264347427050578}}
{"timestamp": "2026-02-17T05:29:19.934303+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i1_p0_740408347", "generation": 7, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6001920768307323, "fitness_mode": "correlation", "simplicity_score": 0.11988829658576378, "novelty_bonus": 0.2404110102752568, "total_score": 0.4336199003731791, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.140840\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.166867\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends several structural features into a single scalar.\n    The formula combines:\n        - size‑to‑edge ratio\n        - degree spread and variability\n        - clustering dampening (local vs global)\n        - triangle density boost\n        - assortativity influence\n        - size scaling\n        - density adjustment\n    All components are multiplicative, ensuring that each aspect of the graph\n    influences the final value.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1\n    degree_spread     = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor     = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio     = triangles / possible_triangles\n    triangle_factor    = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density adjustment\n    density_factor = 1 + density\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends several structural features into a single scalar.\n    The formula combines:\n        - size‑to‑edge ratio\n        - degree spread and variability\n        - clustering dampening (local vs global)\n        - triangle density boost\n        - assortativity influence\n        - size scaling\n        - density adjustment\n    All components are multiplicative, ensuring that each aspect of the graph\n    influences the final value.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1\n    degree_spread     = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor     = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio     = triangles / possible_triangles\n    triangle_factor    = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density adjustment\n    density_factor = 1 + density\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor\n    )", "spearman": 0.6750378759468987, "pearson": 0.6377208676115874, "rmse": 2.768144803056992, "mae": 2.622268323424163}}
{"timestamp": "2026-02-17T05:30:18.858274+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 1, "population_idx": 1, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.140840", "model_name": "gpt-oss:20b", "train_signal": 0.1408403361344538}}
{"timestamp": "2026-02-17T05:31:25.038361+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i1_p2_369074026", "generation": 7, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6001920768307323, "fitness_mode": "correlation", "simplicity_score": 0.11970017056432274, "novelty_bonus": 0.2404110102752568, "total_score": 0.4335822751688909, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.166867\nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles if possible_triangles > 0 else 0.0\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = pow(n, 0.5)\n\n    # Density factor\n    density_factor = 1.0 + density\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles if possible_triangles > 0 else 0.0\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = pow(n, 0.5)\n\n    # Density factor\n    density_factor = 1.0 + density\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor\n    )", "spearman": 0.6750378759468987, "pearson": 0.6377208676115874, "rmse": 2.768144803056992, "mae": 2.622268323424163}}
{"timestamp": "2026-02-17T05:32:01.177013+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i1_p3_169977861", "generation": 7, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6001920768307323, "fitness_mode": "correlation", "simplicity_score": 0.11976228479567613, "novelty_bonus": 0.2404110102752568, "total_score": 0.4335946980151616, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.166867\nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – density influence\n    density_factor = 1.0 + density\n\n    # Component 7 – size scaling\n    size_factor = pow(n, 0.5)\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        density_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – density influence\n    density_factor = 1.0 + density\n\n    # Component 7 – size scaling\n    size_factor = pow(n, 0.5)\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        density_factor *\n        size_factor\n    )", "spearman": 0.6750378759468987, "pearson": 0.6377208676115873, "rmse": 2.768144803056992, "mae": 2.622268323424163}}
{"timestamp": "2026-02-17T05:33:24.777374+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i1_p4_833427326", "generation": 7, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.166867\nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T05:34:08.807565+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:34:08.808549+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 7, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:34:32.591613+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i2_p0_492560184", "generation": 7, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9757022809123649, "fitness_mode": "correlation", "simplicity_score": 0.22131298568177266, "novelty_bonus": 0.1511133895024238, "total_score": 0.5631959539705813, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.085798\nbelow_novelty_threshold: novelty_bonus=0.128567\nbelow_novelty_threshold: novelty_bonus=0.136587\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport math\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    \n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n    \n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic connectivity term (inverse of avg_degree * density)\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering and assortativity create shortcuts\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    m     = s.get('m', 0)\n    tri   = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree distribution: use median degree to capture central tendency\n    degrees = s.get('degrees', [])\n    if degrees:\n        l = len(degrees)\n        mid = l // 2\n        median_deg = degrees[mid] if l % 2 == 1 else (degrees[mid - 1] + degrees[mid]) / 2.0\n        base *= (1.0 + median_deg / max(avg_deg, 1e-6))\n\n    # Degree heterogeneity factor\n    std_deg = s.get('std_degree', 0.0)\n    base *= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise extremely high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1)\n\n    # Optional: dampen with a logarithmic factor of max degree to keep values in range\n    base /= math.log(max_deg + 2)\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    \n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic connectivity term (inverse of avg_degree * density)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering and assortativity create shortcuts\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree distribution: use median degree to capture central tendency\n    degrees = s.get('degrees', [])\n    if degrees:\n        l = len(degrees)\n        mid = l // 2\n        median_deg = degrees[mid] if l % 2 == 1 else (degrees[mid - 1] + degrees[mid]) / 2.0\n        base *= (1.0 + median_deg / max(avg_deg, 1e-6))\n\n    # Degree heterogeneity factor\n    std_deg = s.get('std_degree', 0.0)\n    base *= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise extremely high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1)\n\n    return base", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    \n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic connectivity term (inverse of avg_degree * density)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering and assortativity create shortcuts\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree distribution: use median degree to capture central tendency\n    degrees = s.get('degrees', [])\n    if degrees:\n        l = len(degrees)\n        mid = l // 2\n        median_deg = degrees[mid] if l % 2 == 1 else (degrees[mid - 1] + degrees[mid]) / 2.0\n        base *= (1.0 + median_deg / max(avg_deg, 1e-6))\n\n    # Degree heterogeneity factor\n    std_deg = s.get('std_degree', 0.0)\n    base *= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise extremely high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1)\n\n    return base", "spearman": 0.9471986799669994, "pearson": 0.7342281985656743, "rmse": 104.66036315648087, "mae": 59.86021722728738}}
{"timestamp": "2026-02-17T05:34:32.593035+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 7, "island_id": 2, "population_idx": 0, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:35:10.387304+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i2_p1_102180582", "generation": 7, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9230732292917166, "fitness_mode": "correlation", "simplicity_score": 0.15785526236365877, "novelty_bonus": 0.2305007792275826, "total_score": 0.5367064358697473, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.128567\nbelow_novelty_threshold: novelty_bonus=0.136587\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of pre‑computed graph statistics.\n    The formula combines size, connectivity, clustering, assortativity, degree\n    heterogeneity, and a median‑degree adjustment.  No external libraries are used.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n    degrees   = s.get('degrees', [])\n\n    # Median degree (fallback to average if list missing)\n    if degrees:\n        mid = len(degrees) // 2\n        median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = avg_deg\n\n    # Base estimate inversely related to connectivity\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Median‑degree scaling (more balanced degrees tend to increase path length)\n    base *= (median_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return max(base, 0.0)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of pre‑computed graph statistics.\n    The formula combines size, connectivity, clustering, assortativity, degree\n    heterogeneity, and a median‑degree adjustment.  No external libraries are used.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n    degrees   = s.get('degrees', [])\n\n    # Median degree (fallback to average if list missing)\n    if degrees:\n        mid = len(degrees) // 2\n        median_deg = degrees[mid] if len(degrees) % 2 else (degrees[mid - 1] + degrees[mid]) / 2.0\n    else:\n        median_deg = avg_deg\n\n    # Base estimate inversely related to connectivity\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Median‑degree scaling (more balanced degrees tend to increase path length)\n    base *= (median_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return max(base, 0.0)", "spearman": 0.8719702992574815, "pearson": 0.7310390682040094, "rmse": 11.871425062151454, "mae": 6.798847816471416}}
{"timestamp": "2026-02-17T05:35:45.528495+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i2_p2_978103280", "generation": 7, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9359423769507803, "fitness_mode": "correlation", "simplicity_score": 0.22046122305667584, "novelty_bonus": 0.21984753805918122, "total_score": 0.5532783368248595, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.128567\nbelow_novelty_threshold: novelty_bonus=0.136587\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    The formula balances graph size, connectivity, clustering, degree\n    heterogeneity, assortativity and the harmonic mean of degrees.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic graph statistics\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # Connectivity base: larger graphs or sparser graphs give longer paths\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # Shortcuts from clustering and assortativity\n    # ------------------------------------------------------------------\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)          # use transitivity as an additional clustering proxy\n    base *= (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # Triangle density (more triangles -> shorter paths)\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # Degree heterogeneity normalisation\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # Penalise very large maximum degree (few hubs)\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1)\n\n    # ------------------------------------------------------------------\n    # Harmonic mean of degrees: a high harmonic mean indicates many low‑degree nodes\n    # which typically increase average path length\n    # ------------------------------------------------------------------\n    if degrees:\n        harmonic_sum = sum(1.0 / d for d in degrees if d > 0)\n        harmonic_mean = len(degrees) / harmonic_sum if harmonic_sum > 0 else 1.0\n        base *= (harmonic_mean / max(avg_deg, 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    The formula balances graph size, connectivity, clustering, degree\n    heterogeneity, assortativity and the harmonic mean of degrees.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic graph statistics\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # Connectivity base: larger graphs or sparser graphs give longer paths\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # Shortcuts from clustering and assortativity\n    # ------------------------------------------------------------------\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)          # use transitivity as an additional clustering proxy\n    base *= (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # Triangle density (more triangles -> shorter paths)\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # Degree heterogeneity normalisation\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # Penalise very large maximum degree (few hubs)\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1)\n\n    # ------------------------------------------------------------------\n    # Harmonic mean of degrees: a high harmonic mean indicates many low‑degree nodes\n    # which typically increase average path length\n    # ------------------------------------------------------------------\n    if degrees:\n        harmonic_sum = sum(1.0 / d for d in degrees if d > 0)\n        harmonic_mean = len(degrees) / harmonic_sum if harmonic_sum > 0 else 1.0\n        base *= (harmonic_mean / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.8864636615915399, "pearson": 0.7637696783480696, "rmse": 15.106686567501832, "mae": 8.609263783408176}}
{"timestamp": "2026-02-17T05:36:14.589020+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:36:14.590247+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 7, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:36:56.968340+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 2, "population_idx": 3, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:36:56.969543+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 7, "island_id": 2, "population_idx": 3, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:37:42.080751+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i2_p4_835411918", "generation": 7, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9146218487394957, "fitness_mode": "correlation", "simplicity_score": 0.15923032520197838, "novelty_bonus": 0.20944788224608768, "total_score": 0.5483007702227347, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.128567\nbelow_novelty_threshold: novelty_bonus=0.136587\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic graph properties with safe defaults\n    n      = float(s.get('n', 1))\n    m      = float(s.get('m', 0))\n    density = float(s.get('density', 0.0))\n    avg_deg  = float(s.get('avg_degree', 0.0))\n    max_deg  = float(s.get('max_degree', 1))\n    min_deg  = float(s.get('min_degree', 0))\n    std_deg  = float(s.get('std_degree', 0.0))\n    avg_clust = float(s.get('avg_clustering', 0.0))\n    trans    = float(s.get('transitivity', 0.0))\n    assort   = float(s.get('degree_assortativity', 0.0))\n    tri      = float(s.get('num_triangles', 0))\n    degs     = s.get('degrees', [])\n\n    # Avoid division by zero\n    eps = 1e-6\n    denom_conn = max(avg_deg, eps) * max(density, eps)\n    base = n / denom_conn\n\n    # Scaling from clustering, assortativity and triangle density\n    tri_factor = 1.0 + tri / max(m, eps)\n    scaling = 1.0 + trans + abs(assort) + tri_factor\n\n    # Heterogeneity adjustment (std dev and minimum degree)\n    hetero = 1.0 + std_deg / max(avg_deg, eps) + min_deg / max(avg_deg, eps)\n\n    # Penalty for very large maximum degree\n    penalty = max_deg + 1.0\n\n    # Median degree factor (if degrees list provided)\n    if degs:\n        mid = len(degs) // 2\n        median_deg = float(degs[mid])\n    else:\n        median_deg = avg_deg\n    median_factor = 1.0 + median_deg / max(avg_deg, eps)\n\n    # Final estimate\n    result = base * scaling * (1.0 + avg_clust) * median_factor\n    result /= hetero\n    result /= penalty\n\n    return float(result)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic graph properties with safe defaults\n    n      = float(s.get('n', 1))\n    m      = float(s.get('m', 0))\n    density = float(s.get('density', 0.0))\n    avg_deg  = float(s.get('avg_degree', 0.0))\n    max_deg  = float(s.get('max_degree', 1))\n    min_deg  = float(s.get('min_degree', 0))\n    std_deg  = float(s.get('std_degree', 0.0))\n    avg_clust = float(s.get('avg_clustering', 0.0))\n    trans    = float(s.get('transitivity', 0.0))\n    assort   = float(s.get('degree_assortativity', 0.0))\n    tri      = float(s.get('num_triangles', 0))\n    degs     = s.get('degrees', [])\n\n    # Avoid division by zero\n    eps = 1e-6\n    denom_conn = max(avg_deg, eps) * max(density, eps)\n    base = n / denom_conn\n\n    # Scaling from clustering, assortativity and triangle density\n    tri_factor = 1.0 + tri / max(m, eps)\n    scaling = 1.0 + trans + abs(assort) + tri_factor\n\n    # Heterogeneity adjustment (std dev and minimum degree)\n    hetero = 1.0 + std_deg / max(avg_deg, eps) + min_deg / max(avg_deg, eps)\n\n    # Penalty for very large maximum degree\n    penalty = max_deg + 1.0\n\n    # Median degree factor (if degrees list provided)\n    if degs:\n        mid = len(degs) // 2\n        median_deg = float(degs[mid])\n    else:\n        median_deg = avg_deg\n    median_factor = 1.0 + median_deg / max(avg_deg, eps)\n\n    # Final estimate\n    result = base * scaling * (1.0 + avg_clust) * median_factor\n    result /= hetero\n    result /= penalty\n\n    return float(result)", "spearman": 0.9072406810170255, "pearson": 0.7114182064475614, "rmse": 53.54835411396474, "mae": 34.345183418379804}}
{"timestamp": "2026-02-17T05:38:29.491710+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.138505", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:38:29.492444+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 7, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.138505", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:39:04.585161+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 3, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.071509", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:39:04.585908+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 7, "island_id": 3, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:40:05.455879+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:40:05.457502+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 7, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:40:33.007761+00:00", "event_type": "candidate_rejected", "payload": {"generation": 7, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.061337", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:40:33.009537+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 7, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:41:12.290696+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i3_p2_321199476", "generation": 7, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.5928931572629051, "fitness_mode": "correlation", "simplicity_score": 0.21895565682377716, "novelty_bonus": 0.1920152829090549, "total_score": 0.4439060289952909, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The function combines size, density, clustering, triangle richness,\n    assortativity, and degree dispersion in a novel algebraic form.\n    It does not perform any graph traversal and uses only built‑in Python operations.\n    \n    Parameters\n    ----------\n    s : dict\n        Pre‑computed statistics of a graph.  Expected keys are:\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', 'degrees'.\n    \n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values and cast to float for arithmetic consistency\n    n       = float(s['n'])\n    m       = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Base term – inversely related to the mean degree\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)                    # larger n gives larger baseline\n    base *= (1.0 + density)                # denser graphs shrink path lengths\n    base *= (1.0 - avg_clust)              # high clustering can stretch distances\n    base *= (1.0 - assort)                 # disassortative networks tend to be closer\n\n    # ------------------------------------------------------------------\n    # 2. Triangle fraction with a bell‑shaped amplification\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + 1e-12)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac) * 10.0   # peak around tri_frac≈0.5\n    base += tri_term\n\n    # ------------------------------------------------------------------\n    # 3. Degree dispersion adjustment\n    # ------------------------------------------------------------------\n    if degs:\n        sum_sq = 0.0\n        for d in degs:\n            sum_sq += d * d\n        avg_sq = sum_sq / n\n    else:\n        avg_sq = 0.0\n\n    deg_disp = std_deg / (max_deg + 1e-12)\n    dispersion_term = deg_disp * avg_sq / (max_deg + 1e-12)\n    base += dispersion_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a novel combination of\n    structural features.  The estimator is purely algebraic, requiring no\n    external libraries or graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n            n                 (int)          # number of vertices\n            m                 (int)          # number of edges\n            density           (float)\n            avg_degree        (float)\n            max_degree        (int)\n            min_degree        (int)\n            std_degree        (float)\n            avg_clustering    (float)\n            transitivity      (float)\n            degree_assortativity (float)\n            num_triangles     (int)\n            degrees           (list[int])   # sorted degree list\n\n    Returns\n    -------\n    float\n        An estimate that grows with the true average shortest‑path length.\n    \"\"\"\n    eps = 1e-12\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_clustering = float(s['avg_clustering'])\n    assortativity = float(s['degree_assortativity'])\n    max_deg = float(s['max_degree'])\n    std_deg = float(s['std_degree'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    # Basic base term: inverse of mean degree times density effects\n    base = n / (m + 1.0)                     # inversely proportional to avg degree\n    base *= (1.0 + density)                  # denser graphs shrink distances\n    base *= (1.0 - avg_clustering)           # high clustering can stretch paths\n    base *= (1.0 - assortativity)            # disassortativity typically shortens paths\n\n    # Triangle density contribution (non‑linear scaling)\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    # Amplify the effect: a bell‑shaped contribution centred at ~0.3\n    tri_term = tri_frac * (1.0 - tri_frac) * 12.0\n    base += tri_term\n\n    # Degree dispersion and heterogeneity adjustment\n    # Compute mean of squared degrees\n    if degrees:\n        avg_sq_deg = sum(d * d for d in degrees) / n\n    else:\n        avg_sq_deg = 0.0\n    deg_disp = std_deg / (max_deg + eps)\n    dispersion_term = deg_disp * avg_sq_deg / (max_deg + eps)\n    base += dispersion_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from global graph descriptors\n    without performing any traversal.  The expression is a hand‑crafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, and degree heterogeneity.  No external libraries or\n    `import` statements are used.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract variables and cast to float for consistency\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    eps = 1e-12\n\n    # ----------------- Harmonic mean of degrees --------------------\n    if degs:\n        inv_sum = sum(1.0 / (d + eps) for d in degs if d > 0)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ----------------- Triangle fraction ----------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ----------------- Core multiplicative factor -------------------\n    # Ratio of simple linear terms replaces the logarithmic scaling\n    base = (1.0 + n * density + eps) / (1.0 + avg_deg + harmonic_mean + eps)\n\n    # Modulate by clustering, triangle density and transitivity\n    base *= (1.0 + tri_frac) ** 0.5\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n\n    # Influence of assortativity (disassortative networks often shorten paths)\n    base *= (1.0 - assort) ** 0.2\n\n    # ----------------- Additive correction for degree dispersion ----\n    disp_term = std_deg * (harmonic_mean - min_deg) / (max_deg + 1.0 + eps)\n\n    return base + disp_term\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.071509\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.061337\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base", "spearman": -0.685020625515638, "pearson": -0.403379653076641, "rmse": 1.975291354525213, "mae": 1.6537335163225142}}
{"timestamp": "2026-02-17T05:41:57.993582+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i3_p3_47635042", "generation": 7, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.39563025210084035, "fitness_mode": "correlation", "simplicity_score": 0.21923321441031113, "novelty_bonus": 0.3516991221812372, "total_score": 0.3458230412029751, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The function combines size, density, clustering, triangle richness,\n    assortativity, and degree dispersion in a novel algebraic form.\n    It does not perform any graph traversal and uses only built‑in Python operations.\n    \n    Parameters\n    ----------\n    s : dict\n        Pre‑computed statistics of a graph.  Expected keys are:\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', 'degrees'.\n    \n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values and cast to float for arithmetic consistency\n    n       = float(s['n'])\n    m       = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Base term – inversely related to the mean degree\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)                    # larger n gives larger baseline\n    base *= (1.0 + density)                # denser graphs shrink path lengths\n    base *= (1.0 - avg_clust)              # high clustering can stretch distances\n    base *= (1.0 - assort)                 # disassortative networks tend to be closer\n\n    # ------------------------------------------------------------------\n    # 2. Triangle fraction with a bell‑shaped amplification\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + 1e-12)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac) * 10.0   # peak around tri_frac≈0.5\n    base += tri_term\n\n    # ------------------------------------------------------------------\n    # 3. Degree dispersion adjustment\n    # ------------------------------------------------------------------\n    if degs:\n        sum_sq = 0.0\n        for d in degs:\n            sum_sq += d * d\n        avg_sq = sum_sq / n\n    else:\n        avg_sq = 0.0\n\n    deg_disp = std_deg / (max_deg + 1e-12)\n    dispersion_term = deg_disp * avg_sq / (max_deg + 1e-12)\n    base += dispersion_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a novel combination of\n    structural features.  The estimator is purely algebraic, requiring no\n    external libraries or graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n            n                 (int)          # number of vertices\n            m                 (int)          # number of edges\n            density           (float)\n            avg_degree        (float)\n            max_degree        (int)\n            min_degree        (int)\n            std_degree        (float)\n            avg_clustering    (float)\n            transitivity      (float)\n            degree_assortativity (float)\n            num_triangles     (int)\n            degrees           (list[int])   # sorted degree list\n\n    Returns\n    -------\n    float\n        An estimate that grows with the true average shortest‑path length.\n    \"\"\"\n    eps = 1e-12\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_clustering = float(s['avg_clustering'])\n    assortativity = float(s['degree_assortativity'])\n    max_deg = float(s['max_degree'])\n    std_deg = float(s['std_degree'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    # Basic base term: inverse of mean degree times density effects\n    base = n / (m + 1.0)                     # inversely proportional to avg degree\n    base *= (1.0 + density)                  # denser graphs shrink distances\n    base *= (1.0 - avg_clustering)           # high clustering can stretch paths\n    base *= (1.0 - assortativity)            # disassortativity typically shortens paths\n\n    # Triangle density contribution (non‑linear scaling)\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    # Amplify the effect: a bell‑shaped contribution centred at ~0.3\n    tri_term = tri_frac * (1.0 - tri_frac) * 12.0\n    base += tri_term\n\n    # Degree dispersion and heterogeneity adjustment\n    # Compute mean of squared degrees\n    if degrees:\n        avg_sq_deg = sum(d * d for d in degrees) / n\n    else:\n        avg_sq_deg = 0.0\n    deg_disp = std_deg / (max_deg + eps)\n    dispersion_term = deg_disp * avg_sq_deg / (max_deg + eps)\n    base += dispersion_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from global graph descriptors\n    without performing any traversal.  The expression is a hand‑crafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, and degree heterogeneity.  No external libraries or\n    `import` statements are used.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract variables and cast to float for consistency\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    eps = 1e-12\n\n    # ----------------- Harmonic mean of degrees --------------------\n    if degs:\n        inv_sum = sum(1.0 / (d + eps) for d in degs if d > 0)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ----------------- Triangle fraction ----------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ----------------- Core multiplicative factor -------------------\n    # Ratio of simple linear terms replaces the logarithmic scaling\n    base = (1.0 + n * density + eps) / (1.0 + avg_deg + harmonic_mean + eps)\n\n    # Modulate by clustering, triangle density and transitivity\n    base *= (1.0 + tri_frac) ** 0.5\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n\n    # Influence of assortativity (disassortative networks often shorten paths)\n    base *= (1.0 - assort) ** 0.2\n\n    # ----------------- Additive correction for degree dispersion ----\n    disp_term = std_deg * (harmonic_mean - min_deg) / (max_deg + 1.0 + eps)\n\n    return base + disp_term\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.071509\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.061337\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from global graph descriptors\n    without performing any traversal.  The expression is a handcrafted\n    non‑linear combination of size, density, clustering, triangle density,\n    assortativity, and degree heterogeneity.  No external libraries or\n    `import` statements are used.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Basic scalars – cast to float for consistency\n    # ------------------------------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # ------------------------------------------------------------------\n    # 2. Harmonic mean of the degree sequence (used as a density proxy)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = sum(1.0/(d + eps) for d in degrees if d > 0)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density fraction (fraction of possible triangles present)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n*(n-1.0)*(n-2.0)/6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ------------------------------------------------------------------\n    # 4. Core multiplicative factor – blends size, density, and average\n    #    degree information\n    # ------------------------------------------------------------------\n    base = (n/(m + 1.0)) * (1.0 + density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 5. Modulation terms – each feature contributes a mild non‑linear\n    #    adjustment that mimics observed scaling behaviour\n    # ------------------------------------------------------------------\n    base *= (1.0 - avg_clust)**0.4          # high clustering tends to increase distance\n    base *= (1.0 - trans)**0.3              # transitivity amplifies clustering effects\n    base *= (1.0 - assort)**0.2             # disassortative networks usually have shorter paths\n    base *= (1.0 + tri_frac)**0.5           # moderate triangle density usually shortens paths\n    base *= (harmonic_mean)**0.05           # subtle influence of harmonic mean of degrees\n\n    # ------------------------------------------------------------------\n    # 6. Degree dispersion correction – captures heterogeneity in the\n    #    degree sequence\n    # ------------------------------------------------------------------\n    if max_deg > eps:\n        disp_factor = std_deg / max_deg\n    else:\n        disp_factor = 0.0\n    base += disp_factor * (max_deg - min_deg) / (max_deg + 1.0 + eps)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from global graph descriptors\n    without performing any traversal.  The expression is a handcrafted\n    non‑linear combination of size, density, clustering, triangle density,\n    assortativity, and degree heterogeneity.  No external libraries or\n    `import` statements are used.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Basic scalars – cast to float for consistency\n    # ------------------------------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # ------------------------------------------------------------------\n    # 2. Harmonic mean of the degree sequence (used as a density proxy)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = sum(1.0/(d + eps) for d in degrees if d > 0)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density fraction (fraction of possible triangles present)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n*(n-1.0)*(n-2.0)/6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ------------------------------------------------------------------\n    # 4. Core multiplicative factor – blends size, density, and average\n    #    degree information\n    # ------------------------------------------------------------------\n    base = (n/(m + 1.0)) * (1.0 + density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 5. Modulation terms – each feature contributes a mild non‑linear\n    #    adjustment that mimics observed scaling behaviour\n    # ------------------------------------------------------------------\n    base *= (1.0 - avg_clust)**0.4          # high clustering tends to increase distance\n    base *= (1.0 - trans)**0.3              # transitivity amplifies clustering effects\n    base *= (1.0 - assort)**0.2             # disassortative networks usually have shorter paths\n    base *= (1.0 + tri_frac)**0.5           # moderate triangle density usually shortens paths\n    base *= (harmonic_mean)**0.05           # subtle influence of harmonic mean of degrees\n\n    # ------------------------------------------------------------------\n    # 6. Degree dispersion correction – captures heterogeneity in the\n    #    degree sequence\n    # ------------------------------------------------------------------\n    if max_deg > eps:\n        disp_factor = std_deg / max_deg\n    else:\n        disp_factor = 0.0\n    base += disp_factor * (max_deg - min_deg) / (max_deg + 1.0 + eps)\n\n    return base", "spearman": 0.3929333233330834, "pearson": 0.44535266130080975, "rmse": 2.7408458462091763, "mae": 2.5943476057111843}}
{"timestamp": "2026-02-17T05:42:36.421067+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g7_i3_p4_507621439", "generation": 7, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.4981992797118847, "fitness_mode": "correlation", "simplicity_score": 0.22002454515451178, "novelty_bonus": 0.4484443574285196, "total_score": 0.4367734221396053, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The function combines size, density, clustering, triangle richness,\n    assortativity, and degree dispersion in a novel algebraic form.\n    It does not perform any graph traversal and uses only built‑in Python operations.\n    \n    Parameters\n    ----------\n    s : dict\n        Pre‑computed statistics of a graph.  Expected keys are:\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', 'degrees'.\n    \n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values and cast to float for arithmetic consistency\n    n       = float(s['n'])\n    m       = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Base term – inversely related to the mean degree\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)                    # larger n gives larger baseline\n    base *= (1.0 + density)                # denser graphs shrink path lengths\n    base *= (1.0 - avg_clust)              # high clustering can stretch distances\n    base *= (1.0 - assort)                 # disassortative networks tend to be closer\n\n    # ------------------------------------------------------------------\n    # 2. Triangle fraction with a bell‑shaped amplification\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + 1e-12)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac) * 10.0   # peak around tri_frac≈0.5\n    base += tri_term\n\n    # ------------------------------------------------------------------\n    # 3. Degree dispersion adjustment\n    # ------------------------------------------------------------------\n    if degs:\n        sum_sq = 0.0\n        for d in degs:\n            sum_sq += d * d\n        avg_sq = sum_sq / n\n    else:\n        avg_sq = 0.0\n\n    deg_disp = std_deg / (max_deg + 1e-12)\n    dispersion_term = deg_disp * avg_sq / (max_deg + 1e-12)\n    base += dispersion_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a novel combination of\n    structural features.  The estimator is purely algebraic, requiring no\n    external libraries or graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n            n                 (int)          # number of vertices\n            m                 (int)          # number of edges\n            density           (float)\n            avg_degree        (float)\n            max_degree        (int)\n            min_degree        (int)\n            std_degree        (float)\n            avg_clustering    (float)\n            transitivity      (float)\n            degree_assortativity (float)\n            num_triangles     (int)\n            degrees           (list[int])   # sorted degree list\n\n    Returns\n    -------\n    float\n        An estimate that grows with the true average shortest‑path length.\n    \"\"\"\n    eps = 1e-12\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_clustering = float(s['avg_clustering'])\n    assortativity = float(s['degree_assortativity'])\n    max_deg = float(s['max_degree'])\n    std_deg = float(s['std_degree'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    # Basic base term: inverse of mean degree times density effects\n    base = n / (m + 1.0)                     # inversely proportional to avg degree\n    base *= (1.0 + density)                  # denser graphs shrink distances\n    base *= (1.0 - avg_clustering)           # high clustering can stretch paths\n    base *= (1.0 - assortativity)            # disassortativity typically shortens paths\n\n    # Triangle density contribution (non‑linear scaling)\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    # Amplify the effect: a bell‑shaped contribution centred at ~0.3\n    tri_term = tri_frac * (1.0 - tri_frac) * 12.0\n    base += tri_term\n\n    # Degree dispersion and heterogeneity adjustment\n    # Compute mean of squared degrees\n    if degrees:\n        avg_sq_deg = sum(d * d for d in degrees) / n\n    else:\n        avg_sq_deg = 0.0\n    deg_disp = std_deg / (max_deg + eps)\n    dispersion_term = deg_disp * avg_sq_deg / (max_deg + eps)\n    base += dispersion_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from global graph descriptors\n    without performing any traversal.  The expression is a hand‑crafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, and degree heterogeneity.  No external libraries or\n    `import` statements are used.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics with keys:\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract variables and cast to float for consistency\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    eps = 1e-12\n\n    # ----------------- Harmonic mean of degrees --------------------\n    if degs:\n        inv_sum = sum(1.0 / (d + eps) for d in degs if d > 0)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ----------------- Triangle fraction ----------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ----------------- Core multiplicative factor -------------------\n    # Ratio of simple linear terms replaces the logarithmic scaling\n    base = (1.0 + n * density + eps) / (1.0 + avg_deg + harmonic_mean + eps)\n\n    # Modulate by clustering, triangle density and transitivity\n    base *= (1.0 + tri_frac) ** 0.5\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n\n    # Influence of assortativity (disassortative networks often shorten paths)\n    base *= (1.0 - assort) ** 0.2\n\n    # ----------------- Additive correction for degree dispersion ----\n    disp_term = std_deg * (harmonic_mean - min_deg) / (max_deg + 1.0 + eps)\n\n    return base + disp_term\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.071509\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.061337\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base", "spearman": -0.5164704117602941, "pearson": -0.34079219586340376, "rmse": 2.0580675931635772, "mae": 1.7751872077754265}}
{"timestamp": "2026-02-17T05:42:36.426565+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 8, "model_name": "gpt-oss:20b", "best_val_score": 0.5676243841107219, "no_improve_count": 2}}
{"timestamp": "2026-02-17T05:45:06.833510+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i0_p0_137338024", "generation": 8, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.628235294117647, "fitness_mode": "correlation", "simplicity_score": 0.15061169165295601, "novelty_bonus": 0.15665994118078175, "total_score": 0.41125292399990865, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.146974\nbelow_novelty_threshold: novelty_bonus=0.141697\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from pre‑computed graph features.\n    The formula combines a random‑graph baseline with structural adjustments\n    for density, clustering, transitivity, degree heterogeneity, and other\n    network motifs.  No external libraries are required.\n    \"\"\"\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    # Ensure a non‑negative result\n    return max(base, 1e-6)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from pre‑computed graph features.\n    The formula combines a random‑graph baseline with structural adjustments\n    for density, clustering, transitivity, degree heterogeneity, and other\n    network motifs.  No external libraries are required.\n    \"\"\"\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    # Ensure a non‑negative result\n    return max(base, 1e-6)", "spearman": 0.6682652066301659, "pearson": 0.4902046785855589, "rmse": 1.1433950313854035, "mae": 0.8264347427050578}}
{"timestamp": "2026-02-17T05:45:49.823752+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i0_p1_5034707", "generation": 8, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.628235294117647, "fitness_mode": "correlation", "simplicity_score": 0.2189140589433829, "novelty_bonus": 0.15665994118078175, "total_score": 0.42491339745799406, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.146974\nbelow_novelty_threshold: novelty_bonus=0.141697\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula combines a logarithmic baseline with structural adjustments inspired\n    by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / max(n, 1)) ** -0.05  # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / max(n, 1)) ** 0.05             # edge density adjustment\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula combines a logarithmic baseline with structural adjustments inspired\n    by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / max(n, 1)) ** -0.05  # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / max(n, 1)) ** 0.05             # edge density adjustment\n\n    return base", "spearman": 0.6682652066301659, "pearson": 0.4902046785855589, "rmse": 1.1433950313854035, "mae": 0.8264347427050578}}
{"timestamp": "2026-02-17T05:46:34.365417+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.149782", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:46:34.366060+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 8, "island_id": 0, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.149782", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:47:04.609541+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 0, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.147191", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:47:04.610095+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 8, "island_id": 0, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:47:56.225705+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 0, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:47:56.227331+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 8, "island_id": 0, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:48:35.264628+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i0_p3_660606435", "generation": 8, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.628235294117647, "fitness_mode": "correlation", "simplicity_score": 0.15633817437479944, "novelty_bonus": 0.15665994118078175, "total_score": 0.4123982205442773, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.141697\nbelow_novelty_threshold: novelty_bonus=0.149782\nbelow_novelty_threshold: novelty_bonus=0.147191\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a random‑graph baseline (logarithmic in n and avg_degree)\n    and several structural adjustments that capture density, clustering, transitivity,\n    triangle density, degree heterogeneity, hubs, low‑degree vertices, assortativity,\n    and overall edge density.\n    \"\"\"\n    import math\n\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    density    = s.get('density', 0.0)\n    max_deg    = s.get('max_degree', 0)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    assort     = s.get('degree_assortativity', 0.0)\n    degrees    = s.get('degrees', [])\n\n    # Logarithmic baseline (random‑graph intuition)\n    log_n       = math.log2(n) if n > 0 else 0.0\n    log_avg_deg = math.log2(avg_deg) if avg_deg > 0 else 0.0\n    base        = log_n / max(log_avg_deg, 1e-6)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                     # denser → shorter paths\n    base *= (1 + avg_clust) ** -0.2                  # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                      # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05               # triangle density\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05      # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03     # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03            # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03                # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                          # overall edge density\n\n    return max(base, 0.0)\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a random‑graph baseline (logarithmic in n and avg_degree)\n    and several structural adjustments that capture density, clustering, transitivity,\n    triangle density, degree heterogeneity, hubs, low‑degree vertices, assortativity,\n    and overall edge density.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic baseline using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                     # denser → shorter paths\n    base *= (1 + avg_clust) ** -0.2                  # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                      # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05               # triangle density\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05      # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03     # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03            # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03                # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                          # overall edge density\n\n    return max(base, 0.0)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a random‑graph baseline (logarithmic in n and avg_degree)\n    and several structural adjustments that capture density, clustering, transitivity,\n    triangle density, degree heterogeneity, hubs, low‑degree vertices, assortativity,\n    and overall edge density.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic baseline using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                     # denser → shorter paths\n    base *= (1 + avg_clust) ** -0.2                  # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                      # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05               # triangle density\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05      # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03     # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03            # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03                # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                          # overall edge density\n\n    return max(base, 0.0)", "spearman": 0.6682652066301659, "pearson": 0.4902046785855589, "rmse": 1.1433950313854035, "mae": 0.8264347427050578}}
{"timestamp": "2026-02-17T05:48:35.265664+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 8, "island_id": 0, "population_idx": 3, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:49:20.279317+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i0_p4_537875900", "generation": 8, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.628235294117647, "fitness_mode": "correlation", "simplicity_score": 0.21895565682377716, "novelty_bonus": 0.15665994118078175, "total_score": 0.4249217170340729, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.149782\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from pre‑computed graph features.\n    The formula combines a random‑graph baseline (logarithmic in n and avg_degree)\n    with multiplicative adjustments for density, clustering, transitivity,\n    triangle density, degree heterogeneity, hubs, low‑degree vertices,\n    assortativity, and edge density.\n    \"\"\"\n    # Basic graph attributes\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Random‑graph baseline\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    # Edge density adjustment\n    if n > 0:\n        base *= (m / n) ** 0.05\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from pre‑computed graph features.\n    The formula combines a random‑graph baseline (logarithmic in n and avg_degree)\n    with multiplicative adjustments for density, clustering, transitivity,\n    triangle density, degree heterogeneity, hubs, low‑degree vertices,\n    assortativity, and edge density.\n    \"\"\"\n    # Basic graph attributes\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Random‑graph baseline\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    # Edge density adjustment\n    if n > 0:\n        base *= (m / n) ** 0.05\n\n    return base", "spearman": 0.6682652066301659, "pearson": 0.4902046785855589, "rmse": 1.1433950313854035, "mae": 0.8264347427050578}}
{"timestamp": "2026-02-17T05:50:04.321909+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i1_p0_185420240", "generation": 8, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.166867\nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T05:50:49.494885+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i1_p1_642797655", "generation": 8, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    A composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    degree_spread = (max_deg - min_deg + 1) / (max_deg + 1)\n    degree_variability = 1 + std_deg / (max_deg + 1)\n    degree_factor = (avg_deg / (max_deg + 1)) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.166867\nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T05:51:38.644825+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 1, "population_idx": 2, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.140840", "model_name": "gpt-oss:20b", "train_signal": 0.1408403361344538}}
{"timestamp": "2026-02-17T05:52:07.686665+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 1, "population_idx": 3, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.265978", "model_name": "gpt-oss:20b", "train_signal": 0.2659783913565426}}
{"timestamp": "2026-02-17T05:52:43.632145+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 1, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:52:43.633973+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 8, "island_id": 1, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:53:10.469575+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 1, "population_idx": 4, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.265978", "model_name": "gpt-oss:20b", "train_signal": 0.2659783913565426}}
{"timestamp": "2026-02-17T05:53:10.470224+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 8, "island_id": 1, "population_idx": 4, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:53:57.520221+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.128390", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:53:57.520860+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 8, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.128390", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:54:33.489485+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 2, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.128390", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:54:33.489996+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 8, "island_id": 2, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:55:24.621430+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i2_p1_627931366", "generation": 8, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9484273709483794, "fitness_mode": "correlation", "simplicity_score": 0.22291758830983302, "novelty_bonus": 0.210565674156738, "total_score": 0.561837822024041, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.136587\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.128390\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    The formula combines size, connectivity, clustering, assortativity,\n    triangle density, degree heterogeneity and maximum degree in a compact\n    multiplicative way.  No external libraries or graph traversal are used.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg     = s.get('avg_degree', 0.0)\n    density     = s.get('density', 0.0)\n    trans       = s.get('transitivity', 0.0)\n    assort      = s.get('degree_assortativity', 0.0)\n    m           = s.get('m', 0)\n    tri         = s.get('num_triangles', 0)\n    std_deg     = s.get('std_degree', 0.0)\n    min_deg     = s.get('min_degree', 0)\n    max_deg     = s.get('max_degree', 1)\n\n    # Basic connectivity term: larger n and smaller avg_deg/density give longer paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6) + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Balance with an extra factor that rewards higher average degree relative to the max\n    base *= (1.0 + avg_deg / (max_deg + 1.0))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    The formula combines size, connectivity, clustering, assortativity,\n    triangle density, degree heterogeneity and maximum degree in a compact\n    multiplicative way.  No external libraries or graph traversal are used.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg     = s.get('avg_degree', 0.0)\n    density     = s.get('density', 0.0)\n    trans       = s.get('transitivity', 0.0)\n    assort      = s.get('degree_assortativity', 0.0)\n    m           = s.get('m', 0)\n    tri         = s.get('num_triangles', 0)\n    std_deg     = s.get('std_degree', 0.0)\n    min_deg     = s.get('min_degree', 0)\n    max_deg     = s.get('max_degree', 1)\n\n    # Basic connectivity term: larger n and smaller avg_deg/density give longer paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6) + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Balance with an extra factor that rewards higher average degree relative to the max\n    base *= (1.0 + avg_deg / (max_deg + 1.0))\n\n    return base", "spearman": 0.9081692042301059, "pearson": 0.7808442000640267, "rmse": 22.626697278251726, "mae": 14.021749623505134}}
{"timestamp": "2026-02-17T05:56:08.477232+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i2_p2_837365739", "generation": 8, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7889075630252101, "fitness_mode": "correlation", "simplicity_score": 0.22303413472535122, "novelty_bonus": 0.19049181593338138, "total_score": 0.4542369337891363, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.136587\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.128390\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed graph\n    statistics.  The formula balances graph size, connectivity, clustering,\n    degree heterogeneity, assortativity and triangle density while staying\n    simple and avoiding any external library calls.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans    = s.get('transitivity', 0.0)\n    assort   = s.get('degree_assortativity', 0.0)\n    m        = s.get('m', 0)\n    tri      = s.get('num_triangles', 0)\n    std_deg  = s.get('std_degree', 0.0)\n    min_deg  = s.get('min_degree', 0)\n    max_deg  = s.get('max_degree', 1)\n\n    # Base term: inversely proportional to connectivity\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and global transitivity\n    base /= (1.0 + trans)\n\n    # Effect of assortativity (absolute value to treat both ends)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity (high spread shortens paths)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + max_deg / max(avg_deg, 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed graph\n    statistics.  The formula balances graph size, connectivity, clustering,\n    degree heterogeneity, assortativity and triangle density while staying\n    simple and avoiding any external library calls.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans    = s.get('transitivity', 0.0)\n    assort   = s.get('degree_assortativity', 0.0)\n    m        = s.get('m', 0)\n    tri      = s.get('num_triangles', 0)\n    std_deg  = s.get('std_degree', 0.0)\n    min_deg  = s.get('min_degree', 0)\n    max_deg  = s.get('max_degree', 1)\n\n    # Base term: inversely proportional to connectivity\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and global transitivity\n    base /= (1.0 + trans)\n\n    # Effect of assortativity (absolute value to treat both ends)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity (high spread shortens paths)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + max_deg / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.7049651241281033, "pearson": 0.6515586272070086, "rmse": 31.55725227572522, "mae": 23.49281792949231}}
{"timestamp": "2026-02-17T05:56:48.038361+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.132801", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:56:48.039075+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 8, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.132801", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:57:15.080413+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i2_p3_957793919", "generation": 8, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9690756302521008, "fitness_mode": "correlation", "simplicity_score": 0.2229950669851596, "novelty_bonus": 0.18722140850347713, "total_score": 0.562939740305684, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.136587\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.128390\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: novelty_bonus=0.132801\nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of pre‑computed\n    graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density,\n    # using the square root of the node count for scaling.\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = (n ** 0.5) / denom_conn\n\n    # Adjust for clustering (use the stronger of average clustering and transitivity)\n    cluster_factor = 1.0 + max(avg_clust, trans)\n    base *= cluster_factor\n\n    # Adjust for assortativity (magnitude matters)\n    base *= 1.0 + abs(assort)\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # Normalize by degree heterogeneity\n    base /= 1.0 + std_deg / max(avg_deg, 1e-6)\n    base /= 1.0 + min_deg / max(avg_deg, 1e-6)\n\n    # Penalize very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula balances graph size, connectivity,\n    clustering, assortativity, triangle density, and degree heterogeneity\n    while avoiding the use of any forbidden operations.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term (size divided by average degree × density)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering (average + transitivity) shortens paths\n    cluster = s.get('avg_clustering', 0.0) + s.get('transitivity', 0.0)\n    base *= (1.0 + cluster)\n\n    # Assortativity magnitude reduces distances\n    assort = abs(s.get('degree_assortativity', 0.0))\n    base *= (1.0 + assort)\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula balances graph size, connectivity,\n    clustering, assortativity, triangle density, and degree heterogeneity\n    while avoiding the use of any forbidden operations.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term (size divided by average degree × density)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering (average + transitivity) shortens paths\n    cluster = s.get('avg_clustering', 0.0) + s.get('transitivity', 0.0)\n    base *= (1.0 + cluster)\n\n    # Assortativity magnitude reduces distances\n    assort = abs(s.get('degree_assortativity', 0.0))\n    base *= (1.0 + assort)\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    return base", "spearman": 0.9243486087152181, "pearson": 0.8182425909263327, "rmse": 17.042818901772133, "mae": 10.014928839561465}}
{"timestamp": "2026-02-17T05:57:15.081185+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 8, "island_id": 2, "population_idx": 3, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T05:58:05.096990+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i2_p4_118039", "generation": 8, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9534213685474189, "fitness_mode": "correlation", "simplicity_score": 0.22054150232247327, "novelty_bonus": 0.21413757973528336, "total_score": 0.5638299613947549, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.128390\nbelow_novelty_threshold: novelty_bonus=0.132801\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed graph\n    statistics.  The formula is deliberately simple and uses only built‑in\n    operations (no external libraries or imports).\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of node degrees\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic graph size\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity terms\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity normalisation\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise extreme hub concentration\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Optional fine‑tuning using the raw degree list\n    deg_list = s.get('degrees', [])\n    if deg_list:\n        # Harmonic mean of degrees – high values indicate many low‑degree nodes\n        sum_inv = 0.0\n        count = 0\n        for d in deg_list:\n            if d > 0:\n                sum_inv += 1.0 / d\n                count += 1\n        if count > 0 and sum_inv > 0:\n            harmonic = count / sum_inv\n            # A larger harmonic mean tends to increase path length\n            base *= (1.0 + harmonic / (avg_deg + 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed graph\n    statistics.  The formula is deliberately simple and uses only built‑in\n    operations (no external libraries or imports).\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of node degrees\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    # Basic graph size\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity terms\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity normalisation\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise extreme hub concentration\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Optional fine‑tuning using the raw degree list\n    deg_list = s.get('degrees', [])\n    if deg_list:\n        # Harmonic mean of degrees – high values indicate many low‑degree nodes\n        sum_inv = 0.0\n        count = 0\n        for d in deg_list:\n            if d > 0:\n                sum_inv += 1.0 / d\n                count += 1\n        if count > 0 and sum_inv > 0:\n            harmonic = count / sum_inv\n            # A larger harmonic mean tends to increase path length\n            base *= (1.0 + harmonic / (avg_deg + 1e-6))\n\n    return base", "spearman": 0.9109607740193505, "pearson": 0.7800040144704201, "rmse": 26.996243185843007, "mae": 16.79616703705856}}
{"timestamp": "2026-02-17T05:58:57.546437+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i3_p0_288740213", "generation": 8, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.386218487394958, "fitness_mode": "correlation", "simplicity_score": 0.2194330307315332, "novelty_bonus": 0.2366666412124343, "total_score": 0.3928795483337825, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The function combines size, density, clustering, triangle richness,\n    assortativity, and degree dispersion in a novel algebraic form.\n    It does not perform any graph traversal and uses only built‑in Python operations.\n    \n    Parameters\n    ----------\n    s : dict\n        Pre‑computed statistics of a graph.  Expected keys are:\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', 'degrees'.\n    \n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values and cast to float for arithmetic consistency\n    n       = float(s['n'])\n    m       = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Base term – inversely related to the mean degree\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)                    # larger n gives larger baseline\n    base *= (1.0 + density)                # denser graphs shrink path lengths\n    base *= (1.0 - avg_clust)              # high clustering can stretch distances\n    base *= (1.0 - assort)                 # disassortative networks tend to be closer\n\n    # ------------------------------------------------------------------\n    # 2. Triangle fraction with a bell‑shaped amplification\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + 1e-12)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac) * 10.0   # peak around tri_frac≈0.5\n    base += tri_term\n\n    # ------------------------------------------------------------------\n    # 3. Degree dispersion adjustment\n    # ------------------------------------------------------------------\n    if degs:\n        sum_sq = 0.0\n        for d in degs:\n            sum_sq += d * d\n        avg_sq = sum_sq / n\n    else:\n        avg_sq = 0.0\n\n    deg_disp = std_deg / (max_deg + 1e-12)\n    dispersion_term = deg_disp * avg_sq / (max_deg + 1e-12)\n    base += dispersion_term\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.071509\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.061337\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length of a graph from\n    a set of global, pre‑computed statistics.\n\n    The estimator combines several structural features in a\n    non‑linear fashion:\n\n    * a sparsity baseline that grows with the number of nodes\n      and shrinks with the number of edges;\n    * dampening factors that capture the influence of\n      density, local clustering, global transitivity and\n      degree assortativity;\n    * a bell‑shaped triangle‑density term that accentuates\n      intermediate values of the triangle fraction;\n    * a dispersion correction that accounts for the spread\n      of the degree distribution through its standard\n      deviation and harmonic mean.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors.  Expected keys:\n        'n', 'm', 'density', 'avg_degree', 'max_degree',\n        'min_degree', 'std_degree', 'avg_clustering',\n        'transitivity', 'degree_assortativity',\n        'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values (convert to float for safe arithmetic)\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degs       = s['degrees']\n\n    eps = 1e-12  # to avoid division by zero\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of the degree sequence (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    inv_sum = 0.0\n    for d in degs:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic_mean = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle fraction (normalized to [0,1]) and a bell‑shaped transform\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = tri_frac * (1.0 - tri_frac)  # peaks near tri_frac = 0.5\n\n    # ------------------------------------------------------------------\n    # 3. Base term reflecting sparsity: grows with n, shrinks with m\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)\n\n    # ------------------------------------------------------------------\n    # 4. Dampening / boosting factors for other structural motifs\n    # ------------------------------------------------------------------\n    base *= (1.0 + density) ** (-0.5)        # denser graphs tend to have smaller distances\n    base *= (1.0 + avg_clust) ** (-0.3)      # high local clustering can increase distances\n    base *= (1.0 + trans) ** (-0.4)          # global transitivity usually shortens distances\n    base *= (1.0 + assort) ** 0.2            # slightly larger distance for positively assortative networks\n\n    # ------------------------------------------------------------------\n    # 5. Add the triangle influence (amplified around intermediate triangle densities)\n    # ------------------------------------------------------------------\n    base += 5.0 * tri_bell\n\n    # ------------------------------------------------------------------\n    # 6. Dispersion correction: incorporate degree heterogeneity\n    # ------------------------------------------------------------------\n    dispersion = std_deg / (max_deg + eps)\n    base += dispersion * (harmonic_mean / (max_deg + 1.0 + eps))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length of a graph from\n    a set of global, pre‑computed statistics.\n\n    The estimator combines several structural features in a\n    non‑linear fashion:\n\n    * a sparsity baseline that grows with the number of nodes\n      and shrinks with the number of edges;\n    * dampening factors that capture the influence of\n      density, local clustering, global transitivity and\n      degree assortativity;\n    * a bell‑shaped triangle‑density term that accentuates\n      intermediate values of the triangle fraction;\n    * a dispersion correction that accounts for the spread\n      of the degree distribution through its standard\n      deviation and harmonic mean.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors.  Expected keys:\n        'n', 'm', 'density', 'avg_degree', 'max_degree',\n        'min_degree', 'std_degree', 'avg_clustering',\n        'transitivity', 'degree_assortativity',\n        'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values (convert to float for safe arithmetic)\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degs       = s['degrees']\n\n    eps = 1e-12  # to avoid division by zero\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of the degree sequence (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    inv_sum = 0.0\n    for d in degs:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic_mean = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle fraction (normalized to [0,1]) and a bell‑shaped transform\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = tri_frac * (1.0 - tri_frac)  # peaks near tri_frac = 0.5\n\n    # ------------------------------------------------------------------\n    # 3. Base term reflecting sparsity: grows with n, shrinks with m\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)\n\n    # ------------------------------------------------------------------\n    # 4. Dampening / boosting factors for other structural motifs\n    # ------------------------------------------------------------------\n    base *= (1.0 + density) ** (-0.5)        # denser graphs tend to have smaller distances\n    base *= (1.0 + avg_clust) ** (-0.3)      # high local clustering can increase distances\n    base *= (1.0 + trans) ** (-0.4)          # global transitivity usually shortens distances\n    base *= (1.0 + assort) ** 0.2            # slightly larger distance for positively assortative networks\n\n    # ------------------------------------------------------------------\n    # 5. Add the triangle influence (amplified around intermediate triangle densities)\n    # ------------------------------------------------------------------\n    base += 5.0 * tri_bell\n\n    # ------------------------------------------------------------------\n    # 6. Dispersion correction: incorporate degree heterogeneity\n    # ------------------------------------------------------------------\n    dispersion = std_deg / (max_deg + eps)\n    base += dispersion * (harmonic_mean / (max_deg + 1.0 + eps))\n\n    return base", "spearman": 0.5559858996474912, "pearson": 0.4784579388620445, "rmse": 2.5012710227800827, "mae": 2.353370779535882}}
{"timestamp": "2026-02-17T06:00:08.611683+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.228139", "model_name": "gpt-oss:20b", "train_signal": 0.2281392557022809}}
{"timestamp": "2026-02-17T06:00:57.088887+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.121601", "model_name": "gpt-oss:20b", "train_signal": 0.12160145940975087}}
{"timestamp": "2026-02-17T06:01:39.488649+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.187323", "model_name": "gpt-oss:20b", "train_signal": 0.18732292917166865}}
{"timestamp": "2026-02-17T06:02:23.430591+00:00", "event_type": "candidate_rejected", "payload": {"generation": 8, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.066106", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:02:23.434098+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 8, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.066106", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:03:04.259272+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g8_i3_p4_847097622", "generation": 8, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.48667466986794716, "fitness_mode": "correlation", "simplicity_score": 0.1260314744651756, "novelty_bonus": 0.15478399916193109, "total_score": 0.2756623451628776, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The function combines size, density, clustering, triangle richness,\n    assortativity, and degree dispersion in a novel algebraic form.\n    It does not perform any graph traversal and uses only built‑in Python operations.\n    \n    Parameters\n    ----------\n    s : dict\n        Pre‑computed statistics of a graph.  Expected keys are:\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', 'degrees'.\n    \n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values and cast to float for arithmetic consistency\n    n       = float(s['n'])\n    m       = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Base term – inversely related to the mean degree\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)                    # larger n gives larger baseline\n    base *= (1.0 + density)                # denser graphs shrink path lengths\n    base *= (1.0 - avg_clust)              # high clustering can stretch distances\n    base *= (1.0 - assort)                 # disassortative networks tend to be closer\n\n    # ------------------------------------------------------------------\n    # 2. Triangle fraction with a bell‑shaped amplification\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + 1e-12)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac) * 10.0   # peak around tri_frac≈0.5\n    base += tri_term\n\n    # ------------------------------------------------------------------\n    # 3. Degree dispersion adjustment\n    # ------------------------------------------------------------------\n    if degs:\n        sum_sq = 0.0\n        for d in degs:\n            sum_sq += d * d\n        avg_sq = sum_sq / n\n    else:\n        avg_sq = 0.0\n\n    deg_disp = std_deg / (max_deg + 1e-12)\n    dispersion_term = deg_disp * avg_sq / (max_deg + 1e-12)\n    base += dispersion_term\n\n    return base\nRecent failures:\nbelow_train_threshold: train_signal=0.228139\nbelow_train_threshold: train_signal=0.121601\nbelow_train_threshold: train_signal=0.187323\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: novelty_bonus=0.066106\nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    A purely algebraic proxy for the graph’s average shortest‑path length\n    constructed from the supplied global statistics.  The expression\n    combines size, density, clustering, triangle richness, assortativity,\n    and degree dispersion.  No graph traversal or external libraries are\n    used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary containing pre‑computed graph features.\n        Expected keys:\n            'n'                     : int   (number of nodes)\n            'm'                     : int   (number of edges)\n            'density'               : float\n            'avg_degree'            : float\n            'max_degree'            : int\n            'min_degree'            : int\n            'std_degree'            : float\n            'avg_clustering'        : float\n            'transitivity'          : float\n            'degree_assortativity'  : float\n            'num_triangles'         : int\n            'degrees'               : list[int]  (sorted degree list)\n\n    Returns\n    -------\n    float\n        A scalar proxy that increases monotonically with the true\n        average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # safeguard against divisions by zero\n\n    # ------------------------------------------------------------------\n    # Basic scalars\n    # ------------------------------------------------------------------\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_c = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    std_deg = float(s['std_degree'])\n    max_deg = float(s['max_degree'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    # ------------------------------------------------------------------\n    # Harmonic mean of degrees (captures the presence of many low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = eps\n\n    # ------------------------------------------------------------------\n    # Triangle density (fraction of all possible triangles)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ------------------------------------------------------------------\n    # Core base that grows with graph size and sparsity, shrinks with\n    # high connectivity and degree homogeneity\n    # ------------------------------------------------------------------\n    base = n * (1.0 - density) / (harmonic + eps)\n\n    # ------------------------------------------------------------------\n    # Modulating factors that inject the remaining structural\n    # information in a non‑linear fashion\n    # ------------------------------------------------------------------\n    tri_term = tri_frac * (1.0 - tri_frac)          # bell‑shaped impact\n    dispersion = std_deg / (max_deg + eps)          # heterogeneity of degrees\n    factor = (\n        (1.0 + 0.5 * tri_term)                     # triangle influence\n        * (1.0 + avg_c)                            # local clustering\n        * (1.0 + trans)                            # global transitivity\n        * (1.0 - assort)                           # assortativity bias\n        * (1.0 + 0.3 * dispersion)                # degree dispersion\n    )\n\n    return base * factor\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    A purely algebraic surrogate for the graph’s average shortest‑path length\n    built only from global graph descriptors.  The expression mixes\n    multiplicative factors that depend on the graph size, density,\n    maximum degree, triangle abundance, degree spread, and the presence\n    of very low‑degree vertices.  No traversal of the graph or external\n    libraries is performed.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph statistics with the keys\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', and 'degrees' (sorted list).\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true\n        average shortest‑path length.  The function is intentionally\n        novel with respect to the previously reported formulas.\n    \"\"\"\n    eps = 1e-12  # avoid divide‑by‑zero\n\n    # Basic numerical values --------------------------------------------------\n    n        = float(s['n'])\n    density  = float(s['density'])\n    max_deg  = float(s['max_degree'])\n    min_deg  = float(s['min_degree'])\n    num_tri  = float(s['num_triangles'])\n    degrees  = s['degrees']\n\n    # Triangle fraction -------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # Harmonic mean of degrees ------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = eps\n\n    # -------------------------------------------------------------------------\n\n    # 1. Size‑density term : larger graphs and sparser connectivity enlarge the estimate\n    term_size_density = n / (density + eps)\n\n    # 2. Max‑degree scaling : very high max degree typically shortens paths,\n    #    so we counter‑balance with a factor that grows with max_deg.\n    term_max_deg = 1.0 + max_deg / (n + eps)\n\n    # 3. Triangle influence : a bell‑shaped function peaking when triangle\n    #    density is moderate (neither too sparse nor fully complete).\n    term_tri = 1.0 + 2.0 * tri_frac * (1.0 - tri_frac)\n\n    # 4. Harmonic mean contribution : a higher harmonic mean (more low‑degree\n    #    nodes) tends to lengthen distances.\n    term_harmonic = 1.0 + 0.5 * harmonic / (n + eps)\n\n    # 5. Minimum‑degree adjustment : presence of isolated or leaf nodes\n    #    further inflates distances.\n    term_min_deg = 1.0 + 0.2 * min_deg / (max_deg + eps)\n\n    # Final composite proxy ---------------------------------------------------\n    return (\n        term_size_density *\n        term_max_deg *\n        term_tri *\n        term_harmonic *\n        term_min_deg\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    A purely algebraic surrogate for the graph’s average shortest‑path length\n    built only from global graph descriptors.  The expression mixes\n    multiplicative factors that depend on the graph size, density,\n    maximum degree, triangle abundance, degree spread, and the presence\n    of very low‑degree vertices.  No traversal of the graph or external\n    libraries is performed.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph statistics with the keys\n        'n', 'm', 'density', 'avg_degree', 'max_degree', 'min_degree',\n        'std_degree', 'avg_clustering', 'transitivity',\n        'degree_assortativity', 'num_triangles', and 'degrees' (sorted list).\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true\n        average shortest‑path length.  The function is intentionally\n        novel with respect to the previously reported formulas.\n    \"\"\"\n    eps = 1e-12  # avoid divide‑by‑zero\n\n    # Basic numerical values --------------------------------------------------\n    n        = float(s['n'])\n    density  = float(s['density'])\n    max_deg  = float(s['max_degree'])\n    min_deg  = float(s['min_degree'])\n    num_tri  = float(s['num_triangles'])\n    degrees  = s['degrees']\n\n    # Triangle fraction -------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # Harmonic mean of degrees ------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = eps\n\n    # -------------------------------------------------------------------------\n\n    # 1. Size‑density term : larger graphs and sparser connectivity enlarge the estimate\n    term_size_density = n / (density + eps)\n\n    # 2. Max‑degree scaling : very high max degree typically shortens paths,\n    #    so we counter‑balance with a factor that grows with max_deg.\n    term_max_deg = 1.0 + max_deg / (n + eps)\n\n    # 3. Triangle influence : a bell‑shaped function peaking when triangle\n    #    density is moderate (neither too sparse nor fully complete).\n    term_tri = 1.0 + 2.0 * tri_frac * (1.0 - tri_frac)\n\n    # 4. Harmonic mean contribution : a higher harmonic mean (more low‑degree\n    #    nodes) tends to lengthen distances.\n    term_harmonic = 1.0 + 0.5 * harmonic / (n + eps)\n\n    # 5. Minimum‑degree adjustment : presence of isolated or leaf nodes\n    #    further inflates distances.\n    term_min_deg = 1.0 + 0.2 * min_deg / (max_deg + eps)\n\n    # Final composite proxy ---------------------------------------------------\n    return (\n        term_size_density *\n        term_max_deg *\n        term_tri *\n        term_harmonic *\n        term_min_deg\n    )", "spearman": 0.4080417010425262, "pearson": 0.4094731142432328, "rmse": 1293.6272350351276, "mae": 973.3444950804311}}
{"timestamp": "2026-02-17T06:03:04.260173+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 8, "island_id": 3, "population_idx": 4, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:03:04.263818+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 9, "model_name": "gpt-oss:20b", "best_val_score": 0.5676243841107219, "no_improve_count": 3}}
{"timestamp": "2026-02-17T06:03:36.571676+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i0_p0_881087511", "generation": 9, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6345738295318126, "fitness_mode": "correlation", "simplicity_score": 0.16439006760998678, "novelty_bonus": 0.15524335527452104, "total_score": 0.41522016433295944, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.149782\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.35                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.18             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.08                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.04          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.04   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.02         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.02            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / max(n, 1)) ** 0.04             # edge density adjustment\n\n    # Small constant to avoid zero output\n    return base + 0.05\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.35                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.18             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.08                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.04          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.04   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.02         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.02            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / max(n, 1)) ** 0.04             # edge density adjustment\n\n    # Small constant to avoid zero output\n    return base + 0.05", "spearman": 0.6715382884572115, "pearson": 0.49494750028915835, "rmse": 1.1108628446394557, "mae": 0.790307445564419}}
{"timestamp": "2026-02-17T06:04:34.194448+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i0_p1_941270799", "generation": 9, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.628235294117647, "fitness_mode": "correlation", "simplicity_score": 0.21899754220321135, "novelty_bonus": 0.15665994118078175, "total_score": 0.42493009410995974, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.149782\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted product of logarithmic estimates and structural adjustments\n    inspired by random‑graph theory and small‑world effects.  No external libraries are\n    required – only built‑in Python functions are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 0)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    assort     = s.get('degree_assortativity', 0.0)\n    degrees    = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2) using bit length\n    log_n        = n.bit_length() - 1\n    log_avg_deg  = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / max(n, 1)) ** 0.05             # edge density adjustment\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted product of logarithmic estimates and structural adjustments\n    inspired by random‑graph theory and small‑world effects.  No external libraries are\n    required – only built‑in Python functions are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 0)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    assort     = s.get('degree_assortativity', 0.0)\n    degrees    = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2) using bit length\n    log_n        = n.bit_length() - 1\n    log_avg_deg  = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / max(n, 1)) ** 0.05             # edge density adjustment\n\n    return base", "spearman": 0.6682652066301659, "pearson": 0.4902046785855589, "rmse": 1.1433950313854035, "mae": 0.8264347427050578}}
{"timestamp": "2026-02-17T06:15:06.306692+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i0_p2_734142722", "generation": 9, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6307322929171668, "fitness_mode": "correlation", "simplicity_score": 0.2187102608464588, "novelty_bonus": 0.15719519595087406, "total_score": 0.4209328617608242, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.149782\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= pow(1 - density, 0.5)                # denser graphs → shorter paths\n    base *= pow(1 + avg_clust, -0.3)             # higher clustering → shorter paths\n    base *= pow(1 + trans, -0.1)                # transitivity effect\n    base *= pow(1 + num_tri / max(n, 1), -0.05)  # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= pow(1 + std_deg / avg_deg, 0.05)   # high degree variance → longer paths\n        base *= pow(1 + max_deg / avg_deg, -0.02)  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= pow(1 + 1 / min_deg, 0.02)         # very low min degree → longer paths\n\n    base *= pow(1 + abs(assort), 0.02)            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= pow(1 + median_deg / avg_deg, -0.02)\n\n    base *= pow(m / max(n, 1), 0.04)              # edge density adjustment\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= pow(1 - density, 0.5)                # denser graphs → shorter paths\n    base *= pow(1 + avg_clust, -0.3)             # higher clustering → shorter paths\n    base *= pow(1 + trans, -0.1)                # transitivity effect\n    base *= pow(1 + num_tri / max(n, 1), -0.05)  # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= pow(1 + std_deg / avg_deg, 0.05)   # high degree variance → longer paths\n        base *= pow(1 + max_deg / avg_deg, -0.02)  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= pow(1 + 1 / min_deg, 0.02)         # very low min degree → longer paths\n\n    base *= pow(1 + abs(assort), 0.02)            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= pow(1 + median_deg / avg_deg, -0.02)\n\n    base *= pow(m / max(n, 1), 0.04)              # edge density adjustment\n\n    return base", "spearman": 0.6600645016125404, "pearson": 0.48129669207584574, "rmse": 1.1817154978568998, "mae": 0.8658598018367241}}
{"timestamp": "2026-02-17T06:16:11.975325+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i0_p3_579623275", "generation": 9, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.628235294117647, "fitness_mode": "correlation", "simplicity_score": 0.2190821898695896, "novelty_bonus": 0.15665994118078175, "total_score": 0.4249470236432354, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.149782\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    The formula blends a random‑graph baseline (logarithmic in size and degree)\n    with multiplicative corrections for density, clustering, transitivity,\n    degree heterogeneity, and assortativity.  All operations use only built‑in\n    Python functions; no external libraries are required.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    The formula blends a random‑graph baseline (logarithmic in size and degree)\n    with multiplicative corrections for density, clustering, transitivity,\n    degree heterogeneity, and assortativity.  All operations use only built‑in\n    Python functions; no external libraries are required.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base", "spearman": 0.6682652066301659, "pearson": 0.4902046785855589, "rmse": 1.1433950313854035, "mae": 0.8264347427050578}}
{"timestamp": "2026-02-17T06:16:49.996364+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i0_p4_682637665", "generation": 9, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6184393757503002, "fitness_mode": "correlation", "simplicity_score": 0.2188317116485725, "novelty_bonus": 0.15860277336170525, "total_score": 0.418782110211623, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using only pre‑computed graph features.\n    The formula is a weighted combination of logarithmic estimates and structural\n    adjustments inspired by random‑graph theory and small‑world effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.4                # denser graphs → shorter paths\n    base *= (1 + avg_clust) ** -0.2             # higher clustering → shorter paths\n    base *= (1 + trans) ** -0.1                # transitivity effect\n    base *= (1 + num_tri / n) ** -0.05          # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05   # high degree variance → longer paths\n        base *= (1 + max_deg / avg_deg) ** -0.03  # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03         # very low min degree → longer paths\n\n    base *= (1 + abs(assort)) ** 0.03            # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.03\n\n    base *= (m / n) ** 0.05                     # edge density adjustment\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.149782\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from pre‑computed graph features.\n    The formula combines a random‑graph baseline with structural adjustments\n    inspired by small‑world and degree‑heterogeneity effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    # Basic counts and statistics\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    density    = s.get('density', 0.0)\n    max_deg    = s.get('max_degree', 0)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    assort     = s.get('degree_assortativity', 0.0)\n    degrees    = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n       = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Random‑graph baseline\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.5                     # denser → shorter\n    base *= (1 + avg_clust) ** -0.25                # higher clustering → shorter\n    base *= (1 + trans) ** -0.15                    # transitivity effect\n    base *= (1 + num_tri / n) ** -0.07              # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.07     # high degree variance → longer\n        base *= (1 + max_deg / avg_deg) ** -0.04   # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04           # very low min degree → longer\n\n    base *= (1 + abs(assort)) ** 0.04                # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    base *= (m / n) ** 0.07                         # edge density adjustment\n    base *= (log_n + 1) ** 0.02                     # small scaling\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from pre‑computed graph features.\n    The formula combines a random‑graph baseline with structural adjustments\n    inspired by small‑world and degree‑heterogeneity effects.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    # Basic counts and statistics\n    m          = s.get('m', 0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    density    = s.get('density', 0.0)\n    max_deg    = s.get('max_degree', 0)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    assort     = s.get('degree_assortativity', 0.0)\n    degrees    = s.get('degrees', [])\n\n    # Logarithmic estimates (base‑2)\n    log_n       = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Random‑graph baseline\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.5                     # denser → shorter\n    base *= (1 + avg_clust) ** -0.25                # higher clustering → shorter\n    base *= (1 + trans) ** -0.15                    # transitivity effect\n    base *= (1 + num_tri / n) ** -0.07              # triangles reduce path length\n\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.07     # high degree variance → longer\n        base *= (1 + max_deg / avg_deg) ** -0.04   # hubs shorten paths\n\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.04           # very low min degree → longer\n\n    base *= (1 + abs(assort)) ** 0.04                # assortativity effect\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1 + median_deg / avg_deg) ** -0.04\n\n    base *= (m / n) ** 0.07                         # edge density adjustment\n    base *= (log_n + 1) ** 0.02                     # small scaling\n\n    return base", "spearman": 0.6548698717467938, "pearson": 0.4770535108542746, "rmse": 1.1939941231511755, "mae": 0.8641959577235858}}
{"timestamp": "2026-02-17T06:17:33.370857+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i1_p0_297183838", "generation": 9, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12143899741980949, "novelty_bonus": 0.185688142203555, "total_score": 0.46041650270154233, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.140840\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = float(s['n'])\n    m          = float(s['m'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_cluster= float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    triangles  = float(s['num_triangles'])\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = float(s['n'])\n    m          = float(s['m'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_cluster= float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    triangles  = float(s['num_triangles'])\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T06:18:04.449080+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i1_p1_110019618", "generation": 9, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.140840\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T06:18:54.083156+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i1_p2_528696959", "generation": 9, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.140840\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T06:19:32.390160+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i1_p3_743840470", "generation": 9, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.140840\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T06:20:44.496110+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i1_p4_699731813", "generation": 9, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6001920768307323, "fitness_mode": "correlation", "simplicity_score": 0.11995221466596108, "novelty_bonus": 0.2404110102752568, "total_score": 0.43363268398921856, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.140840\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density ratio\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Density factor\n    density_factor = 1.0 + density\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density ratio\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Density factor\n    density_factor = 1.0 + density\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor\n    )", "spearman": 0.6750378759468987, "pearson": 0.6377208676115874, "rmse": 2.768144803056992, "mae": 2.622268323424163}}
{"timestamp": "2026-02-17T06:21:32.609249+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i2_p0_484334292", "generation": 9, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.944297719087635, "fitness_mode": "correlation", "simplicity_score": 0.22131298568177266, "novelty_bonus": 0.2190908895226764, "total_score": 0.5582138195920475, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.128390\nbelow_novelty_threshold: novelty_bonus=0.132801\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula balances graph size, connectivity,\n    clustering, assortativity, triangle density, and degree heterogeneity.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg    = s.get('avg_degree', 0.0)\n    density    = s.get('density', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    m          = s.get('m', 0)\n    tri        = s.get('num_triangles', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    min_deg    = s.get('min_degree', 0)\n    max_deg    = s.get('max_degree', 1)\n    degrees    = s.get('degrees', [])\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Optional median adjustment to capture skewness\n    if degrees:\n        mid = len(degrees) // 2\n        median_deg = degrees[mid]\n        base /= (1.0 + abs(median_deg - avg_deg) / max(avg_deg, 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula balances graph size, connectivity,\n    clustering, assortativity, triangle density, and degree heterogeneity.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg    = s.get('avg_degree', 0.0)\n    density    = s.get('density', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    m          = s.get('m', 0)\n    tri        = s.get('num_triangles', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    min_deg    = s.get('min_degree', 0)\n    max_deg    = s.get('max_degree', 1)\n    degrees    = s.get('degrees', [])\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Optional median adjustment to capture skewness\n    if degrees:\n        mid = len(degrees) // 2\n        median_deg = degrees[mid]\n        base /= (1.0 + abs(median_deg - avg_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.89644791119778, "pearson": 0.7533951633828486, "rmse": 12.182157638536893, "mae": 6.996221141934999}}
{"timestamp": "2026-02-17T06:22:19.919904+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i2_p1_909299712", "generation": 9, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9690756302521008, "fitness_mode": "correlation", "simplicity_score": 0.22280297985395578, "novelty_bonus": 0.18722140850347713, "total_score": 0.5629013228794433, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.128390\nbelow_novelty_threshold: novelty_bonus=0.132801\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from pre‑computed graph\n    statistics.  The estimate is built from a simple baseline that\n    inversely scales with the product of average degree and density, and\n    then applies multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph size\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Retrieve features with safe defaults\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # ------------------------------------------------------------------\n    # 1. Baseline estimate: inversely related to connectivity\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # 2. Shortcuts from clustering and assortativity\n    # ------------------------------------------------------------------\n    base *= (1.0 + trans + avg_clust)\n    base *= (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density adjustment\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # 4. Normalise by degree heterogeneity\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 5. Penalise very large maximum degree (few hubs)\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1.0)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from pre‑computed graph\n    statistics.  The estimate is built from a simple baseline that\n    inversely scales with the product of average degree and density, and\n    then applies multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and maximum degree.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph size\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Retrieve features with safe defaults\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # ------------------------------------------------------------------\n    # 1. Baseline estimate: inversely related to connectivity\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # 2. Shortcuts from clustering and assortativity\n    # ------------------------------------------------------------------\n    base *= (1.0 + trans + avg_clust)\n    base *= (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density adjustment\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # 4. Normalise by degree heterogeneity\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 5. Penalise very large maximum degree (few hubs)\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1.0)\n\n    return base", "spearman": 0.9243486087152181, "pearson": 0.8182425909263327, "rmse": 17.042818901772133, "mae": 10.014928839561465}}
{"timestamp": "2026-02-17T06:23:26.295148+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i2_p2_359082123", "generation": 9, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9566866746698679, "fitness_mode": "correlation", "simplicity_score": 0.2209014926046282, "novelty_bonus": 0.165425919874988, "total_score": 0.552406289438796, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.128390\nbelow_novelty_threshold: novelty_bonus=0.132801\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of pre‑computed\n    graph statistics.  The formula is a weighted combination of graph size,\n    connectivity, clustering, assortativity, triangle density, and degree\n    heterogeneity.  No external libraries or graph traversal are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n    avg_clust = s.get('avg_clustering', 0.0)\n    degrees   = s.get('degrees', [])\n\n    # Basic connectivity term (avoid division by zero with a tiny constant)\n    denom = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base  = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n    base *= (1.0 + avg_clust)\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Proportion of high‑degree nodes\n    if degrees:\n        count_high = 0\n        for d in degrees:\n            if d > avg_deg:\n                count_high += 1\n        prop_high = count_high / n\n        base *= (1.0 + prop_high)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of pre‑computed\n    graph statistics.  The formula is a weighted combination of graph size,\n    connectivity, clustering, assortativity, triangle density, and degree\n    heterogeneity.  No external libraries or graph traversal are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n    avg_clust = s.get('avg_clustering', 0.0)\n    degrees   = s.get('degrees', [])\n\n    # Basic connectivity term (avoid division by zero with a tiny constant)\n    denom = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base  = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n    base *= (1.0 + avg_clust)\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Proportion of high‑degree nodes\n    if degrees:\n        count_high = 0\n        for d in degrees:\n            if d > avg_deg:\n                count_high += 1\n        prop_high = count_high / n\n        base *= (1.0 + prop_high)\n\n    return base", "spearman": 0.9171964299107479, "pearson": 0.8506320473412026, "rmse": 26.821525728817356, "mae": 16.08006148125742}}
{"timestamp": "2026-02-17T06:23:52.329851+00:00", "event_type": "candidate_rejected", "payload": {"generation": 9, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:23:52.330524+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 9, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:24:22.511648+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i2_p3_272520200", "generation": 9, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7072749099639856, "fitness_mode": "correlation", "simplicity_score": 0.22323284751129324, "novelty_bonus": 0.46350302157635515, "total_score": 0.4743522423443245, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.128390\nbelow_novelty_threshold: novelty_bonus=0.132801\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list (unused here)\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    import math\n\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg   = s.get('avg_degree', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n    clust     = s.get('avg_clustering', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n\n    # Basic logarithmic estimate based on size and average degree\n    denom = max(avg_deg, 1.0) + 1.0          # avoid log(0)\n    base = math.log(n) / math.log(denom)\n\n    # Adjust for clustering, assortativity and triangle density\n    base *= (1.0 + clust)\n    base *= (1.0 + abs(assort))\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity and minimal degree\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n    clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n\n    # Base estimate inversely related to connectivity\n    denom = max(avg_deg, 1.0) * max(density, 1e-6) + 1.0\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + clust)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity and minimal degree\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalise very large maximum degree\n    base /= (max_deg + 1.0)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n    clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n\n    # Base estimate inversely related to connectivity\n    denom = max(avg_deg, 1.0) * max(density, 1e-6) + 1.0\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + clust)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity and minimal degree\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalise very large maximum degree\n    base /= (max_deg + 1.0)\n\n    return base", "spearman": 0.5813095327383185, "pearson": 0.6347927993558415, "rmse": 2.2158277134582876, "mae": 1.4404304338212308}}
{"timestamp": "2026-02-17T06:24:22.512346+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 9, "island_id": 2, "population_idx": 3, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:25:46.468876+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i2_p4_558797905", "generation": 9, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.5347899159663866, "fitness_mode": "correlation", "simplicity_score": 0.21970994658839654, "novelty_bonus": 0.26460554914129086, "total_score": 0.3980592724505264, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.128390\nbelow_novelty_threshold: novelty_bonus=0.132801\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula balances the influence of graph size,\n    connectivity, clustering, degree heterogeneity, assortativity and\n    triangle density, and it optionally refines the estimate with a\n    skewness correction based on the degree distribution.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of node degrees\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Basic connectivity term: larger graphs with lower connectivity\n    # tend to have longer average paths.\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts introduced by clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Assortativity influences path length symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density usually reduces average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity: highly heterogeneous networks (hubs)\n    # typically have shorter paths.\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    # Optional skewness correction based on the degree distribution\n    if degrees:\n        sum_deg = 0\n        for d in degrees:\n            sum_deg += d\n        mean_deg = sum_deg / len(degrees)\n\n        skew_sum = 0.0\n        for d in degrees:\n            diff = d - mean_deg\n            skew_sum += diff * diff * diff\n        skewness = skew_sum / len(degrees)\n\n        base /= (1.0 + abs(skewness) / (mean_deg + 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula balances the influence of graph size,\n    connectivity, clustering, degree heterogeneity, assortativity and\n    triangle density, and it optionally refines the estimate with a\n    skewness correction based on the degree distribution.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of node degrees\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Basic connectivity term: larger graphs with lower connectivity\n    # tend to have longer average paths.\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts introduced by clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Assortativity influences path length symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density usually reduces average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity: highly heterogeneous networks (hubs)\n    # typically have shorter paths.\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    # Optional skewness correction based on the degree distribution\n    if degrees:\n        sum_deg = 0\n        for d in degrees:\n            sum_deg += d\n        mean_deg = sum_deg / len(degrees)\n\n        skew_sum = 0.0\n        for d in degrees:\n            diff = d - mean_deg\n            skew_sum += diff * diff * diff\n        skewness = skew_sum / len(degrees)\n\n        base /= (1.0 + abs(skewness) / (mean_deg + 1e-6))\n\n    return base", "spearman": 0.5494712367809196, "pearson": 0.49166789999870325, "rmse": 12.107395551678124, "mae": 6.428072052396321}}
{"timestamp": "2026-02-17T06:26:37.923794+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i3_p0_822899753", "generation": 9, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.6261224489795919, "fitness_mode": "correlation", "simplicity_score": 0.21914645745303662, "novelty_bonus": 0.3480086418870256, "total_score": 0.37778262282518427, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length of a graph from\n    a set of global, pre‑computed statistics.\n\n    The estimator combines several structural features in a\n    non‑linear fashion:\n\n    * a sparsity baseline that grows with the number of nodes\n      and shrinks with the number of edges;\n    * dampening factors that capture the influence of\n      density, local clustering, global transitivity and\n      degree assortativity;\n    * a bell‑shaped triangle‑density term that accentuates\n      intermediate values of the triangle fraction;\n    * a dispersion correction that accounts for the spread\n      of the degree distribution through its standard\n      deviation and harmonic mean.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors.  Expected keys:\n        'n', 'm', 'density', 'avg_degree', 'max_degree',\n        'min_degree', 'std_degree', 'avg_clustering',\n        'transitivity', 'degree_assortativity',\n        'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values (convert to float for safe arithmetic)\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degs       = s['degrees']\n\n    eps = 1e-12  # to avoid division by zero\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of the degree sequence (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    inv_sum = 0.0\n    for d in degs:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic_mean = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle fraction (normalized to [0,1]) and a bell‑shaped transform\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = tri_frac * (1.0 - tri_frac)  # peaks near tri_frac = 0.5\n\n    # ------------------------------------------------------------------\n    # 3. Base term reflecting sparsity: grows with n, shrinks with m\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)\n\n    # ------------------------------------------------------------------\n    # 4. Dampening / boosting factors for other structural motifs\n    # ------------------------------------------------------------------\n    base *= (1.0 + density) ** (-0.5)        # denser graphs tend to have smaller distances\n    base *= (1.0 + avg_clust) ** (-0.3)      # high local clustering can increase distances\n    base *= (1.0 + trans) ** (-0.4)          # global transitivity usually shortens distances\n    base *= (1.0 + assort) ** 0.2            # slightly larger distance for positively assortative networks\n\n    # ------------------------------------------------------------------\n    # 5. Add the triangle influence (amplified around intermediate triangle densities)\n    # ------------------------------------------------------------------\n    base += 5.0 * tri_bell\n\n    # ------------------------------------------------------------------\n    # 6. Dispersion correction: incorporate degree heterogeneity\n    # ------------------------------------------------------------------\n    dispersion = std_deg / (max_deg + eps)\n    base += dispersion * (harmonic_mean / (max_deg + 1.0 + eps))\n\n    return base\nRecent failures:\nbelow_train_threshold: train_signal=0.121601\nbelow_train_threshold: train_signal=0.187323\nbelow_novelty_threshold: novelty_bonus=0.066106\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed\n    graph statistics without any traversal.  The formula mixes a sparsity\n    baseline with multiplicative dampening factors and several additive\n    corrections that capture degree heterogeneity, clustering, and\n    triangle density.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features with keys:\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles, degrees\n\n    Returns\n    -------\n    float\n        Proxy value that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Extract scalar features\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Sparsity baseline: more nodes → larger base, more edges → smaller base\n    # ------------------------------------------------------------------\n    base = (n + avg_deg) / (m + 1.0)\n\n    # ------------------------------------------------------------------\n    # 2. Dampening / boosting factors for structural motifs\n    # ------------------------------------------------------------------\n    base *= (1.0 + density) ** (-0.5)          # denser graphs → shorter paths\n    base *= (1.0 + avg_clust) ** (-0.3)        # high local clustering can lengthen paths\n    base *= (1.0 + trans)    ** (-0.4)          # global transitivity usually shortens paths\n    base *= (1.0 + assort)   ** ( 0.2)          # slight positive assortativity tends to increase distances\n\n    # ------------------------------------------------------------------\n    # 3. Triangle‑density bell‑shaped contribution\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac     = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = tri_frac * (1.0 - tri_frac)    # peaks near 0.5\n    base += 5.0 * tri_bell\n\n    # ------------------------------------------------------------------\n    # 4. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    inv_sum = 0.0\n    for d in degrees:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic_mean = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n    base += 0.1 * harmonic_mean\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction for degree heterogeneity\n    # ------------------------------------------------------------------\n    dispersion = std_deg / (max_deg + eps)\n    base += dispersion * (harmonic_mean / (max_deg + 1.0 + eps))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed\n    graph statistics without any traversal.  The formula mixes a sparsity\n    baseline with multiplicative dampening factors and several additive\n    corrections that capture degree heterogeneity, clustering, and\n    triangle density.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features with keys:\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles, degrees\n\n    Returns\n    -------\n    float\n        Proxy value that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Extract scalar features\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Sparsity baseline: more nodes → larger base, more edges → smaller base\n    # ------------------------------------------------------------------\n    base = (n + avg_deg) / (m + 1.0)\n\n    # ------------------------------------------------------------------\n    # 2. Dampening / boosting factors for structural motifs\n    # ------------------------------------------------------------------\n    base *= (1.0 + density) ** (-0.5)          # denser graphs → shorter paths\n    base *= (1.0 + avg_clust) ** (-0.3)        # high local clustering can lengthen paths\n    base *= (1.0 + trans)    ** (-0.4)          # global transitivity usually shortens paths\n    base *= (1.0 + assort)   ** ( 0.2)          # slight positive assortativity tends to increase distances\n\n    # ------------------------------------------------------------------\n    # 3. Triangle‑density bell‑shaped contribution\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac     = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = tri_frac * (1.0 - tri_frac)    # peaks near 0.5\n    base += 5.0 * tri_bell\n\n    # ------------------------------------------------------------------\n    # 4. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    inv_sum = 0.0\n    for d in degrees:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic_mean = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n    base += 0.1 * harmonic_mean\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction for degree heterogeneity\n    # ------------------------------------------------------------------\n    dispersion = std_deg / (max_deg + eps)\n    base += dispersion * (harmonic_mean / (max_deg + 1.0 + eps))\n\n    return base", "spearman": -0.45910147753693853, "pearson": -0.3477867222483092, "rmse": 2.010257589027877, "mae": 1.7370326862133079}}
{"timestamp": "2026-02-17T06:27:20.303415+00:00", "event_type": "candidate_rejected", "payload": {"generation": 9, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:27:20.304375+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 9, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:28:10.365638+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i3_p1_996616948", "generation": 9, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.34108043217286915, "fitness_mode": "correlation", "simplicity_score": 0.21954690955517187, "novelty_bonus": 0.3162071516056195, "total_score": 0.30423916408363755, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length of a graph from\n    a set of global, pre‑computed statistics.\n\n    The estimator combines several structural features in a\n    non‑linear fashion:\n\n    * a sparsity baseline that grows with the number of nodes\n      and shrinks with the number of edges;\n    * dampening factors that capture the influence of\n      density, local clustering, global transitivity and\n      degree assortativity;\n    * a bell‑shaped triangle‑density term that accentuates\n      intermediate values of the triangle fraction;\n    * a dispersion correction that accounts for the spread\n      of the degree distribution through its standard\n      deviation and harmonic mean.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors.  Expected keys:\n        'n', 'm', 'density', 'avg_degree', 'max_degree',\n        'min_degree', 'std_degree', 'avg_clustering',\n        'transitivity', 'degree_assortativity',\n        'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values (convert to float for safe arithmetic)\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degs       = s['degrees']\n\n    eps = 1e-12  # to avoid division by zero\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of the degree sequence (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    inv_sum = 0.0\n    for d in degs:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic_mean = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle fraction (normalized to [0,1]) and a bell‑shaped transform\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = tri_frac * (1.0 - tri_frac)  # peaks near tri_frac = 0.5\n\n    # ------------------------------------------------------------------\n    # 3. Base term reflecting sparsity: grows with n, shrinks with m\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)\n\n    # ------------------------------------------------------------------\n    # 4. Dampening / boosting factors for other structural motifs\n    # ------------------------------------------------------------------\n    base *= (1.0 + density) ** (-0.5)        # denser graphs tend to have smaller distances\n    base *= (1.0 + avg_clust) ** (-0.3)      # high local clustering can increase distances\n    base *= (1.0 + trans) ** (-0.4)          # global transitivity usually shortens distances\n    base *= (1.0 + assort) ** 0.2            # slightly larger distance for positively assortative networks\n\n    # ------------------------------------------------------------------\n    # 5. Add the triangle influence (amplified around intermediate triangle densities)\n    # ------------------------------------------------------------------\n    base += 5.0 * tri_bell\n\n    # ------------------------------------------------------------------\n    # 6. Dispersion correction: incorporate degree heterogeneity\n    # ------------------------------------------------------------------\n    dispersion = std_deg / (max_deg + eps)\n    base += dispersion * (harmonic_mean / (max_deg + 1.0 + eps))\n\n    return base\nRecent failures:\nbelow_train_threshold: train_signal=0.121601\nbelow_train_threshold: train_signal=0.187323\nbelow_novelty_threshold: novelty_bonus=0.066106\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Proxy for the average shortest‑path length based only on a set of\n    pre‑computed global graph statistics.\n\n    The estimator is a handcrafted non‑linear combination of:\n      * size (n) and sparsity (m)\n      * density\n      * average local clustering\n      * global transitivity\n      * degree assortativity\n      * triangle richness (bell‑shaped)\n      * harmonic mean of degrees\n      * degree heterogeneity (std / max)\n      * harmonic mean / max‑degree ratio\n\n    No graph traversal is performed; only basic arithmetic and a few\n    math functions are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary containing the following keys:\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles, degrees\n\n    Returns\n    -------\n    float\n        A scalar that increases with the true average shortest‑path length.\n    \"\"\"\n    import math\n\n    eps = 1e-12  # for numerical stability\n\n    # Basic scalars\n    n      = float(s['n'])\n    m      = float(s['m'])\n    dens   = float(s['density'])\n    avg_c  = float(s['avg_clustering'])\n    trans  = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    max_deg = float(s['max_degree'])\n    std_deg = float(s['std_degree'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    # 1. Harmonic mean of degrees (captures prevalence of low‑degree vertices)\n    inv_sum = 0.0\n    for d in degrees:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n\n    # 2. Triangle fraction and bell‑shaped transform\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = tri_frac * (1.0 - tri_frac)          # peaks near 0.5\n\n    # 3. Base distance estimate (log‑scale size × degree heterogeneity)\n    base = math.log(n + 1.0) * (harmonic / (max_deg + 1.0 + eps))\n\n    # 4. Dampening / boosting factors for other structural features\n    base *= (1.0 + dens) ** (-0.4)        # denser graphs => smaller distances\n    base *= (1.0 + avg_c) ** (-0.3)       # high clustering can lengthen paths\n    base *= (1.0 + trans) ** (-0.5)       # high transitivity shortens distances\n    base *= (1.0 + assort) ** 0.2         # slight increase for positive assortativity\n\n    # 5. Triangle influence (enhanced around intermediate densities)\n    base += 4.0 * tri_bell\n\n    # 6. Dispersion correction: degree variability effect\n    dispersion = std_deg / (max_deg + eps)\n    base += 2.0 * dispersion * (harmonic / (max_deg + 1.0 + eps))\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Proxy for the average shortest‑path length based only on a set of\n    pre‑computed global graph statistics.\n\n    The estimator is a handcrafted non‑linear combination of:\n      * size (n) and sparsity (m)\n      * density\n      * average local clustering\n      * global transitivity\n      * degree assortativity\n      * triangle richness (bell‑shaped)\n      * harmonic mean of degrees\n      * degree heterogeneity (std / max)\n      * harmonic mean / max‑degree ratio\n\n    No graph traversal is performed; only basic arithmetic is used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary containing the following keys:\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles, degrees\n\n    Returns\n    -------\n    float\n        A scalar that increases with the true average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # for numerical stability\n\n    # Basic scalars\n    n      = float(s['n'])\n    m      = float(s['m'])\n    dens   = float(s['density'])\n    avg_c  = float(s['avg_clustering'])\n    trans  = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    max_deg = float(s['max_degree'])\n    std_deg = float(s['std_degree'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    # 1. Harmonic mean of degrees (captures prevalence of low‑degree vertices)\n    inv_sum = 0.0\n    for d in degrees:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n\n    # 2. Triangle fraction and bell‑shaped transform\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = tri_frac * (1.0 - tri_frac)          # peaks near 0.5\n\n    # 3. Base distance estimate (sqrt‑scale size × degree heterogeneity)\n    base = (n + 1.0) ** 0.5 * (harmonic / (max_deg + 1.0 + eps))\n\n    # 4. Dampening / boosting factors for other structural features\n    base *= (1.0 + dens) ** (-0.4)        # denser graphs => smaller distances\n    base *= (1.0 + avg_c) ** (-0.3)       # high clustering can lengthen paths\n    base *= (1.0 + trans) ** (-0.5)       # high transitivity shortens distances\n    base *= (1.0 + assort) ** 0.2         # slight increase for positive assortativity\n\n    # 5. Triangle influence (enhanced around intermediate densities)\n    base += 4.0 * tri_bell\n\n    # 6. Dispersion correction: degree variability effect\n    dispersion = std_deg / (max_deg + eps)\n    base += 2.0 * dispersion * (harmonic / (max_deg + 1.0 + eps))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Proxy for the average shortest‑path length based only on a set of\n    pre‑computed global graph statistics.\n\n    The estimator is a handcrafted non‑linear combination of:\n      * size (n) and sparsity (m)\n      * density\n      * average local clustering\n      * global transitivity\n      * degree assortativity\n      * triangle richness (bell‑shaped)\n      * harmonic mean of degrees\n      * degree heterogeneity (std / max)\n      * harmonic mean / max‑degree ratio\n\n    No graph traversal is performed; only basic arithmetic is used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary containing the following keys:\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles, degrees\n\n    Returns\n    -------\n    float\n        A scalar that increases with the true average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # for numerical stability\n\n    # Basic scalars\n    n      = float(s['n'])\n    m      = float(s['m'])\n    dens   = float(s['density'])\n    avg_c  = float(s['avg_clustering'])\n    trans  = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    max_deg = float(s['max_degree'])\n    std_deg = float(s['std_degree'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    # 1. Harmonic mean of degrees (captures prevalence of low‑degree vertices)\n    inv_sum = 0.0\n    for d in degrees:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n\n    # 2. Triangle fraction and bell‑shaped transform\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = tri_frac * (1.0 - tri_frac)          # peaks near 0.5\n\n    # 3. Base distance estimate (sqrt‑scale size × degree heterogeneity)\n    base = (n + 1.0) ** 0.5 * (harmonic / (max_deg + 1.0 + eps))\n\n    # 4. Dampening / boosting factors for other structural features\n    base *= (1.0 + dens) ** (-0.4)        # denser graphs => smaller distances\n    base *= (1.0 + avg_c) ** (-0.3)       # high clustering can lengthen paths\n    base *= (1.0 + trans) ** (-0.5)       # high transitivity shortens distances\n    base *= (1.0 + assort) ** 0.2         # slight increase for positive assortativity\n\n    # 5. Triangle influence (enhanced around intermediate densities)\n    base += 4.0 * tri_bell\n\n    # 6. Dispersion correction: degree variability effect\n    dispersion = std_deg / (max_deg + eps)\n    base += 2.0 * dispersion * (harmonic / (max_deg + 1.0 + eps))\n\n    return base", "spearman": -0.3309352733818346, "pearson": -0.3392992261390081, "rmse": 1.8138561916957532, "mae": 1.4628628960501124}}
{"timestamp": "2026-02-17T06:28:10.367130+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 9, "island_id": 3, "population_idx": 1, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:29:06.242807+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i3_p2_837933170", "generation": 9, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.3464585834333733, "fitness_mode": "correlation", "simplicity_score": 0.2191680314193786, "novelty_bonus": 0.6959146654470167, "total_score": 0.33889466308440996, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length of a graph from\n    a set of global, pre‑computed statistics.\n\n    The estimator combines several structural features in a\n    non‑linear fashion:\n\n    * a sparsity baseline that grows with the number of nodes\n      and shrinks with the number of edges;\n    * dampening factors that capture the influence of\n      density, local clustering, global transitivity and\n      degree assortativity;\n    * a bell‑shaped triangle‑density term that accentuates\n      intermediate values of the triangle fraction;\n    * a dispersion correction that accounts for the spread\n      of the degree distribution through its standard\n      deviation and harmonic mean.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors.  Expected keys:\n        'n', 'm', 'density', 'avg_degree', 'max_degree',\n        'min_degree', 'std_degree', 'avg_clustering',\n        'transitivity', 'degree_assortativity',\n        'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values (convert to float for safe arithmetic)\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degs       = s['degrees']\n\n    eps = 1e-12  # to avoid division by zero\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of the degree sequence (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    inv_sum = 0.0\n    for d in degs:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic_mean = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle fraction (normalized to [0,1]) and a bell‑shaped transform\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = tri_frac * (1.0 - tri_frac)  # peaks near tri_frac = 0.5\n\n    # ------------------------------------------------------------------\n    # 3. Base term reflecting sparsity: grows with n, shrinks with m\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)\n\n    # ------------------------------------------------------------------\n    # 4. Dampening / boosting factors for other structural motifs\n    # ------------------------------------------------------------------\n    base *= (1.0 + density) ** (-0.5)        # denser graphs tend to have smaller distances\n    base *= (1.0 + avg_clust) ** (-0.3)      # high local clustering can increase distances\n    base *= (1.0 + trans) ** (-0.4)          # global transitivity usually shortens distances\n    base *= (1.0 + assort) ** 0.2            # slightly larger distance for positively assortative networks\n\n    # ------------------------------------------------------------------\n    # 5. Add the triangle influence (amplified around intermediate triangle densities)\n    # ------------------------------------------------------------------\n    base += 5.0 * tri_bell\n\n    # ------------------------------------------------------------------\n    # 6. Dispersion correction: incorporate degree heterogeneity\n    # ------------------------------------------------------------------\n    dispersion = std_deg / (max_deg + eps)\n    base += dispersion * (harmonic_mean / (max_deg + 1.0 + eps))\n\n    return base\nRecent failures:\nbelow_train_threshold: train_signal=0.187323\nbelow_novelty_threshold: novelty_bonus=0.066106\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph\n    statistics.  The formula combines a sparsity baseline with\n    multiplicative dampening factors for density, clustering, transitivity,\n    assortativity, a bell‑shaped triangle‑density contribution,\n    a harmonic‑mean degree adjustment and a heterogeneity correction.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed descriptors of a graph.\n        Required keys:\n        - 'n', 'm', 'density', 'avg_degree', 'max_degree',\n        - 'min_degree', 'std_degree', 'avg_clustering',\n        - 'transitivity', 'degree_assortativity',\n        - 'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values (convert to float for arithmetic safety)\n    n                = float(s['n'])\n    m                = float(s['m'])\n    density          = float(s['density'])\n    avg_degree       = float(s['avg_degree'])\n    max_degree       = float(s['max_degree'])\n    min_degree       = float(s['min_degree'])\n    std_degree       = float(s['std_degree'])\n    avg_clustering   = float(s['avg_clustering'])\n    transitivity     = float(s['transitivity'])\n    degree_assort    = float(s['degree_assortativity'])\n    num_triangles    = float(s['num_triangles'])\n    degrees          = s['degrees']\n\n    eps = 1e-12                     # tiny constant to avoid div/0\n\n    # ---------- 1. Baseline (sparsity) ----------\n    base = n / (m + 1.0)             # larger graphs => longer paths\n\n    # ---------- 2. Dampening factors ----------\n    base *= 1.0 / (1.0 + density)    # denser => shorter paths\n    base *= (1.0 + avg_clustering) ** -0.3\n    base *= (1.0 + transitivity) ** -0.4\n    base *= (1.0 + degree_assort) ** 0.2\n\n    # ---------- 3. Triangle influence (bell‑shaped) ----------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_triangles / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = 1.0 - 2.0 * abs(tri_frac - 0.5)   # peak at tri_frac ≈ 0.5\n    base += tri_bell * 1.5\n\n    # ---------- 4. Harmonic‑mean degree adjustment ----------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.05\n\n    # ---------- 5. Degree‑heterogeneity correction ----------\n    hetero = std_degree / (max_degree + eps)\n    base += hetero * (harmonic / (max_degree + 1.0 + eps))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph\n    statistics.  The formula combines a sparsity baseline with\n    multiplicative dampening factors for density, clustering, transitivity,\n    assortativity, a bell‑shaped triangle‑density contribution,\n    a harmonic‑mean degree adjustment and a heterogeneity correction.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed descriptors of a graph.\n        Required keys:\n        - 'n', 'm', 'density', 'avg_degree', 'max_degree',\n        - 'min_degree', 'std_degree', 'avg_clustering',\n        - 'transitivity', 'degree_assortativity',\n        - 'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values (convert to float for arithmetic safety)\n    n                = float(s['n'])\n    m                = float(s['m'])\n    density          = float(s['density'])\n    avg_degree       = float(s['avg_degree'])\n    max_degree       = float(s['max_degree'])\n    min_degree       = float(s['min_degree'])\n    std_degree       = float(s['std_degree'])\n    avg_clustering   = float(s['avg_clustering'])\n    transitivity     = float(s['transitivity'])\n    degree_assort    = float(s['degree_assortativity'])\n    num_triangles    = float(s['num_triangles'])\n    degrees          = s['degrees']\n\n    eps = 1e-12                     # tiny constant to avoid div/0\n\n    # ---------- 1. Baseline (sparsity) ----------\n    base = n / (m + 1.0)             # larger graphs => longer paths\n\n    # ---------- 2. Dampening factors ----------\n    base *= 1.0 / (1.0 + density)    # denser => shorter paths\n    base *= (1.0 + avg_clustering) ** -0.3\n    base *= (1.0 + transitivity) ** -0.4\n    base *= (1.0 + degree_assort) ** 0.2\n\n    # ---------- 3. Triangle influence (bell‑shaped) ----------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_triangles / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = 1.0 - 2.0 * abs(tri_frac - 0.5)   # peak at tri_frac ≈ 0.5\n    base += tri_bell * 1.5\n\n    # ---------- 4. Harmonic‑mean degree adjustment ----------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.05\n\n    # ---------- 5. Degree‑heterogeneity correction ----------\n    hetero = std_degree / (max_degree + eps)\n    base += hetero * (harmonic / (max_degree + 1.0 + eps))\n\n    return base", "spearman": -0.17257331433285836, "pearson": -0.13069844145628068, "rmse": 2.2647658181516337, "mae": 2.049415759129505}}
{"timestamp": "2026-02-17T06:29:53.084909+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i3_p3_530284567", "generation": 9, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.3939015606242497, "fitness_mode": "correlation", "simplicity_score": 0.21970994658839654, "novelty_bonus": 0.18203161784951039, "total_score": 0.36432136891988864, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length of a graph from\n    a set of global, pre‑computed statistics.\n\n    The estimator combines several structural features in a\n    non‑linear fashion:\n\n    * a sparsity baseline that grows with the number of nodes\n      and shrinks with the number of edges;\n    * dampening factors that capture the influence of\n      density, local clustering, global transitivity and\n      degree assortativity;\n    * a bell‑shaped triangle‑density term that accentuates\n      intermediate values of the triangle fraction;\n    * a dispersion correction that accounts for the spread\n      of the degree distribution through its standard\n      deviation and harmonic mean.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors.  Expected keys:\n        'n', 'm', 'density', 'avg_degree', 'max_degree',\n        'min_degree', 'std_degree', 'avg_clustering',\n        'transitivity', 'degree_assortativity',\n        'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values (convert to float for safe arithmetic)\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degs       = s['degrees']\n\n    eps = 1e-12  # to avoid division by zero\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of the degree sequence (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    inv_sum = 0.0\n    for d in degs:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic_mean = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle fraction (normalized to [0,1]) and a bell‑shaped transform\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = tri_frac * (1.0 - tri_frac)  # peaks near tri_frac = 0.5\n\n    # ------------------------------------------------------------------\n    # 3. Base term reflecting sparsity: grows with n, shrinks with m\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)\n\n    # ------------------------------------------------------------------\n    # 4. Dampening / boosting factors for other structural motifs\n    # ------------------------------------------------------------------\n    base *= (1.0 + density) ** (-0.5)        # denser graphs tend to have smaller distances\n    base *= (1.0 + avg_clust) ** (-0.3)      # high local clustering can increase distances\n    base *= (1.0 + trans) ** (-0.4)          # global transitivity usually shortens distances\n    base *= (1.0 + assort) ** 0.2            # slightly larger distance for positively assortative networks\n\n    # ------------------------------------------------------------------\n    # 5. Add the triangle influence (amplified around intermediate triangle densities)\n    # ------------------------------------------------------------------\n    base += 5.0 * tri_bell\n\n    # ------------------------------------------------------------------\n    # 6. Dispersion correction: incorporate degree heterogeneity\n    # ------------------------------------------------------------------\n    dispersion = std_deg / (max_deg + eps)\n    base += dispersion * (harmonic_mean / (max_deg + 1.0 + eps))\n\n    return base\nRecent failures:\nbelow_train_threshold: train_signal=0.187323\nbelow_novelty_threshold: novelty_bonus=0.066106\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length of a graph from a set of\n    pre‑computed global statistics without performing any graph traversal\n    or importing external libraries.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary containing pre‑computed graph descriptors:\n            n                   : int    number of nodes\n            m                   : int    number of edges\n            density             : float  edge density (2m/(n(n-1)))\n            avg_degree          : float  average vertex degree\n            max_degree          : int    maximum degree\n            min_degree          : int    minimum degree\n            std_degree          : float  standard deviation of degrees\n            avg_clustering      : float  average local clustering coefficient\n            transitivity        : float  global transitivity\n            degree_assortativity: float  degree assortativity coefficient\n            num_triangles       : int    number of triangles\n            degrees             : list[int] sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.  The\n        estimator combines sparsity, clustering, transitivity,\n        assortativity, triangle richness and degree dispersion.\n    \"\"\"\n    # ---- Extract and normalise the values ----\n    n      = float(s['n'])\n    m      = float(s['m'])\n    density = float(s['density'])\n    avg_deg  = float(s['avg_degree'])\n    max_deg  = float(s['max_degree'])\n    min_deg  = float(s['min_degree'])\n    std_deg  = float(s['std_degree'])\n    avg_clust= float(s['avg_clustering'])\n    trans   = float(s['transitivity'])\n    assort  = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    eps = 1e-12  # small value to avoid division by zero\n\n    # ---- 1. Harmonic mean of the degree sequence ----\n    inv_sum = 0.0\n    for d in degrees:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic_mean = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n\n    # ---- 2. Triangle density fraction (normalized to [0,1]) ----\n    tri_frac = 0.0\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n\n    # ---- 3. Base term reflecting sparsity: grows with size, shrinks with edges ----\n    base = (n / (m + 1.0)) * (1.0 + density)\n\n    # ---- 4. Dampening / boosting factors for other structural motifs ----\n    base *= (1.0 + avg_clust) ** (-0.3)   # high local clustering can lengthen paths\n    base *= (1.0 + trans)     ** (-0.4)   # global transitivity usually shortens paths\n    base *= (1.0 + assort)    **  0.2     # slightly larger distance for positively assortative networks\n\n    # ---- 5. Triangle influence: bell‑shaped term accentuating intermediate triangle densities ----\n    base += 4.0 * tri_frac * (1.0 - tri_frac)\n\n    # ---- 6. Degree‑heterogeneity correction (dispersion + harmonic mean) ----\n    dispersion = std_deg / (max_deg + eps)\n    base += dispersion * (harmonic_mean / (max_deg + 1.0 + eps))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length of a graph from a set of\n    pre‑computed global statistics without performing any graph traversal\n    or importing external libraries.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary containing pre‑computed graph descriptors:\n            n                   : int    number of nodes\n            m                   : int    number of edges\n            density             : float  edge density (2m/(n(n-1)))\n            avg_degree          : float  average vertex degree\n            max_degree          : int    maximum degree\n            min_degree          : int    minimum degree\n            std_degree          : float  standard deviation of degrees\n            avg_clustering      : float  average local clustering coefficient\n            transitivity        : float  global transitivity\n            degree_assortativity: float  degree assortativity coefficient\n            num_triangles       : int    number of triangles\n            degrees             : list[int] sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.  The\n        estimator combines sparsity, clustering, transitivity,\n        assortativity, triangle richness and degree dispersion.\n    \"\"\"\n    # ---- Extract and normalise the values ----\n    n      = float(s['n'])\n    m      = float(s['m'])\n    density = float(s['density'])\n    avg_deg  = float(s['avg_degree'])\n    max_deg  = float(s['max_degree'])\n    min_deg  = float(s['min_degree'])\n    std_deg  = float(s['std_degree'])\n    avg_clust= float(s['avg_clustering'])\n    trans   = float(s['transitivity'])\n    assort  = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    eps = 1e-12  # small value to avoid division by zero\n\n    # ---- 1. Harmonic mean of the degree sequence ----\n    inv_sum = 0.0\n    for d in degrees:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic_mean = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n\n    # ---- 2. Triangle density fraction (normalized to [0,1]) ----\n    tri_frac = 0.0\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n\n    # ---- 3. Base term reflecting sparsity: grows with size, shrinks with edges ----\n    base = (n / (m + 1.0)) * (1.0 + density)\n\n    # ---- 4. Dampening / boosting factors for other structural motifs ----\n    base *= (1.0 + avg_clust) ** (-0.3)   # high local clustering can lengthen paths\n    base *= (1.0 + trans)     ** (-0.4)   # global transitivity usually shortens paths\n    base *= (1.0 + assort)    **  0.2     # slightly larger distance for positively assortative networks\n\n    # ---- 5. Triangle influence: bell‑shaped term accentuating intermediate triangle densities ----\n    base += 4.0 * tri_frac * (1.0 - tri_frac)\n\n    # ---- 6. Degree‑heterogeneity correction (dispersion + harmonic mean) ----\n    dispersion = std_deg / (max_deg + eps)\n    base += dispersion * (harmonic_mean / (max_deg + 1.0 + eps))\n\n    return base", "spearman": 0.5315397884947124, "pearson": 0.46251182578691313, "rmse": 2.4636365326298453, "mae": 2.313765637830976}}
{"timestamp": "2026-02-17T06:30:27.145631+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g9_i3_p4_807812763", "generation": 9, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.386218487394958, "fitness_mode": "correlation", "simplicity_score": 0.21995052817975927, "novelty_bonus": 0.2366666412124343, "total_score": 0.39298304782342774, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length of a graph from\n    a set of global, pre‑computed statistics.\n\n    The estimator combines several structural features in a\n    non‑linear fashion:\n\n    * a sparsity baseline that grows with the number of nodes\n      and shrinks with the number of edges;\n    * dampening factors that capture the influence of\n      density, local clustering, global transitivity and\n      degree assortativity;\n    * a bell‑shaped triangle‑density term that accentuates\n      intermediate values of the triangle fraction;\n    * a dispersion correction that accounts for the spread\n      of the degree distribution through its standard\n      deviation and harmonic mean.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors.  Expected keys:\n        'n', 'm', 'density', 'avg_degree', 'max_degree',\n        'min_degree', 'std_degree', 'avg_clustering',\n        'transitivity', 'degree_assortativity',\n        'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Extract values (convert to float for safe arithmetic)\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degs       = s['degrees']\n\n    eps = 1e-12  # to avoid division by zero\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of the degree sequence (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    inv_sum = 0.0\n    for d in degs:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic_mean = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle fraction (normalized to [0,1]) and a bell‑shaped transform\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = tri_frac * (1.0 - tri_frac)  # peaks near tri_frac = 0.5\n\n    # ------------------------------------------------------------------\n    # 3. Base term reflecting sparsity: grows with n, shrinks with m\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)\n\n    # ------------------------------------------------------------------\n    # 4. Dampening / boosting factors for other structural motifs\n    # ------------------------------------------------------------------\n    base *= (1.0 + density) ** (-0.5)        # denser graphs tend to have smaller distances\n    base *= (1.0 + avg_clust) ** (-0.3)      # high local clustering can increase distances\n    base *= (1.0 + trans) ** (-0.4)          # global transitivity usually shortens distances\n    base *= (1.0 + assort) ** 0.2            # slightly larger distance for positively assortative networks\n\n    # ------------------------------------------------------------------\n    # 5. Add the triangle influence (amplified around intermediate triangle densities)\n    # ------------------------------------------------------------------\n    base += 5.0 * tri_bell\n\n    # ------------------------------------------------------------------\n    # 6. Dispersion correction: incorporate degree heterogeneity\n    # ------------------------------------------------------------------\n    dispersion = std_deg / (max_deg + eps)\n    base += dispersion * (harmonic_mean / (max_deg + 1.0 + eps))\n\n    return base\nRecent failures:\nbelow_train_threshold: train_signal=0.187323\nbelow_novelty_threshold: novelty_bonus=0.066106\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length of a graph from pre‑computed\n    global statistics.  The estimator combines sparsity, clustering,\n    transitivity, assortativity, triangle density and degree\n    heterogeneity in a non‑linear way, avoiding any graph traversal\n    or external library.\n\n    Parameters\n    ----------\n    s : dict\n        Graph descriptor with keys:\n            'n', 'm', 'density', 'avg_degree', 'max_degree',\n            'min_degree', 'std_degree', 'avg_clustering',\n            'transitivity', 'degree_assortativity',\n            'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true\n        average shortest‑path length.\n    \"\"\"\n    # Extract and cast to float for numeric safety\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12  # safeguard against division by zero\n\n    # 1. Base term reflecting sparsity: larger n, fewer edges => larger distance\n    base = n / (m + 1.0)\n\n    # 2. Dampening / boosting factors for other motifs\n    base *= (1.0 + density) ** (-0.5)           # denser graphs tend to have shorter paths\n    base *= (1.0 + avg_clust) ** (-0.3)          # high local clustering can increase distances\n    base *= (1.0 + trans) ** (-0.4)              # global transitivity usually shortens paths\n    base *= (1.0 + assort) ** 0.2                # slightly larger distance for positively assortative graphs\n\n    # 3. Triangle influence (bell‑shaped: peaks at intermediate triangle density)\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = tri_frac * (1.0 - tri_frac)       # maximum at tri_frac = 0.5\n    base += 5.0 * tri_bell\n\n    # 4. Harmonic mean of the degree sequence (low‑degree nodes increase distance)\n    inv_sum = 0.0\n    for d in degrees:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic_mean = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n\n    # 5. Dispersion correction (degree heterogeneity)\n    dispersion = std_deg / (max_deg + eps)\n    base += dispersion * (harmonic_mean / (max_deg + 1.0 + eps))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length of a graph from pre‑computed\n    global statistics.  The estimator combines sparsity, clustering,\n    transitivity, assortativity, triangle density and degree\n    heterogeneity in a non‑linear way, avoiding any graph traversal\n    or external library.\n\n    Parameters\n    ----------\n    s : dict\n        Graph descriptor with keys:\n            'n', 'm', 'density', 'avg_degree', 'max_degree',\n            'min_degree', 'std_degree', 'avg_clustering',\n            'transitivity', 'degree_assortativity',\n            'num_triangles', 'degrees'.\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true\n        average shortest‑path length.\n    \"\"\"\n    # Extract and cast to float for numeric safety\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12  # safeguard against division by zero\n\n    # 1. Base term reflecting sparsity: larger n, fewer edges => larger distance\n    base = n / (m + 1.0)\n\n    # 2. Dampening / boosting factors for other motifs\n    base *= (1.0 + density) ** (-0.5)           # denser graphs tend to have shorter paths\n    base *= (1.0 + avg_clust) ** (-0.3)          # high local clustering can increase distances\n    base *= (1.0 + trans) ** (-0.4)              # global transitivity usually shortens paths\n    base *= (1.0 + assort) ** 0.2                # slightly larger distance for positively assortative graphs\n\n    # 3. Triangle influence (bell‑shaped: peaks at intermediate triangle density)\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_bell = tri_frac * (1.0 - tri_frac)       # maximum at tri_frac = 0.5\n    base += 5.0 * tri_bell\n\n    # 4. Harmonic mean of the degree sequence (low‑degree nodes increase distance)\n    inv_sum = 0.0\n    for d in degrees:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic_mean = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n\n    # 5. Dispersion correction (degree heterogeneity)\n    dispersion = std_deg / (max_deg + eps)\n    base += dispersion * (harmonic_mean / (max_deg + 1.0 + eps))\n\n    return base", "spearman": 0.5559858996474912, "pearson": 0.4784579388620445, "rmse": 2.5012710227800827, "mae": 2.353370779535882}}
{"timestamp": "2026-02-17T06:30:27.147452+00:00", "event_type": "generation_migration", "payload": {"generation": 9, "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:30:27.149227+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 10, "model_name": "gpt-oss:20b", "best_val_score": 0.5676243841107219, "no_improve_count": 4}}
{"timestamp": "2026-02-17T06:31:36.026985+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i0_p0_519915431", "generation": 10, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.604609843937575, "fitness_mode": "correlation", "simplicity_score": 0.2173550856267008, "novelty_bonus": 0.18036204336327644, "total_score": 0.4263743500023199, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.149782\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed\n    graph statistics.  The formula is a weighted combination of\n    logarithmic size, density, clustering, triangles, degree\n    heterogeneity, assortativity and a harmonic‑mean degree term.\n    No external libraries or graph traversal are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Logarithmic size and average degree (base‑2 approximation)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for overall density (denser graphs → shorter paths)\n    base *= (1 - density) ** 0.4\n\n    # Adjust for clustering (high clustering can reduce path length in small‑worlds)\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for global transitivity\n    base *= (1 + trans) ** -0.1\n\n    # Triangle fraction (bell‑shaped influence)\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1 - tri_frac)          # maximised near 0.5\n    base *= (1 + tri_term) ** 0.3\n\n    # Degree heterogeneity (std / max)\n    hetero = std_deg / (max_deg + eps)\n    base *= (1 + hetero) ** 0.2\n\n    # Assortativity (absolute value)\n    base *= (1 + abs(assort)) ** -0.1\n\n    # Max degree relative to average degree\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.1\n\n    # Minimum degree (penalise very small min degree)\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Edge‑to‑vertex ratio\n    base *= (m / max(n, 1)) ** 0.05\n\n    # Harmonic mean of degrees (captures presence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base *= (1 + harmonic_mean / max(avg_deg, 1)) ** -0.1\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed\n    graph statistics.  The formula is a weighted combination of\n    logarithmic size, density, clustering, triangles, degree\n    heterogeneity, assortativity and a harmonic‑mean degree term.\n    No external libraries or graph traversal are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Logarithmic size and average degree (base‑2 approximation)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for overall density (denser graphs → shorter paths)\n    base *= (1 - density) ** 0.4\n\n    # Adjust for clustering (high clustering can reduce path length in small‑worlds)\n    base *= (1 + avg_clust) ** -0.2\n\n    # Adjust for global transitivity\n    base *= (1 + trans) ** -0.1\n\n    # Triangle fraction (bell‑shaped influence)\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1 - tri_frac)          # maximised near 0.5\n    base *= (1 + tri_term) ** 0.3\n\n    # Degree heterogeneity (std / max)\n    hetero = std_deg / (max_deg + eps)\n    base *= (1 + hetero) ** 0.2\n\n    # Assortativity (absolute value)\n    base *= (1 + abs(assort)) ** -0.1\n\n    # Max degree relative to average degree\n    if avg_deg > 0:\n        base *= (1 + max_deg / avg_deg) ** -0.1\n\n    # Minimum degree (penalise very small min degree)\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.05\n\n    # Edge‑to‑vertex ratio\n    base *= (m / max(n, 1)) ** 0.05\n\n    # Harmonic mean of degrees (captures presence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base *= (1 + harmonic_mean / max(avg_deg, 1)) ** -0.1\n\n    return base", "spearman": 0.6575894397359935, "pearson": 0.4930905667586327, "rmse": 1.0497820444573795, "mae": 0.758085480171026}}
{"timestamp": "2026-02-17T06:32:29.922384+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i0_p1_502945841", "generation": 10, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.21867031608579401, "novelty_bonus": 0.17144438359620162, "total_score": 0.446533162440623, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.149782\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T06:34:45.579770+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i0_p2_194119331", "generation": 10, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6275630252100839, "fitness_mode": "correlation", "simplicity_score": 0.2173550856267008, "novelty_bonus": 0.15908697999103116, "total_score": 0.4246914484810836, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.149782\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    # Basic parameters\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    # Approximate logarithms using bit length\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri + 1e-12)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)\n    base *= (1.0 + tri_term) ** 0.5\n\n    # Adjust for density, clustering, transitivity\n    base *= (1.0 - density) ** 0.4\n    base *= (1.0 + avg_clust) ** -0.2\n    base *= (1.0 + trans) ** -0.1\n\n    # Degree heterogeneity\n    if avg_deg > 0:\n        base *= (1.0 + std_deg / avg_deg) ** 0.05\n        base *= (1.0 + max_deg / avg_deg) ** -0.02\n    else:\n        base *= 1.0\n\n    # Minimum degree influence\n    if min_deg > 0:\n        base *= (1.0 + 1.0 / min_deg) ** 0.02\n    else:\n        base *= 1.0\n\n    # Assortativity\n    base *= (1.0 + abs(assort)) ** 0.02\n\n    # Median degree adjustment\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1.0 + median_deg / avg_deg) ** -0.02\n\n    # Edge density ratios\n    base *= (m / max(n, 1)) ** 0.03\n    base *= (n / max(m + 1, 1)) ** 0.02\n\n    # Logarithmic refinement\n    base *= (log_n + 1) ** 0.01\n\n    return base", "extracted_code": "def new_invariant(s):\n    # Basic parameters\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    # Approximate logarithms using bit length\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (possible_tri + 1e-12)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)\n    base *= (1.0 + tri_term) ** 0.5\n\n    # Adjust for density, clustering, transitivity\n    base *= (1.0 - density) ** 0.4\n    base *= (1.0 + avg_clust) ** -0.2\n    base *= (1.0 + trans) ** -0.1\n\n    # Degree heterogeneity\n    if avg_deg > 0:\n        base *= (1.0 + std_deg / avg_deg) ** 0.05\n        base *= (1.0 + max_deg / avg_deg) ** -0.02\n    else:\n        base *= 1.0\n\n    # Minimum degree influence\n    if min_deg > 0:\n        base *= (1.0 + 1.0 / min_deg) ** 0.02\n    else:\n        base *= 1.0\n\n    # Assortativity\n    base *= (1.0 + abs(assort)) ** 0.02\n\n    # Median degree adjustment\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > 0:\n            base *= (1.0 + median_deg / avg_deg) ** -0.02\n\n    # Edge density ratios\n    base *= (m / max(n, 1)) ** 0.03\n    base *= (n / max(m + 1, 1)) ** 0.02\n\n    # Logarithmic refinement\n    base *= (log_n + 1) ** 0.01\n\n    return base", "spearman": 0.6669886747168681, "pearson": 0.5012107770685421, "rmse": 1.1267499011339848, "mae": 0.8028212799176602}}
{"timestamp": "2026-02-17T06:36:58.199840+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i0_p3_438267032", "generation": 10, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5975990396158463, "fitness_mode": "correlation", "simplicity_score": 0.21722920908637272, "novelty_bonus": 0.15546781695230172, "total_score": 0.4223039923481013, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.149782\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed\n    graph statistics.  The formula is a weighted combination of\n    logarithmic size, degree distribution, density, clustering,\n    triangle density, degree heterogeneity, assortativity and\n    harmonic mean of degrees.  No external libraries or graph traversal\n    are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys:\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles, degrees\n\n    Returns\n    -------\n    float\n        Proxy for the average shortest‑path length.\n    \"\"\"\n    # Basic values\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degs = s.get('degrees', [])\n\n    # ---------- 1. Logarithmic size and degree ----------\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # ---------- 2. Density adjustment ----------\n    base *= (1.0 + density) ** -0.4\n\n    # ---------- 3. Clustering / transitivity ----------\n    base *= (1.0 + avg_clust) ** -0.2\n    base *= (1.0 + trans) ** -0.1\n\n    # ---------- 4. Triangle density ----------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_tri = 1.0\n    tri_frac = num_tri / (possible_tri + 1e-12)\n    tri_term = tri_frac * (1.0 - tri_frac)          # bell‑shaped\n    base *= (1.0 + tri_term) ** 0.3\n\n    # ---------- 5. Degree heterogeneity ----------\n    base *= (1.0 + std_deg / max(avg_deg, 1.0)) ** 0.2\n\n    # ---------- 6. Assortativity ----------\n    base *= (1.0 + abs(assort)) ** -0.1\n\n    # ---------- 7. Max/min degree ratios ----------\n    base *= (1.0 + max_deg / max(avg_deg, 1.0)) ** -0.1\n    base *= (1.0 + min_deg / max(avg_deg, 1.0)) ** 0.1\n\n    # ---------- 8. Edge density ratios ----------\n    base *= (m / max(n, 1.0)) ** 0.05\n    base *= (n / max(m + 1, 1.0)) ** 0.05\n\n    # ---------- 9. Harmonic mean of degrees ----------\n    if degs:\n        eps = 1e-12\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += (harmonic_mean / max(n, 1.0)) * 0.1\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed\n    graph statistics.  The formula is a weighted combination of\n    logarithmic size, degree distribution, density, clustering,\n    triangle density, degree heterogeneity, assortativity and\n    harmonic mean of degrees.  No external libraries or graph traversal\n    are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys:\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles, degrees\n\n    Returns\n    -------\n    float\n        Proxy for the average shortest‑path length.\n    \"\"\"\n    # Basic values\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degs = s.get('degrees', [])\n\n    # ---------- 1. Logarithmic size and degree ----------\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # ---------- 2. Density adjustment ----------\n    base *= (1.0 + density) ** -0.4\n\n    # ---------- 3. Clustering / transitivity ----------\n    base *= (1.0 + avg_clust) ** -0.2\n    base *= (1.0 + trans) ** -0.1\n\n    # ---------- 4. Triangle density ----------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_tri = 1.0\n    tri_frac = num_tri / (possible_tri + 1e-12)\n    tri_term = tri_frac * (1.0 - tri_frac)          # bell‑shaped\n    base *= (1.0 + tri_term) ** 0.3\n\n    # ---------- 5. Degree heterogeneity ----------\n    base *= (1.0 + std_deg / max(avg_deg, 1.0)) ** 0.2\n\n    # ---------- 6. Assortativity ----------\n    base *= (1.0 + abs(assort)) ** -0.1\n\n    # ---------- 7. Max/min degree ratios ----------\n    base *= (1.0 + max_deg / max(avg_deg, 1.0)) ** -0.1\n    base *= (1.0 + min_deg / max(avg_deg, 1.0)) ** 0.1\n\n    # ---------- 8. Edge density ratios ----------\n    base *= (m / max(n, 1.0)) ** 0.05\n    base *= (n / max(m + 1, 1.0)) ** 0.05\n\n    # ---------- 9. Harmonic mean of degrees ----------\n    if degs:\n        eps = 1e-12\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += (harmonic_mean / max(n, 1.0)) * 0.1\n\n    return base", "spearman": 0.6644356108902724, "pearson": 0.4811984512059486, "rmse": 1.1055879723898367, "mae": 0.7847485307226835}}
{"timestamp": "2026-02-17T06:37:43.139601+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 0, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:37:43.140096+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 10, "island_id": 0, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:39:22.909972+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i0_p4_325342355", "generation": 10, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6156542617046818, "fitness_mode": "correlation", "simplicity_score": 0.2171672955203916, "novelty_bonus": 0.1694625146017511, "total_score": 0.42195390552690476, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\n\ndef new_invariant(s):\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    assort = s.get('degree_assortativity', 0.0)\n    degrees = s.get('degrees', [])\n\n    # Logarithm approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Structural adjustments\n    base *= (1 - density) ** 0.45\n    base *= (1 + avg_clust) ** -0.12\n    base *= (1 + trans) ** -0.08\n    base *= (1 + num_tri / n) ** -0.07\n    base *= (1 + std_deg / max(avg_deg, 1)) ** 0.07\n    base *= (1 + max_deg / max(avg_deg, 1)) ** -0.03\n    if min_deg > 0:\n        base *= (1 + 1 / min_deg) ** 0.03\n    base *= (1 + abs(assort)) ** 0.03\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1 + median_deg / max(avg_deg, 1)) ** -0.03\n    base *= (m / max(n, 1)) ** 0.09\n    base *= (1 + avg_deg) ** -0.02\n    base *= (n / max(m + 1, 1)) ** 0.02\n    base *= (log_n + 1) ** 0.01\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.149782\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a lightweight\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph parameters\n    n = float(s.get('n', 0))\n    if n <= 1:\n        return 0.0\n\n    m = float(s.get('m', 0))\n    density = float(s.get('density', 0.0))\n    avg_deg = float(s.get('avg_degree', 0.0))\n    max_deg = float(s.get('max_degree', 0))\n    min_deg = float(s.get('min_degree', 0))\n    std_deg = float(s.get('std_degree', 0.0))\n    avg_clust = float(s.get('avg_clustering', 0.0))\n    trans = float(s.get('transitivity', 0.0))\n    assort = float(s.get('degree_assortativity', 0.0))\n    num_tri = float(s.get('num_triangles', 0))\n    degrees = s.get('degrees', [])\n\n    # ---------- 1. Logarithmic base (random‑graph intuition) ----------\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # ---------- 2. Structural adjustments ----------\n    # Density: denser graphs tend to have shorter paths\n    base *= (1.0 + density) ** -0.5\n\n    # Clustering: high clustering can reduce path length in small‑world\n    base *= (1.0 + avg_clust) ** -0.2\n\n    # Transitivity: similar effect to clustering\n    base *= (1.0 + trans) ** -0.1\n\n    # Assortativity: disassortative mixing can increase path length\n    base *= (1.0 + abs(assort)) ** -0.05\n\n    # Triangle fraction: a bell‑shaped influence\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1.0 + tri_frac) ** -0.1\n\n    # ---------- 3. Degree heterogeneity ----------\n    # Harmonic mean of degrees (captures presence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n    base *= (1.0 + harmonic_mean) ** -0.05\n\n    # Dispersion term: std / max degree\n    disp_term = std_deg / (max_deg + eps)\n    base *= (1.0 + disp_term) ** 0.05\n\n    # ---------- 4. Edge density correction ----------\n    # Edge count relative to node count\n    base *= (m / max(n, 1)) ** 0.07\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph parameters\n    n = float(s.get('n', 0))\n    if n <= 1:\n        return 0.0\n\n    m = float(s.get('m', 0))\n    density = float(s.get('density', 0.0))\n    avg_deg = float(s.get('avg_degree', 0.0))\n    max_deg = float(s.get('max_degree', 0))\n    min_deg = float(s.get('min_degree', 0))\n    std_deg = float(s.get('std_degree', 0.0))\n    avg_clust = float(s.get('avg_clustering', 0.0))\n    trans = float(s.get('transitivity', 0.0))\n    assort = float(s.get('degree_assortativity', 0.0))\n    num_tri = float(s.get('num_triangles', 0))\n    degrees = s.get('degrees', [])\n\n    # ---------- 1. Logarithmic base (random‑graph intuition) ----------\n    int_n = int(n) if n > 0 else 1\n    log_n = int_n.bit_length() - 1\n\n    if avg_deg > 0:\n        int_avg_deg = int(avg_deg)\n        log_avg_deg = int_avg_deg.bit_length() - 1\n        if log_avg_deg < 1:\n            log_avg_deg = 1\n    else:\n        log_avg_deg = 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # ---------- 2. Structural adjustments ----------\n    base *= (1.0 + density) ** -0.5\n    base *= (1.0 + avg_clust) ** -0.2\n    base *= (1.0 + trans) ** -0.1\n    base *= (1.0 + abs(assort)) ** -0.05\n\n    # Triangle fraction (bell‑shaped influence)\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1.0 + tri_frac) ** -0.1\n\n    # ---------- 3. Degree heterogeneity ----------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n    base *= (1.0 + harmonic_mean) ** -0.05\n\n    disp_term = std_deg / (max_deg + eps)\n    base *= (1.0 + disp_term) ** 0.05\n\n    # ---------- 4. Edge density correction ----------\n    base *= (max(m, eps) / max(n, 1.0)) ** 0.07\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph parameters\n    n = float(s.get('n', 0))\n    if n <= 1:\n        return 0.0\n\n    m = float(s.get('m', 0))\n    density = float(s.get('density', 0.0))\n    avg_deg = float(s.get('avg_degree', 0.0))\n    max_deg = float(s.get('max_degree', 0))\n    min_deg = float(s.get('min_degree', 0))\n    std_deg = float(s.get('std_degree', 0.0))\n    avg_clust = float(s.get('avg_clustering', 0.0))\n    trans = float(s.get('transitivity', 0.0))\n    assort = float(s.get('degree_assortativity', 0.0))\n    num_tri = float(s.get('num_triangles', 0))\n    degrees = s.get('degrees', [])\n\n    # ---------- 1. Logarithmic base (random‑graph intuition) ----------\n    int_n = int(n) if n > 0 else 1\n    log_n = int_n.bit_length() - 1\n\n    if avg_deg > 0:\n        int_avg_deg = int(avg_deg)\n        log_avg_deg = int_avg_deg.bit_length() - 1\n        if log_avg_deg < 1:\n            log_avg_deg = 1\n    else:\n        log_avg_deg = 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # ---------- 2. Structural adjustments ----------\n    base *= (1.0 + density) ** -0.5\n    base *= (1.0 + avg_clust) ** -0.2\n    base *= (1.0 + trans) ** -0.1\n    base *= (1.0 + abs(assort)) ** -0.05\n\n    # Triangle fraction (bell‑shaped influence)\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1.0 + tri_frac) ** -0.1\n\n    # ---------- 3. Degree heterogeneity ----------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n    base *= (1.0 + harmonic_mean) ** -0.05\n\n    disp_term = std_deg / (max_deg + eps)\n    base *= (1.0 + disp_term) ** 0.05\n\n    # ---------- 4. Edge density correction ----------\n    base *= (max(m, eps) / max(n, 1.0)) ** 0.07\n\n    return base", "spearman": 0.6553633840846023, "pearson": 0.48679208412163516, "rmse": 1.1024196813780418, "mae": 0.791183383032625}}
{"timestamp": "2026-02-17T06:39:22.910790+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 10, "island_id": 0, "population_idx": 4, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:40:25.247105+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i1_p0_607374000", "generation": 10, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12243862523924334, "novelty_bonus": 0.185688142203555, "total_score": 0.46061642826542915, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.140840\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = pow(n, 0.5)\n\n    # Combine all components multiplicatively\n    return size_edge_ratio * degree_factor * clustering_factor * triangle_factor * assort_factor * size_factor\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = pow(n, 0.5)\n\n    # Combine all components multiplicatively\n    return size_edge_ratio * degree_factor * clustering_factor * triangle_factor * assort_factor * size_factor", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T06:41:46.801661+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i1_p1_183167579", "generation": 10, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.140840\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T06:42:36.425531+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 1, "population_idx": 2, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.142089", "model_name": "gpt-oss:20b", "train_signal": 0.14208883553421367}}
{"timestamp": "2026-02-17T06:43:28.461214+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i1_p3_368726768", "generation": 10, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.3746938775510204, "fitness_mode": "correlation", "simplicity_score": 0.11535475902430758, "novelty_bonus": 0.33960480519401304, "total_score": 0.22047403140401645, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nbelow_train_threshold: train_signal=0.142089\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, assortativity, and degree‑distribution\n    skewness into a single scalar value.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n    degrees    = s['degrees']          # sorted list (ascending)\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density scaling\n    density_factor = density\n\n    # Component 8 – top‑degree influence\n    k = 5 if n >= 5 else n\n    if k > 0:\n        top_k_sum = sum(degrees[-k:])\n        top_k_avg = top_k_sum / k\n    else:\n        top_k_avg = 0.0\n    top_factor = (top_k_avg + 1.0) / denom\n\n    # Component 9 – minimum degree influence\n    min_factor = (min_deg + 1.0) / denom\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor *\n        top_factor *\n        min_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, assortativity, and degree‑distribution\n    skewness into a single scalar value.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n    degrees    = s['degrees']          # sorted list (ascending)\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density scaling\n    density_factor = density\n\n    # Component 8 – top‑degree influence\n    k = 5 if n >= 5 else n\n    if k > 0:\n        top_k_sum = sum(degrees[-k:])\n        top_k_avg = top_k_sum / k\n    else:\n        top_k_avg = 0.0\n    top_factor = (top_k_avg + 1.0) / denom\n\n    # Component 9 – minimum degree influence\n    min_factor = (min_deg + 1.0) / denom\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor *\n        top_factor *\n        min_factor\n    )", "spearman": -0.19104327608190208, "pearson": -0.14597179384254638, "rmse": 2.9091702464725566, "mae": 2.760679116703744}}
{"timestamp": "2026-02-17T06:44:00.933369+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i1_p4_401913476", "generation": 10, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nbelow_train_threshold: train_signal=0.142089\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T06:45:02.499492+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:45:02.500583+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 10, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:45:51.109665+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i2_p0_379600409", "generation": 10, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7504921968787513, "fitness_mode": "correlation", "simplicity_score": 0.22054150232247327, "novelty_bonus": 0.42540680902280115, "total_score": 0.5083155078004508, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.128390\nbelow_novelty_threshold: novelty_bonus=0.132801\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    The formula is a compact, interpretable combination of graph size,\n    connectivity, clustering, degree heterogeneity, assortativity and\n    the presence of hubs (high‑degree vertices).  It uses only\n    built‑in Python operations and does not import any external\n    libraries.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph attributes with safe defaults\n    n          = s.get('n', 1)\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Edge case: trivial graph\n    if n <= 1:\n        return 0.0\n\n    # Avoid division by zero – use small epsilon\n    eps = 1e-6\n\n    # Base estimate: larger networks with low connectivity\n    # tend to have longer average shortest paths.\n    denom_conn = max(avg_deg, eps) * max(density, eps)\n    base = n / denom_conn\n\n    # Clustering and transitivity create shortcuts.\n    base *= (1.0 + avg_clust + trans)\n\n    # Assortativity influences path length – treat magnitude symmetrically.\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment – more triangles usually shorten paths.\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity: networks with a wide degree spread\n    # (hubs) typically have shorter paths.\n    base /= (1.0 + std_deg / max(avg_deg, eps))\n\n    # Penalise an excessively high maximum degree (too few hubs).\n    base /= (1.0 + max_deg / max(avg_deg, eps))\n\n    # Proportion of very high‑degree nodes (hubs) – they provide shortcuts.\n    if degrees:\n        high_deg_cutoff = avg_deg * 2.0\n        # Count nodes whose degree exceeds twice the average.\n        high_deg_count = sum(1 for d in degrees if d > high_deg_cutoff)\n        high_deg_ratio = high_deg_count / n\n        base *= (1.0 + high_deg_ratio)\n\n    # Ensure a reasonable lower bound for very dense graphs.\n    # In extremely dense graphs, the average shortest path can be very\n    # small, so we cap the scaling factor.\n    if density > 0.9:\n        base = min(base, 1.5)\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "def new_invariant(s):\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    if n <= 1:\n        return 0.0\n\n    eps = 1e-6\n    denom_conn = max(avg_deg, eps) * max(density, eps)\n    base = n / denom_conn\n\n    base *= 1.0 + avg_clust + trans\n    base *= 1.0 + abs(assort)\n\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    base /= 1.0 + std_deg / max(avg_deg, eps)\n    base /= 1.0 + max_deg / max(avg_deg, eps)\n\n    if degrees:\n        high_deg_cutoff = avg_deg * 2.0\n        high_deg_count = sum(1 for d in degrees if d > high_deg_cutoff)\n        high_deg_ratio = high_deg_count / n\n        base *= 1.0 + high_deg_ratio\n\n    if density > 0.9:\n        base = min(base, 1.5)\n\n    return base", "extracted_code": "def new_invariant(s):\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    if n <= 1:\n        return 0.0\n\n    eps = 1e-6\n    denom_conn = max(avg_deg, eps) * max(density, eps)\n    base = n / denom_conn\n\n    base *= 1.0 + avg_clust + trans\n    base *= 1.0 + abs(assort)\n\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    base /= 1.0 + std_deg / max(avg_deg, eps)\n    base /= 1.0 + max_deg / max(avg_deg, eps)\n\n    if degrees:\n        high_deg_cutoff = avg_deg * 2.0\n        high_deg_count = sum(1 for d in degrees if d > high_deg_cutoff)\n        high_deg_ratio = high_deg_count / n\n        base *= 1.0 + high_deg_ratio\n\n    if density > 0.9:\n        base = min(base, 1.5)\n\n    return base", "spearman": 0.6731703292582316, "pearson": 0.6774180049828069, "rmse": 98.17867935159087, "mae": 69.72121711447544}}
{"timestamp": "2026-02-17T06:45:51.110182+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 10, "island_id": 2, "population_idx": 0, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:47:01.440623+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.128540", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:47:01.441213+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 10, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.128540", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:47:46.392804+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 2, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.146354", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:47:46.393302+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 10, "island_id": 2, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:48:21.117199+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:48:21.117854+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 10, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:48:49.747817+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i2_p2_867025521", "generation": 10, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9774309723889555, "fitness_mode": "correlation", "simplicity_score": 0.22078856477659164, "novelty_bonus": 0.17650877698103795, "total_score": 0.5668148386619452, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.128540\nbelow_novelty_threshold: novelty_bonus=0.146354\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of pre‑computed\n    graph statistics.  The expression is deliberately simple, uses only\n    built‑in operations and does not import any external modules.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic graph quantities with safe defaults\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # 1. Base estimate: inversely related to connectivity\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # 2. Shortcuts from clustering, transitivity and assortativity\n    # ------------------------------------------------------------------\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density adjustment\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # 4. Degree heterogeneity normalisation\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 5. Penalise extreme maximum degree (few hubs)\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1.0)\n\n    # ------------------------------------------------------------------\n    # 6. Optional median‑degree refinement\n    # ------------------------------------------------------------------\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        # If the median is lower than the average, paths are likely longer\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n    base *= (1.0 + (assort if assort >= 0 else -assort))\n\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    base /= (max_deg + 1.0)\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n    base *= (1.0 + (assort if assort >= 0 else -assort))\n\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    base /= (max_deg + 1.0)\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.9394089852246308, "pearson": 0.851683774763385, "rmse": 21.002780260731164, "mae": 12.112654815545278}}
{"timestamp": "2026-02-17T06:48:49.748341+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 10, "island_id": 2, "population_idx": 2, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:49:43.790381+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i2_p3_600555754", "generation": 10, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9564945978391356, "fitness_mode": "correlation", "simplicity_score": 0.22002454515451178, "novelty_bonus": 0.19654646539067466, "total_score": 0.5559951743062462, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.128540\nbelow_novelty_threshold: novelty_bonus=0.146354\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of node degrees\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Avoid division by zero\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering, transitivity, and assortativity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Harmonic mean of degrees (captures presence of many low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        count   = 0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / d\n                count += 1\n        if count > 0 and inv_sum > 0:\n            harm_mean = count / inv_sum\n            base *= (1.0 + harm_mean / max(avg_deg, 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of node degrees\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Avoid division by zero\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering, transitivity, and assortativity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Harmonic mean of degrees (captures presence of many low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        count   = 0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / d\n                count += 1\n        if count > 0 and inv_sum > 0:\n            harm_mean = count / inv_sum\n            base *= (1.0 + harm_mean / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.906052651316283, "pearson": 0.8024445182878114, "rmse": 35.848455132722755, "mae": 22.05725670951042}}
{"timestamp": "2026-02-17T06:50:30.193031+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:50:30.193734+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 10, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:51:17.949233+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i2_p4_247718367", "generation": 10, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8961824729891957, "fitness_mode": "correlation", "simplicity_score": 0.22056848796131304, "novelty_bonus": 0.23328509438308365, "total_score": 0.5159135212645717, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length using a compact combination\n    of pre‑computed graph statistics. The formula balances the effect of\n    graph size, connectivity, clustering, degree heterogeneity and\n    assortativity.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average node degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Approximate average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics with safe defaults\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n\n    # Base estimate inversely related to average degree and density\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Adjust for clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.128540\nbelow_novelty_threshold: novelty_bonus=0.146354\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of pre‑computed\n    graph statistics.  The estimate is a weighted combination of\n    connectivity, clustering, degree heterogeneity, assortativity and\n    triangle density.  It is deliberately simple and uses only the\n    standard library (math).\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    import math\n\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic connectivity term\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n    degrees   = s.get('degrees', [])\n\n    # Harmonic mean of degrees – used to capture degree balance\n    if degrees:\n        harm = len(degrees) / sum(1.0 / d if d > 0 else 0.0 for d in degrees)\n    else:\n        harm = 0.0\n\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + 0.5 * abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Scale by harmonic mean – more balanced degree distributions\n    if harm > 0:\n        base *= (harm / max(avg_deg, 1e-6))\n\n    # Log‑scale for large graphs to keep the estimate in a reasonable range\n    base *= math.log(n + 1)\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of pre‑computed\n    graph statistics.  The estimate is a weighted combination of\n    connectivity, clustering, degree heterogeneity, assortativity and\n    triangle density.  It uses only built‑in Python functions.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n    degrees   = s.get('degrees', [])\n\n    # Harmonic mean of degrees – used to capture degree balance\n    if degrees:\n        harm = len(degrees) / sum(1.0 / d if d > 0 else 0.0 for d in degrees)\n    else:\n        harm = 0.0\n\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + 0.5 * abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Scale by harmonic mean – more balanced degree distributions\n    if harm > 0:\n        base *= (harm / max(avg_deg, 1e-6))\n\n    # Log‑scale replacement: use square‑root to keep the estimate in range\n    base *= (n + 1) ** 0.5\n\n    return base", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of pre‑computed\n    graph statistics.  The estimate is a weighted combination of\n    connectivity, clustering, degree heterogeneity, assortativity and\n    triangle density.  It uses only built‑in Python functions.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n    degrees   = s.get('degrees', [])\n\n    # Harmonic mean of degrees – used to capture degree balance\n    if degrees:\n        harm = len(degrees) / sum(1.0 / d if d > 0 else 0.0 for d in degrees)\n    else:\n        harm = 0.0\n\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + 0.5 * abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very large maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Scale by harmonic mean – more balanced degree distributions\n    if harm > 0:\n        base *= (harm / max(avg_deg, 1e-6))\n\n    # Log‑scale replacement: use square‑root to keep the estimate in range\n    base *= (n + 1) ** 0.5\n\n    return base", "spearman": 0.803628590714768, "pearson": 0.6320099867314988, "rmse": 107.75084293499164, "mae": 65.85665229738133}}
{"timestamp": "2026-02-17T06:51:17.951375+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 10, "island_id": 2, "population_idx": 4, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:52:12.500573+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.136569", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:52:12.501281+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 10, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.136569", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:53:26.953245+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 3, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.052693", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:53:26.954022+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 10, "island_id": 3, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:54:17.002833+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.018197", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:54:17.003254+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 10, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.018197", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:54:54.190807+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.131571", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:54:54.191330+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 10, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:55:38.126046+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.005731", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:55:38.126418+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 10, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.005731", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:56:29.663251+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i3_p2_565105692", "generation": 10, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.306890756302521, "fitness_mode": "correlation", "simplicity_score": 0.2182476923793156, "novelty_bonus": 0.43269730182515054, "total_score": 0.3186398585516465, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.052693\nbelow_novelty_threshold: novelty_bonus=0.018197\nbelow_novelty_threshold: novelty_bonus=0.131571\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: novelty_bonus=0.005731\nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using only global graph\n    descriptors.  The formula is a handcrafted non‑linear combination\n    that takes into account connectivity, triangle density, clustering,\n    assortativity, and degree heterogeneity.  No traversal or external\n    library is required.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features.  Expected keys are:\n            n                     (int)  number of nodes\n            m                     (int)  number of edges\n            density               (float)\n            avg_degree            (float)\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)\n            transitivity          (float)\n            degree_assortativity  (float)\n            num_triangles         (int)\n            degrees               (list[int]) sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that increases monotonically with the true\n        average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # guard against division by zero\n\n    # ---------- Extract feature values ----------\n    n           = float(s['n'])\n    m           = float(s['m'])\n    density     = float(s['density'])\n    avg_deg     = float(s['avg_degree'])\n    max_deg     = float(s['max_degree'])\n    min_deg     = float(s['min_degree'])\n    std_deg     = float(s['std_degree'])\n    avg_clust   = float(s['avg_clustering'])\n    trans       = float(s['transitivity'])\n    assort      = float(s['degree_assortativity'])\n    num_tri     = float(s['num_triangles'])\n    degs        = s['degrees']\n\n    # ---------- 1. Harmonic mean of degrees ----------\n    if degs:\n        inv_sum = sum(1.0/(d + eps) for d in degs if d > 0)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ---------- 2. Triangle density ----------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ---------- 3. Base connectivity factor ----------\n    # Larger graphs with low density or low average degree lead to\n    # larger typical distances, so we invert the product.\n    base = n / (density * (avg_deg + eps) + eps)\n\n    # ---------- 4. Structural adjustments ----------\n    # Triangle richness: peak around medium triangle density\n    base *= (1.0 + tri_frac * (1.0 - tri_frac)) ** 0.6\n\n    # Strong local clustering usually creates long local loops,\n    # lengthening typical distances.\n    base *= (1.0 - avg_clust) ** 0.3\n\n    # Global transitivity is a coarse proxy for shortcut density.\n    base *= (1.0 - trans) ** 0.2\n\n    # Disassortative mixing tends to shorten paths; the coefficient\n    # is applied directly, positive assortativity elongates distances.\n    base *= (1.0 + assort * 0.5)\n\n    # ---------- 5. Degree heterogeneity penalty ----------\n    # Hubs (high degree variability) generally reduce distances.\n    heterogeneity = (std_deg / (max_deg + eps)) * \\\n                    (harmonic_mean / (max_deg + eps))\n    return base + heterogeneity\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    A novel, purely numeric proxy for the average shortest‑path length that\n    combines a handful of structural descriptors in a non‑linear way.  No\n    graph traversal is performed and the function is fully deterministic\n    given the input dictionary.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed global graph descriptors.  Expected keys are:\n        * 'n'                     (int)      number of nodes\n        * 'm'                     (int)      number of edges\n        * 'density'               (float)    edge density 2m/(n(n‑1))\n        * 'avg_degree'            (float)    average node degree\n        * 'max_degree'            (int)\n        * 'min_degree'            (int)\n        * 'std_degree'            (float)    standard deviation of the degree sequence\n        * 'avg_clustering'        (float)    average local clustering coefficient\n        * 'transitivity'          (float)    global transitivity\n        * 'degree_assortativity'  (float)    assortativity coefficient\n        * 'num_triangles'         (int)      number of triangles\n        * 'degrees'               (list[int]) sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar that increases monotonically with the true average\n        shortest‑path length but is constructed from a novel\n        combination of features.\n    \"\"\"\n    eps = 1e-12  # to avoid division by zero\n\n    # --- extract basic statistics ---------------------------------------------------\n    n           = float(s['n'])\n    m           = float(s['m'])\n    density     = float(s['density'])\n    avg_deg     = float(s['avg_degree'])\n    max_deg     = float(s['max_degree'])\n    min_deg     = float(s['min_degree'])\n    std_deg     = float(s['std_degree'])\n    avg_clust   = float(s['avg_clustering'])\n    trans       = float(s['transitivity'])\n    assort      = float(s['degree_assortativity'])\n    num_tri     = float(s['num_triangles'])\n    degs        = s['degrees']\n\n    # --- median degree (derived from the sorted list) -------------------------------\n    if degs:\n        median_deg = degs[len(degs) // 2]\n    else:\n        median_deg = 0.0\n\n    # --- harmonic mean of degrees --------------------------------------------------\n    if degs:\n        inv_sum = sum(1.0 / (d + eps) for d in degs if d > 0)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # --- triangle fraction ---------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # --- base term that captures the size–connectivity trade‑off --------------------\n    exp_base = 0.5 + 0.5 * density                      # 0.5 -> 1.0 as density rises\n    base = (n ** exp_base) / ((avg_deg + eps) ** 0.4)   # larger n, smaller avg_deg increase base\n\n    # --- multiplicative adjustments for clustering, transitivity, assortativity ----\n    base *= (1.0 + avg_clust) ** (-0.30)                # higher clustering tends to increase distances\n    base *= (1.0 - trans) ** (-0.20)                    # more transitivity shortens paths\n    base *= (1.0 + abs(assort)) ** (-0.15)              # positive assortativity elongates paths\n\n    # --- degree heterogeneity penalty ------------------------------------------------\n    base *= (1.0 + std_deg / (max_deg + eps)) ** (-0.10)\n\n    # --- bell‑shaped triangle factor -------------------------------------------------\n    tri_term = 4.0 * tri_frac * (1.0 - tri_frac)          # max 1.0 at tri_frac=0.5\n    base *= (1.0 + tri_term) ** 0.50\n\n    # --- additive contributions from harmonic mean and median degree ---------------\n    base += (harmonic_mean / (max_deg + eps)) * 0.20\n    base += (median_deg / (avg_deg + eps)) * 0.05\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    A novel, purely numeric proxy for the average shortest‑path length that\n    combines a handful of structural descriptors in a non‑linear way.  No\n    graph traversal is performed and the function is fully deterministic\n    given the input dictionary.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed global graph descriptors.  Expected keys are:\n        * 'n'                     (int)      number of nodes\n        * 'm'                     (int)      number of edges\n        * 'density'               (float)    edge density 2m/(n(n‑1))\n        * 'avg_degree'            (float)    average node degree\n        * 'max_degree'            (int)\n        * 'min_degree'            (int)\n        * 'std_degree'            (float)    standard deviation of the degree sequence\n        * 'avg_clustering'        (float)    average local clustering coefficient\n        * 'transitivity'          (float)    global transitivity\n        * 'degree_assortativity'  (float)    assortativity coefficient\n        * 'num_triangles'         (int)      number of triangles\n        * 'degrees'               (list[int]) sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar that increases monotonically with the true average\n        shortest‑path length but is constructed from a novel\n        combination of features.\n    \"\"\"\n    eps = 1e-12  # to avoid division by zero\n\n    # --- extract basic statistics ---------------------------------------------------\n    n           = float(s['n'])\n    m           = float(s['m'])\n    density     = float(s['density'])\n    avg_deg     = float(s['avg_degree'])\n    max_deg     = float(s['max_degree'])\n    min_deg     = float(s['min_degree'])\n    std_deg     = float(s['std_degree'])\n    avg_clust   = float(s['avg_clustering'])\n    trans       = float(s['transitivity'])\n    assort      = float(s['degree_assortativity'])\n    num_tri     = float(s['num_triangles'])\n    degs        = s['degrees']\n\n    # --- median degree (derived from the sorted list) -------------------------------\n    if degs:\n        median_deg = degs[len(degs) // 2]\n    else:\n        median_deg = 0.0\n\n    # --- harmonic mean of degrees --------------------------------------------------\n    if degs:\n        inv_sum = sum(1.0 / (d + eps) for d in degs if d > 0)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # --- triangle fraction ---------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # --- base term that captures the size–connectivity trade‑off --------------------\n    exp_base = 0.5 + 0.5 * density                      # 0.5 -> 1.0 as density rises\n    base = (n ** exp_base) / ((avg_deg + eps) ** 0.4)   # larger n, smaller avg_deg increase base\n\n    # --- multiplicative adjustments for clustering, transitivity, assortativity ----\n    base *= (1.0 + avg_clust) ** (-0.30)                # higher clustering tends to increase distances\n    base *= (1.0 - trans) ** (-0.20)                    # more transitivity shortens paths\n    base *= (1.0 + abs(assort)) ** (-0.15)              # positive assortativity elongates paths\n\n    # --- degree heterogeneity penalty ------------------------------------------------\n    base *= (1.0 + std_deg / (max_deg + eps)) ** (-0.10)\n\n    # --- bell‑shaped triangle factor -------------------------------------------------\n    tri_term = 4.0 * tri_frac * (1.0 - tri_frac)          # max 1.0 at tri_frac=0.5\n    base *= (1.0 + tri_term) ** 0.50\n\n    # --- additive contributions from harmonic mean and median degree ---------------\n    base += (harmonic_mean / (max_deg + eps)) * 0.20\n    base += (median_deg / (avg_deg + eps)) * 0.05\n\n    return base", "spearman": 0.29036225905647645, "pearson": 0.33956340764538595, "rmse": 2.2463029391563527, "mae": 2.1256255054425206}}
{"timestamp": "2026-02-17T06:56:29.664790+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 10, "island_id": 3, "population_idx": 2, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:57:13.141313+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g10_i3_p3_9243352", "generation": 10, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.3499159663865546, "fitness_mode": "correlation", "simplicity_score": 0.21956993949421266, "novelty_bonus": 0.17481619240983148, "total_score": 0.30734212020365653, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.018197\nbelow_novelty_threshold: novelty_bonus=0.131571\nbelow_novelty_threshold: novelty_bonus=0.005731\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    A hand‑crafted estimator for the average shortest‑path length based solely on\n    a collection of pre‑computed graph descriptors.  \n    The expression blends size, density, clustering, triangle abundance,\n    degree heterogeneity, and assortativity without any traversal or\n    external library calls.\n\n    Parameters\n    ----------\n    s : dict\n        Graph statistics, with required keys:\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles, degrees (sorted list)\n\n    Returns\n    -------\n    float\n        A scalar that grows roughly with the true average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # avoid division by zero\n\n    # Core numeric values (converted to float for safety)\n    n   = float(s['n'])\n    m   = float(s['m'])\n    d   = float(s['density'])\n    ad  = float(s['avg_degree'])\n    mx  = float(s['max_degree'])\n    mn  = float(s['min_degree'])\n    sd  = float(s['std_degree'])\n    ac  = float(s['avg_clustering'])\n    tr  = float(s['transitivity'])\n    ar  = float(s['degree_assortativity'])\n    nt  = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees – captures prevalence of low‑degree nodes\n    # ------------------------------------------------------------------\n    inv_sum = 0.0\n    for dgt in degs:\n        if dgt > 0:\n            inv_sum += 1.0 / (dgt + eps)\n    if inv_sum > 0:\n        harm_mean = n / (inv_sum + eps)\n    else:\n        harm_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Normalised triangle density – bell‑shaped influence\n    # ------------------------------------------------------------------\n    if n >= 3:\n        max_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = nt / (max_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # peaks when tri_frac ≈ 0.5\n\n    # ------------------------------------------------------------------\n    # 3. Basic scaling by size versus connectivity\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)                     # more edges ⇒ smaller typical distances\n    base *= (1.0 + d)                       # density shortens paths\n    base *= (1.0 - ac)                      # strong local clustering can lengthen paths\n    base *= (1.0 - tr)                      # higher global transitivity yields shortcuts\n    base *= (1.0 + abs(ar))                 # assortativity (either sign) lengthens paths\n\n    # ------------------------------------------------------------------\n    # 4. Adjust with triangles, degree spread and heterogeneity\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term)                # optimal mid‑range triangle density\n    base *= (1.0 + harm_mean / (mx + eps))  # low‑degree hubs enlarge distances\n    if sd > 0:\n        base *= (1.0 - sd / (mx + eps))     # very heterogeneous degrees often shorten distances\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    A hand‑crafted estimator for the average shortest‑path length based solely on\n    a collection of pre‑computed graph descriptors.  \n    The expression blends size, density, clustering, triangle abundance,\n    degree heterogeneity, and assortativity without any traversal or\n    external library calls.\n\n    Parameters\n    ----------\n    s : dict\n        Graph statistics, with required keys:\n            n, m, density, avg_degree, max_degree, min_degree,\n            std_degree, avg_clustering, transitivity,\n            degree_assortativity, num_triangles, degrees (sorted list)\n\n    Returns\n    -------\n    float\n        A scalar that grows roughly with the true average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # avoid division by zero\n\n    # Core numeric values (converted to float for safety)\n    n   = float(s['n'])\n    m   = float(s['m'])\n    d   = float(s['density'])\n    ad  = float(s['avg_degree'])\n    mx  = float(s['max_degree'])\n    mn  = float(s['min_degree'])\n    sd  = float(s['std_degree'])\n    ac  = float(s['avg_clustering'])\n    tr  = float(s['transitivity'])\n    ar  = float(s['degree_assortativity'])\n    nt  = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees – captures prevalence of low‑degree nodes\n    # ------------------------------------------------------------------\n    inv_sum = 0.0\n    for dgt in degs:\n        if dgt > 0:\n            inv_sum += 1.0 / (dgt + eps)\n    if inv_sum > 0:\n        harm_mean = n / (inv_sum + eps)\n    else:\n        harm_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Normalised triangle density – bell‑shaped influence\n    # ------------------------------------------------------------------\n    if n >= 3:\n        max_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = nt / (max_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # peaks when tri_frac ≈ 0.5\n\n    # ------------------------------------------------------------------\n    # 3. Basic scaling by size versus connectivity\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)                     # more edges ⇒ smaller typical distances\n    base *= (1.0 + d)                       # density shortens paths\n    base *= (1.0 - ac)                      # strong local clustering can lengthen paths\n    base *= (1.0 - tr)                      # higher global transitivity yields shortcuts\n    base *= (1.0 + abs(ar))                 # assortativity (either sign) lengthens paths\n\n    # ------------------------------------------------------------------\n    # 4. Adjust with triangles, degree spread and heterogeneity\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term)                # optimal mid‑range triangle density\n    base *= (1.0 + harm_mean / (mx + eps))  # low‑degree hubs enlarge distances\n    if sd > 0:\n        base *= (1.0 - sd / (mx + eps))     # very heterogeneous degrees often shorten distances\n\n    return base", "spearman": 0.42196654916372917, "pearson": 0.33117987205996985, "rmse": 2.5725460488115304, "mae": 2.422635150958986}}
{"timestamp": "2026-02-17T06:57:58.921564+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:57:58.922323+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 10, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:58:26.755319+00:00", "event_type": "candidate_rejected", "payload": {"generation": 10, "island_id": 3, "population_idx": 4, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.029628", "model_name": "gpt-oss:20b", "train_signal": 0.029627851140456178}}
{"timestamp": "2026-02-17T06:58:26.755962+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 10, "island_id": 3, "population_idx": 4, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T06:58:26.759472+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 11, "model_name": "gpt-oss:20b", "best_val_score": 0.5676243841107219, "no_improve_count": 5}}
{"timestamp": "2026-02-17T06:59:15.890694+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i0_p0_892090119", "generation": 11, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.634765906362545, "fitness_mode": "correlation", "simplicity_score": 0.21980506886437962, "novelty_bonus": 0.1596567673269358, "total_score": 0.448213702862429, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7127113177829447, "pearson": 0.5172731209879801, "rmse": 1.0797932772812926, "mae": 0.7254099320518048}}
{"timestamp": "2026-02-17T07:01:18.952047+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i0_p1_801296903", "generation": 11, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5645618247298919, "fitness_mode": "correlation", "simplicity_score": 0.21881129908116942, "novelty_bonus": 0.18370194304369702, "total_score": 0.4324159313065575, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed\n    graph statistics.  The formula is a non‑linear combination of size,\n    density, clustering, triangles, assortativity, and degree heterogeneity.\n    Only built‑in Python operations are used – no imports, no graph traversal.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph attributes\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # ---------- 1. Logarithmic size / degree terms ----------\n    log_n = n.bit_length() - 1                     # log2(n)\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1 if avg_deg_int > 0 else 0\n    base = log_n / max(1, log_avg_deg)\n\n    # ---------- 2. Adjust for connectivity ----------\n    base *= (1 + density) ** -0.5                 # denser → shorter paths\n    base *= (1 + avg_clust) ** -0.25              # higher clustering → shorter paths\n\n    # ---------- 3. Triangle influence ----------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1 - tri_frac)          # bell‑shaped effect\n    base *= (1 + tri_term) ** 0.6\n\n    # ---------- 4. Assortativity and degree heterogeneity ----------\n    base *= (1 + abs(assort)) ** -0.2\n    base *= (1 + std_deg / (max_deg + eps)) ** 0.1\n\n    # ---------- 5. Max/min degree ratio ----------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ---------- 6. Harmonic mean of degrees ----------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n    base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed\n    graph statistics.  The formula is a non‑linear combination of size,\n    density, clustering, triangles, assortativity, and degree heterogeneity.\n    Only built‑in Python operations are used – no imports, no graph traversal.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph attributes\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # ---------- 1. Logarithmic size / degree terms ----------\n    log_n = n.bit_length() - 1                     # log2(n)\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1 if avg_deg_int > 0 else 0\n    base = log_n / max(1, log_avg_deg)\n\n    # ---------- 2. Adjust for connectivity ----------\n    base *= (1 + density) ** -0.5                 # denser → shorter paths\n    base *= (1 + avg_clust) ** -0.25              # higher clustering → shorter paths\n\n    # ---------- 3. Triangle influence ----------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1 - tri_frac)          # bell‑shaped effect\n    base *= (1 + tri_term) ** 0.6\n\n    # ---------- 4. Assortativity and degree heterogeneity ----------\n    base *= (1 + abs(assort)) ** -0.2\n    base *= (1 + std_deg / (max_deg + eps)) ** 0.1\n\n    # ---------- 5. Max/min degree ratio ----------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ---------- 6. Harmonic mean of degrees ----------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n    base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.667086177154429, "pearson": 0.4736482388405821, "rmse": 0.9356950111721852, "mae": 0.5672252595751396}}
{"timestamp": "2026-02-17T07:02:57.166017+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i0_p2_715681764", "generation": 11, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5645618247298919, "fitness_mode": "correlation", "simplicity_score": 0.21899754220321135, "novelty_bonus": 0.18370194304369702, "total_score": 0.4324531799309659, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines size, density, clustering, triangle density,\n    degree heterogeneity, assortativity, and a harmonic mean of degrees.\n    Only built‑in Python operations are used (no imports, no graph traversal).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # ---------- 1. Base estimate from random‑graph intuition ----------\n    log_n = n.bit_length() - 1\n    int_avg_deg = int(avg_deg)\n    log_avg_deg = int_avg_deg.bit_length() - 1 if int_avg_deg > 0 else 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ---------- 2. Adjust for density (denser → shorter paths) ----------\n    base *= (1 + density) ** -0.5\n\n    # ---------- 3. Adjust for clustering (higher clustering → shorter paths) ----------\n    base *= (1 + avg_clust) ** -0.25\n\n    # ---------- 4. Triangle density factor (bell‑shaped influence) ----------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1 - tri_frac)          # maximised near tri_frac≈0.5\n    base *= (1 + tri_term) ** 0.6\n\n    # ---------- 5. Adjust for assortativity ----------\n    base *= (1 + abs(assort)) ** -0.2\n\n    # ---------- 6. Degree heterogeneity adjustment ----------\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ---------- 7. Max/min degree ratio adjustment ----------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ---------- 8. Harmonic mean of degrees contribution ----------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines size, density, clustering, triangle density,\n    degree heterogeneity, assortativity, and a harmonic mean of degrees.\n    Only built‑in Python operations are used (no imports, no graph traversal).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # ---------- 1. Base estimate from random‑graph intuition ----------\n    log_n = n.bit_length() - 1\n    int_avg_deg = int(avg_deg)\n    log_avg_deg = int_avg_deg.bit_length() - 1 if int_avg_deg > 0 else 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ---------- 2. Adjust for density (denser → shorter paths) ----------\n    base *= (1 + density) ** -0.5\n\n    # ---------- 3. Adjust for clustering (higher clustering → shorter paths) ----------\n    base *= (1 + avg_clust) ** -0.25\n\n    # ---------- 4. Triangle density factor (bell‑shaped influence) ----------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1 - tri_frac)          # maximised near tri_frac≈0.5\n    base *= (1 + tri_term) ** 0.6\n\n    # ---------- 5. Adjust for assortativity ----------\n    base *= (1 + abs(assort)) ** -0.2\n\n    # ---------- 6. Degree heterogeneity adjustment ----------\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ---------- 7. Max/min degree ratio adjustment ----------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ---------- 8. Harmonic mean of degrees contribution ----------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.667086177154429, "pearson": 0.4736482388405825, "rmse": 0.9356950111721856, "mae": 0.5672252595751398}}
{"timestamp": "2026-02-17T07:03:44.645934+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i0_p3_15789510", "generation": 11, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.2192550974144253, "novelty_bonus": 0.17144438359620162, "total_score": 0.44665011870634924, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T07:04:43.795786+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i0_p4_186218953", "generation": 11, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5487154861944777, "fitness_mode": "correlation", "simplicity_score": 0.21893482216786572, "novelty_bonus": 0.18168253865162431, "total_score": 0.4242206242515161, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    # Basic parameters\n    n = s['n']\n    avg_deg = s['avg_degree']\n    density = s['density']\n    clustering = s['avg_clustering']\n    \n    # Approximate logarithms using bit length (log2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1\n    \n    # Base estimate from random graph theory\n    base = log_n / max(1, log_avg_deg)\n    \n    # Adjust for density: denser graphs have shorter paths\n    base = base * (1 + density)**-0.5\n    \n    # Adjust for clustering: higher clustering can reduce path length in small‑world networks\n    base = base * (1 + clustering)**-0.25\n    \n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed\n    graph statistics.  The formula is a non‑linear combination of\n    size, density, clustering, triangles, assortativity, and degree\n    heterogeneity.  Only built‑in Python operations are used – no\n    imports, no external libraries, no graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    # avg_deg may be < 1; cast to int and ensure at least 1\n    int_avg_deg = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = int_avg_deg.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for density (denser graphs → shorter paths)\n    base *= (1 + density) ** -0.5\n\n    # 3. Adjust for clustering (higher clustering → shorter paths in small‑worlds)\n    base *= (1 + avg_clust) ** -0.25\n\n    # 4. Adjust for transitivity\n    base *= (1 + trans) ** -0.2\n\n    # 5. Adjust for assortativity\n    base *= (1 + abs(assort)) ** -0.1\n\n    # 6. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.15\n\n    # 7. Degree heterogeneity adjustment\n    base *= (1 + std_deg / (max_deg + eps)) ** 0.05\n\n    # 8. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 9. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + eps)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed\n    graph statistics.  The formula is a non‑linear combination of\n    size, density, clustering, triangles, assortativity, and degree\n    heterogeneity.  Only built‑in Python operations are used – no\n    imports, no external libraries, no graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    # avg_deg may be < 1; cast to int and ensure at least 1\n    int_avg_deg = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = int_avg_deg.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for density (denser graphs → shorter paths)\n    base *= (1 + density) ** -0.5\n\n    # 3. Adjust for clustering (higher clustering → shorter paths in small‑worlds)\n    base *= (1 + avg_clust) ** -0.25\n\n    # 4. Adjust for transitivity\n    base *= (1 + trans) ** -0.2\n\n    # 5. Adjust for assortativity\n    base *= (1 + abs(assort)) ** -0.1\n\n    # 6. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.15\n\n    # 7. Degree heterogeneity adjustment\n    base *= (1 + std_deg / (max_deg + eps)) ** 0.05\n\n    # 8. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 9. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + eps)\n\n    return base", "spearman": 0.6518577964449113, "pearson": 0.4616581185068006, "rmse": 0.9600957917423353, "mae": 0.5793798011420194}}
{"timestamp": "2026-02-17T07:05:25.081920+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i1_p0_343926159", "generation": 11, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224735024490937, "novelty_bonus": 0.185688142203555, "total_score": 0.4606234037073992, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nbelow_train_threshold: train_signal=0.142089\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T07:06:02.601703+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i1_p1_778762031", "generation": 11, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nbelow_train_threshold: train_signal=0.142089\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T07:07:08.513230+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i1_p2_340994179", "generation": 11, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nbelow_train_threshold: train_signal=0.142089\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T07:07:52.496224+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i1_p3_341460146", "generation": 11, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6987274909963985, "fitness_mode": "correlation", "simplicity_score": 0.11611622597871005, "novelty_bonus": 0.24266104421269463, "total_score": 0.4161850625471526, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nbelow_train_threshold: train_signal=0.142089\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, assortativity, and degree skewness into a\n    single scalar value.  All calculations use only the pre‑computed features\n    supplied in the dictionary `s`; no graph traversal or external imports\n    are required.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n    degrees    = s['degrees']          # sorted list of degrees\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density influence\n    density_factor = 1.0 + s['density']\n\n    # Component 8 – degree skewness influence\n    if std_deg > 0.0 and degrees:\n        # Compute third central moment\n        mean = avg_deg\n        third_moment = sum((d - mean) ** 3 for d in degrees)\n        skewness = third_moment / (len(degrees) * (std_deg ** 3))\n    else:\n        skewness = 0.0\n    skewness_factor = 1.0 + abs(skewness)\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor *\n        skewness_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, assortativity, and degree skewness into a\n    single scalar value.  All calculations use only the pre‑computed features\n    supplied in the dictionary `s`; no graph traversal or external imports\n    are required.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n    degrees    = s['degrees']          # sorted list of degrees\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density influence\n    density_factor = 1.0 + s['density']\n\n    # Component 8 – degree skewness influence\n    if std_deg > 0.0 and degrees:\n        # Compute third central moment\n        mean = avg_deg\n        third_moment = sum((d - mean) ** 3 for d in degrees)\n        skewness = third_moment / (len(degrees) * (std_deg ** 3))\n    else:\n        skewness = 0.0\n    skewness_factor = 1.0 + abs(skewness)\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor *\n        skewness_factor\n    )", "spearman": 0.6403270081752045, "pearson": 0.5797363578396546, "rmse": 2.654003351917868, "mae": 2.5178387869027348}}
{"timestamp": "2026-02-17T07:08:37.542703+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i1_p4_737329098", "generation": 11, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12140914268007068, "novelty_bonus": 0.185688142203555, "total_score": 0.4604105317535946, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nbelow_train_threshold: train_signal=0.142089\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics (converted to float for safety)\n    n          = float(s['n'])\n    m          = float(s['m'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_cluster= float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    triangles  = float(s['num_triangles'])\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = pow(n, 0.5)\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics (converted to float for safety)\n    n          = float(s['n'])\n    m          = float(s['m'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_cluster= float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    triangles  = float(s['num_triangles'])\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = pow(n, 0.5)\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T07:09:23.934186+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i2_p0_582641470", "generation": 11, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9774309723889555, "fitness_mode": "correlation", "simplicity_score": 0.2214354802823629, "novelty_bonus": 0.17650877698103795, "total_score": 0.5669442217630994, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n    base *= (1.0 + (assort if assort >= 0 else -assort))\n\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    base /= (max_deg + 1.0)\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.128540\nbelow_novelty_threshold: novelty_bonus=0.146354\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.9394089852246308, "pearson": 0.851683774763385, "rmse": 21.002780260731164, "mae": 12.112654815545282}}
{"timestamp": "2026-02-17T07:10:25.489010+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i2_p1_743615101", "generation": 11, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.6221848739495797, "fitness_mode": "correlation", "simplicity_score": 0.21966292554789707, "novelty_bonus": 0.17731842237809237, "total_score": 0.40456079764015257, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n    base *= (1.0 + (assort if assort >= 0 else -assort))\n\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    base /= (max_deg + 1.0)\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.128540\nbelow_novelty_threshold: novelty_bonus=0.146354\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph size\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity terms\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Avoid division by zero\n    denom_conn = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering and transitivity shorten paths – reduce the estimate\n    base /= (1.0 + avg_clust)\n    base /= (1.0 + trans)\n\n    # Assortativity: positive assortativity tends to increase distances,\n    # negative assortativity tends to decrease them.\n    if assort >= 0.0:\n        base *= (1.0 + assort)\n    else:\n        base /= (1.0 + abs(assort))\n\n    # Triangle density: more triangles typically reduce distances.\n    if m > 0:\n        base /= (1.0 + tri / m)\n\n    # Degree heterogeneity: high spread (hubs) usually shorten distances.\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n\n    # Minimum degree: a very low minimum degree can lengthen paths.\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Maximum degree: a very high maximum degree (few hubs) tends to shorten paths.\n    base /= (1.0 + max_deg / max(avg_deg, 1.0))\n\n    # Median‑to‑average difference: a skewed degree distribution can\n    # further reduce distances if the average is above the median.\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > median_deg:\n            base /= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1.0))\n        else:\n            base *= (1.0 + (median_deg - avg_deg) / max(avg_deg, 1.0))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted degree list\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph size\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity terms\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Avoid division by zero\n    denom_conn = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering and transitivity shorten paths – reduce the estimate\n    base /= (1.0 + avg_clust)\n    base /= (1.0 + trans)\n\n    # Assortativity: positive assortativity tends to increase distances,\n    # negative assortativity tends to decrease them.\n    if assort >= 0.0:\n        base *= (1.0 + assort)\n    else:\n        base /= (1.0 + abs(assort))\n\n    # Triangle density: more triangles typically reduce distances.\n    if m > 0:\n        base /= (1.0 + tri / m)\n\n    # Degree heterogeneity: high spread (hubs) usually shorten distances.\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n\n    # Minimum degree: a very low minimum degree can lengthen paths.\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Maximum degree: a very high maximum degree (few hubs) tends to shorten paths.\n    base /= (1.0 + max_deg / max(avg_deg, 1.0))\n\n    # Median‑to‑average difference: a skewed degree distribution can\n    # further reduce distances if the average is above the median.\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        if avg_deg > median_deg:\n            base /= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1.0))\n        else:\n            base *= (1.0 + (median_deg - avg_deg) / max(avg_deg, 1.0))\n\n    return base", "spearman": 0.6148653716342909, "pearson": 0.4203321518630213, "rmse": 11.376228012540507, "mae": 6.8677396306823075}}
{"timestamp": "2026-02-17T07:10:59.428882+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i2_p2_637171135", "generation": 11, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9774309723889555, "fitness_mode": "correlation", "simplicity_score": 0.22098750271261194, "novelty_bonus": 0.17650877698103795, "total_score": 0.5668546262491492, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n    base *= (1.0 + (assort if assort >= 0 else -assort))\n\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    base /= (max_deg + 1.0)\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.128540\nbelow_novelty_threshold: novelty_bonus=0.146354\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.9394089852246308, "pearson": 0.851683774763385, "rmse": 21.002780260731164, "mae": 12.112654815545278}}
{"timestamp": "2026-02-17T07:11:40.472676+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g11_i2_p3_622182356", "generation": 11, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8253061224489797, "fitness_mode": "correlation", "simplicity_score": 0.22131298568177266, "novelty_bonus": 0.33051499912764326, "total_score": 0.5035085991622048, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n    base *= (1.0 + (assort if assort >= 0 else -assort))\n\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    base /= (max_deg + 1.0)\n\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    max_deg = s.get('max_degree', 1)\n\n    # Basic connectivity term\n    denom = max(avg_deg, 1.0) * max(density, 1e-6)\n    base = n / denom\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1.0))\n    base /= (1.0 + min_deg / max(avg_deg, 1.0))\n\n    # Penalize very high maximum degree (few hubs)\n    base /= (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.128540\nbelow_novelty_threshold: novelty_bonus=0.146354\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core statistics\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n    degrees   = s.get('degrees', [])\n\n    # Base connectivity term\n    denom = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base  = n / denom\n\n    # Shortcuts induced by clustering, assortativity and triangles\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + max_deg / max(avg_deg, 1e-6))\n\n    # Optional median‑degree adjustment\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Approximate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core statistics\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    m         = s.get('m', 0)\n    tri       = s.get('num_triangles', 0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    std_deg   = s.get('std_degree', 0.0)\n    min_deg   = s.get('min_degree', 0)\n    max_deg   = s.get('max_degree', 1)\n    degrees   = s.get('degrees', [])\n\n    # Base connectivity term\n    denom = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base  = n / denom\n\n    # Shortcuts induced by clustering, assortativity and triangles\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + max_deg / max(avg_deg, 1e-6))\n\n    # Optional median‑degree adjustment\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.7201830045751145, "pearson": 0.7540476915126133, "rmse": 58.730997872403385, "mae": 41.56969072685663}}
{"timestamp": "2026-02-17T07:13:12.105300+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.067319", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:13:12.106371+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 11, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.067319", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:13:51.962472+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 2, "population_idx": 4, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:13:51.964020+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 11, "island_id": 2, "population_idx": 4, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:14:47.368807+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.087013", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:14:47.369527+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 11, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.087013", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:15:34.866565+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 3, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.070175", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:15:34.867133+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 11, "island_id": 3, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:16:16.487447+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.007820", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:16:16.488372+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 11, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.007820", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:17:07.971160+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:17:07.972265+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 11, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:17:45.690403+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.228619", "model_name": "gpt-oss:20b", "train_signal": 0.22861944777911164}}
{"timestamp": "2026-02-17T07:18:40.837557+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.064032", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:18:40.838294+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 11, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.064032", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:19:41.482504+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 3, "population_idx": 3, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.107654", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:19:41.483352+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 11, "island_id": 3, "population_idx": 3, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:20:26.529999+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.145446", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:20:26.530851+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 11, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.145446", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:21:06.890019+00:00", "event_type": "candidate_rejected", "payload": {"generation": 11, "island_id": 3, "population_idx": 4, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:21:06.890782+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 11, "island_id": 3, "population_idx": 4, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:21:06.896245+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 12, "model_name": "gpt-oss:20b", "best_val_score": 0.5676243841107219, "no_improve_count": 6}}
{"timestamp": "2026-02-17T07:23:06.964249+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g12_i0_p0_465059985", "generation": 12, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.21867031608579401, "novelty_bonus": 0.17144438359620162, "total_score": 0.446533162440623, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    # Guard against empty or trivial graphs\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    # Retrieve statistics with defaults\n    m              = s.get('m', 0)\n    density        = s.get('density', 0.0)\n    avg_deg        = s.get('avg_degree', 0.0)\n    max_deg        = s.get('max_degree', 0)\n    min_deg        = s.get('min_degree', 0)\n    std_deg        = s.get('std_degree', 0.0)\n    avg_clust      = s.get('avg_clustering', 0.0)\n    trans          = s.get('transitivity', 0.0)   # not used directly but kept for completeness\n    assort         = s.get('degree_assortativity', 0.0)\n    num_tri        = s.get('num_triangles', 0)\n    degrees        = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # 1. Logarithmic size vs. average degree (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # 2. Adjust for density (denser graphs → shorter paths)\n    base *= (1 + density) ** -0.5\n\n    # 3. Adjust for clustering (higher clustering → shorter paths)\n    base *= (1 + avg_clust) ** -0.25\n\n    # 4. Triangle density adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # 5. Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 6. Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 7. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 8. Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    # Guard against empty or trivial graphs\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    # Retrieve statistics with defaults\n    m              = s.get('m', 0)\n    density        = s.get('density', 0.0)\n    avg_deg        = s.get('avg_degree', 0.0)\n    max_deg        = s.get('max_degree', 0)\n    min_deg        = s.get('min_degree', 0)\n    std_deg        = s.get('std_degree', 0.0)\n    avg_clust      = s.get('avg_clustering', 0.0)\n    trans          = s.get('transitivity', 0.0)   # not used directly but kept for completeness\n    assort         = s.get('degree_assortativity', 0.0)\n    num_tri        = s.get('num_triangles', 0)\n    degrees        = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # 1. Logarithmic size vs. average degree (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # 2. Adjust for density (denser graphs → shorter paths)\n    base *= (1 + density) ** -0.5\n\n    # 3. Adjust for clustering (higher clustering → shorter paths)\n    base *= (1 + avg_clust) ** -0.25\n\n    # 4. Triangle density adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # 5. Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 6. Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 7. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 8. Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T07:23:56.541045+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g12_i0_p1_421248823", "generation": 12, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.2185716027501285, "novelty_bonus": 0.17144438359620162, "total_score": 0.4465134197734899, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T07:26:38.835194+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g12_i0_p2_974678000", "generation": 12, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.2185716027501285, "novelty_bonus": 0.17144438359620162, "total_score": 0.4465134197734899, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    # Guard against empty or trivial graphs\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics (use .get to avoid KeyError)\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 0)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)          # not used directly\n    assort     = s.get('degree_assortativity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # 1. Logarithmic size vs. average degree\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # 2. Adjust for density (denser graphs → shorter paths)\n    base *= (1 + density) ** -0.5\n\n    # 3. Adjust for clustering (higher clustering → shorter paths)\n    base *= (1 + avg_clust) ** -0.25\n\n    # 4. Triangle density adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # 5. Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 6. Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 7. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 8. Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    # Guard against empty or trivial graphs\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics (use .get to avoid KeyError)\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 0)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)          # not used directly\n    assort     = s.get('degree_assortativity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # 1. Logarithmic size vs. average degree\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # 2. Adjust for density (denser graphs → shorter paths)\n    base *= (1 + density) ** -0.5\n\n    # 3. Adjust for clustering (higher clustering → shorter paths)\n    base *= (1 + avg_clust) ** -0.25\n\n    # 4. Triangle density adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # 5. Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 6. Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 7. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 8. Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T07:27:24.670230+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g12_i0_p3_884039910", "generation": 12, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5096278511404562, "fitness_mode": "correlation", "simplicity_score": 0.2192550974144253, "novelty_bonus": 0.2097898924636471, "total_score": 0.44192036553143693, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines several structural features (size, degree, density,\n    clustering, triangle density, degree heterogeneity, assortativity,\n    degree ratio, and the harmonic mean of degrees).  Only built‑in Python\n    operations are used – no imports, no graph traversal, no external libraries.\n    \"\"\"\n    # Basic graph statistics with safe defaults\n    n          = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg    = s.get('avg_degree', 0.0)\n    density    = s.get('density', 0.0)\n    max_deg    = s.get('max_degree', 0)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # 2. Adjust for density (denser graphs → shorter paths)\n    base *= (1 + density) ** -0.5\n\n    # 3. Adjust for clustering (higher clustering → shorter paths)\n    base *= (1 + avg_clust) ** -0.25\n\n    # 4. Triangle density adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # 5. Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 6. Assortativity adjustment\n    base *= (1 + abs(s.get('degree_assortativity', 0.0))) ** 0.05\n\n    # 7. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 8. Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines several structural features (size, degree, density,\n    clustering, triangle density, degree heterogeneity, assortativity,\n    degree ratio, and the harmonic mean of degrees).  Only built‑in Python\n    operations are used – no imports, no graph traversal, no external libraries.\n    \"\"\"\n    # Basic graph statistics with safe defaults\n    n          = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg    = s.get('avg_degree', 0.0)\n    density    = s.get('density', 0.0)\n    max_deg    = s.get('max_degree', 0)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # 2. Adjust for density (denser graphs → shorter paths)\n    base *= (1 + density) ** -0.5\n\n    # 3. Adjust for clustering (higher clustering → shorter paths)\n    base *= (1 + avg_clust) ** -0.25\n\n    # 4. Triangle density adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # 5. Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 6. Assortativity adjustment\n    base *= (1 + abs(s.get('degree_assortativity', 0.0))) ** 0.05\n\n    # 7. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 8. Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.6702647566189155, "pearson": 0.5058094533731564, "rmse": 1.1006949746475214, "mae": 0.7714154902787778}}
{"timestamp": "2026-02-17T07:31:32.486797+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g12_i0_p4_774046441", "generation": 12, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.2190821898695896, "novelty_bonus": 0.17144438359620162, "total_score": 0.4466155371973821, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T07:32:05.485314+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g12_i1_p0_615920840", "generation": 12, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nbelow_train_threshold: train_signal=0.142089\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T07:32:33.957433+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g12_i1_p1_485345072", "generation": 12, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nbelow_train_threshold: train_signal=0.142089\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T07:33:21.083649+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g12_i1_p2_179589676", "generation": 12, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nbelow_train_threshold: train_signal=0.142089\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T07:34:19.952648+00:00", "event_type": "candidate_rejected", "payload": {"generation": 12, "island_id": 1, "population_idx": 3, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.244082", "model_name": "gpt-oss:20b", "train_signal": 0.24408163265306118}}
{"timestamp": "2026-02-17T07:44:59.429378+00:00", "event_type": "candidate_rejected", "payload": {"generation": 12, "island_id": 1, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:44:59.431280+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 12, "island_id": 1, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:45:41.004431+00:00", "event_type": "candidate_rejected", "payload": {"generation": 12, "island_id": 1, "population_idx": 4, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.163409", "model_name": "gpt-oss:20b", "train_signal": 0.1634093637454982}}
{"timestamp": "2026-02-17T07:45:41.005050+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 12, "island_id": 1, "population_idx": 4, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:46:15.454869+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g12_i2_p0_447043821", "generation": 12, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9774309723889555, "fitness_mode": "correlation", "simplicity_score": 0.22084478163114366, "novelty_bonus": 0.17650877698103795, "total_score": 0.5668260820328556, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.146354\nbelow_novelty_threshold: novelty_bonus=0.067319\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.\n\n    The estimate is built from a simple connectivity baseline\n    (size divided by a product of average degree and density) and then\n    adjusted multiplicatively to capture the influence of clustering,\n    transitivity, assortativity, triangle density, degree heterogeneity,\n    and the shape of the degree distribution.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # 1. Connectivity baseline: size divided by (avg degree × density)\n    #    (a higher avg degree or density shortens paths)\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # 2. Shortcuts from clustering and transitivity\n    # ------------------------------------------------------------------\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # ------------------------------------------------------------------\n    # 3. Effect of assortativity (use magnitude only)\n    # ------------------------------------------------------------------\n    base *= (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # 4. Triangle density adjustment – more triangles reduce distances\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # 5. Normalise by degree heterogeneity (std dev) and minimum degree\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 6. Penalise very high maximum degree (few hubs)\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1.0)\n\n    # ------------------------------------------------------------------\n    # 7. Median degree adjustment – captures skewness of the degree\n    #    distribution\n    # ------------------------------------------------------------------\n    if degrees:\n        median_idx = len(degrees) // 2\n        median_deg = degrees[median_idx]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.\n\n    The estimate is built from a simple connectivity baseline\n    (size divided by a product of average degree and density) and then\n    adjusted multiplicatively to capture the influence of clustering,\n    transitivity, assortativity, triangle density, degree heterogeneity,\n    and the shape of the degree distribution.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # 1. Connectivity baseline: size divided by (avg degree × density)\n    #    (a higher avg degree or density shortens paths)\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # 2. Shortcuts from clustering and transitivity\n    # ------------------------------------------------------------------\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # ------------------------------------------------------------------\n    # 3. Effect of assortativity (use magnitude only)\n    # ------------------------------------------------------------------\n    base *= (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # 4. Triangle density adjustment – more triangles reduce distances\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # 5. Normalise by degree heterogeneity (std dev) and minimum degree\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 6. Penalise very high maximum degree (few hubs)\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1.0)\n\n    # ------------------------------------------------------------------\n    # 7. Median degree adjustment – captures skewness of the degree\n    #    distribution\n    # ------------------------------------------------------------------\n    if degrees:\n        median_idx = len(degrees) // 2\n        median_deg = degrees[median_idx]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.9394089852246308, "pearson": 0.851683774763385, "rmse": 21.002780260731164, "mae": 12.112654815545278}}
{"timestamp": "2026-02-17T07:46:42.944525+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g12_i2_p1_693028666", "generation": 12, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9774309723889555, "fitness_mode": "correlation", "simplicity_score": 0.22098750271261194, "novelty_bonus": 0.17650877698103795, "total_score": 0.5668546262491492, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.146354\nbelow_novelty_threshold: novelty_bonus=0.067319\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula uses a connectivity baseline and\n    multiplicative corrections for clustering, assortativity, triangle\n    density, degree heterogeneity, and degree distribution skewness.\n    No external libraries are required.\n    \"\"\"\n    # Basic graph parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # 1. Connectivity baseline: size divided by (average degree × density)\n    #    A higher average degree or density shortens paths.\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # 2. Shortcuts from clustering and transitivity (both are local\n    #    measures that reduce average distances).\n    # ------------------------------------------------------------------\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # ------------------------------------------------------------------\n    # 3. Effect of assortativity (use magnitude only – both positive\n    #    and negative assortativity can increase distances).\n    # ------------------------------------------------------------------\n    base *= (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # 4. Triangle density adjustment: more triangles typically\n    #    reduce average distance.\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # 5. Normalise by degree heterogeneity: a larger spread of degrees\n    #    (especially hubs) tends to shorten paths.\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 6. Penalise very low minimum degree (sparse cores can increase\n    #    distances).\n    # ------------------------------------------------------------------\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 7. Penalise very high maximum degree (few, very high‑degree hubs)\n    #    to avoid over‑shortening.\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1.0)\n\n    # ------------------------------------------------------------------\n    # 8. Median degree adjustment: captures skewness of the degree\n    #    distribution.  If the median is below the mean, the graph is\n    #    right‑skewed (more hubs) – reduce the estimate.\n    # ------------------------------------------------------------------\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.  The formula uses a connectivity baseline and\n    multiplicative corrections for clustering, assortativity, triangle\n    density, degree heterogeneity, and degree distribution skewness.\n    No external libraries are required.\n    \"\"\"\n    # Basic graph parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # 1. Connectivity baseline: size divided by (average degree × density)\n    #    A higher average degree or density shortens paths.\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # 2. Shortcuts from clustering and transitivity (both are local\n    #    measures that reduce average distances).\n    # ------------------------------------------------------------------\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # ------------------------------------------------------------------\n    # 3. Effect of assortativity (use magnitude only – both positive\n    #    and negative assortativity can increase distances).\n    # ------------------------------------------------------------------\n    base *= (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # 4. Triangle density adjustment: more triangles typically\n    #    reduce average distance.\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # 5. Normalise by degree heterogeneity: a larger spread of degrees\n    #    (especially hubs) tends to shorten paths.\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 6. Penalise very low minimum degree (sparse cores can increase\n    #    distances).\n    # ------------------------------------------------------------------\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 7. Penalise very high maximum degree (few, very high‑degree hubs)\n    #    to avoid over‑shortening.\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1.0)\n\n    # ------------------------------------------------------------------\n    # 8. Median degree adjustment: captures skewness of the degree\n    #    distribution.  If the median is below the mean, the graph is\n    #    right‑skewed (more hubs) – reduce the estimate.\n    # ------------------------------------------------------------------\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.9394089852246308, "pearson": 0.851683774763385, "rmse": 21.002780260731164, "mae": 12.112654815545278}}
{"timestamp": "2026-02-17T07:47:25.346319+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g12_i2_p2_458181975", "generation": 12, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9661944777911164, "fitness_mode": "correlation", "simplicity_score": 0.22054150232247327, "novelty_bonus": 0.20532929605854244, "total_score": 0.565600586619491, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.146354\nbelow_novelty_threshold: novelty_bonus=0.067319\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.\n\n    The estimate is built from a simple connectivity baseline (size over\n    density × average degree) and then scaled by multiplicative factors\n    that capture clustering, transitivity, assortativity, triangle\n    density, degree heterogeneity, and the shape of the degree\n    distribution.  No external libraries are required.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Bonus factor for very low minimum degree relative to maximum\n    base *= (1.0 + min_deg / (max_deg + 1.0))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.\n\n    The estimate is built from a simple connectivity baseline (size over\n    density × average degree) and then scaled by multiplicative factors\n    that capture clustering, transitivity, assortativity, triangle\n    density, degree heterogeneity, and the shape of the degree\n    distribution.  No external libraries are required.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Bonus factor for very low minimum degree relative to maximum\n    base *= (1.0 + min_deg / (max_deg + 1.0))\n\n    return base", "spearman": 0.919786994674867, "pearson": 0.8237368080900119, "rmse": 24.62077504496716, "mae": 14.748019586208295}}
{"timestamp": "2026-02-17T07:48:11.040131+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g12_i2_p3_819421494", "generation": 12, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.6266986794717887, "fitness_mode": "correlation", "simplicity_score": 0.2204878707178393, "novelty_bonus": 0.45847026754914555, "total_score": 0.46854332702512697, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.146354\nbelow_novelty_threshold: novelty_bonus=0.067319\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed graph\n    statistics.  The formula is intentionally simple but incorporates several\n    structural aspects that influence path length: overall connectivity,\n    clustering, assortativity, triangle density, degree heterogeneity, and\n    degree distribution shape.  No external libraries are required.\n    \"\"\"\n    # Basic graph attributes\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # Connectivity baseline – higher degree or density shortens paths\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # Shortcuts from clustering, transitivity and assortativity\n    # ------------------------------------------------------------------\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # Triangle density – more triangles usually reduce average distance\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # Normalise by degree heterogeneity and minimum degree\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # Effect of hubs – a large max degree relative to the average tends\n    # to shorten paths.  We penalise very high max degrees to avoid\n    # over‑shortening when only a few hubs exist.\n    # ------------------------------------------------------------------\n    hub_factor = 1.0 + max_deg / max(avg_deg, 1e-6)\n    base /= hub_factor\n\n    # ------------------------------------------------------------------\n    # Median degree adjustment – captures skewness of the degree distribution.\n    # If the average exceeds the median, the distribution is right‑skewed\n    # (more hubs), which typically shortens paths.\n    # ------------------------------------------------------------------\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        skew = (avg_deg - median_deg) / max(avg_deg, 1e-6)\n        base /= (1.0 + skew)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed graph\n    statistics.  The formula is intentionally simple but incorporates several\n    structural aspects that influence path length: overall connectivity,\n    clustering, assortativity, triangle density, degree heterogeneity, and\n    degree distribution shape.  No external libraries are required.\n    \"\"\"\n    # Basic graph attributes\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # Connectivity baseline – higher degree or density shortens paths\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # Shortcuts from clustering, transitivity and assortativity\n    # ------------------------------------------------------------------\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # Triangle density – more triangles usually reduce average distance\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # Normalise by degree heterogeneity and minimum degree\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # Effect of hubs – a large max degree relative to the average tends\n    # to shorten paths.  We penalise very high max degrees to avoid\n    # over‑shortening when only a few hubs exist.\n    # ------------------------------------------------------------------\n    hub_factor = 1.0 + max_deg / max(avg_deg, 1e-6)\n    base /= hub_factor\n\n    # ------------------------------------------------------------------\n    # Median degree adjustment – captures skewness of the degree distribution.\n    # If the average exceeds the median, the distribution is right‑skewed\n    # (more hubs), which typically shortens paths.\n    # ------------------------------------------------------------------\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        skew = (avg_deg - median_deg) / max(avg_deg, 1e-6)\n        base /= (1.0 + skew)\n\n    return base", "spearman": 0.5738093452336309, "pearson": 0.6260480256819746, "rmse": 77.33885587295661, "mae": 49.759920173452755}}
{"timestamp": "2026-02-17T07:48:42.665812+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g12_i2_p4_213038149", "generation": 12, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9774309723889555, "fitness_mode": "correlation", "simplicity_score": 0.22098750271261194, "novelty_bonus": 0.17650877698103795, "total_score": 0.5668546262491492, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.146354\nbelow_novelty_threshold: novelty_bonus=0.067319\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n\n    The estimate is built from a connectivity baseline (size divided by a\n    product of average degree and density) and a set of multiplicative\n    corrections that capture the effects of clustering, assortativity,\n    triangle density, degree heterogeneity and the shape of the degree\n    distribution.  No graph traversal is performed and no external libraries\n    are required.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph statistics.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # 1. Connectivity baseline – larger graphs with lower density or\n    #    lower average degree tend to have longer paths.\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # 2. Shortcuts created by local structure\n    # ------------------------------------------------------------------\n    base *= (1.0 + avg_clust)          # clustering\n    base *= (1.0 + trans)              # transitivity\n    base *= (1.0 + abs(assort))        # assortativity magnitude\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density – more triangles usually reduce average distance\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # 4. Degree heterogeneity – hubs shorten paths; penalise high spread\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 5. Minimum degree – very sparse nodes increase distances\n    # ------------------------------------------------------------------\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 6. Maximum degree – a single massive hub can artificially shorten\n    #    the estimate, so we dampen its effect.\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1.0)\n\n    # ------------------------------------------------------------------\n    # 7. Median degree – captures skewness of the degree distribution.\n    # ------------------------------------------------------------------\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n\n    The estimate is built from a connectivity baseline (size divided by a\n    product of average degree and density) and a set of multiplicative\n    corrections that capture the effects of clustering, assortativity,\n    triangle density, degree heterogeneity and the shape of the degree\n    distribution.  No graph traversal is performed and no external libraries\n    are required.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph statistics.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # 1. Connectivity baseline – larger graphs with lower density or\n    #    lower average degree tend to have longer paths.\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # 2. Shortcuts created by local structure\n    # ------------------------------------------------------------------\n    base *= (1.0 + avg_clust)          # clustering\n    base *= (1.0 + trans)              # transitivity\n    base *= (1.0 + abs(assort))        # assortativity magnitude\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density – more triangles usually reduce average distance\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # 4. Degree heterogeneity – hubs shorten paths; penalise high spread\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 5. Minimum degree – very sparse nodes increase distances\n    # ------------------------------------------------------------------\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 6. Maximum degree – a single massive hub can artificially shorten\n    #    the estimate, so we dampen its effect.\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1.0)\n\n    # ------------------------------------------------------------------\n    # 7. Median degree – captures skewness of the degree distribution.\n    # ------------------------------------------------------------------\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.9394089852246308, "pearson": 0.851683774763385, "rmse": 21.002780260731164, "mae": 12.112654815545278}}
{"timestamp": "2026-02-17T07:49:25.428447+00:00", "event_type": "candidate_rejected", "payload": {"generation": 12, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.072706", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:49:25.429397+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 12, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.072706", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:50:11.950311+00:00", "event_type": "candidate_rejected", "payload": {"generation": 12, "island_id": 3, "population_idx": 0, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.035851", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:50:11.951012+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 12, "island_id": 3, "population_idx": 0, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:50:59.694755+00:00", "event_type": "candidate_rejected", "payload": {"generation": 12, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.078105", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:50:59.695285+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 12, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.078105", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:51:40.107199+00:00", "event_type": "candidate_rejected", "payload": {"generation": 12, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.033197", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:51:40.107977+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 12, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:52:16.889879+00:00", "event_type": "candidate_rejected", "payload": {"generation": 12, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.297767", "model_name": "gpt-oss:20b", "train_signal": 0.29776710684273705}}
{"timestamp": "2026-02-17T07:53:09.444807+00:00", "event_type": "candidate_rejected", "payload": {"generation": 12, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:53:09.445321+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 12, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:53:45.011940+00:00", "event_type": "candidate_rejected", "payload": {"generation": 12, "island_id": 3, "population_idx": 3, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.091048", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:53:45.012450+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 12, "island_id": 3, "population_idx": 3, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:54:27.049803+00:00", "event_type": "candidate_rejected", "payload": {"generation": 12, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.002368", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:54:27.050189+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 12, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.002368", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:54:59.615856+00:00", "event_type": "candidate_rejected", "payload": {"generation": 12, "island_id": 3, "population_idx": 4, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.013325", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:54:59.616383+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 12, "island_id": 3, "population_idx": 4, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T07:54:59.618394+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 13, "model_name": "gpt-oss:20b", "best_val_score": 0.5676243841107219, "no_improve_count": 7}}
{"timestamp": "2026-02-17T07:58:26.005197+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g13_i0_p0_558681765", "generation": 13, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6053781512605042, "fitness_mode": "correlation", "simplicity_score": 0.21853256875814728, "novelty_bonus": 0.17061710343260905, "total_score": 0.43997227179708764, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    eps = 1e-12\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic approximations\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density, clustering, transitivity\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n    base *= (1 + trans) ** -0.1\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "extracted_code": "def new_invariant(s):\n    eps = 1e-12\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    # Logarithmic approximations\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density, clustering, transitivity\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n    base *= (1 + trans) ** -0.1\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.6901612540313509, "pearson": 0.4946394173634604, "rmse": 0.9534316039926954, "mae": 0.5934752362236815}}
{"timestamp": "2026-02-17T08:01:22.155007+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g13_i0_p1_579579793", "generation": 13, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.21877068010385942, "novelty_bonus": 0.17144438359620162, "total_score": 0.44655323524423607, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, max/min degree ratio,\n    and a harmonic mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    # Basic graph statistics with defaults\n    n          = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 0)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, max/min degree ratio,\n    and a harmonic mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    # Basic graph statistics with defaults\n    n          = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 0)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    num_tri    = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T08:02:24.014912+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g13_i0_p2_391314152", "generation": 13, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.2189765633534611, "novelty_bonus": 0.17144438359620162, "total_score": 0.4465944118941564, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T08:03:10.871031+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g13_i0_p3_147760109", "generation": 13, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.2189765633534611, "novelty_bonus": 0.17144438359620162, "total_score": 0.4465944118941564, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines a logarithmic size estimate with corrections for\n    density, clustering, triangle density, degree heterogeneity, assortativity,\n    degree ratio, and a harmonic mean of degrees.  Only built‑in Python\n    operations are used – no imports, no graph traversal, no external libraries.\n    \"\"\"\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Logarithmic size estimate (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines a logarithmic size estimate with corrections for\n    density, clustering, triangle density, degree heterogeneity, assortativity,\n    degree ratio, and a harmonic mean of degrees.  Only built‑in Python\n    operations are used – no imports, no graph traversal, no external libraries.\n    \"\"\"\n    # Basic graph statistics\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Logarithmic size estimate (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T08:05:02.613230+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g13_i0_p4_620833626", "generation": 13, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.21901859382331743, "novelty_bonus": 0.17144438359620162, "total_score": 0.4466028179881277, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 1)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "extracted_code": "def new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 1)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T08:07:20.582098+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g13_i1_p0_328525499", "generation": 13, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6001920768307323, "fitness_mode": "correlation", "simplicity_score": 0.11976228479567613, "novelty_bonus": 0.2404110102752568, "total_score": 0.4335946980151616, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.244082\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.163409\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = pow(n, 0.5)\n\n    # Component 7 – density factor\n    density_factor = 1.0 + density\n\n    # Combine all components multiplicatively\n    return (size_edge_ratio *\n            degree_factor *\n            clustering_factor *\n            triangle_factor *\n            assort_factor *\n            size_factor *\n            density_factor)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = pow(n, 0.5)\n\n    # Component 7 – density factor\n    density_factor = 1.0 + density\n\n    # Combine all components multiplicatively\n    return (size_edge_ratio *\n            degree_factor *\n            clustering_factor *\n            triangle_factor *\n            assort_factor *\n            size_factor *\n            density_factor)", "spearman": 0.6750378759468987, "pearson": 0.6377208676115874, "rmse": 2.768144803056992, "mae": 2.622268323424163}}
{"timestamp": "2026-02-17T08:07:55.318115+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g13_i1_p1_485885764", "generation": 13, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.244082\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.163409\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T08:08:21.976482+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g13_i1_p2_697814255", "generation": 13, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.244082\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.163409\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    All computations use only built‑in functions (no imports).\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    All computations use only built‑in functions (no imports).\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T08:09:08.866952+00:00", "event_type": "candidate_rejected", "payload": {"generation": 13, "island_id": 1, "population_idx": 3, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.140840", "model_name": "gpt-oss:20b", "train_signal": 0.1408403361344538}}
{"timestamp": "2026-02-17T08:10:11.478187+00:00", "event_type": "candidate_rejected", "payload": {"generation": 13, "island_id": 1, "population_idx": 4, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.265978", "model_name": "gpt-oss:20b", "train_signal": 0.2659783913565426}}
{"timestamp": "2026-02-17T08:10:50.997968+00:00", "event_type": "candidate_rejected", "payload": {"generation": 13, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:10:50.998148+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 13, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:11:20.401401+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g13_i2_p0_303454828", "generation": 13, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.95812725090036, "fitness_mode": "correlation", "simplicity_score": 0.22116302089367137, "novelty_bonus": 0.2149800475195911, "total_score": 0.5421834548555221, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.146354\nbelow_novelty_threshold: novelty_bonus=0.067319\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of pre‑computed\n    graph statistics.  The formula is a simple multiplicative model that\n    captures the main structural drivers of distance:\n        * connectivity (size, density, average degree)\n        * clustering / transitivity\n        * assortativity magnitude\n        * triangle density\n        * degree heterogeneity (std, min, max)\n        * degree distribution skewness (median adjustment)\n\n    No external libraries are required; only the standard ``math`` module\n    (for ``log``) is used.  The expression is intentionally compact so that\n    it can be evaluated quickly on large collections of feature dictionaries.\n    \"\"\"\n    import math\n\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Size scaling – larger graphs tend to have longer paths\n    base *= math.log(n + 1)\n\n    # Shortcuts from local structure\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n\n    # Triangle density effect\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity normalisation\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise extreme maximum degree (too few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.  The expression is a simple\n    multiplicative model that captures the main structural drivers of\n    distance: connectivity, local clustering, assortativity, triangle\n    density, degree heterogeneity and the skewness of the degree\n    distribution.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term – higher average degree or density shortens paths\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Size scaling – larger graphs tend to have longer paths\n    base *= n ** 0.5\n\n    # Shortcuts from local structure\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n\n    # Triangle density effect\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity normalisation\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise extreme maximum degree (too few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.  The expression is a simple\n    multiplicative model that captures the main structural drivers of\n    distance: connectivity, local clustering, assortativity, triangle\n    density, degree heterogeneity and the skewness of the degree\n    distribution.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term – higher average degree or density shortens paths\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Size scaling – larger graphs tend to have longer paths\n    base *= n ** 0.5\n\n    # Shortcuts from local structure\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n\n    # Triangle density effect\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity normalisation\n    std_deg = s.get('std_degree', 0.0)\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise extreme maximum degree (too few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.8669136728418211, "pearson": 0.7810255777108231, "rmse": 205.42232732948827, "mae": 120.1277840843123}}
{"timestamp": "2026-02-17T08:11:20.402570+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 13, "island_id": 2, "population_idx": 0, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:12:17.325391+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g13_i2_p1_514229180", "generation": 13, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9774309723889555, "fitness_mode": "correlation", "simplicity_score": 0.22098750271261194, "novelty_bonus": 0.17650877698103795, "total_score": 0.5668546262491492, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.146354\nbelow_novelty_threshold: novelty_bonus=0.067319\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core graph statistics\n    m           = s.get('m', 0)\n    density     = s.get('density', 0.0)\n    avg_deg     = s.get('avg_degree', 0.0)\n    max_deg     = s.get('max_degree', 1)\n    min_deg     = s.get('min_degree', 0)\n    std_deg     = s.get('std_degree', 0.0)\n    avg_clust   = s.get('avg_clustering', 0.0)\n    trans       = s.get('transitivity', 0.0)\n    assort      = s.get('degree_assortativity', 0.0)\n    tri         = s.get('num_triangles', 0)\n    degrees     = s.get('degrees', [])\n\n    # --- Connectivity baseline -----------------------------------------\n    # Higher average degree and density shrink the mean distance.\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # --- Shortcuts from clustering, transitivity, and assortativity ----\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # --- Triangle density adjustment ------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # --- Normalisation by degree heterogeneity -------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # --- Penalise very high maximum degree (few hubs) ------------------\n    base /= (max_deg + 1.0)\n\n    # --- Median‑degree adjustment (captures skewness of degree dist.) ---\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features. Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core graph statistics\n    m           = s.get('m', 0)\n    density     = s.get('density', 0.0)\n    avg_deg     = s.get('avg_degree', 0.0)\n    max_deg     = s.get('max_degree', 1)\n    min_deg     = s.get('min_degree', 0)\n    std_deg     = s.get('std_degree', 0.0)\n    avg_clust   = s.get('avg_clustering', 0.0)\n    trans       = s.get('transitivity', 0.0)\n    assort      = s.get('degree_assortativity', 0.0)\n    tri         = s.get('num_triangles', 0)\n    degrees     = s.get('degrees', [])\n\n    # --- Connectivity baseline -----------------------------------------\n    # Higher average degree and density shrink the mean distance.\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # --- Shortcuts from clustering, transitivity, and assortativity ----\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # --- Triangle density adjustment ------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # --- Normalisation by degree heterogeneity -------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # --- Penalise very high maximum degree (few hubs) ------------------\n    base /= (max_deg + 1.0)\n\n    # --- Median‑degree adjustment (captures skewness of degree dist.) ---\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.9394089852246308, "pearson": 0.851683774763385, "rmse": 21.002780260731164, "mae": 12.112654815545278}}
{"timestamp": "2026-02-17T08:12:55.480563+00:00", "event_type": "candidate_rejected", "payload": {"generation": 13, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.048129", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:12:55.481670+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 13, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.048129", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:13:28.361528+00:00", "event_type": "candidate_rejected", "payload": {"generation": 13, "island_id": 2, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.039461", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:13:28.362017+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 13, "island_id": 2, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:13:55.403288+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g13_i2_p3_700955667", "generation": 13, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9774309723889555, "fitness_mode": "correlation", "simplicity_score": 0.22098750271261194, "novelty_bonus": 0.17650877698103795, "total_score": 0.5668546262491492, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.048129\nbelow_novelty_threshold: novelty_bonus=0.039461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # 1. Connectivity baseline – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # 2. Shortcuts from clustering, transitivity and assortativity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # 3. Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # 4. Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # 5. Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # 6. Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # 1. Connectivity baseline – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # 2. Shortcuts from clustering, transitivity and assortativity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n    base *= (1.0 + abs(assort))\n\n    # 3. Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # 4. Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # 5. Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # 6. Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.9394089852246308, "pearson": 0.851683774763385, "rmse": 21.002780260731164, "mae": 12.112654815545278}}
{"timestamp": "2026-02-17T08:14:31.205017+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g13_i2_p4_782496942", "generation": 13, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9774309723889555, "fitness_mode": "correlation", "simplicity_score": 0.22098750271261194, "novelty_bonus": 0.17650877698103795, "total_score": 0.5668546262491492, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.048129\nbelow_novelty_threshold: novelty_bonus=0.039461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed graph\n    statistics.  The formula is a multiplicative combination of a connectivity\n    baseline and several correction factors that capture clustering, assortativity,\n    triangle density, degree heterogeneity and the shape of the degree distribution.\n    No external libraries are used; only basic Python operators.\n    \"\"\"\n    # Basic graph parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # 1. Connectivity baseline: larger graphs with low density/degree\n    #    have longer paths.  The small constant avoids division by zero.\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # 2. Shortcuts from local structure\n    #    Clustering and global transitivity create many triangles,\n    #    which tend to shorten paths.\n    # ------------------------------------------------------------------\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # ------------------------------------------------------------------\n    # 3. Effect of degree assortativity\n    #    High absolute assortativity can either increase or decrease\n    #    path length; we treat the magnitude symmetrically.\n    # ------------------------------------------------------------------\n    base *= (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # 4. Triangle density adjustment\n    #    More triangles per edge usually reduce the average distance.\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # 5. Normalise by degree heterogeneity\n    #    Networks with large degree variance (hubs) typically have\n    #    shorter paths.  We divide by a term that increases with std.\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 6. Penalise very low minimum degree\n    #    A high minimum degree tends to shrink the graph’s diameter.\n    # ------------------------------------------------------------------\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 7. Penalise extremely high maximum degree\n    #    A single very high degree node can overly bias the estimate,\n    #    so we divide by (max_deg + 1) to keep it in check.\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1.0)\n\n    # ------------------------------------------------------------------\n    # 8. Median‑degree adjustment\n    #    Captures skewness of the degree distribution: if the median is\n    #    lower than the mean, the graph is right‑skewed (more hubs) and\n    #    paths tend to be shorter.\n    # ------------------------------------------------------------------\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed graph\n    statistics.  The formula is a multiplicative combination of a connectivity\n    baseline and several correction factors that capture clustering, assortativity,\n    triangle density, degree heterogeneity and the shape of the degree distribution.\n    No external libraries are used; only basic Python operators.\n    \"\"\"\n    # Basic graph parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # 1. Connectivity baseline: larger graphs with low density/degree\n    #    have longer paths.  The small constant avoids division by zero.\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # 2. Shortcuts from local structure\n    #    Clustering and global transitivity create many triangles,\n    #    which tend to shorten paths.\n    # ------------------------------------------------------------------\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # ------------------------------------------------------------------\n    # 3. Effect of degree assortativity\n    #    High absolute assortativity can either increase or decrease\n    #    path length; we treat the magnitude symmetrically.\n    # ------------------------------------------------------------------\n    base *= (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # 4. Triangle density adjustment\n    #    More triangles per edge usually reduce the average distance.\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # 5. Normalise by degree heterogeneity\n    #    Networks with large degree variance (hubs) typically have\n    #    shorter paths.  We divide by a term that increases with std.\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 6. Penalise very low minimum degree\n    #    A high minimum degree tends to shrink the graph’s diameter.\n    # ------------------------------------------------------------------\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 7. Penalise extremely high maximum degree\n    #    A single very high degree node can overly bias the estimate,\n    #    so we divide by (max_deg + 1) to keep it in check.\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1.0)\n\n    # ------------------------------------------------------------------\n    # 8. Median‑degree adjustment\n    #    Captures skewness of the degree distribution: if the median is\n    #    lower than the mean, the graph is right‑skewed (more hubs) and\n    #    paths tend to be shorter.\n    # ------------------------------------------------------------------\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.9394089852246308, "pearson": 0.851683774763385, "rmse": 21.002780260731164, "mae": 12.112654815545278}}
{"timestamp": "2026-02-17T08:15:13.658350+00:00", "event_type": "candidate_rejected", "payload": {"generation": 13, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.084574", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:15:13.659469+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 13, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.084574", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:15:52.126981+00:00", "event_type": "candidate_rejected", "payload": {"generation": 13, "island_id": 3, "population_idx": 0, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:15:52.128102+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 13, "island_id": 3, "population_idx": 0, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:16:40.189964+00:00", "event_type": "candidate_rejected", "payload": {"generation": 13, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.206146", "model_name": "gpt-oss:20b", "train_signal": 0.20614645858343336}}
{"timestamp": "2026-02-17T08:17:22.485737+00:00", "event_type": "candidate_rejected", "payload": {"generation": 13, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.120724", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:17:22.486219+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 13, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.120724", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:18:02.604383+00:00", "event_type": "candidate_rejected", "payload": {"generation": 13, "island_id": 3, "population_idx": 2, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.242545", "model_name": "gpt-oss:20b", "train_signal": 0.24254501800720288}}
{"timestamp": "2026-02-17T08:18:02.604617+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 13, "island_id": 3, "population_idx": 2, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:18:45.463259+00:00", "event_type": "candidate_rejected", "payload": {"generation": 13, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:18:45.463716+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 13, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:19:22.747125+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g13_i3_p3_741108468", "generation": 13, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.6799039615846338, "fitness_mode": "correlation", "simplicity_score": 0.21929909943905956, "novelty_bonus": 0.151394647905022, "total_score": 0.40489585470032957, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\nRecent failures:\nbelow_train_threshold: train_signal=0.206146\nbelow_novelty_threshold: novelty_bonus=0.120724\nbelow_train_threshold: train_signal=0.242545\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics.\n    The formula combines size, connectivity, clustering, triangles, assortativity\n    and degree heterogeneity without any explicit graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        'n'                     : int\n        'm'                     : int\n        'density'               : float\n        'avg_degree'            : float\n        'max_degree'            : int\n        'min_degree'            : int\n        'std_degree'            : float\n        'avg_clustering'        : float\n        'transitivity'          : float\n        'degree_assortativity'  : float\n        'num_triangles'         : int\n        'degrees'               : list[int]\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    import math\n\n    eps = 1e-12\n\n    n      = float(s['n'])\n    m      = float(s['m'])\n    density   = float(s['density'])\n    avg_deg   = float(s['avg_degree'])\n    max_deg   = float(s['max_degree'])\n    min_deg   = float(s['min_degree'])\n    std_deg   = float(s['std_degree'])\n    avg_c     = float(s['avg_clustering'])\n    trans     = float(s['transitivity'])\n    assort    = float(s['degree_assortativity'])\n    num_tri   = float(s['num_triangles'])\n    degrees   = s['degrees']\n\n    # ----- Base term : grows with graph size, shrinks with edge count -------------\n    base = n / (m + 1.0)\n\n    # ----- Connectivity correction (density × avg degree) -------------------------\n    conn = density * (avg_deg + 1.0)\n    if conn < eps:\n        conn = eps\n    base *= 1.0 / conn\n\n    # ----- Clustering and transitivity reductions --------------------------------\n    base *= 1.0 / (1.0 + avg_c)\n    base *= 1.0 / (1.0 + trans)\n\n    # ----- Assortativity adjustment ------------------------------------------------\n    # Disassortative networks tend to have shorter paths\n    base *= math.exp(-abs(assort))\n\n    # ----- Triangle density factor -------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n        base *= 1.0 / (1.0 + tri_frac)\n\n    # ----- Harmonic‑mean degree scaling --------------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = n\n    base *= harmonic / (avg_deg + eps)\n\n    # ----- Max‑degree spread adjustment --------------------------------------------\n    base *= (1.0 + max_deg) / (1.0 + std_deg + eps)\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics.\n    The estimator is a handcrafted non‑linear combination of size, density,\n    clustering, triangle density, assortativity, degree heterogeneity, and\n    harmonic‑mean information. No external libraries or graph traversal\n    operations are used.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n            'n'                     : int\n            'm'                     : int\n            'density'               : float\n            'avg_degree'            : float\n            'max_degree'            : int\n            'min_degree'            : int\n            'std_degree'            : float\n            'avg_clustering'        : float\n            'transitivity'          : float\n            'degree_assortativity'  : float\n            'num_triangles'         : int\n            'degrees'               : list[int]\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average\n        shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid divisions by zero\n\n    # ------------------------------------------------------------------\n    # Convert everything to float for safe arithmetic\n    # ------------------------------------------------------------------\n    n      = float(s['n'])\n    m      = float(s['m'])\n    density   = float(s['density'])\n    avg_deg   = float(s['avg_degree'])\n    max_deg   = float(s['max_degree'])\n    min_deg   = float(s['min_degree'])\n    std_deg   = float(s['std_degree'])\n    avg_c     = float(s['avg_clustering'])\n    trans     = float(s['transitivity'])\n    assort    = float(s['degree_assortativity'])\n    num_tri   = float(s['num_triangles'])\n    degrees   = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Base term : larger graphs give larger values, but more edges\n    #    shorten distances.\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)\n\n    # ------------------------------------------------------------------\n    # 2. Connectivity correction – high density & high average degree\n    #    reduce distances.\n    # ------------------------------------------------------------------\n    conn = density * (avg_deg + 1.0)\n    if conn < eps:\n        conn = eps\n    base *= 1.0 / conn\n\n    # ------------------------------------------------------------------\n    # 3. Clustering and transitivity reduce paths by providing shortcuts.\n    # ------------------------------------------------------------------\n    base *= 1.0 / (1.0 + avg_c)\n    base *= 1.0 / (1.0 + trans)\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity adjustment – disassortative mixes tend to shorten\n    #    paths.  We damp the effect symmetrically for positive/negative\n    #    assortativity values.\n    # ------------------------------------------------------------------\n    base *= 1.0 / (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # 5. Triangle density – more triangles usually shorten the graph,\n    #    so we down‑scale by a factor that increases with triangle\n    #    density.\n    # ------------------------------------------------------------------\n    if n >= 3.0:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n        base *= 1.0 / (1.0 + tri_frac)\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic‑mean degree scaling – captures how many low‑degree\n    #    nodes exist.  Larger harmonic mean indicates a denser core,\n    #    which typically shortens distances.\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = n\n    base *= harmonic / (avg_deg + eps)\n\n    # ------------------------------------------------------------------\n    # 7. Max‑degree spread adjustment – highly heterogeneous degree\n    #    distributions (large max degree) usually shorten distances.\n    # ------------------------------------------------------------------\n    base *= (1.0 + max_deg) / (1.0 + std_deg + eps)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics.\n    The estimator is a handcrafted non‑linear combination of size, density,\n    clustering, triangle density, assortativity, degree heterogeneity, and\n    harmonic‑mean information. No external libraries or graph traversal\n    operations are used.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n            'n'                     : int\n            'm'                     : int\n            'density'               : float\n            'avg_degree'            : float\n            'max_degree'            : int\n            'min_degree'            : int\n            'std_degree'            : float\n            'avg_clustering'        : float\n            'transitivity'          : float\n            'degree_assortativity'  : float\n            'num_triangles'         : int\n            'degrees'               : list[int]\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average\n        shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid divisions by zero\n\n    # ------------------------------------------------------------------\n    # Convert everything to float for safe arithmetic\n    # ------------------------------------------------------------------\n    n      = float(s['n'])\n    m      = float(s['m'])\n    density   = float(s['density'])\n    avg_deg   = float(s['avg_degree'])\n    max_deg   = float(s['max_degree'])\n    min_deg   = float(s['min_degree'])\n    std_deg   = float(s['std_degree'])\n    avg_c     = float(s['avg_clustering'])\n    trans     = float(s['transitivity'])\n    assort    = float(s['degree_assortativity'])\n    num_tri   = float(s['num_triangles'])\n    degrees   = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Base term : larger graphs give larger values, but more edges\n    #    shorten distances.\n    # ------------------------------------------------------------------\n    base = n / (m + 1.0)\n\n    # ------------------------------------------------------------------\n    # 2. Connectivity correction – high density & high average degree\n    #    reduce distances.\n    # ------------------------------------------------------------------\n    conn = density * (avg_deg + 1.0)\n    if conn < eps:\n        conn = eps\n    base *= 1.0 / conn\n\n    # ------------------------------------------------------------------\n    # 3. Clustering and transitivity reduce paths by providing shortcuts.\n    # ------------------------------------------------------------------\n    base *= 1.0 / (1.0 + avg_c)\n    base *= 1.0 / (1.0 + trans)\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity adjustment – disassortative mixes tend to shorten\n    #    paths.  We damp the effect symmetrically for positive/negative\n    #    assortativity values.\n    # ------------------------------------------------------------------\n    base *= 1.0 / (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # 5. Triangle density – more triangles usually shorten the graph,\n    #    so we down‑scale by a factor that increases with triangle\n    #    density.\n    # ------------------------------------------------------------------\n    if n >= 3.0:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n        base *= 1.0 / (1.0 + tri_frac)\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic‑mean degree scaling – captures how many low‑degree\n    #    nodes exist.  Larger harmonic mean indicates a denser core,\n    #    which typically shortens distances.\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = n\n    base *= harmonic / (avg_deg + eps)\n\n    # ------------------------------------------------------------------\n    # 7. Max‑degree spread adjustment – highly heterogeneous degree\n    #    distributions (large max degree) usually shorten distances.\n    # ------------------------------------------------------------------\n    base *= (1.0 + max_deg) / (1.0 + std_deg + eps)\n\n    return base", "spearman": 0.6312352808820222, "pearson": 0.4124391729287832, "rmse": 7.2885659434238015, "mae": 3.1263647687877985}}
{"timestamp": "2026-02-17T08:19:22.747898+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 13, "island_id": 3, "population_idx": 3, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:19:54.603047+00:00", "event_type": "candidate_rejected", "payload": {"generation": 13, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.051429", "model_name": "gpt-oss:20b", "train_signal": 0.05142857142857142}}
{"timestamp": "2026-02-17T08:19:54.605803+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 14, "model_name": "gpt-oss:20b", "best_val_score": 0.5676243841107219, "no_improve_count": 8}}
{"timestamp": "2026-02-17T08:20:59.680124+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g14_i0_p0_181636083", "generation": 14, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.21901859382331743, "novelty_bonus": 0.17144438359620162, "total_score": 0.4466028179881277, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "extracted_code": "def new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T08:21:46.033961+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g14_i0_p1_624369454", "generation": 14, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.2190821898695896, "novelty_bonus": 0.17144438359620162, "total_score": 0.4466155371973821, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    # Basic graph statistics (use .get to avoid KeyError)\n    n          = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg     = s.get('avg_degree', 0.0)\n    density     = s.get('density', 0.0)\n    max_deg     = s.get('max_degree', 0)\n    min_deg     = s.get('min_degree', 0)\n    std_deg     = s.get('std_degree', 0.0)\n    avg_clust   = s.get('avg_clustering', 0.0)\n    assort      = s.get('degree_assortativity', 0.0)\n    num_tri     = s.get('num_triangles', 0)\n    degrees     = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # 1. Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # 2. Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # 3. Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # 4. Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # 5. Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 6. Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 7. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 8. Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    # Basic graph statistics (use .get to avoid KeyError)\n    n          = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg     = s.get('avg_degree', 0.0)\n    density     = s.get('density', 0.0)\n    max_deg     = s.get('max_degree', 0)\n    min_deg     = s.get('min_degree', 0)\n    std_deg     = s.get('std_degree', 0.0)\n    avg_clust   = s.get('avg_clustering', 0.0)\n    assort      = s.get('degree_assortativity', 0.0)\n    num_tri     = s.get('num_triangles', 0)\n    degrees     = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # 1. Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # 2. Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # 3. Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # 4. Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # 5. Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 6. Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 7. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 8. Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T08:22:15.596144+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g14_i0_p2_723887618", "generation": 14, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.2190821898695896, "novelty_bonus": 0.17144438359620162, "total_score": 0.4466155371973821, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses only built‑in Python operations and avoids any graph traversal.\n    \"\"\"\n    # Guard against empty or trivial graphs\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics (use .get to avoid KeyError)\n    avg_deg      = s.get('avg_degree', 0.0)\n    density      = s.get('density', 0.0)\n    max_deg      = s.get('max_degree', 0)\n    min_deg      = s.get('min_degree', 0)\n    std_deg      = s.get('std_degree', 0.0)\n    avg_clust    = s.get('avg_clustering', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    num_tri      = s.get('num_triangles', 0)\n    degrees      = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # 1. Logarithmic size vs. degree (base‑2 approximation)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # 2. Adjust for density (denser graphs → shorter paths)\n    base *= (1 + density) ** -0.5\n\n    # 3. Adjust for clustering (higher clustering → slightly shorter paths)\n    base *= (1 + avg_clust) ** -0.25\n\n    # 4. Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # 5. Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 6. Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 7. Max/min degree ratio adjustment (captures presence of hubs)\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 8. Harmonic mean of degrees contribution (low‑degree nodes increase path length)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses only built‑in Python operations and avoids any graph traversal.\n    \"\"\"\n    # Guard against empty or trivial graphs\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics (use .get to avoid KeyError)\n    avg_deg      = s.get('avg_degree', 0.0)\n    density      = s.get('density', 0.0)\n    max_deg      = s.get('max_degree', 0)\n    min_deg      = s.get('min_degree', 0)\n    std_deg      = s.get('std_degree', 0.0)\n    avg_clust    = s.get('avg_clustering', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    num_tri      = s.get('num_triangles', 0)\n    degrees      = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # 1. Logarithmic size vs. degree (base‑2 approximation)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # 2. Adjust for density (denser graphs → shorter paths)\n    base *= (1 + density) ** -0.5\n\n    # 3. Adjust for clustering (higher clustering → slightly shorter paths)\n    base *= (1 + avg_clust) ** -0.25\n\n    # 4. Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # 5. Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 6. Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 7. Max/min degree ratio adjustment (captures presence of hubs)\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 8. Harmonic mean of degrees contribution (low‑degree nodes increase path length)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T08:23:34.999662+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g14_i0_p3_498095537", "generation": 14, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.2189765633534611, "novelty_bonus": 0.17144438359620162, "total_score": 0.4465944118941564, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses only built‑in Python operations and avoids any graph traversal.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic size / degree base\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density and clustering\n    base *= (1 + density) ** -0.5\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle density adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses only built‑in Python operations and avoids any graph traversal.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic size / degree base\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density and clustering\n    base *= (1 + density) ** -0.5\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle density adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T08:24:27.130820+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g14_i0_p4_819901763", "generation": 14, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.21895565682377716, "novelty_bonus": 0.17144438359620162, "total_score": 0.4465902305882196, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / d\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / d\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908171, "rmse": 0.9404930915442863, "mae": 0.5846023573350361}}
{"timestamp": "2026-02-17T08:27:55.126149+00:00", "event_type": "candidate_rejected", "payload": {"generation": 14, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:27:55.127408+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 14, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:28:17.772390+00:00", "event_type": "candidate_rejected", "payload": {"generation": 14, "island_id": 1, "population_idx": 0, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.140840", "model_name": "gpt-oss:20b", "train_signal": 0.1408403361344538}}
{"timestamp": "2026-02-17T08:28:17.772626+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 14, "island_id": 1, "population_idx": 0, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:28:51.250074+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g14_i1_p1_959114070", "generation": 14, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.265978\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T08:29:20.867727+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g14_i1_p2_284407795", "generation": 14, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.265978\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T08:30:27.870006+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g14_i1_p3_767051311", "generation": 14, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6001920768307323, "fitness_mode": "correlation", "simplicity_score": 0.11988829658576378, "novelty_bonus": 0.2404110102752568, "total_score": 0.4336199003731791, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.265978\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density boost\n    density_factor = 1.0 + density\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density boost\n    density_factor = 1.0 + density\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor\n    )", "spearman": 0.6750378759468987, "pearson": 0.6377208676115874, "rmse": 2.768144803056992, "mae": 2.622268323424163}}
{"timestamp": "2026-02-17T08:31:15.594312+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g14_i1_p4_975164603", "generation": 14, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.265978\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T08:31:59.066871+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g14_i2_p0_892500570", "generation": 14, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9760864345738295, "fitness_mode": "correlation", "simplicity_score": 0.2205955879701489, "novelty_bonus": 0.18032055788563106, "total_score": 0.567813274909468, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.048129\nbelow_novelty_threshold: novelty_bonus=0.039461\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base", "spearman": 0.9391959798994978, "pearson": 0.8461647502067359, "rmse": 23.050747992769622, "mae": 13.95268304651002}}
{"timestamp": "2026-02-17T08:32:37.068877+00:00", "event_type": "candidate_rejected", "payload": {"generation": 14, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.089735", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:32:37.070045+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 14, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.089735", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:33:16.013672+00:00", "event_type": "candidate_rejected", "payload": {"generation": 14, "island_id": 2, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.085395", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:33:16.014112+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 14, "island_id": 2, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:33:47.278130+00:00", "event_type": "candidate_rejected", "payload": {"generation": 14, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:33:47.279564+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 14, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:34:23.824548+00:00", "event_type": "candidate_rejected", "payload": {"generation": 14, "island_id": 2, "population_idx": 2, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.161873", "model_name": "gpt-oss:20b", "train_signal": 0.16187274909963983}}
{"timestamp": "2026-02-17T08:34:23.825265+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 14, "island_id": 2, "population_idx": 2, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:34:56.334661+00:00", "event_type": "candidate_rejected", "payload": {"generation": 14, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:34:56.335335+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 14, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:35:31.302313+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g14_i2_p3_533088527", "generation": 14, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.8238655462184874, "fitness_mode": "correlation", "simplicity_score": 0.22113343699055302, "novelty_bonus": 0.33794255750134206, "total_score": 0.5195733037447406, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.085395\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.161873\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport math\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n    The baseline is a connectivity term (size over density × average degree) scaled\n    by the logarithm of the node count.  Multiplicative corrections are applied\n    for clustering, transitivity, assortativity, triangle density, degree\n    heterogeneity, minimum degree, maximum degree and the skewness of the\n    degree distribution (median vs. average).  No graph traversal is performed\n    and no external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = math.log(n + 1) * (n / denom)\n\n    # Shortcuts from clustering, transitivity and assortativity\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n\n    # Triangle density adjustment\n    tri = s.get('num_triangles', 0)\n    m = s.get('m', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree (increases distances)\n    min_deg = s.get('min_degree', 0)\n    if min_deg > 0:\n        base *= (1.0 + 1.0 / (min_deg + 1.0))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (1.0 + max_deg / max(avg_deg, 1e-6))\n\n    # Adjust for degree distribution skewness (median vs. average)\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "def new_invariant(s):\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom\n\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n\n    tri = s.get('num_triangles', 0)\n    m = s.get('m', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    min_deg = s.get('min_degree', 0)\n    if min_deg > 0:\n        base *= (1.0 + 1.0 / (min_deg + 1.0))\n\n    max_deg = s.get('max_degree', 1)\n    base /= (1.0 + max_deg / max(avg_deg, 1e-6))\n\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "extracted_code": "def new_invariant(s):\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom\n\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n\n    tri = s.get('num_triangles', 0)\n    m = s.get('m', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    min_deg = s.get('min_degree', 0)\n    if min_deg > 0:\n        base *= (1.0 + 1.0 / (min_deg + 1.0))\n\n    max_deg = s.get('max_degree', 1)\n    base /= (1.0 + max_deg / max(avg_deg, 1e-6))\n\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.747927698192455, "pearson": 0.7644324177860455, "rmse": 154.12193585079746, "mae": 104.4947617479512}}
{"timestamp": "2026-02-17T08:35:31.302878+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 14, "island_id": 2, "population_idx": 3, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:36:25.149697+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g14_i2_p4_791125482", "generation": 14, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7021848739495797, "fitness_mode": "correlation", "simplicity_score": 0.22065013459130509, "novelty_bonus": 0.16562514062851552, "total_score": 0.44966021517296734, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity base term – higher degree or density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust)\n    base *= (1.0 + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity (standard deviation) and minimum degree\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.085395\nbelow_train_threshold: train_signal=0.161873\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.\n\n    The formula is a simple multiplicative model that starts from a\n    connectivity baseline (size divided by the product of average degree\n    and density).  It then applies corrections for clustering, assortativity,\n    triangle density, degree heterogeneity, and the shape of the degree\n    distribution.  The final result is scaled by the square‑root of the\n    graph size to keep the estimate in the typical range of average\n    shortest path lengths.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ---------- Connectivity baseline ----------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6) + 1e-6\n    base = n / denom_conn\n\n    # ---------- Shortcuts from clustering ----------\n    base /= (1.0 + avg_clust)\n    base /= (1.0 + trans)\n\n    # ---------- Effect of assortativity ----------\n    base *= (1.0 + abs(assort))\n\n    # ---------- Triangle density ----------\n    if m > 0:\n        base /= (1.0 + tri / m)\n\n    # ---------- Degree heterogeneity ----------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # ---------- Minimum degree ----------\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ---------- Maximum degree ----------\n    base /= (max_deg + 1.0)\n\n    # ---------- Median degree adjustment ----------\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # ---------- Size scaling ----------\n    base /= (n ** 0.5)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a set of pre‑computed\n    graph statistics.\n\n    The formula is a simple multiplicative model that starts from a\n    connectivity baseline (size divided by the product of average degree\n    and density).  It then applies corrections for clustering, assortativity,\n    triangle density, degree heterogeneity, and the shape of the degree\n    distribution.  The final result is scaled by the square‑root of the\n    graph size to keep the estimate in the typical range of average\n    shortest path lengths.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph features.  Expected keys include:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ---------- Connectivity baseline ----------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6) + 1e-6\n    base = n / denom_conn\n\n    # ---------- Shortcuts from clustering ----------\n    base /= (1.0 + avg_clust)\n    base /= (1.0 + trans)\n\n    # ---------- Effect of assortativity ----------\n    base *= (1.0 + abs(assort))\n\n    # ---------- Triangle density ----------\n    if m > 0:\n        base /= (1.0 + tri / m)\n\n    # ---------- Degree heterogeneity ----------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # ---------- Minimum degree ----------\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ---------- Maximum degree ----------\n    base /= (max_deg + 1.0)\n\n    # ---------- Median degree adjustment ----------\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # ---------- Size scaling ----------\n    base /= (n ** 0.5)\n\n    return base", "spearman": 0.7116852921323034, "pearson": 0.4892164105958151, "rmse": 2.426943961016536, "mae": 2.263936214498195}}
{"timestamp": "2026-02-17T08:37:21.991518+00:00", "event_type": "candidate_rejected", "payload": {"generation": 14, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.099544", "model_name": "gpt-oss:20b", "train_signal": 0.09954381752701079}}
{"timestamp": "2026-02-17T08:38:10.554010+00:00", "event_type": "candidate_rejected", "payload": {"generation": 14, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.039824", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:38:10.554618+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 14, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.039824", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:39:01.433054+00:00", "event_type": "candidate_rejected", "payload": {"generation": 14, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: os.", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:39:01.433808+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 14, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:40:00.497538+00:00", "event_type": "candidate_rejected", "payload": {"generation": 14, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.051457", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:40:00.498580+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 14, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.051457", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:40:37.088265+00:00", "event_type": "candidate_rejected", "payload": {"generation": 14, "island_id": 3, "population_idx": 2, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:40:37.089270+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 14, "island_id": 3, "population_idx": 2, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:41:17.083831+00:00", "event_type": "candidate_rejected", "payload": {"generation": 14, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.191837", "model_name": "gpt-oss:20b", "train_signal": 0.19183673469387755}}
{"timestamp": "2026-02-17T08:42:00.370806+00:00", "event_type": "candidate_rejected", "payload": {"generation": 14, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.010891", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:42:00.371608+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 14, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.010891", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:42:45.831346+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g14_i3_p4_877548739", "generation": 14, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.41781512605042015, "fitness_mode": "correlation", "simplicity_score": 0.21934341955418668, "novelty_bonus": 0.26456369943318236, "total_score": 0.3473756471871282, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.051457\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.191837\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: novelty_bonus=0.010891\nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The estimator combines several\n    structural descriptors in a non‑linear fashion but uses only\n    fundamental Python operations – no external libraries or graph\n    traversal algorithms are required.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary containing the following keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    edge density (2m/(n(n-1)))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)      maximum degree\n            min_degree            (int)      minimum degree\n            std_degree            (float)    standard deviation of degrees\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    degree assortativity coefficient\n            num_triangles         (int)      number of triangles\n            degrees               (list[int]) sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true\n        average shortest‑path length.\n    \"\"\"\n    # Basic safety constants\n    eps = 1e-12\n\n    # Unpack the feature dictionary\n    n        = float(s['n'])\n    m        = float(s['m'])\n    density  = float(s['density'])\n    avg_deg  = float(s['avg_degree'])\n    max_deg  = float(s['max_degree'])\n    min_deg  = float(s['min_degree'])\n    std_deg  = float(s['std_degree'])\n    avg_c    = float(s['avg_clustering'])\n    trans    = float(s['transitivity'])\n    assort   = float(s['degree_assortativity'])\n    num_tri  = float(s['num_triangles'])\n    degrees  = s['degrees']\n\n    # --------------------\n    # Core scaling term\n    # --------------------\n    # High density and average degree shorten distances.\n    denom = max(avg_deg, eps) * max(density, eps)\n    base = n / denom\n\n    # --------------------\n    # Adjustments for local structure\n    # --------------------\n    # Average clustering tends to create “short‑cut” triangles.\n    base *= (1.0 + avg_c)\n\n    # Global transitivity usually correlates with shorter paths.\n    base *= (1.0 - trans)\n\n    # Assortativity: disassortative mixing (large |assort|) often reduces distances.\n    base *= (1.0 + abs(assort))\n\n    # --------------------\n    # Triangle density effect\n    # --------------------\n    if n >= 3:\n        max_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (max_tri + eps)\n        # More triangles lower the average shortest path length.\n        base /= (1.0 + tri_frac)\n\n    # --------------------\n    # Degree heterogeneity adjustment\n    # --------------------\n    base /= (1.0 + std_deg / max(avg_deg, eps))\n\n    # A very large maximum degree (hub) shortens distances – penalise over‑shortening.\n    base /= (1.0 + max_deg / (max_deg + 1.0))\n\n    # --------------------\n    # Minor correction from harmonic mean of degrees\n    # --------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        hm = n / (inv_sum + eps)\n        # Scale by a small factor so the contribution is modest.\n        base *= 1.0 + hm / (n * 100.0)\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a handcrafted,\n    non‑linear combination of global graph statistics.  No external\n    libraries or graph traversal are required – everything is done\n    with basic arithmetic on the supplied feature dictionary.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys (all floats unless noted):\n            n                     (int)   number of vertices\n            m                     (int)   number of edges\n            density               (float) 2m/(n(n-1))\n            avg_degree            (float) average degree\n            max_degree            (int)   maximum degree\n            min_degree            (int)   minimum degree\n            std_degree            (float) standard deviation of degrees\n            avg_clustering        (float) average local clustering\n            transitivity          (float) global transitivity\n            degree_assortativity  (float) assortativity coefficient\n            num_triangles         (int)   number of triangles\n            degrees               (list[int]) sorted degree list\n\n    Returns\n    -------\n    float\n        Proxy for the average shortest‑path length.\n    \"\"\"\n    # small constant to keep divisions safe\n    eps = 1e-12\n\n    # ----------- unpack & cast ----------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    # ----------- triangle density -------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ----------- harmonic mean of degrees ----------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        hm = n / (inv_sum + eps)\n    else:\n        hm = 0.0\n\n    # ----------- base expression --------------------------------------\n    base = (n + 1.0) / (density + 1.0)            # size vs connectivity\n    base *= (avg_deg + 1.0) / (max_deg + 1.0)     # degree spread\n    base *= (1.0 + min_deg)                       # preserve influence of low‑degree nodes\n\n    # ----------- structural modifiers --------------------------------\n    base *= (1.0 + tri_frac) ** 0.7               # triangles shrink paths\n    base *= (1.0 - avg_c) ** 0.4                  # strong local clustering can lengthen paths\n    base *= (1.0 - trans) ** 0.3                  # high global transitivity usually shortens paths\n    base *= (1.0 + abs(assort)) ** 0.5            # disassortative mixing tends to reduce distances\n\n    # ----------- heterogeneity correction ----------------------------\n    base /= (1.0 + std_deg / (avg_deg + eps))     # more heterogeneous degree sequences shorten paths\n\n    # ----------- small harmonic‑mean boost ----------------------------\n    base += (hm / (n + eps)) * 0.1\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a handcrafted,\n    non‑linear combination of global graph statistics.  No external\n    libraries or graph traversal are required – everything is done\n    with basic arithmetic on the supplied feature dictionary.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys (all floats unless noted):\n            n                     (int)   number of vertices\n            m                     (int)   number of edges\n            density               (float) 2m/(n(n-1))\n            avg_degree            (float) average degree\n            max_degree            (int)   maximum degree\n            min_degree            (int)   minimum degree\n            std_degree            (float) standard deviation of degrees\n            avg_clustering        (float) average local clustering\n            transitivity          (float) global transitivity\n            degree_assortativity  (float) assortativity coefficient\n            num_triangles         (int)   number of triangles\n            degrees               (list[int]) sorted degree list\n\n    Returns\n    -------\n    float\n        Proxy for the average shortest‑path length.\n    \"\"\"\n    # small constant to keep divisions safe\n    eps = 1e-12\n\n    # ----------- unpack & cast ----------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    # ----------- triangle density -------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n\n    # ----------- harmonic mean of degrees ----------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        hm = n / (inv_sum + eps)\n    else:\n        hm = 0.0\n\n    # ----------- base expression --------------------------------------\n    base = (n + 1.0) / (density + 1.0)            # size vs connectivity\n    base *= (avg_deg + 1.0) / (max_deg + 1.0)     # degree spread\n    base *= (1.0 + min_deg)                       # preserve influence of low‑degree nodes\n\n    # ----------- structural modifiers --------------------------------\n    base *= (1.0 + tri_frac) ** 0.7               # triangles shrink paths\n    base *= (1.0 - avg_c) ** 0.4                  # strong local clustering can lengthen paths\n    base *= (1.0 - trans) ** 0.3                  # high global transitivity usually shortens paths\n    base *= (1.0 + abs(assort)) ** 0.5            # disassortative mixing tends to reduce distances\n\n    # ----------- heterogeneity correction ----------------------------\n    base /= (1.0 + std_deg / (avg_deg + eps))     # more heterogeneous degree sequences shorten paths\n\n    # ----------- small harmonic‑mean boost ----------------------------\n    base += (hm / (n + eps)) * 0.1\n\n    return base", "spearman": -0.4482757068926723, "pearson": -0.37653277448077593, "rmse": 135.92868374949654, "mae": 95.48557575755059}}
{"timestamp": "2026-02-17T08:42:45.832222+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 14, "island_id": 3, "population_idx": 4, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:42:45.835550+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 15, "model_name": "gpt-oss:20b", "best_val_score": 0.567813274909468, "no_improve_count": 0}}
{"timestamp": "2026-02-17T08:44:01.516003+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i0_p0_937158470", "generation": 15, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.2189765633534611, "novelty_bonus": 0.17144438359620162, "total_score": 0.4465944118941564, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses only built‑in Python operations and avoids any imports.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density (denser graphs → shorter paths)\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering (higher clustering → shorter paths)\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses only built‑in Python operations and avoids any imports.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density (denser graphs → shorter paths)\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering (higher clustering → shorter paths)\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T08:45:06.059621+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i0_p1_845975155", "generation": 15, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.2189140589433829, "novelty_bonus": 0.17144438359620162, "total_score": 0.4465819110121408, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    if avg_deg > 0:\n        avg_deg_int = int(avg_deg)\n        log_avg_deg = avg_deg_int.bit_length() - 1\n    else:\n        log_avg_deg = 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    if avg_deg > 0:\n        avg_deg_int = int(avg_deg)\n        log_avg_deg = avg_deg_int.bit_length() - 1\n    else:\n        log_avg_deg = 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T08:46:00.345545+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i0_p2_119305544", "generation": 15, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.2190821898695896, "novelty_bonus": 0.17144438359620162, "total_score": 0.4466155371973821, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses logarithmic size, degree, density, clustering, triangle\n    density, degree heterogeneity, assortativity, and a harmonic mean of degrees.\n    Only built‑in Python operations are employed.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses logarithmic size, degree, density, clustering, triangle\n    density, degree heterogeneity, assortativity, and a harmonic mean of degrees.\n    Only built‑in Python operations are employed.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T08:47:03.795646+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i0_p3_568629592", "generation": 15, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5727250900360145, "fitness_mode": "correlation", "simplicity_score": 0.21853256875814728, "novelty_bonus": 0.1656076292659544, "total_score": 0.4187596868035226, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses logarithmic size, degree, density, clustering, triangle\n    density, degree heterogeneity, assortativity, transitivity and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density, clustering, and transitivity\n    base *= (1 + density) ** -0.6\n    base *= (1 + avg_clust) ** -0.3\n    base *= (1 + trans) ** -0.2\n\n    # Triangle density adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.25\n\n    # Degree heterogeneity and assortativity corrections\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.15\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.1\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += 0.5 * harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses logarithmic size, degree, density, clustering, triangle\n    density, degree heterogeneity, assortativity, transitivity and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density, clustering, and transitivity\n    base *= (1 + density) ** -0.6\n    base *= (1 + avg_clust) ** -0.3\n    base *= (1 + trans) ** -0.2\n\n    # Triangle density adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.25\n\n    # Degree heterogeneity and assortativity corrections\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.15\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.1\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += 0.5 * harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.6507417685442137, "pearson": 0.46862699606040037, "rmse": 1.057674134203181, "mae": 0.7377478260954845}}
{"timestamp": "2026-02-17T08:48:26.179009+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i0_p4_905461201", "generation": 15, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5691716686674669, "fitness_mode": "correlation", "simplicity_score": 0.21863063541073116, "novelty_bonus": 0.17278289587540818, "total_score": 0.42811855978386726, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Adjust for transitivity: higher transitivity often shortens paths\n    base *= (1 + trans) ** -0.2\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.15\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Adjust for transitivity: higher transitivity often shortens paths\n    base *= (1 + trans) ** -0.2\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.15\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.6651151278781972, "pearson": 0.4765668314984505, "rmse": 0.9702538879344456, "mae": 0.6000190191735851}}
{"timestamp": "2026-02-17T08:49:09.336689+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i1_p0_470027017", "generation": 15, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.265978\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T08:49:41.338758+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i1_p1_263526655", "generation": 15, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.265978\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    The function uses only built‑in operations and the pre‑computed features\n    supplied in the dictionary `s`.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    The function uses only built‑in operations and the pre‑computed features\n    supplied in the dictionary `s`.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T08:50:31.846827+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i1_p2_597212430", "generation": 15, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.6001920768307323, "fitness_mode": "correlation", "simplicity_score": 0.11988829658576378, "novelty_bonus": 0.2404110102752568, "total_score": 0.4336199003731791, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.265978\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – density influence\n    density_factor = 1 + density\n\n    # Component 7 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        density_factor *\n        size_factor\n    )", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Component 4 – triangle density boost\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Component 6 – density influence\n    density_factor = 1 + density\n\n    # Component 7 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        density_factor *\n        size_factor\n    )", "spearman": 0.6750378759468987, "pearson": 0.6377208676115873, "rmse": 2.768144803056992, "mae": 2.622268323424163}}
{"timestamp": "2026-02-17T08:51:00.105840+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i1_p3_175470318", "generation": 15, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.265978\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T08:51:25.392375+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i1_p4_894692881", "generation": 15, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.265978\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T08:52:02.398009+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i2_p0_820292813", "generation": 15, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9774309723889555, "fitness_mode": "correlation", "simplicity_score": 0.2214354802823629, "novelty_bonus": 0.17650877698103795, "total_score": 0.5669442217630994, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.085395\nbelow_train_threshold: train_signal=0.161873\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.  The estimate is a simple\n    multiplicative model that starts with a connectivity baseline\n    (n / (density × avg_degree)) and then applies corrections for\n    clustering, transitivity, assortativity, triangle density,\n    degree heterogeneity, and the shape of the degree distribution.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n    base *= (1.0 + s.get('transitivity', 0.0))\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.  The estimate is a simple\n    multiplicative model that starts with a connectivity baseline\n    (n / (density × avg_degree)) and then applies corrections for\n    clustering, transitivity, assortativity, triangle density,\n    degree heterogeneity, and the shape of the degree distribution.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n    base *= (1.0 + s.get('transitivity', 0.0))\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.9394089852246308, "pearson": 0.851683774763385, "rmse": 21.002780260731164, "mae": 12.112654815545278}}
{"timestamp": "2026-02-17T08:52:40.797953+00:00", "event_type": "candidate_rejected", "payload": {"generation": 15, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.048060", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:52:40.798627+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 15, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.048060", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:53:39.645832+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i2_p1_109848117", "generation": 15, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.436062424969988, "fitness_mode": "correlation", "simplicity_score": 0.22040825984618836, "novelty_bonus": 0.2941124436723267, "total_score": 0.32753176548044594, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.085395\nbelow_train_threshold: train_signal=0.161873\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: novelty_bonus=0.048060\nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph size and connectivity\n    n = s.get('n', 1)\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n\n    # Avoid division by zero\n    eps = 1e-6\n\n    # Base estimate: larger graphs with fewer edges have longer paths\n    base = n / (m + 1)\n\n    # Lower density increases path length\n    base *= (1.0 + (1.0 - density))\n\n    # Clustering and transitivity create shortcuts → reduce path length\n    base /= (1.0 + avg_clust + eps)\n    base /= (1.0 + trans + eps)\n\n    # Degree assortativity magnitude can increase path length\n    base *= (1.0 + abs(assort))\n\n    # Triangle density (triangles per edge) tends to shorten paths\n    base /= (1.0 + tri / (m + 1) + eps)\n\n    # Degree heterogeneity (high std) typically shortens paths\n    base /= (1.0 + std_deg / (max(avg_deg, eps)))\n\n    # Very low minimum degree can lengthen paths\n    base /= (1.0 + min_deg / (max(avg_deg, eps)))\n\n    # Penalise extremely high maximum degree (few hubs)\n    base /= (max_deg + 1.0)\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    The formula is a multiplicative model that starts from a\n    size‑based baseline (sqrt of the node count divided by the\n    average degree) and then applies simple corrections for\n    density, clustering, transitivity, assortativity, triangle\n    density, degree heterogeneity, minimum/maximum degree and\n    the shape of the degree distribution (median vs. mean).\n    \"\"\"\n    n      = s.get('n', 1)\n    m      = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg  = s.get('avg_degree', 0.0)\n    max_deg  = s.get('max_degree', 1)\n    min_deg  = s.get('min_degree', 0)\n    std_deg  = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    tri       = s.get('num_triangles', 0)\n    degrees   = s.get('degrees', [])\n\n    eps = 1e-6\n\n    # Baseline: larger graphs with higher average degree tend to have\n    # shorter average distances.  The sqrt reduces the influence of\n    # very large graphs.\n    base = (n ** 0.5) / (avg_deg + 1 + eps)\n\n    # Low density increases the path length.\n    base *= (1.0 + (1.0 - density))\n\n    # Clustering and transitivity create shortcuts, so they reduce the\n    # average distance.  We divide to model this effect.\n    base /= (1.0 + avg_clust + eps)\n    base /= (1.0 + trans + eps)\n\n    # Strong assortativity (in magnitude) tends to increase the path\n    # length because high‑degree nodes are connected to other high‑degree\n    # nodes, leaving low‑degree nodes more isolated.\n    base *= (1.0 + abs(assort))\n\n    # Triangles per edge shorten the distance; we divide by a factor\n    # that grows with the triangle density.\n    if m > 0:\n        base /= (1.0 + tri / (m + eps))\n\n    # High degree heterogeneity (large std) typically shortens the\n    # distance because hubs connect many nodes.  We divide to capture\n    # this effect.\n    base /= (1.0 + std_deg / (avg_deg + eps))\n\n    # Very low minimum degree can create bottlenecks; we slightly\n    # penalise the baseline.\n    base /= (1.0 + min_deg / (avg_deg + eps))\n\n    # A very large maximum degree relative to the average can\n    # over‑estimate the shortcut effect; we moderate this with a\n    # divisor.\n    base /= (1.0 + max_deg / (avg_deg + eps))\n\n    # If the median degree differs from the mean, it indicates a\n    # skewed degree distribution.  We adjust the baseline accordingly.\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (median_deg - avg_deg) / (avg_deg + eps))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    The formula is a multiplicative model that starts from a\n    size‑based baseline (sqrt of the node count divided by the\n    average degree) and then applies simple corrections for\n    density, clustering, transitivity, assortativity, triangle\n    density, degree heterogeneity, minimum/maximum degree and\n    the shape of the degree distribution (median vs. mean).\n    \"\"\"\n    n      = s.get('n', 1)\n    m      = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg  = s.get('avg_degree', 0.0)\n    max_deg  = s.get('max_degree', 1)\n    min_deg  = s.get('min_degree', 0)\n    std_deg  = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans     = s.get('transitivity', 0.0)\n    assort    = s.get('degree_assortativity', 0.0)\n    tri       = s.get('num_triangles', 0)\n    degrees   = s.get('degrees', [])\n\n    eps = 1e-6\n\n    # Baseline: larger graphs with higher average degree tend to have\n    # shorter average distances.  The sqrt reduces the influence of\n    # very large graphs.\n    base = (n ** 0.5) / (avg_deg + 1 + eps)\n\n    # Low density increases the path length.\n    base *= (1.0 + (1.0 - density))\n\n    # Clustering and transitivity create shortcuts, so they reduce the\n    # average distance.  We divide to model this effect.\n    base /= (1.0 + avg_clust + eps)\n    base /= (1.0 + trans + eps)\n\n    # Strong assortativity (in magnitude) tends to increase the path\n    # length because high‑degree nodes are connected to other high‑degree\n    # nodes, leaving low‑degree nodes more isolated.\n    base *= (1.0 + abs(assort))\n\n    # Triangles per edge shorten the distance; we divide by a factor\n    # that grows with the triangle density.\n    if m > 0:\n        base /= (1.0 + tri / (m + eps))\n\n    # High degree heterogeneity (large std) typically shortens the\n    # distance because hubs connect many nodes.  We divide to capture\n    # this effect.\n    base /= (1.0 + std_deg / (avg_deg + eps))\n\n    # Very low minimum degree can create bottlenecks; we slightly\n    # penalise the baseline.\n    base /= (1.0 + min_deg / (avg_deg + eps))\n\n    # A very large maximum degree relative to the average can\n    # over‑estimate the shortcut effect; we moderate this with a\n    # divisor.\n    base /= (1.0 + max_deg / (avg_deg + eps))\n\n    # If the median degree differs from the mean, it indicates a\n    # skewed degree distribution.  We adjust the baseline accordingly.\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (median_deg - avg_deg) / (avg_deg + eps))\n\n    return base", "spearman": 0.3904327608190205, "pearson": 0.17522325596009003, "rmse": 2.7498347231747107, "mae": 2.596988011456262}}
{"timestamp": "2026-02-17T08:53:39.646380+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 15, "island_id": 2, "population_idx": 1, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:54:20.865075+00:00", "event_type": "candidate_rejected", "payload": {"generation": 15, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.143471", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:54:20.865651+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 15, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.143471", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:54:47.703454+00:00", "event_type": "candidate_rejected", "payload": {"generation": 15, "island_id": 2, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.143471", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:54:47.703998+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 15, "island_id": 2, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:55:09.483248+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i2_p3_989974305", "generation": 15, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9774309723889555, "fitness_mode": "correlation", "simplicity_score": 0.2214354802823629, "novelty_bonus": 0.17650877698103795, "total_score": 0.5669442217630994, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.048060\nbelow_novelty_threshold: novelty_bonus=0.143471\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is based on a connectivity baseline (size over density ×\n    average degree) and multiplicative corrections for clustering,\n    assortativity, triangle density, degree heterogeneity and the\n    distribution of degrees.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic connectivity term: larger graphs with low density/degree\n    # tend to have longer paths.\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts created by clustering and transitivity\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n    base *= (1.0 + s.get('transitivity', 0.0))\n\n    # Assortativity (absolute value) affects how easily hubs connect\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n\n    # Triangle density: more triangles usually shorten paths\n    m   = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity: highly heterogeneous networks (hubs) have\n    # shorter paths, so we normalise by the spread\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Minimum degree: a very low min degree can create bottlenecks\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Maximum degree: penalise very high max degree to avoid over‑shortening\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment to capture the skew of the distribution\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is based on a connectivity baseline (size over density ×\n    average degree) and multiplicative corrections for clustering,\n    assortativity, triangle density, degree heterogeneity and the\n    distribution of degrees.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Basic connectivity term: larger graphs with low density/degree\n    # tend to have longer paths.\n    avg_deg   = s.get('avg_degree', 0.0)\n    density   = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts created by clustering and transitivity\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n    base *= (1.0 + s.get('transitivity', 0.0))\n\n    # Assortativity (absolute value) affects how easily hubs connect\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n\n    # Triangle density: more triangles usually shorten paths\n    m   = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity: highly heterogeneous networks (hubs) have\n    # shorter paths, so we normalise by the spread\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Minimum degree: a very low min degree can create bottlenecks\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Maximum degree: penalise very high max degree to avoid over‑shortening\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment to capture the skew of the distribution\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.9394089852246308, "pearson": 0.851683774763385, "rmse": 21.002780260731164, "mae": 12.112654815545278}}
{"timestamp": "2026-02-17T08:55:52.897028+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i2_p4_284573368", "generation": 15, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9772388955582233, "fitness_mode": "correlation", "simplicity_score": 0.22113343699055302, "novelty_bonus": 0.18877249943814667, "total_score": 0.5706469319419225, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph\n    statistics.  The formula starts from a connectivity baseline\n    (size over density × average degree) and then applies\n    multiplicative corrections for clustering, assortativity,\n    triangle density, degree heterogeneity and degree distribution.\n    No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and assortativity\n    base *= (1.0 + s.get('transitivity', 0.0))\n    base *= (1.0 + abs(s.get('degree_assortativity', 0.0)))\n    base *= (1.0 + s.get('avg_clustering', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # Penalise very low minimum degree\n    min_deg = s.get('min_degree', 0)\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs)\n    max_deg = s.get('max_degree', 1)\n    base /= (max_deg + 1.0)\n\n    # Adjust for median degree to capture distribution shape\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.048060\nbelow_novelty_threshold: novelty_bonus=0.143471\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base", "spearman": 0.9395769894247358, "pearson": 0.835364562106582, "rmse": 19.49688649831046, "mae": 11.281421473337119}}
{"timestamp": "2026-02-17T08:56:40.224895+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i3_p0_228201091", "generation": 15, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.5535174069627851, "fitness_mode": "correlation", "simplicity_score": 0.21995052817975927, "novelty_bonus": 0.3326731798345124, "total_score": 0.3724465259479647, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.191837\nbelow_novelty_threshold: novelty_bonus=0.010891\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed\n    graph statistics.  The expression is a handcrafted, non‑linear\n    combination of all the supplied features; no single feature is\n    returned directly, and no external libraries are imported.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of global graph descriptors with the following keys:\n        n (int)                     – number of nodes\n        m (int)                     – number of edges\n        density (float)             – 2m/(n(n‑1))\n        avg_degree (float)          – average node degree\n        max_degree (int)            – maximum degree\n        min_degree (int)            – minimum degree\n        std_degree (float)          – standard deviation of degrees\n        avg_clustering (float)      – average local clustering\n        transitivity (float)        – global transitivity\n        degree_assortativity (float) – assortativity coefficient\n        num_triangles (int)         – number of triangles\n        degrees (list[int])         – sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy that increases monotonically with the true\n        average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # tiny value to avoid division by zero\n\n    # ---- extract all numeric values ----\n    n      = float(s['n'])\n    m      = float(s['m'])\n    dens   = float(s['density'])\n    adeg   = float(s['avg_degree'])\n    maxd   = float(s['max_degree'])\n    mind   = float(s['min_degree'])\n    stdd   = float(s['std_degree'])\n    aclus  = float(s['avg_clustering'])\n    tran   = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    ntri   = float(s['num_triangles'])\n    degs   = s['degrees']\n\n    # ---- base term – size and connectivity ----\n    #  A denser graph (large m, large dens) reduces path length,\n    #  but the base grows with the number of nodes.\n    base = n / (m + 1.0)          # 0 for single‑vertex graphs\n    base *= (1.0 + dens)          # higher density shortens distances\n\n    # ---- clustering & transitivity adjustments ----\n    #  Strong local clustering can create local shortcuts\n    #  but may lengthen global distances if many components are\n    #  isolated.  We therefore attenuate the base with a factor\n    #  that grows with clustering but also with transitivity.\n    base *= (1.0 + aclus)\n    base *= (1.0 - tran)          # global transitivity usually shortens paths\n\n    # ---- triangle contribution ----\n    #  Triangle density influences the richness of local cycles.\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = ntri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 5.0         # amplify mid‑range triangle densities\n\n    # ---- degree heterogeneity adjustment ----\n    #  More heterogeneous degree distributions (large stdd) typically\n    #  contain hubs that reduce average distances.  We therefore\n    #  dampen the base by the heterogeneity ratio.\n    hetero_ratio = stdd / (maxd + 1.0)\n    base *= (1.0 + hetero_ratio)\n\n    # ---- minimum degree penalty ----\n    #  If the graph contains many low‑degree vertices, paths tend to\n    #  be longer.  We penalise the base by the minimum degree.\n    base /= (1.0 + mind)\n\n    # ---- assortativity effect ----\n    #  Disassortative mixing (high absolute assortativity) can create\n    #  long “spokes” connecting peripheral nodes; we scale accordingly.\n    base *= (1.0 + abs(assort))\n\n    # ---- harmonic mean of degrees ----\n    #  The harmonic mean captures the influence of low‑degree nodes\n    #  on global connectivity.  It is added as a small correction.\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n    base += harmonic_mean * 0.1\n\n    return base\n```\n\nThis implementation combines all supplied descriptors through a series of multiplicative and additive transformations, ensuring that the resulting scalar depends on more than a single input feature and respects the restriction against importing external libraries.", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed\n    graph statistics.  The expression is a handcrafted, non‑linear\n    combination of all the supplied features; no single feature is\n    returned directly, and no external libraries are imported.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of global graph descriptors with the following keys:\n        n (int)                     – number of nodes\n        m (int)                     – number of edges\n        density (float)             – 2m/(n(n‑1))\n        avg_degree (float)          – average node degree\n        max_degree (int)            – maximum degree\n        min_degree (int)            – minimum degree\n        std_degree (float)          – standard deviation of degrees\n        avg_clustering (float)      – average local clustering\n        transitivity (float)        – global transitivity\n        degree_assortativity (float) – assortativity coefficient\n        num_triangles (int)         – number of triangles\n        degrees (list[int])         – sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy that increases monotonically with the true\n        average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # tiny value to avoid division by zero\n\n    # ---- extract all numeric values ----\n    n      = float(s['n'])\n    m      = float(s['m'])\n    dens   = float(s['density'])\n    adeg   = float(s['avg_degree'])\n    maxd   = float(s['max_degree'])\n    mind   = float(s['min_degree'])\n    stdd   = float(s['std_degree'])\n    aclus  = float(s['avg_clustering'])\n    tran   = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    ntri   = float(s['num_triangles'])\n    degs   = s['degrees']\n\n    # ---- base term – size and connectivity ----\n    #  A denser graph (large m, large dens) reduces path length,\n    #  but the base grows with the number of nodes.\n    base = n / (m + 1.0)          # 0 for single‑vertex graphs\n    base *= (1.0 + dens)          # higher density shortens distances\n\n    # ---- clustering & transitivity adjustments ----\n    #  Strong local clustering can create local shortcuts\n    #  but may lengthen global distances if many components are\n    #  isolated.  We therefore attenuate the base with a factor\n    #  that grows with clustering but also with transitivity.\n    base *= (1.0 + aclus)\n    base *= (1.0 - tran)          # global transitivity usually shortens paths\n\n    # ---- triangle contribution ----\n    #  Triangle density influences the richness of local cycles.\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = ntri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 5.0         # amplify mid‑range triangle densities\n\n    # ---- degree heterogeneity adjustment ----\n    #  More heterogeneous degree distributions (large stdd) typically\n    #  contain hubs that reduce average distances.  We therefore\n    #  dampen the base by the heterogeneity ratio.\n    hetero_ratio = stdd / (maxd + 1.0)\n    base *= (1.0 + hetero_ratio)\n\n    # ---- minimum degree penalty ----\n    #  If the graph contains many low‑degree vertices, paths tend to\n    #  be longer.  We penalise the base by the minimum degree.\n    base /= (1.0 + mind)\n\n    # ---- assortativity effect ----\n    #  Disassortative mixing (high absolute assortativity) can create\n    #  long “spokes” connecting peripheral nodes; we scale accordingly.\n    base *= (1.0 + abs(assort))\n\n    # ---- harmonic mean of degrees ----\n    #  The harmonic mean captures the influence of low‑degree nodes\n    #  on global connectivity.  It is added as a small correction.\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n    base += harmonic_mean * 0.1\n\n    return base", "spearman": -0.45730893272331813, "pearson": -0.32877338354600427, "rmse": 2.2026373565376614, "mae": 1.9419772378456508}}
{"timestamp": "2026-02-17T08:57:24.248534+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g15_i3_p1_33672541", "generation": 15, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.4699639855942377, "fitness_mode": "correlation", "simplicity_score": 0.21987737539002666, "novelty_bonus": 0.42400956428444014, "total_score": 0.4142294206402443, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.191837\nbelow_novelty_threshold: novelty_bonus=0.010891\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a dictionary of pre‑computed graph\n    features.  The estimator is a handcrafted, non‑linear combination of size,\n    density, clustering, triangles, assortativity, degree distribution, and\n    degree heterogeneity.  No external libraries are used and the function\n    performs no graph traversal.\n    \"\"\"\n    eps = 1e-12\n\n    n         = float(s['n'])\n    m         = float(s['m'])\n    density   = float(s['density'])\n    avg_deg   = float(s['avg_degree'])\n    max_deg   = float(s['max_degree'])\n    min_deg   = float(s['min_degree'])\n    std_deg   = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans     = float(s['transitivity'])\n    assort    = float(s['degree_assortativity'])\n    num_tri   = float(s['num_triangles'])\n    degrees   = s['degrees']\n\n    # ---- Base term: size, density and basic connectivity ----\n    base = n / (m + 1.0)            # more edges → shorter paths\n    base *= (1.0 + density)         # denser → shorter paths\n    base *= (1.0 + avg_clust * 0.5) # stronger local clustering adds potential shortcuts\n    base *= (1.0 - trans)           # higher transitivity tends to reduce distances\n    base *= (1.0 + abs(assort))     # magnitude of assortativity modulates connectivity\n\n    # ---- Triangle influence ----\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n    else:\n        possible_tri = 1.0\n    tri_frac = num_tri / (possible_tri + eps)\n    base += tri_frac * n * 0.5      # mid‑range triangle densities contribute positively\n\n    # ---- Harmonic mean of degrees ----\n    inv_sum = 0.0\n    for d in degrees:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n    base += harmonic * 0.1          # overall degree spread has a modest effect\n\n    # ---- Degree heterogeneity adjustment ----\n    hetero = std_deg / (max_deg + eps)\n    base += hetero * min_deg * 0.05 # highly variable degrees with many low‑degree nodes\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a dictionary of pre‑computed graph\n    features.  The estimator is a handcrafted, non‑linear combination of size,\n    density, clustering, triangles, assortativity, degree distribution, and\n    degree heterogeneity.  No external libraries are used and the function\n    performs no graph traversal.\n    \"\"\"\n    eps = 1e-12\n\n    n         = float(s['n'])\n    m         = float(s['m'])\n    density   = float(s['density'])\n    avg_deg   = float(s['avg_degree'])\n    max_deg   = float(s['max_degree'])\n    min_deg   = float(s['min_degree'])\n    std_deg   = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans     = float(s['transitivity'])\n    assort    = float(s['degree_assortativity'])\n    num_tri   = float(s['num_triangles'])\n    degrees   = s['degrees']\n\n    # ---- Base term: size, density and basic connectivity ----\n    base = n / (m + 1.0)            # more edges → shorter paths\n    base *= (1.0 + density)         # denser → shorter paths\n    base *= (1.0 + avg_clust * 0.5) # stronger local clustering adds potential shortcuts\n    base *= (1.0 - trans)           # higher transitivity tends to reduce distances\n    base *= (1.0 + abs(assort))     # magnitude of assortativity modulates connectivity\n\n    # ---- Triangle influence ----\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n    else:\n        possible_tri = 1.0\n    tri_frac = num_tri / (possible_tri + eps)\n    base += tri_frac * n * 0.5      # mid‑range triangle densities contribute positively\n\n    # ---- Harmonic mean of degrees ----\n    inv_sum = 0.0\n    for d in degrees:\n        if d > 0:\n            inv_sum += 1.0 / (d + eps)\n    harmonic = n / (inv_sum + eps) if inv_sum > 0 else 0.0\n    base += harmonic * 0.1          # overall degree spread has a modest effect\n\n    # ---- Degree heterogeneity adjustment ----\n    hetero = std_deg / (max_deg + eps)\n    base += hetero * min_deg * 0.05 # highly variable degrees with many low‑degree nodes\n\n    return base", "spearman": -0.4861021525538139, "pearson": -0.27454814941811445, "rmse": 2.0097142597415525, "mae": 1.7225754109324407}}
{"timestamp": "2026-02-17T08:58:10.576913+00:00", "event_type": "candidate_rejected", "payload": {"generation": 15, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.148618", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:58:10.577889+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 15, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.148618", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:58:58.284269+00:00", "event_type": "candidate_rejected", "payload": {"generation": 15, "island_id": 3, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.018136", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:58:58.284896+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 15, "island_id": 3, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:59:33.998442+00:00", "event_type": "candidate_rejected", "payload": {"generation": 15, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T08:59:33.999297+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 15, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:00:13.106920+00:00", "event_type": "candidate_rejected", "payload": {"generation": 15, "island_id": 3, "population_idx": 3, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.189436", "model_name": "gpt-oss:20b", "train_signal": 0.1894357743097239}}
{"timestamp": "2026-02-17T09:00:13.110085+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 15, "island_id": 3, "population_idx": 3, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:01:05.725283+00:00", "event_type": "candidate_rejected", "payload": {"generation": 15, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.065258", "model_name": "gpt-oss:20b", "train_signal": 0.06525810324129651}}
{"timestamp": "2026-02-17T09:01:05.729986+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 16, "model_name": "gpt-oss:20b", "best_val_score": 0.5706469319419225, "no_improve_count": 0}}
{"timestamp": "2026-02-17T09:02:08.515884+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g16_i0_p0_525119582", "generation": 16, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.2190821898695896, "novelty_bonus": 0.17144438359620162, "total_score": 0.4466155371973821, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.147191\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines a logarithmic size term with adjustments for density,\n    clustering, triangle density, degree heterogeneity, assortativity,\n    and a harmonic‑mean contribution.  Only built‑in Python operations are used.\n    \"\"\"\n    # Guard against empty or trivial graphs\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics (use .get to provide safe defaults)\n    avg_deg          = s.get('avg_degree', 0.0)\n    density          = s.get('density', 0.0)\n    max_deg          = s.get('max_degree', 0)\n    min_deg          = s.get('min_degree', 0)\n    std_deg          = s.get('std_degree', 0.0)\n    avg_clust        = s.get('avg_clustering', 0.0)\n    assort           = s.get('degree_assortativity', 0.0)\n    num_tri          = s.get('num_triangles', 0)\n    degrees          = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # ---------- 1. Logarithmic base (size vs. average degree) ----------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to an integer before calling bit_length\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # ---------- 2. Adjust for density (denser graphs → shorter paths) ----------\n    base *= (1 + density) ** -0.5\n\n    # ---------- 3. Adjust for clustering (higher clustering → shorter paths) ----------\n    base *= (1 + avg_clust) ** -0.25\n\n    # ---------- 4. Triangle density adjustment ----------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # ---------- 5. Degree heterogeneity adjustment ----------\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ---------- 6. Assortativity adjustment ----------\n    base *= (1 + abs(assort)) ** 0.05\n\n    # ---------- 7. Max/min degree ratio adjustment ----------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ---------- 8. Harmonic mean of degrees contribution ----------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines a logarithmic size term with adjustments for density,\n    clustering, triangle density, degree heterogeneity, assortativity,\n    and a harmonic‑mean contribution.  Only built‑in Python operations are used.\n    \"\"\"\n    # Guard against empty or trivial graphs\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    # Basic statistics (use .get to provide safe defaults)\n    avg_deg          = s.get('avg_degree', 0.0)\n    density          = s.get('density', 0.0)\n    max_deg          = s.get('max_degree', 0)\n    min_deg          = s.get('min_degree', 0)\n    std_deg          = s.get('std_degree', 0.0)\n    avg_clust        = s.get('avg_clustering', 0.0)\n    assort           = s.get('degree_assortativity', 0.0)\n    num_tri          = s.get('num_triangles', 0)\n    degrees          = s.get('degrees', [])\n\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # ---------- 1. Logarithmic base (size vs. average degree) ----------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to an integer before calling bit_length\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # ---------- 2. Adjust for density (denser graphs → shorter paths) ----------\n    base *= (1 + density) ** -0.5\n\n    # ---------- 3. Adjust for clustering (higher clustering → shorter paths) ----------\n    base *= (1 + avg_clust) ** -0.25\n\n    # ---------- 4. Triangle density adjustment ----------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # ---------- 5. Degree heterogeneity adjustment ----------\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ---------- 6. Assortativity adjustment ----------\n    base *= (1 + abs(assort)) ** 0.05\n\n    # ---------- 7. Max/min degree ratio adjustment ----------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ---------- 8. Harmonic mean of degrees contribution ----------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T09:03:23.587563+00:00", "event_type": "candidate_rejected", "payload": {"generation": 16, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.148435", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:03:23.588014+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 16, "island_id": 0, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.148435", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:04:44.798054+00:00", "event_type": "candidate_rejected", "payload": {"generation": 16, "island_id": 0, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.148435", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:04:44.798525+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 16, "island_id": 0, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:05:33.813802+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g16_i0_p2_746883649", "generation": 16, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.2189765633534611, "novelty_bonus": 0.17144438359620162, "total_score": 0.4465944118941564, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T09:06:50.530203+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g16_i0_p3_941684548", "generation": 16, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.21901859382331743, "novelty_bonus": 0.17144438359620162, "total_score": 0.4466028179881277, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic size estimate\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density (denser → shorter paths)\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering (higher clustering → shorter paths)\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle density adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic size estimate\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density (denser → shorter paths)\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering (higher clustering → shorter paths)\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle density adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T09:08:31.537607+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g16_i0_p4_205046971", "generation": 16, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.21947833032914538, "novelty_bonus": 0.17144438359620162, "total_score": 0.44669476528929325, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    n = s.get('n', 0)\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s.get('avg_degree', 0.0)\n    density = s.get('density', 0.0)\n    max_deg = s.get('max_degree', 0)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    num_tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    eps = 1e-12\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    log_avg_deg = int(avg_deg).bit_length() - 1 if avg_deg > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    eps = 1e-12\n\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg)\n    log_avg_deg = avg_deg_int.bit_length() - 1 if avg_deg_int > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    base *= (1 + density) ** -0.5\n    base *= (1 + avg_clust) ** -0.25\n\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    base *= (1 + abs(assort)) ** 0.05\n\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "extracted_code": "def new_invariant(s):\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    eps = 1e-12\n\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg)\n    log_avg_deg = avg_deg_int.bit_length() - 1 if avg_deg_int > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    base *= (1 + density) ** -0.5\n    base *= (1 + avg_clust) ** -0.25\n\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    base *= (1 + abs(assort)) ** 0.05\n\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T09:10:20.795989+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g16_i1_p0_196446992", "generation": 16, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.44614645858343327, "fitness_mode": "correlation", "simplicity_score": 0.11597524401656129, "novelty_bonus": 0.32315037833918414, "total_score": 0.3774850959284081, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.265978\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.140840\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "def new_invariant(s):\n    \"\"\"Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, assortativity, and median degree.\"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Density factor\n    density_factor = 1.0 + density\n\n    # Median degree factor\n    l = len(degrees)\n    if l == 0:\n        median_deg = 0.0\n    elif l % 2 == 1:\n        median_deg = degrees[l // 2]\n    else:\n        median_deg = (degrees[l // 2 - 1] + degrees[l // 2]) / 2.0\n    median_factor = 1.0 + median_deg / denom\n\n    # Combine all components multiplicatively\n    return (size_edge_ratio *\n            degree_factor *\n            clustering_factor *\n            triangle_factor *\n            assort_factor *\n            size_factor *\n            density_factor *\n            median_factor)", "extracted_code": "def new_invariant(s):\n    \"\"\"Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, assortativity, and median degree.\"\"\"\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n    degrees = s['degrees']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Density factor\n    density_factor = 1.0 + density\n\n    # Median degree factor\n    l = len(degrees)\n    if l == 0:\n        median_deg = 0.0\n    elif l % 2 == 1:\n        median_deg = degrees[l // 2]\n    else:\n        median_deg = (degrees[l // 2 - 1] + degrees[l // 2]) / 2.0\n    median_factor = 1.0 + median_deg / denom\n\n    # Combine all components multiplicatively\n    return (size_edge_ratio *\n            degree_factor *\n            clustering_factor *\n            triangle_factor *\n            assort_factor *\n            size_factor *\n            density_factor *\n            median_factor)", "spearman": 0.5146898672466813, "pearson": 0.4749493849456128, "rmse": 2.704400887538064, "mae": 2.5563006283367957}}
{"timestamp": "2026-02-17T09:12:38.023143+00:00", "event_type": "candidate_rejected", "payload": {"generation": 16, "island_id": 1, "population_idx": 1, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.173782", "model_name": "gpt-oss:20b", "train_signal": 0.173781512605042}}
{"timestamp": "2026-02-17T09:13:31.865570+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g16_i1_p2_944446606", "generation": 16, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.140840\nbelow_train_threshold: train_signal=0.173782\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T09:14:11.844680+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g16_i1_p3_861411410", "generation": 16, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.39486194477791114, "fitness_mode": "correlation", "simplicity_score": 0.11588879413420539, "novelty_bonus": 0.26159169004296534, "total_score": 0.23146401105836117, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.140840\nbelow_train_threshold: train_signal=0.173782\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, assortativity, and degree statistics into a\n    single scalar value.  All operations use only built‑in Python functions\n    (no imports are required).\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n    degrees    = s['degrees']          # already sorted\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Density factor (avoid zero)\n    density_factor = density if density > 0 else 1.0\n\n    # Median degree factor (use sorted list)\n    deg_len = len(degrees)\n    if deg_len == 0:\n        median_deg = 0.0\n    elif deg_len % 2 == 1:\n        median_deg = degrees[deg_len // 2]\n    else:\n        median_deg = (degrees[deg_len // 2 - 1] + degrees[deg_len // 2]) / 2.0\n    median_factor = median_deg / denom\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor *\n        median_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, assortativity, and degree statistics into a\n    single scalar value.  All operations use only built‑in Python functions\n    (no imports are required).\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n    degrees    = s['degrees']          # already sorted\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Density factor (avoid zero)\n    density_factor = density if density > 0 else 1.0\n\n    # Median degree factor (use sorted list)\n    deg_len = len(degrees)\n    if deg_len == 0:\n        median_deg = 0.0\n    elif deg_len % 2 == 1:\n        median_deg = degrees[deg_len // 2]\n    else:\n        median_deg = (degrees[deg_len // 2 - 1] + degrees[deg_len // 2]) / 2.0\n    median_factor = median_deg / denom\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor *\n        median_factor\n    )", "spearman": -0.25961749043726096, "pearson": -0.16368720747423138, "rmse": 2.9057453052329474, "mae": 2.756867039139129}}
{"timestamp": "2026-02-17T09:15:33.484789+00:00", "event_type": "candidate_rejected", "payload": {"generation": 16, "island_id": 1, "population_idx": 4, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.137863", "model_name": "gpt-oss:20b", "train_signal": 0.13786314525810325}}
{"timestamp": "2026-02-17T09:16:09.495373+00:00", "event_type": "candidate_rejected", "payload": {"generation": 16, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.063721", "model_name": "gpt-oss:20b", "train_signal": 0.06372148859543818}}
{"timestamp": "2026-02-17T09:16:42.249013+00:00", "event_type": "candidate_rejected", "payload": {"generation": 16, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:16:42.250251+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 16, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:17:01.751778+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g16_i2_p1_467677416", "generation": 16, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9496758703481392, "fitness_mode": "correlation", "simplicity_score": 0.22181723815302037, "novelty_bonus": 0.17580380576557897, "total_score": 0.5530454878827409, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.048060\nbelow_novelty_threshold: novelty_bonus=0.143471\nbelow_train_threshold: train_signal=0.063721\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport math\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of pre‑computed\n    graph statistics.  The formula starts with the graph size divided by a\n    connectivity term and then applies multiplicative adjustments for\n    clustering, transitivity, assortativity, triangle density, degree\n    heterogeneity, maximum degree and edge density.  No graph traversal\n    algorithms are used.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + math.sqrt(m) / (n + 1e-6))\n\n    # Additional density shortcut\n    base *= (1.0 + density)\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.  The formula starts with the graph\n    size divided by a connectivity term and then applies multiplicative\n    adjustments for clustering, transitivity, assortativity, triangle\n    density, degree heterogeneity, maximum degree and edge density.\n    No external libraries or graph traversal algorithms are used.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Core connectivity: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    # Additional density shortcut\n    base *= (1.0 + density)\n\n    return base", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.  The formula starts with the graph\n    size divided by a connectivity term and then applies multiplicative\n    adjustments for clustering, transitivity, assortativity, triangle\n    density, degree heterogeneity, maximum degree and edge density.\n    No external libraries or graph traversal algorithms are used.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Core connectivity: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    # Additional density shortcut\n    base *= (1.0 + density)\n\n    return base", "spearman": 0.9118817970449262, "pearson": 0.8274286632691343, "rmse": 21.947039976664787, "mae": 13.871842319616876}}
{"timestamp": "2026-02-17T09:17:01.752269+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 16, "island_id": 2, "population_idx": 1, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:17:33.785353+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g16_i2_p2_790208309", "generation": 16, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9653301320528209, "fitness_mode": "correlation", "simplicity_score": 0.22211866077003525, "novelty_bonus": 0.1791126969191008, "total_score": 0.5585888020112568, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.143471\nbelow_train_threshold: train_signal=0.063721\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.  The formula is a product of\n    connectivity, clustering, assortativity, triangle density and\n    degree heterogeneity terms, with a mild penalty for very high\n    maximum degree and a bonus for a large number of edges.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Base term: size divided by a connectivity factor\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.  The formula is a product of\n    connectivity, clustering, assortativity, triangle density and\n    degree heterogeneity terms, with a mild penalty for very high\n    maximum degree and a bonus for a large number of edges.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Base term: size divided by a connectivity factor\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base", "spearman": 0.9208625215630392, "pearson": 0.8235767180485581, "rmse": 20.404651133184917, "mae": 12.511896113478793}}
{"timestamp": "2026-02-17T09:18:14.873559+00:00", "event_type": "candidate_rejected", "payload": {"generation": 16, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:18:14.874514+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 16, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:18:57.644453+00:00", "event_type": "candidate_rejected", "payload": {"generation": 16, "island_id": 2, "population_idx": 3, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.115494", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:18:57.645390+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 16, "island_id": 2, "population_idx": 3, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:19:28.489285+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g16_i2_p4_777165813", "generation": 16, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7050660264105642, "fitness_mode": "correlation", "simplicity_score": 0.22185006579734193, "novelty_bonus": 0.4241657820144057, "total_score": 0.48291203007084776, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_train_threshold: train_signal=0.063721\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.115494\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of pre‑computed\n    graph statistics.  The formula is intentionally simple and purely\n    multiplicative: it starts with a size/connectedness baseline and then\n    applies corrections for clustering, assortativity, triangle density,\n    degree heterogeneity and maximum degree.  No external libraries are used.\n    \"\"\"\n    # Basic graph properties\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Baseline: larger graphs with low connectivity tend to have longer paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering and transitivity create shortcuts\n    base *= (1.0 + avg_clust + trans)\n\n    # Assortativity magnitude can either lengthen or shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (1.0 + max_deg / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of pre‑computed\n    graph statistics.  The formula is intentionally simple and purely\n    multiplicative: it starts with a size/connectedness baseline and then\n    applies corrections for clustering, assortativity, triangle density,\n    degree heterogeneity and maximum degree.  No external libraries are used.\n    \"\"\"\n    # Basic graph properties\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Baseline: larger graphs with low connectivity tend to have longer paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering and transitivity create shortcuts\n    base *= (1.0 + avg_clust + trans)\n\n    # Assortativity magnitude can either lengthen or shorten paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (1.0 + max_deg / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base", "spearman": 0.6225845646141154, "pearson": 0.6673499357305002, "rmse": 85.16899871965613, "mae": 58.93850634885657}}
{"timestamp": "2026-02-17T09:20:15.474126+00:00", "event_type": "candidate_rejected", "payload": {"generation": 16, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.149166", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:20:15.474948+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 16, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.149166", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:20:54.768837+00:00", "event_type": "candidate_rejected", "payload": {"generation": 16, "island_id": 3, "population_idx": 0, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.245330", "model_name": "gpt-oss:20b", "train_signal": 0.24533013205282111}}
{"timestamp": "2026-02-17T09:20:54.769910+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 16, "island_id": 3, "population_idx": 0, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:21:59.724428+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g16_i3_p1_35770155", "generation": 16, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.7233909910812949, "fitness_mode": "correlation", "simplicity_score": 0.1569801800935419, "novelty_bonus": 0.18714239576370129, "total_score": 0.49546376938844383, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\nRecent failures:\nbelow_train_threshold: train_signal=0.065258\nbelow_novelty_threshold: novelty_bonus=0.149166\nbelow_train_threshold: train_signal=0.245330\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of\n    pre‑computed graph statistics.  The estimator is a handcrafted\n    non‑linear combination of size, density, degree, clustering,\n    triangles, assortativity, and degree heterogeneity.  It uses only\n    basic Python operations (no external imports, no graph traversal).\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph descriptors with keys:\n        - 'n'                   : int      number of vertices\n        - 'm'                   : int      number of edges\n        - 'density'             : float    edge density\n        - 'avg_degree'          : float    average degree\n        - 'max_degree'          : int\n        - 'min_degree'          : int\n        - 'std_degree'          : float\n        - 'avg_clustering'      : float\n        - 'transitivity'        : float\n        - 'degree_assortativity': float\n        - 'num_triangles'       : int\n        - 'degrees'             : list[int] sorted degree sequence\n\n    Returns\n    -------\n    float\n        A proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # Extract features as floats\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12  # to avoid divisions by zero\n\n    # --------------------\n    # 1. Core scaling\n    #    In sparse or very large graphs the distance is large.\n    #    We use the square‑root of the size and divide by density\n    #    and average degree, which are classic ingredients for path length\n    #    in random graph theory.\n    # --------------------\n    base = (n ** 0.5) / ((density + eps) * (avg_deg + eps))\n\n    # --------------------\n    # 2. Modulators that lengthen or shorten paths\n    # --------------------\n    # 2a. Clustering / transitivity usually provide shortcuts:\n    #     we let them *increase* the base value (making it larger) and then\n    #     scale it by the same factor, effectively reducing the final output.\n    base *= (1 + avg_clust + eps)\n    base *= (1 + trans + eps)\n\n    # 2b. Assortativity magnitude tends to increase distances,\n    #     irrespective of its sign, so we multiply by a factor\n    #     that grows with |assort|.\n    base *= (1 + abs(assort) + eps)\n\n    # 2c. Triangles create many local cycles; the more abundant\n    #     they are relative to the edge count, the shorter the global\n    #     distance tends to be.  We therefore shrink the base in\n    #     proportion to the triangle-to‑edge ratio.\n    if m > 0:\n        tri_ratio = num_tri / (m + eps)\n        base *= (1 - 0.3 * tri_ratio)  # 0.3 is an empirically chosen weight\n\n    # --------------------\n    # 3. Heterogeneity corrections\n    # --------------------\n    # High degree variance (hubs) typically reduce distances.\n    base /= (1 + std_deg / (avg_deg + eps))\n\n    # The presence of very high or very low degrees also influences\n    # connectivity.  We penalise a high maximum degree (fewer hubs)\n    # and reward a higher minimum degree (fewer isolated nodes).\n    base /= (1 + max_deg / (avg_deg + eps))\n    base *= (1 + min_deg / (avg_deg + eps))\n\n    # --------------------\n    # 4. Harmonic‑mean bonus\n    # --------------------\n    # A large harmonic mean indicates many low‑degree nodes, which tends\n    # to increase distances.  We add a small scaled bonus to capture this.\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        h_mean = n / (inv_sum + eps)\n        base += 0.05 * h_mean\n\n    # Ensure a non‑negative return\n    return max(base, 0.0)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of\n    pre‑computed graph statistics.  The estimator is a handcrafted\n    non‑linear combination of size, density, degree, clustering,\n    triangles, assortativity, and degree heterogeneity.  It uses only\n    basic Python operations (no external imports, no graph traversal).\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph descriptors with keys:\n        - 'n'                   : int      number of vertices\n        - 'm'                   : int      number of edges\n        - 'density'             : float    edge density\n        - 'avg_degree'          : float    average degree\n        - 'max_degree'          : int\n        - 'min_degree'          : int\n        - 'std_degree'          : float\n        - 'avg_clustering'      : float\n        - 'transitivity'        : float\n        - 'degree_assortativity': float\n        - 'num_triangles'       : int\n        - 'degrees'             : list[int] sorted degree sequence\n\n    Returns\n    -------\n    float\n        A proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # Extract features as floats\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12  # to avoid divisions by zero\n\n    # --------------------\n    # 1. Core scaling\n    #    In sparse or very large graphs the distance is large.\n    #    We use the square‑root of the size and divide by density\n    #    and average degree, which are classic ingredients for path length\n    #    in random graph theory.\n    # --------------------\n    base = (n ** 0.5) / ((density + eps) * (avg_deg + eps))\n\n    # --------------------\n    # 2. Modulators that lengthen or shorten paths\n    # --------------------\n    # 2a. Clustering / transitivity usually provide shortcuts:\n    #     we let them *increase* the base value (making it larger) and then\n    #     scale it by the same factor, effectively reducing the final output.\n    base *= (1 + avg_clust + eps)\n    base *= (1 + trans + eps)\n\n    # 2b. Assortativity magnitude tends to increase distances,\n    #     irrespective of its sign, so we multiply by a factor\n    #     that grows with |assort|.\n    base *= (1 + abs(assort) + eps)\n\n    # 2c. Triangles create many local cycles; the more abundant\n    #     they are relative to the edge count, the shorter the global\n    #     distance tends to be.  We therefore shrink the base in\n    #     proportion to the triangle-to‑edge ratio.\n    if m > 0:\n        tri_ratio = num_tri / (m + eps)\n        base *= (1 - 0.3 * tri_ratio)  # 0.3 is an empirically chosen weight\n\n    # --------------------\n    # 3. Heterogeneity corrections\n    # --------------------\n    # High degree variance (hubs) typically reduce distances.\n    base /= (1 + std_deg / (avg_deg + eps))\n\n    # The presence of very high or very low degrees also influences\n    # connectivity.  We penalise a high maximum degree (fewer hubs)\n    # and reward a higher minimum degree (fewer isolated nodes).\n    base /= (1 + max_deg / (avg_deg + eps))\n    base *= (1 + min_deg / (avg_deg + eps))\n\n    # --------------------\n    # 4. Harmonic‑mean bonus\n    # --------------------\n    # A large harmonic mean indicates many low‑degree nodes, which tends\n    # to increase distances.  We add a small scaled bonus to capture this.\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        h_mean = n / (inv_sum + eps)\n        base += 0.05 * h_mean\n\n    # Ensure a non‑negative return\n    return max(base, 0.0)", "spearman": 0.8158500292812502, "pearson": 0.6155037287412044, "rmse": 7.489463345081102, "mae": 4.879488014531869}}
{"timestamp": "2026-02-17T09:22:37.557303+00:00", "event_type": "candidate_rejected", "payload": {"generation": 16, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.039766", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:22:37.558025+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 16, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.039766", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:23:33.432847+00:00", "event_type": "candidate_rejected", "payload": {"generation": 16, "island_id": 3, "population_idx": 2, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:23:33.433873+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 16, "island_id": 3, "population_idx": 2, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:24:14.089487+00:00", "event_type": "candidate_rejected", "payload": {"generation": 16, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:24:14.091962+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 16, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:24:38.150551+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g16_i3_p3_574471448", "generation": 16, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.5349819927971188, "fitness_mode": "correlation", "simplicity_score": 0.16667783984490941, "novelty_bonus": 0.16493812345308623, "total_score": 0.4281533884144931, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics\n    without performing any graph traversal. The estimator is a handcrafted\n    non‑linear combination of size, density, clustering, triangle richness,\n    assortativity, degree heterogeneity, and harmonic‑mean information.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors with keys:\n        - 'n'                   : int            number of nodes\n        - 'm'                   : int            number of edges\n        - 'density'             : float          edge density\n        - 'avg_clustering'      : float          average local clustering\n        - 'transitivity'        : float          global transitivity\n        - 'degree_assortativity': float          assortativity coefficient\n        - 'max_degree'          : int            maximum degree\n        - 'min_degree'          : int            minimum degree\n        - 'std_degree'          : float          standard deviation of degrees\n        - 'num_triangles'       : int            number of triangles\n        - 'degrees'             : list[int]      sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # --- extract and cast ---------------------------------------------\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_c      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12\n\n    # --- base term (inversely tied to edge density) -------------------\n    base = n / (m + 1.0)                 # larger graphs give a higher base\n    base *= (1.0 + density)              # denser graphs shrink typical distances\n    base *= (1.0 - avg_c)                # strong local clustering can lengthen paths\n    base *= (1.0 - trans)                # higher transitivity usually implies short cuts\n    base *= (1.0 - assort)               # disassortative mixing tends to lower path lengths\n\n    # --- triangle contribution -----------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base += tri_frac * 10.0              # amplified around mid‑range triangle density\n\n    # --- harmonic mean of degrees -------------------------------------\n    if degrees:\n        inv_sum = sum(1.0 / (d + eps) for d in degrees if d > 0)\n        harmonic = n / (inv_sum + eps)\n    else:\n        harmonic = 0.0\n    base += harmonic * 0.1               # small boost from overall degree distribution\n\n    # --- dispersion and heterogeneity adjustment ----------------------\n    disp = std_deg / (max_deg + eps)     # degree variability factor\n    correction = disp * (harmonic - min_deg) / (max_deg + 1.0 + eps)\n    base += correction\n\n    return base\nRecent failures:\nbelow_train_threshold: train_signal=0.245330\nbelow_novelty_threshold: novelty_bonus=0.039766\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a combination of\n    global graph features.  The function uses only built‑in Python\n    operations and does not perform any traversal or import external\n    libraries.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph statistics.  Expected keys:\n            n                   (int)       number of nodes\n            m                   (int)       number of edges\n            density             (float)     edge density\n            avg_degree          (float)     average vertex degree\n            max_degree          (int)       maximum degree\n            min_degree          (int)       minimum degree\n            std_degree          (float)     standard deviation of degrees\n            avg_clustering      (float)     average local clustering\n            transitivity        (float)     global transitivity\n            degree_assortativity(float)     degree assortativity coefficient\n            num_triangles       (int)       number of triangles\n            degrees             (list[int]) sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    n           = s['n']\n    m           = s['m']\n    density     = s['density']\n    avg_deg     = s['avg_degree']\n    max_deg     = s['max_degree']\n    min_deg     = s['min_degree']\n    std_deg     = s['std_degree']\n    avg_clust   = s['avg_clustering']\n    trans       = s['transitivity']\n    assort      = s['degree_assortativity']\n    num_tri     = s['num_triangles']\n    degrees     = s['degrees']\n\n    # ---------- base term based on size and connectivity ----------\n    base = (n + 1) / (m + 1)\n\n    # ---------- connectivity modifiers ----------\n    base *= (1.0 + density)                 # higher density → shorter paths\n    base *= (1.0 + avg_clust)               # local clustering adds shortcuts\n    base *= (1.0 + trans)                   # global transitivity shortens paths\n    base *= (1.0 + abs(assort))             # assortativity magnitude influences length\n\n    # ---------- triangle influence ----------\n    if n >= 3:\n        max_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (max_tri + 1e-12)\n    else:\n        tri_frac = 0.0\n    base *= (1.0 + tri_frac)\n\n    # ---------- harmonic mean of degrees ----------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            inv_sum += 1.0 / (d + 1e-12)\n        hmean = n / (inv_sum + 1e-12)\n    else:\n        hmean = 0.0\n    base *= (1.0 + hmean / (n + 1.0))\n\n    # ---------- degree heterogeneity penalty ----------\n    base /= (1.0 + std_deg / (max_deg + 1.0))\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics.\n    Only built‑in Python operations are used; no external libraries or graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors:\n            n                      (int)   number of nodes\n            m                      (int)   number of edges\n            density                (float) edge density\n            avg_degree             (float) average vertex degree\n            max_degree             (int)   maximum degree\n            min_degree             (int)   minimum degree\n            std_degree             (float) standard deviation of degrees\n            avg_clustering         (float) average local clustering\n            transitivity           (float) global transitivity\n            degree_assortativity   (float) degree assortativity coefficient\n            num_triangles          (int)   number of triangles\n            degrees                (list[int]) sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    n           = s['n']\n    m           = s['m']\n    density     = s['density']\n    avg_deg     = s['avg_degree']\n    max_deg     = s['max_degree']\n    min_deg     = s['min_degree']\n    std_deg     = s['std_degree']\n    avg_clust   = s['avg_clustering']\n    trans       = s['transitivity']\n    assort      = s['degree_assortativity']\n    num_tri     = s['num_triangles']\n    degrees     = s['degrees']\n\n    # Base term: size inversely weighted by edge count\n    base = (n + 1) / (m + 1)\n\n    # Modifiers that generally shorten paths\n    base *= (1.0 + density)                   # higher density → shorter paths\n    base *= (1.0 + avg_clust)                 # local clustering adds shortcuts\n    base *= (1.0 + trans)                     # global transitivity shortens paths\n    base *= (1.0 + abs(assort))               # magnitude of assortativity matters\n\n    # Triangle influence\n    if n >= 3:\n        max_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (max_tri + 1e-12)\n    else:\n        tri_frac = 0.0\n    base *= (1.0 + tri_frac)\n\n    # Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            inv_sum += 1.0 / (d + 1e-12)\n        hmean = n / (inv_sum + 1e-12)\n    else:\n        hmean = 0.0\n    base *= (1.0 + hmean / (n + 1.0))\n\n    # Penalty for degree heterogeneity\n    base /= (1.0 + std_deg / (max_deg + 1.0))\n\n    return float(base)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of global graph statistics.\n    Only built‑in Python operations are used; no external libraries or graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph descriptors:\n            n                      (int)   number of nodes\n            m                      (int)   number of edges\n            density                (float) edge density\n            avg_degree             (float) average vertex degree\n            max_degree             (int)   maximum degree\n            min_degree             (int)   minimum degree\n            std_degree             (float) standard deviation of degrees\n            avg_clustering         (float) average local clustering\n            transitivity           (float) global transitivity\n            degree_assortativity   (float) degree assortativity coefficient\n            num_triangles          (int)   number of triangles\n            degrees                (list[int]) sorted degree list\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    n           = s['n']\n    m           = s['m']\n    density     = s['density']\n    avg_deg     = s['avg_degree']\n    max_deg     = s['max_degree']\n    min_deg     = s['min_degree']\n    std_deg     = s['std_degree']\n    avg_clust   = s['avg_clustering']\n    trans       = s['transitivity']\n    assort      = s['degree_assortativity']\n    num_tri     = s['num_triangles']\n    degrees     = s['degrees']\n\n    # Base term: size inversely weighted by edge count\n    base = (n + 1) / (m + 1)\n\n    # Modifiers that generally shorten paths\n    base *= (1.0 + density)                   # higher density → shorter paths\n    base *= (1.0 + avg_clust)                 # local clustering adds shortcuts\n    base *= (1.0 + trans)                     # global transitivity shortens paths\n    base *= (1.0 + abs(assort))               # magnitude of assortativity matters\n\n    # Triangle influence\n    if n >= 3:\n        max_tri = n * (n - 1) * (n - 2) / 6.0\n        tri_frac = num_tri / (max_tri + 1e-12)\n    else:\n        tri_frac = 0.0\n    base *= (1.0 + tri_frac)\n\n    # Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            inv_sum += 1.0 / (d + 1e-12)\n        hmean = n / (inv_sum + 1e-12)\n    else:\n        hmean = 0.0\n    base *= (1.0 + hmean / (n + 1.0))\n\n    # Penalty for degree heterogeneity\n    base /= (1.0 + std_deg / (max_deg + 1.0))\n\n    return float(base)", "spearman": 0.6906727668191706, "pearson": 0.59227402784888, "rmse": 2.176399476696331, "mae": 2.051985163350778}}
{"timestamp": "2026-02-17T09:24:38.151098+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 16, "island_id": 3, "population_idx": 3, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:25:29.866247+00:00", "event_type": "candidate_rejected", "payload": {"generation": 16, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.123265", "model_name": "gpt-oss:20b", "train_signal": 0.12326530612244897}}
{"timestamp": "2026-02-17T09:25:29.869563+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 17, "model_name": "gpt-oss:20b", "best_val_score": 0.5706469319419225, "no_improve_count": 1}}
{"timestamp": "2026-02-17T09:26:16.085047+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g17_i0_p0_130104012", "generation": 17, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.21914645745303662, "novelty_bonus": 0.17144438359620162, "total_score": 0.4466283907140715, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    eps = 1e-12\n\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg)\n    log_avg_deg = avg_deg_int.bit_length() - 1 if avg_deg_int > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    base *= (1 + density) ** -0.5\n    base *= (1 + avg_clust) ** -0.25\n\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    base *= (1 + abs(assort)) ** 0.05\n\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses only built‑in Python operations (no imports, no graph traversal).\n    \"\"\"\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    eps = 1e-12\n\n    # ---------- logarithmic base ----------\n    log_n = n.bit_length() - 1\n\n    if avg_deg > 0:\n        avg_deg_int = int(avg_deg)\n        if avg_deg_int <= 0:\n            avg_deg_int = 1\n        log_avg_deg = avg_deg_int.bit_length() - 1\n    else:\n        log_avg_deg = 1\n\n    base = log_n / max(1, log_avg_deg)\n\n    # ---------- density adjustment ----------\n    base *= (1 + density) ** -0.5\n\n    # ---------- clustering adjustment ----------\n    base *= (1 + avg_clust) ** -0.25\n\n    # ---------- triangle fraction ----------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # ---------- degree heterogeneity ----------\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ---------- assortativity ----------\n    base *= (1 + abs(assort)) ** 0.05\n\n    # ---------- max/min degree ratio ----------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ---------- harmonic mean contribution ----------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses only built‑in Python operations (no imports, no graph traversal).\n    \"\"\"\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    eps = 1e-12\n\n    # ---------- logarithmic base ----------\n    log_n = n.bit_length() - 1\n\n    if avg_deg > 0:\n        avg_deg_int = int(avg_deg)\n        if avg_deg_int <= 0:\n            avg_deg_int = 1\n        log_avg_deg = avg_deg_int.bit_length() - 1\n    else:\n        log_avg_deg = 1\n\n    base = log_n / max(1, log_avg_deg)\n\n    # ---------- density adjustment ----------\n    base *= (1 + density) ** -0.5\n\n    # ---------- clustering adjustment ----------\n    base *= (1 + avg_clust) ** -0.25\n\n    # ---------- triangle fraction ----------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # ---------- degree heterogeneity ----------\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ---------- assortativity ----------\n    base *= (1 + abs(assort)) ** 0.05\n\n    # ---------- max/min degree ratio ----------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ---------- harmonic mean contribution ----------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T09:26:55.470716+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g17_i0_p1_189721748", "generation": 17, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6207442977190877, "fitness_mode": "correlation", "simplicity_score": 0.21961625809647964, "novelty_bonus": 0.16966820858072063, "total_score": 0.4493575775400958, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    eps = 1e-12\n\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg)\n    log_avg_deg = avg_deg_int.bit_length() - 1 if avg_deg_int > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    base *= (1 + density) ** -0.5\n    base *= (1 + avg_clust) ** -0.25\n\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    base *= (1 + abs(assort)) ** 0.05\n\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Max/min degree ratio adjustment\n    # ------------------------------------------------------------------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Max/min degree ratio adjustment\n    # ------------------------------------------------------------------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7090677266931673, "pearson": 0.5098773808014339, "rmse": 0.941122760767, "mae": 0.590237554965218}}
{"timestamp": "2026-02-17T09:27:27.130331+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g17_i0_p2_978949276", "generation": 17, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6000960384153661, "fitness_mode": "correlation", "simplicity_score": 0.21936570018931859, "novelty_bonus": 0.17131676324428624, "total_score": 0.44121431766486596, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    eps = 1e-12\n\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg)\n    log_avg_deg = avg_deg_int.bit_length() - 1 if avg_deg_int > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    base *= (1 + density) ** -0.5\n    base *= (1 + avg_clust) ** -0.25\n\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    base *= (1 + abs(assort)) ** 0.05\n\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses logarithmic size, degree, density, clustering, triangle\n    density, degree heterogeneity, assortativity, and a harmonic mean of degrees.\n    Only built‑in Python operations are used – no imports, no graph traversal,\n    no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = int(s['n'])          # ensure integer for bit_length\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.3\n\n    # Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity correction\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity correction\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio correction\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses logarithmic size, degree, density, clustering, triangle\n    density, degree heterogeneity, assortativity, and a harmonic mean of degrees.\n    Only built‑in Python operations are used – no imports, no graph traversal,\n    no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = int(s['n'])          # ensure integer for bit_length\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.3\n\n    # Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity correction\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity correction\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio correction\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.6918922973074327, "pearson": 0.49769644422518416, "rmse": 0.948722932043838, "mae": 0.5908444216890699}}
{"timestamp": "2026-02-17T09:28:19.593992+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g17_i0_p3_46099150", "generation": 17, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6207442977190877, "fitness_mode": "correlation", "simplicity_score": 0.2194330307315332, "novelty_bonus": 0.16966820858072063, "total_score": 0.4493209320671065, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    eps = 1e-12\n\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg)\n    log_avg_deg = avg_deg_int.bit_length() - 1 if avg_deg_int > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    base *= (1 + density) ** -0.5\n    base *= (1 + avg_clust) ** -0.25\n\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    base *= (1 + abs(assort)) ** 0.05\n\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.4\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.4\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7090677266931673, "pearson": 0.5098773808014339, "rmse": 0.9411227607670002, "mae": 0.590237554965218}}
{"timestamp": "2026-02-17T09:28:56.403761+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g17_i0_p4_499357717", "generation": 17, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6189195678271309, "fitness_mode": "correlation", "simplicity_score": 0.2192550974144253, "novelty_bonus": 0.17144438359620162, "total_score": 0.44665011870634924, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    eps = 1e-12\n\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg)\n    log_avg_deg = avg_deg_int.bit_length() - 1 if avg_deg_int > 0 else 1\n\n    base = log_n / max(log_avg_deg, 1)\n\n    base *= (1 + density) ** -0.5\n    base *= (1 + avg_clust) ** -0.25\n\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    base *= (1 + abs(assort)) ** 0.05\n\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.5\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.25\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses only built‑in Python operations and a handful of simple\n    adjustments that capture the influence of size, degree distribution,\n    density, clustering, triangle density, assortativity and the prevalence\n    of low‑degree nodes.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # Handle trivial graphs\n    if n <= 1:\n        return 0.0\n\n    # ---------- 1. Logarithmic size vs. average degree ----------\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ---------- 2. Adjust for density (denser → shorter paths) ----------\n    base *= (1 + density) ** -0.5\n\n    # ---------- 3. Adjust for clustering (higher clustering → shorter paths) ----------\n    base *= (1 + avg_clust) ** -0.25\n\n    # ---------- 4. Triangle density adjustment ----------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # ---------- 5. Degree heterogeneity adjustment ----------\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ---------- 6. Assortativity adjustment ----------\n    base *= (1 + abs(assort)) ** 0.05\n\n    # ---------- 7. Max/min degree ratio adjustment ----------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ---------- 8. Harmonic mean of degrees (captures low‑degree nodes) ----------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses only built‑in Python operations and a handful of simple\n    adjustments that capture the influence of size, degree distribution,\n    density, clustering, triangle density, assortativity and the prevalence\n    of low‑degree nodes.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # Handle trivial graphs\n    if n <= 1:\n        return 0.0\n\n    # ---------- 1. Logarithmic size vs. average degree ----------\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ---------- 2. Adjust for density (denser → shorter paths) ----------\n    base *= (1 + density) ** -0.5\n\n    # ---------- 3. Adjust for clustering (higher clustering → shorter paths) ----------\n    base *= (1 + avg_clust) ** -0.25\n\n    # ---------- 4. Triangle density adjustment ----------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.2\n\n    # ---------- 5. Degree heterogeneity adjustment ----------\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ---------- 6. Assortativity adjustment ----------\n    base *= (1 + abs(assort)) ** 0.05\n\n    # ---------- 7. Max/min degree ratio adjustment ----------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ---------- 8. Harmonic mean of degrees (captures low‑degree nodes) ----------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7027315682892074, "pearson": 0.5058708851908296, "rmse": 0.9404930915442845, "mae": 0.5846023573350387}}
{"timestamp": "2026-02-17T09:29:37.641260+00:00", "event_type": "candidate_rejected", "payload": {"generation": 17, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:29:37.641977+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 17, "island_id": 1, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:30:09.345409+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g17_i1_p0_816302548", "generation": 17, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7159183673469388, "fitness_mode": "correlation", "simplicity_score": 0.11528524305758846, "novelty_bonus": 0.23486043787885558, "total_score": 0.4193863267538439, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.140840\nbelow_train_threshold: train_signal=0.173782\nbelow_train_threshold: train_signal=0.137863\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport numpy as np\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, assortativity, and degree‑skewness into a\n    single scalar.  All components are derived from pre‑computed features\n    supplied in the dictionary `s`.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n    degrees    = np.array(s['degrees'], dtype=float)\n\n    # ------------------------------------------------------------------\n    # 1. Size‑to‑edge ratio (encodes sparsity)\n    # ------------------------------------------------------------------\n    size_edge_ratio = n / (m + 1.0)\n\n    # ------------------------------------------------------------------\n    # 2. Density adjustment (penalises extreme sparsity or density)\n    # ------------------------------------------------------------------\n    # 1‑density is a simple measure of how far the graph is from being\n    # complete.  We dampen the invariant when the graph is either too\n    # sparse or too dense.\n    density_factor = 1.0 / (1.0 + abs(1.0 - density))\n\n    # ------------------------------------------------------------------\n    # 3. Degree‑distribution factor\n    # ------------------------------------------------------------------\n    denom = max_deg + 1.0\n    degree_spread   = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor   = (avg_deg / denom) * degree_spread * degree_variability\n\n    # ------------------------------------------------------------------\n    # 4. Clustering dampening (local vs global)\n    # ------------------------------------------------------------------\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # ------------------------------------------------------------------\n    # 5. Triangle density boost\n    # ------------------------------------------------------------------\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n    triangle_factor = triangle_ratio + 0.1\n\n    # ------------------------------------------------------------------\n    # 6. Assortativity influence\n    # ------------------------------------------------------------------\n    assort_factor = 1.0 + abs(assort)\n\n    # ------------------------------------------------------------------\n    # 7. Size scaling (captures overall graph size)\n    # ------------------------------------------------------------------\n    size_factor = n ** 0.5\n\n    # ------------------------------------------------------------------\n    # 8. Degree‑skewness factor (captures tail heaviness of degree list)\n    # ------------------------------------------------------------------\n    mean_deg = np.mean(degrees)\n    std_deg_arr = np.std(degrees) + 1e-12  # avoid division by zero\n    skewness = np.mean((degrees - mean_deg) ** 3) / (std_deg_arr ** 3)\n    skew_factor = 1.0 + abs(skewness)\n\n    # ------------------------------------------------------------------\n    # Combine all components multiplicatively\n    # ------------------------------------------------------------------\n    return (\n        size_edge_ratio *\n        density_factor *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        skew_factor\n    )\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, assortativity, and degree‑skewness into a\n    single scalar.  All components are derived from pre‑computed features\n    supplied in the dictionary `s`.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n    degrees    = s['degrees']          # list of degrees\n\n    # 1. Size‑to‑edge ratio (encodes sparsity)\n    size_edge_ratio = n / (m + 1.0)\n\n    # 2. Density adjustment (penalises extreme sparsity or density)\n    density_factor = 1.0 / (1.0 + abs(1.0 - density))\n\n    # 3. Degree‑distribution factor\n    denom = max_deg + 1.0\n    degree_spread   = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor   = (avg_deg / denom) * degree_spread * degree_variability\n\n    # 4. Clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # 5. Triangle density boost\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n    triangle_factor = triangle_ratio + 0.1\n\n    # 6. Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # 7. Size scaling (captures overall graph size)\n    size_factor = n ** 0.5\n\n    # 8. Degree‑skewness factor (captures tail heaviness of degree list)\n    mean_deg = sum(degrees) / len(degrees)\n    # compute standard deviation\n    var = sum((d - mean_deg) ** 2 for d in degrees) / len(degrees)\n    std_deg_arr = var ** 0.5\n    if std_deg_arr == 0:\n        std_deg_arr = 1e-12\n    # compute skewness\n    skew_numer = sum((d - mean_deg) ** 3 for d in degrees) / len(degrees)\n    skewness = skew_numer / (std_deg_arr ** 3)\n    skew_factor = 1.0 + abs(skewness)\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        density_factor *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        skew_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, assortativity, and degree‑skewness into a\n    single scalar.  All components are derived from pre‑computed features\n    supplied in the dictionary `s`.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n    degrees    = s['degrees']          # list of degrees\n\n    # 1. Size‑to‑edge ratio (encodes sparsity)\n    size_edge_ratio = n / (m + 1.0)\n\n    # 2. Density adjustment (penalises extreme sparsity or density)\n    density_factor = 1.0 / (1.0 + abs(1.0 - density))\n\n    # 3. Degree‑distribution factor\n    denom = max_deg + 1.0\n    degree_spread   = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor   = (avg_deg / denom) * degree_spread * degree_variability\n\n    # 4. Clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # 5. Triangle density boost\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n    triangle_factor = triangle_ratio + 0.1\n\n    # 6. Assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # 7. Size scaling (captures overall graph size)\n    size_factor = n ** 0.5\n\n    # 8. Degree‑skewness factor (captures tail heaviness of degree list)\n    mean_deg = sum(degrees) / len(degrees)\n    # compute standard deviation\n    var = sum((d - mean_deg) ** 2 for d in degrees) / len(degrees)\n    std_deg_arr = var ** 0.5\n    if std_deg_arr == 0:\n        std_deg_arr = 1e-12\n    # compute skewness\n    skew_numer = sum((d - mean_deg) ** 3 for d in degrees) / len(degrees)\n    skewness = skew_numer / (std_deg_arr ** 3)\n    skew_factor = 1.0 + abs(skewness)\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        density_factor *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        skew_factor\n    )", "spearman": 0.651742293557339, "pearson": 0.587267850468975, "rmse": 2.787753587550942, "mae": 2.646597240542395}}
{"timestamp": "2026-02-17T09:30:09.345871+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 17, "island_id": 1, "population_idx": 0, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:30:42.590719+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g17_i1_p1_334223479", "generation": 17, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12143899741980949, "novelty_bonus": 0.185688142203555, "total_score": 0.46041650270154233, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.173782\nbelow_train_threshold: train_signal=0.137863\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = float(s['n'])\n    m          = float(s['m'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_cluster= float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    triangles  = float(s['num_triangles'])\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1.0) * (n - 2.0) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = float(s['n'])\n    m          = float(s['m'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_cluster= float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    triangles  = float(s['num_triangles'])\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1.0) * (n - 2.0) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T09:31:43.626647+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g17_i1_p2_192064085", "generation": 17, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12143899741980949, "novelty_bonus": 0.185688142203555, "total_score": 0.46041650270154233, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.173782\nbelow_train_threshold: train_signal=0.137863\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    The formula is a multiplicative combination of several components\n    derived from the input feature dictionary `s`.  No external libraries\n    are used; only built‑in Python functions are required.\n    \"\"\"\n    # Basic statistics\n    n          = float(s['n'])\n    m          = float(s['m'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_cluster= float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    triangles  = float(s['num_triangles'])\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1.0) * (n - 2.0) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    The formula is a multiplicative combination of several components\n    derived from the input feature dictionary `s`.  No external libraries\n    are used; only built‑in Python functions are required.\n    \"\"\"\n    # Basic statistics\n    n          = float(s['n'])\n    m          = float(s['m'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_cluster= float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    triangles  = float(s['num_triangles'])\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1.0) * (n - 2.0) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T09:32:08.937854+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g17_i1_p3_577159768", "generation": 17, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.173782\nbelow_train_threshold: train_signal=0.137863\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    The function uses only built‑in operations and does not perform any\n    graph traversal or shortest‑path computation.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    The function uses only built‑in operations and does not perform any\n    graph traversal or shortest‑path computation.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T09:32:42.143071+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g17_i1_p4_55895044", "generation": 17, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.173782\nbelow_train_threshold: train_signal=0.137863\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T09:33:37.695686+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g17_i2_p0_798753596", "generation": 17, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9760864345738295, "fitness_mode": "correlation", "simplicity_score": 0.2205955879701489, "novelty_bonus": 0.18032055788563106, "total_score": 0.567813274909468, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_train_threshold: train_signal=0.063721\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.115494\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Base connectivity term: larger density or average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Base connectivity term: larger density or average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base", "spearman": 0.9391959798994978, "pearson": 0.8461647502067359, "rmse": 23.050747992769622, "mae": 13.95268304651002}}
{"timestamp": "2026-02-17T09:34:28.730262+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g17_i2_p1_208284614", "generation": 17, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9760864345738295, "fitness_mode": "correlation", "simplicity_score": 0.2205955879701489, "novelty_bonus": 0.18032055788563106, "total_score": 0.567813274909468, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_train_threshold: train_signal=0.063721\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.115494\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph size\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Retrieve statistics with safe defaults\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # 1. Base connectivity term – larger n or sparser graphs give longer\n    #    paths.  The denominator is a product of average degree and\n    #    density; we guard against zero with tiny constants.\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # 2. Shortcuts from clustering and transitivity – they reduce path\n    #    length.\n    # ------------------------------------------------------------------\n    base *= (1.0 + avg_clust + trans)\n\n    # ------------------------------------------------------------------\n    # 3. Effect of assortativity – we treat the magnitude symmetrically.\n    # ------------------------------------------------------------------\n    base *= (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # 4. Triangle density – more triangles usually provide additional\n    #    short cuts.\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # 5. Degree heterogeneity – a very wide degree spread (many hubs)\n    #    typically shortens paths, so we divide by the spread.\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 6. Penalise an extremely high maximum degree (few hubs) to avoid\n    #    over‑shortening.\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1.0)\n\n    # ------------------------------------------------------------------\n    # 7. Median degree adjustment – captures skewness of the degree\n    #    distribution.\n    # ------------------------------------------------------------------\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 8. Edge‑count scaling – more edges generally reduce path length.\n    # ------------------------------------------------------------------\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic graph size\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Retrieve statistics with safe defaults\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # ------------------------------------------------------------------\n    # 1. Base connectivity term – larger n or sparser graphs give longer\n    #    paths.  The denominator is a product of average degree and\n    #    density; we guard against zero with tiny constants.\n    # ------------------------------------------------------------------\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # ------------------------------------------------------------------\n    # 2. Shortcuts from clustering and transitivity – they reduce path\n    #    length.\n    # ------------------------------------------------------------------\n    base *= (1.0 + avg_clust + trans)\n\n    # ------------------------------------------------------------------\n    # 3. Effect of assortativity – we treat the magnitude symmetrically.\n    # ------------------------------------------------------------------\n    base *= (1.0 + abs(assort))\n\n    # ------------------------------------------------------------------\n    # 4. Triangle density – more triangles usually provide additional\n    #    short cuts.\n    # ------------------------------------------------------------------\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # ------------------------------------------------------------------\n    # 5. Degree heterogeneity – a very wide degree spread (many hubs)\n    #    typically shortens paths, so we divide by the spread.\n    # ------------------------------------------------------------------\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 6. Penalise an extremely high maximum degree (few hubs) to avoid\n    #    over‑shortening.\n    # ------------------------------------------------------------------\n    base /= (max_deg + 1.0)\n\n    # ------------------------------------------------------------------\n    # 7. Median degree adjustment – captures skewness of the degree\n    #    distribution.\n    # ------------------------------------------------------------------\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # ------------------------------------------------------------------\n    # 8. Edge‑count scaling – more edges generally reduce path length.\n    # ------------------------------------------------------------------\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base", "spearman": 0.9391959798994978, "pearson": 0.8461647502067359, "rmse": 23.050747992769622, "mae": 13.95268304651002}}
{"timestamp": "2026-02-17T09:35:14.615338+00:00", "event_type": "candidate_rejected", "payload": {"generation": 17, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.078762", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:35:14.616273+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 17, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.078762", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:35:52.751122+00:00", "event_type": "candidate_rejected", "payload": {"generation": 17, "island_id": 2, "population_idx": 2, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:35:52.752701+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 17, "island_id": 2, "population_idx": 2, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:36:33.856781+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g17_i2_p3_793245221", "generation": 17, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9653301320528209, "fitness_mode": "correlation", "simplicity_score": 0.2214354802823629, "novelty_bonus": 0.1791126969191008, "total_score": 0.5584521659137224, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.115494\nbelow_novelty_threshold: novelty_bonus=0.078762\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Avoid division by zero\n    eps = 1e-6\n    denom_conn = (avg_deg if avg_deg > 0 else eps) * (density if density > 0 else eps)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / (avg_deg if avg_deg > 0 else eps))\n    base /= (1.0 + min_deg / (avg_deg if avg_deg > 0 else eps))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + eps))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Avoid division by zero\n    eps = 1e-6\n    denom_conn = (avg_deg if avg_deg > 0 else eps) * (density if density > 0 else eps)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / (avg_deg if avg_deg > 0 else eps))\n    base /= (1.0 + min_deg / (avg_deg if avg_deg > 0 else eps))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + eps))\n\n    return base", "spearman": 0.9208625215630392, "pearson": 0.8235767180485581, "rmse": 20.404651133184917, "mae": 12.511896113478793}}
{"timestamp": "2026-02-17T09:37:22.740977+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g17_i2_p4_347141358", "generation": 17, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9250900360144058, "fitness_mode": "correlation", "simplicity_score": 0.2201752461174133, "novelty_bonus": 0.1569455637386985, "total_score": 0.5507159582760905, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.115494\nbelow_novelty_threshold: novelty_bonus=0.078762\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = (density + 1e-6) * (avg_deg + 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity (weighted)\n    base *= (1.0 + 0.7 * avg_clust + 0.3 * trans)\n\n    # Effect of assortativity (magnitude only, weighted)\n    base *= (1.0 + 0.5 * abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + 0.4 * tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread (weighted)\n    base /= (1.0 + 0.8 * std_deg / (avg_deg + 1e-6))\n    base /= (1.0 + 0.8 * min_deg / (avg_deg + 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + 0.5 * (avg_deg - median_deg) / (avg_deg + 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = (density + 1e-6) * (avg_deg + 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity (weighted)\n    base *= (1.0 + 0.7 * avg_clust + 0.3 * trans)\n\n    # Effect of assortativity (magnitude only, weighted)\n    base *= (1.0 + 0.5 * abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + 0.4 * tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread (weighted)\n    base /= (1.0 + 0.8 * std_deg / (avg_deg + 1e-6))\n    base /= (1.0 + 0.8 * min_deg / (avg_deg + 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + 0.5 * (avg_deg - median_deg) / (avg_deg + 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base", "spearman": 0.9191944798619968, "pearson": 0.7225595383849168, "rmse": 16.199738018101424, "mae": 9.207064049818321}}
{"timestamp": "2026-02-17T09:38:23.718375+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g17_i3_p0_35982380", "generation": 17, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.3256182472989196, "fitness_mode": "correlation", "simplicity_score": 0.1571457010359677, "novelty_bonus": 0.37219449430305684, "total_score": 0.2947082790178736, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of\n    pre‑computed graph statistics.  The estimator is a handcrafted\n    non‑linear combination of size, density, degree, clustering,\n    triangles, assortativity, and degree heterogeneity.  It uses only\n    basic Python operations (no external imports, no graph traversal).\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph descriptors with keys:\n        - 'n'                   : int      number of vertices\n        - 'm'                   : int      number of edges\n        - 'density'             : float    edge density\n        - 'avg_degree'          : float    average degree\n        - 'max_degree'          : int\n        - 'min_degree'          : int\n        - 'std_degree'          : float\n        - 'avg_clustering'      : float\n        - 'transitivity'        : float\n        - 'degree_assortativity': float\n        - 'num_triangles'       : int\n        - 'degrees'             : list[int] sorted degree sequence\n\n    Returns\n    -------\n    float\n        A proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # Extract features as floats\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12  # to avoid divisions by zero\n\n    # --------------------\n    # 1. Core scaling\n    #    In sparse or very large graphs the distance is large.\n    #    We use the square‑root of the size and divide by density\n    #    and average degree, which are classic ingredients for path length\n    #    in random graph theory.\n    # --------------------\n    base = (n ** 0.5) / ((density + eps) * (avg_deg + eps))\n\n    # --------------------\n    # 2. Modulators that lengthen or shorten paths\n    # --------------------\n    # 2a. Clustering / transitivity usually provide shortcuts:\n    #     we let them *increase* the base value (making it larger) and then\n    #     scale it by the same factor, effectively reducing the final output.\n    base *= (1 + avg_clust + eps)\n    base *= (1 + trans + eps)\n\n    # 2b. Assortativity magnitude tends to increase distances,\n    #     irrespective of its sign, so we multiply by a factor\n    #     that grows with |assort|.\n    base *= (1 + abs(assort) + eps)\n\n    # 2c. Triangles create many local cycles; the more abundant\n    #     they are relative to the edge count, the shorter the global\n    #     distance tends to be.  We therefore shrink the base in\n    #     proportion to the triangle-to‑edge ratio.\n    if m > 0:\n        tri_ratio = num_tri / (m + eps)\n        base *= (1 - 0.3 * tri_ratio)  # 0.3 is an empirically chosen weight\n\n    # --------------------\n    # 3. Heterogeneity corrections\n    # --------------------\n    # High degree variance (hubs) typically reduce distances.\n    base /= (1 + std_deg / (avg_deg + eps))\n\n    # The presence of very high or very low degrees also influences\n    # connectivity.  We penalise a high maximum degree (fewer hubs)\n    # and reward a higher minimum degree (fewer isolated nodes).\n    base /= (1 + max_deg / (avg_deg + eps))\n    base *= (1 + min_deg / (avg_deg + eps))\n\n    # --------------------\n    # 4. Harmonic‑mean bonus\n    # --------------------\n    # A large harmonic mean indicates many low‑degree nodes, which tends\n    # to increase distances.  We add a small scaled bonus to capture this.\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        h_mean = n / (inv_sum + eps)\n        base += 0.05 * h_mean\n\n    # Ensure a non‑negative return\n    return max(base, 0.0)\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.039766\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.123265\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of\n    pre‑computed graph statistics.  The formula combines several\n    structural descriptors in a non‑linear way but uses only plain\n    Python arithmetic (no imports, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features.  Expected keys:\n            n                    (int)    number of vertices\n            m                    (int)    number of edges\n            density              (float)  edge density\n            avg_degree           (float)  average vertex degree\n            max_degree           (int)\n            min_degree           (int)\n            std_degree           (float)\n            avg_clustering       (float)  average local clustering\n            transitivity         (float)  global transitivity\n            degree_assortativity (float)  assortativity coefficient\n            num_triangles        (int)    number of triangles\n            degrees              (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy that increases monotonically with the true\n        average shortest‑path length.\n    \"\"\"\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    # 1. Base term that grows with size but is damped by connectivity\n    base = (n + 1.0) / (1.0 + density * n)\n    base /= (1.0 + avg_deg)\n\n    # 2. Triangle density effect (bell‑shaped influence)\n    if n >= 3:\n        possible = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible + 1e-12)\n    else:\n        tri_frac = 0.0\n    tri_term = 1.0 + tri_frac * (1.0 - tri_frac)\n    base *= tri_term\n\n    # 3. Clustering & transitivity usually create shortcuts\n    base /= (1.0 + avg_clust + trans)\n\n    # 4. Assortativity magnitude tends to lengthen paths\n    base *= (1.0 + abs(assort))\n\n    # 5. Heterogeneity correction (hubs shorten distances)\n    hetero = (std_deg / (max_deg + 1e-12)) * (min_deg / (max_deg + 1e-12))\n    base /= (1.0 + hetero)\n\n    # 6. Add a harmonic‑mean bonus (many low‑degree nodes increase distances)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / d\n        harmonic = n / (inv_sum + 1e-12)\n        base += 0.1 * harmonic\n\n    return max(base, 0.0)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of\n    pre‑computed graph statistics.  The formula combines several\n    structural descriptors in a non‑linear way but uses only plain\n    Python arithmetic (no imports, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Pre‑computed graph features.  Expected keys:\n            n                    (int)    number of vertices\n            m                    (int)    number of edges\n            density              (float)  edge density\n            avg_degree           (float)  average vertex degree\n            max_degree           (int)\n            min_degree           (int)\n            std_degree           (float)\n            avg_clustering       (float)  average local clustering\n            transitivity         (float)  global transitivity\n            degree_assortativity (float)  assortativity coefficient\n            num_triangles        (int)    number of triangles\n            degrees              (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy that increases monotonically with the true\n        average shortest‑path length.\n    \"\"\"\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    # 1. Base term that grows with size but is damped by connectivity\n    base = (n + 1.0) / (1.0 + density * n)\n    base /= (1.0 + avg_deg)\n\n    # 2. Triangle density effect (bell‑shaped influence)\n    if n >= 3:\n        possible = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible + 1e-12)\n    else:\n        tri_frac = 0.0\n    tri_term = 1.0 + tri_frac * (1.0 - tri_frac)\n    base *= tri_term\n\n    # 3. Clustering & transitivity usually create shortcuts\n    base /= (1.0 + avg_clust + trans)\n\n    # 4. Assortativity magnitude tends to lengthen paths\n    base *= (1.0 + abs(assort))\n\n    # 5. Heterogeneity correction (hubs shorten distances)\n    hetero = (std_deg / (max_deg + 1e-12)) * (min_deg / (max_deg + 1e-12))\n    base /= (1.0 + hetero)\n\n    # 6. Add a harmonic‑mean bonus (many low‑degree nodes increase distances)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / d\n        harmonic = n / (inv_sum + 1e-12)\n        base += 0.1 * harmonic\n\n    return max(base, 0.0)", "spearman": 0.30324158103952603, "pearson": 0.40919121166504485, "rmse": 2.0353337333859356, "mae": 1.3872158229938618}}
{"timestamp": "2026-02-17T09:39:08.237204+00:00", "event_type": "candidate_rejected", "payload": {"generation": 17, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.108936", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:39:08.238096+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 17, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.108936", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:39:57.627967+00:00", "event_type": "candidate_rejected", "payload": {"generation": 17, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.085673", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:39:57.628499+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 17, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:40:42.527528+00:00", "event_type": "candidate_rejected", "payload": {"generation": 17, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:40:42.529020+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 17, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:41:17.645428+00:00", "event_type": "candidate_rejected", "payload": {"generation": 17, "island_id": 3, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.120619", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:41:17.645826+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 17, "island_id": 3, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:41:56.350387+00:00", "event_type": "candidate_rejected", "payload": {"generation": 17, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.128145", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:41:56.350790+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 17, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.128145", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:42:38.296443+00:00", "event_type": "candidate_rejected", "payload": {"generation": 17, "island_id": 3, "population_idx": 3, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.260504", "model_name": "gpt-oss:20b", "train_signal": 0.26050420168067223}}
{"timestamp": "2026-02-17T09:42:38.297182+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 17, "island_id": 3, "population_idx": 3, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:43:25.489509+00:00", "event_type": "candidate_rejected", "payload": {"generation": 17, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.074644", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:43:25.490165+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 17, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.074644", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:44:21.928943+00:00", "event_type": "candidate_rejected", "payload": {"generation": 17, "island_id": 3, "population_idx": 4, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:44:21.930299+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 17, "island_id": 3, "population_idx": 4, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T09:44:21.936989+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 18, "model_name": "gpt-oss:20b", "best_val_score": 0.5706469319419225, "no_improve_count": 2}}
{"timestamp": "2026-02-17T09:45:43.684918+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g18_i0_p0_597892089", "generation": 18, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6053781512605042, "fitness_mode": "correlation", "simplicity_score": 0.21899754220321135, "novelty_bonus": 0.17061710343260905, "total_score": 0.44006526648610045, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Max/min degree ratio adjustment\n    # ------------------------------------------------------------------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.4\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    eps = 1e-12\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n    trans = s['transitivity']\n\n    # Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for connectivity, clustering, and transitivity\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n    base *= (1 + trans) ** -0.1\n\n    # Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity correction\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity correction\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    eps = 1e-12\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n    trans = s['transitivity']\n\n    # Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for connectivity, clustering, and transitivity\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n    base *= (1 + trans) ** -0.1\n\n    # Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity correction\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity correction\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.6901612540313509, "pearson": 0.4946394173634604, "rmse": 0.9534316039926954, "mae": 0.5934752362236815}}
{"timestamp": "2026-02-17T09:46:30.675994+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g18_i0_p1_804834070", "generation": 18, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6053781512605042, "fitness_mode": "correlation", "simplicity_score": 0.2186504429337532, "novelty_bonus": 0.17061710343260905, "total_score": 0.4399958466322088, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Max/min degree ratio adjustment\n    # ------------------------------------------------------------------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.4\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # Guard against trivial graphs\n    if n <= 1:\n        return 0.0\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1 if avg_deg_int > 0 else 0\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n    base *= (1 + trans) ** -0.1\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Degree heterogeneity and assortativity corrections\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 5. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # Guard against trivial graphs\n    if n <= 1:\n        return 0.0\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1 if avg_deg_int > 0 else 0\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n    base *= (1 + trans) ** -0.1\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Degree heterogeneity and assortativity corrections\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 5. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.6901612540313509, "pearson": 0.4946394173634604, "rmse": 0.9534316039926954, "mae": 0.5934752362236815}}
{"timestamp": "2026-02-17T09:47:37.177290+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g18_i0_p2_184122725", "generation": 18, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.5984633853541417, "fitness_mode": "correlation", "simplicity_score": 0.21895565682377716, "novelty_bonus": 0.1685001070067187, "total_score": 0.43737423929366676, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Max/min degree ratio adjustment\n    # ------------------------------------------------------------------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.4\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    if n <= 1:\n        return 0.0\n\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Assortativity and degree heterogeneity corrections\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 5. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    # 7. Transitivity adjustment\n    base *= (1 + trans) ** -0.1\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    if n <= 1:\n        return 0.0\n\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Assortativity and degree heterogeneity corrections\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 5. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    # 7. Transitivity adjustment\n    base *= (1 + trans) ** -0.1\n\n    return base", "spearman": 0.6860661516537915, "pearson": 0.4926847812365961, "rmse": 0.9572165380203396, "mae": 0.596221130260258}}
{"timestamp": "2026-02-17T09:49:34.981413+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g18_i0_p3_321754478", "generation": 18, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6214165666266506, "fitness_mode": "correlation", "simplicity_score": 0.2179230240453764, "novelty_bonus": 0.1671450791525585, "total_score": 0.4376537266947963, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Max/min degree ratio adjustment\n    # ------------------------------------------------------------------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.4\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    eps = 1e-12  # small constant to avoid division by zero\n\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # 1. Base estimate from size vs. average degree\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity, clustering, and transitivity\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n    base *= (1 + trans) ** -0.1\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Degree heterogeneity corrections\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05\n\n    # 5. Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 6. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 7. Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    # 8. Edge density factor\n    base *= (1 + m / (n * n + eps)) ** -0.1\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    eps = 1e-12  # small constant to avoid division by zero\n\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # 1. Base estimate from size vs. average degree\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity, clustering, and transitivity\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n    base *= (1 + trans) ** -0.1\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Degree heterogeneity corrections\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n    if avg_deg > 0:\n        base *= (1 + std_deg / avg_deg) ** 0.05\n\n    # 5. Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 6. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 7. Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    # 8. Edge density factor\n    base *= (1 + m / (n * n + eps)) ** -0.1\n\n    return base", "spearman": 0.687851196279907, "pearson": 0.49494759578919084, "rmse": 0.9795944663443533, "mae": 0.6163744075358789}}
{"timestamp": "2026-02-17T09:50:36.086400+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g18_i0_p4_268670220", "generation": 18, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6053781512605042, "fitness_mode": "correlation", "simplicity_score": 0.21895565682377716, "novelty_bonus": 0.17061710343260905, "total_score": 0.4400568894102136, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Max/min degree ratio adjustment\n    # ------------------------------------------------------------------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.4\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, assortativity, degree heterogeneity and a harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n    base *= (1 + trans) ** -0.1\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Degree heterogeneity and assortativity corrections\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 5. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, assortativity, degree heterogeneity and a harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n    base *= (1 + trans) ** -0.1\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Degree heterogeneity and assortativity corrections\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 5. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.6901612540313509, "pearson": 0.4946394173634604, "rmse": 0.9534316039926954, "mae": 0.5934752362236815}}
{"timestamp": "2026-02-17T09:51:08.476017+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g18_i1_p0_86957301", "generation": 18, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.173782\nbelow_train_threshold: train_signal=0.137863\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    The function uses only built‑in Python operations (no imports).\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    The function uses only built‑in Python operations (no imports).\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T09:51:35.785160+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g18_i1_p1_178794022", "generation": 18, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.173782\nbelow_train_threshold: train_signal=0.137863\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T10:02:27.463509+00:00", "event_type": "candidate_rejected", "payload": {"generation": 18, "island_id": 1, "population_idx": 2, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.265978", "model_name": "gpt-oss:20b", "train_signal": 0.2659783913565426}}
{"timestamp": "2026-02-17T10:02:55.420534+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g18_i1_p3_803735717", "generation": 18, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.137863\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T10:03:28.541039+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g18_i1_p4_277342438", "generation": 18, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.1224039274841339, "novelty_bonus": 0.185688142203555, "total_score": 0.4606094887144072, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.137863\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    if n > 2:\n        possible_triangles = n * (n - 1) * (n - 2) / 6.0\n    else:\n        possible_triangles = 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T10:04:06.811360+00:00", "event_type": "candidate_rejected", "payload": {"generation": 18, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:04:06.812049+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 18, "island_id": 2, "population_idx": 0, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:04:46.800234+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g18_i2_p0_448558859", "generation": 18, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9760864345738295, "fitness_mode": "correlation", "simplicity_score": 0.2214354802823629, "novelty_bonus": 0.18032055788563106, "total_score": 0.5679812533719109, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Base connectivity term: larger density or average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.115494\nbelow_novelty_threshold: novelty_bonus=0.078762\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    import math\n\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    # Core connectivity term based on logarithmic scaling\n    avg_deg = max(s.get('avg_degree', 0.0), 1e-6)\n    base = math.log(n + 1) / (math.log(avg_deg + 1) + 1e-6)\n\n    # Shortcuts from clustering and transitivity\n    base *= 1.0 + s.get('avg_clustering', 0.0) + s.get('transitivity', 0.0)\n\n    # Effect of assortativity (magnitude only)\n    base *= 1.0 + abs(s.get('degree_assortativity', 0.0))\n\n    # Triangle density adjustment\n    m = s.get('m', 0)\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= 1.0 + std_deg / avg_deg\n    min_deg = s.get('min_degree', 0)\n    base /= 1.0 + min_deg / avg_deg\n\n    # Penalise very high maximum degree\n    max_deg = max(s.get('max_degree', 1), 1)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / avg_deg\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= 1.0 + math.sqrt(m) / (n + 1e-6)\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = max(s.get('avg_degree', 0.0), 1e-6)\n\n    # Core connectivity term\n    base = n / (avg_deg * density + 1e-6)\n\n    # Shortcuts from clustering and transitivity\n    base *= 1.0 + s.get('avg_clustering', 0.0) + s.get('transitivity', 0.0)\n\n    # Effect of assortativity (magnitude only)\n    base *= 1.0 + abs(s.get('degree_assortativity', 0.0))\n\n    # Triangle density adjustment\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= 1.0 + std_deg / avg_deg\n    min_deg = s.get('min_degree', 0)\n    base /= 1.0 + min_deg / avg_deg\n\n    # Penalise very high maximum degree\n    max_deg = max(s.get('max_degree', 1), 1)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / avg_deg\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= 1.0 + (m ** 0.5) / (n + 1e-6)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = max(s.get('avg_degree', 0.0), 1e-6)\n\n    # Core connectivity term\n    base = n / (avg_deg * density + 1e-6)\n\n    # Shortcuts from clustering and transitivity\n    base *= 1.0 + s.get('avg_clustering', 0.0) + s.get('transitivity', 0.0)\n\n    # Effect of assortativity (magnitude only)\n    base *= 1.0 + abs(s.get('degree_assortativity', 0.0))\n\n    # Triangle density adjustment\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= 1.0 + std_deg / avg_deg\n    min_deg = s.get('min_degree', 0)\n    base /= 1.0 + min_deg / avg_deg\n\n    # Penalise very high maximum degree\n    max_deg = max(s.get('max_degree', 1), 1)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / avg_deg\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= 1.0 + (m ** 0.5) / (n + 1e-6)\n\n    return base", "spearman": 0.9391959798994978, "pearson": 0.8461658298020363, "rmse": 23.050542955780035, "mae": 13.952593399801541}}
{"timestamp": "2026-02-17T10:04:46.800818+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 18, "island_id": 2, "population_idx": 0, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:06:00.147559+00:00", "event_type": "candidate_rejected", "payload": {"generation": 18, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.129554", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:06:00.148251+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 18, "island_id": 2, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.129554", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:06:32.888115+00:00", "event_type": "candidate_rejected", "payload": {"generation": 18, "island_id": 2, "population_idx": 1, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.238031", "model_name": "gpt-oss:20b", "train_signal": 0.23803121248499398}}
{"timestamp": "2026-02-17T10:06:32.888878+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 18, "island_id": 2, "population_idx": 1, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:07:28.067905+00:00", "event_type": "candidate_rejected", "payload": {"generation": 18, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.102123", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:07:28.068539+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 18, "island_id": 2, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.102123", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:08:08.811405+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g18_i2_p2_262270421", "generation": 18, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.4422088835534213, "fitness_mode": "correlation", "simplicity_score": 0.22025196878984116, "novelty_bonus": 0.24085502137553416, "total_score": 0.42551038025763066, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Base connectivity term: larger density or average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.129554\nbelow_train_threshold: train_signal=0.238031\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: novelty_bonus=0.102123\nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Base term: larger density or average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # High clustering and transitivity typically shorten paths\n    base /= (1.0 + avg_clust + trans)\n\n    # Magnitude of assortativity tends to lengthen paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density reduces path length\n    if m > 0:\n        base /= (1.0 + tri / m)\n\n    # Degree heterogeneity (high std or low min) usually increases path length\n    base *= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base *= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Presence of high‑degree hubs tends to shorten paths\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (median_deg - avg_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges reduce path length\n    base *= (1.0 / (1.0 + (m ** 0.5) / max(n, 1e-6)))\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Basic inverse‑density scaling\n    base = (n ** 0.5) / (m + 1)\n\n    # Density and average degree encourage shorter paths\n    base *= (1.0 + density + avg_deg / max(avg_deg, 1e-6))\n\n    # Clustering and transitivity act as shortcuts\n    base *= (1.0 + avg_clust + trans)\n\n    # Absolute assortativity tends to lengthen paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density reduces distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity usually increases path length\n    base *= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base *= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Presence of hubs shortens paths\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment (skewness)\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (median_deg - avg_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling: more edges shorten paths\n    base *= 1.0 / (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Basic inverse‑density scaling\n    base = (n ** 0.5) / (m + 1)\n\n    # Density and average degree encourage shorter paths\n    base *= (1.0 + density + avg_deg / max(avg_deg, 1e-6))\n\n    # Clustering and transitivity act as shortcuts\n    base *= (1.0 + avg_clust + trans)\n\n    # Absolute assortativity tends to lengthen paths\n    base *= (1.0 + abs(assort))\n\n    # Triangle density reduces distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity usually increases path length\n    base *= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base *= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Presence of hubs shortens paths\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment (skewness)\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (median_deg - avg_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling: more edges shorten paths\n    base *= 1.0 / (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base", "spearman": 0.6184069601740043, "pearson": 0.3033658014938812, "rmse": 2.8691275100809133, "mae": 2.7245177561783116}}
{"timestamp": "2026-02-17T10:08:08.812309+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 18, "island_id": 2, "population_idx": 2, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:08:47.957470+00:00", "event_type": "candidate_rejected", "payload": {"generation": 18, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:08:47.958448+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 18, "island_id": 2, "population_idx": 3, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:09:36.906360+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g18_i2_p3_657463234", "generation": 18, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.7013205282112844, "fitness_mode": "correlation", "simplicity_score": 0.22137394722358028, "novelty_bonus": 0.42635319817090644, "total_score": 0.48545683079803564, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Base connectivity term: larger density or average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.129554\nbelow_train_threshold: train_signal=0.238031\nbelow_novelty_threshold: novelty_bonus=0.102123\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: static_invalid: forbidden token detected: import \nPrevious candidate code:\n```python\nimport math\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # --- Base term ---------------------------------------------------------\n    # Higher density and average degree shorten paths.\n    denom_conn = max(density, 1e-6) * max(avg_deg, 1e-6)\n    base = (n * math.log1p(n)) / denom_conn\n\n    # --- Short‑cut factors -----------------------------------------------\n    # 1. Clustering and transitivity tend to reduce path length\n    base /= (1.0 + avg_clust + trans)\n\n    # 2. Assortativity: positive values help connectivity, negative hurt\n    base /= (1.0 + assort)\n\n    # 3. Triangle density: more triangles → shorter paths\n    if m > 0:\n        base /= (1.0 + tri / m)\n\n    # 4. Degree heterogeneity: hubs (high std) reduce average distances\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n\n    # 5. Minimum degree: very low min degree can isolate nodes\n    base *= (1.0 + (avg_deg - min_deg) / max(avg_deg, 1e-6))\n\n    # 6. Maximum degree: a very large hub reduces distances\n    base /= (1.0 + max_deg / max(avg_deg, 1e-6))\n\n    # 7. Edge‑count scaling: more edges → shorter paths\n    base *= (1.0 + math.sqrt(m) / (n + 1e-6))\n\n    return base\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    # Base connectivity term: higher density and average degree shorten paths\n    denom_conn = max(density, 1e-6) * max(avg_deg, 1e-6)\n    base = n / denom_conn\n\n    # Short‑cut factors\n    base *= (1.0 + avg_clust + trans)          # clustering / transitivity\n    base *= (1.0 + abs(assort))                # assortativity magnitude\n    if m > 0:\n        base *= (1.0 + tri / m)                # triangle density\n\n    # Degree heterogeneity adjustments\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base *= (1.0 + (avg_deg - min_deg) / max(avg_deg, 1e-6))\n    base /= (1.0 + max_deg / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling: more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    # Base connectivity term: higher density and average degree shorten paths\n    denom_conn = max(density, 1e-6) * max(avg_deg, 1e-6)\n    base = n / denom_conn\n\n    # Short‑cut factors\n    base *= (1.0 + avg_clust + trans)          # clustering / transitivity\n    base *= (1.0 + abs(assort))                # assortativity magnitude\n    if m > 0:\n        base *= (1.0 + tri / m)                # triangle density\n\n    # Degree heterogeneity adjustments\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base *= (1.0 + (avg_deg - min_deg) / max(avg_deg, 1e-6))\n    base /= (1.0 + max_deg / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling: more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base", "spearman": 0.6265521638040953, "pearson": 0.6682655974621312, "rmse": 189.18812297636856, "mae": 133.49151923179718}}
{"timestamp": "2026-02-17T10:09:36.909958+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 18, "island_id": 2, "population_idx": 3, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:10:06.362266+00:00", "event_type": "candidate_rejected", "payload": {"generation": 18, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.111091", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:10:06.362833+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 18, "island_id": 2, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.111091", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:10:42.323792+00:00", "event_type": "candidate_rejected", "payload": {"generation": 18, "island_id": 2, "population_idx": 4, "attempt_index": 1, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:10:42.324573+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 18, "island_id": 2, "population_idx": 4, "status": "failed", "reason": "no_valid_train_predictions", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:11:36.549775+00:00", "event_type": "candidate_rejected", "payload": {"generation": 18, "island_id": 3, "population_idx": 0, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.004082", "model_name": "gpt-oss:20b", "train_signal": 0.004081632653061224}}
{"timestamp": "2026-02-17T10:12:38.080095+00:00", "event_type": "candidate_rejected", "payload": {"generation": 18, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.127860", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:12:38.082046+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 18, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.127860", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:13:20.479515+00:00", "event_type": "candidate_rejected", "payload": {"generation": 18, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.139592", "model_name": "gpt-oss:20b", "train_signal": 0.13959183673469386}}
{"timestamp": "2026-02-17T10:13:20.480464+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 18, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "below_train_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:14:08.707563+00:00", "event_type": "candidate_rejected", "payload": {"generation": 18, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.111073", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:14:08.708368+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 18, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.111073", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:14:45.028259+00:00", "event_type": "candidate_rejected", "payload": {"generation": 18, "island_id": 3, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.104613", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:14:45.028704+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 18, "island_id": 3, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:15:24.964479+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g18_i3_p3_447453107", "generation": 18, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.6068187274909964, "fitness_mode": "correlation", "simplicity_score": 0.15668405172577476, "novelty_bonus": 0.2804997278476503, "total_score": 0.3726884087414511, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of\n    pre‑computed graph statistics.  The estimator is a handcrafted\n    non‑linear combination of size, density, degree, clustering,\n    triangles, assortativity, and degree heterogeneity.  It uses only\n    basic Python operations (no external imports, no graph traversal).\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph descriptors with keys:\n        - 'n'                   : int      number of vertices\n        - 'm'                   : int      number of edges\n        - 'density'             : float    edge density\n        - 'avg_degree'          : float    average degree\n        - 'max_degree'          : int\n        - 'min_degree'          : int\n        - 'std_degree'          : float\n        - 'avg_clustering'      : float\n        - 'transitivity'        : float\n        - 'degree_assortativity': float\n        - 'num_triangles'       : int\n        - 'degrees'             : list[int] sorted degree sequence\n\n    Returns\n    -------\n    float\n        A proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # Extract features as floats\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12  # to avoid divisions by zero\n\n    # --------------------\n    # 1. Core scaling\n    #    In sparse or very large graphs the distance is large.\n    #    We use the square‑root of the size and divide by density\n    #    and average degree, which are classic ingredients for path length\n    #    in random graph theory.\n    # --------------------\n    base = (n ** 0.5) / ((density + eps) * (avg_deg + eps))\n\n    # --------------------\n    # 2. Modulators that lengthen or shorten paths\n    # --------------------\n    # 2a. Clustering / transitivity usually provide shortcuts:\n    #     we let them *increase* the base value (making it larger) and then\n    #     scale it by the same factor, effectively reducing the final output.\n    base *= (1 + avg_clust + eps)\n    base *= (1 + trans + eps)\n\n    # 2b. Assortativity magnitude tends to increase distances,\n    #     irrespective of its sign, so we multiply by a factor\n    #     that grows with |assort|.\n    base *= (1 + abs(assort) + eps)\n\n    # 2c. Triangles create many local cycles; the more abundant\n    #     they are relative to the edge count, the shorter the global\n    #     distance tends to be.  We therefore shrink the base in\n    #     proportion to the triangle-to‑edge ratio.\n    if m > 0:\n        tri_ratio = num_tri / (m + eps)\n        base *= (1 - 0.3 * tri_ratio)  # 0.3 is an empirically chosen weight\n\n    # --------------------\n    # 3. Heterogeneity corrections\n    # --------------------\n    # High degree variance (hubs) typically reduce distances.\n    base /= (1 + std_deg / (avg_deg + eps))\n\n    # The presence of very high or very low degrees also influences\n    # connectivity.  We penalise a high maximum degree (fewer hubs)\n    # and reward a higher minimum degree (fewer isolated nodes).\n    base /= (1 + max_deg / (avg_deg + eps))\n    base *= (1 + min_deg / (avg_deg + eps))\n\n    # --------------------\n    # 4. Harmonic‑mean bonus\n    # --------------------\n    # A large harmonic mean indicates many low‑degree nodes, which tends\n    # to increase distances.  We add a small scaled bonus to capture this.\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        h_mean = n / (inv_sum + eps)\n        base += 0.05 * h_mean\n\n    # Ensure a non‑negative return\n    return max(base, 0.0)\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\nRecent failures:\nbelow_train_threshold: train_signal=0.139592\nbelow_novelty_threshold: novelty_bonus=0.111073\nbelow_novelty_threshold: novelty_bonus=0.104613\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a compact,\n    non‑linear combination of global graph statistics.\n    The function relies only on the pre‑computed features provided\n    in the dictionary `s`.  No graph traversal or external libraries\n    are used.\n    \"\"\"\n    # Extract features and cast to float for numeric safety\n    n      = float(s['n'])\n    m      = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degs       = s['degrees']\n\n    eps = 1e-12  # small guard against division by zero\n\n    # Core connectivity factor (size & density vs. average degree)\n    base = (1.0 + n * density) / (avg_deg + 1.0)\n\n    # Triangle density – a richer local structure usually shortens paths\n    possible_tri = n * (n - 1) * (n - 2) / 6.0 if n >= 3 else 1.0\n    tri_frac = num_tri / (possible_tri + eps)\n    base *= (1.0 + tri_frac) ** 0.6\n\n    # Global clustering and transitivity introduce short cycles\n    base *= (1.0 + avg_clust) ** -0.5\n    base *= (1.0 + trans) ** -0.4\n\n    # Assortativity (absolute value) tends to stretch paths\n    base *= (1.0 + abs(assort)) ** 0.2\n\n    # Degree heterogeneity – hubs shrink distances\n    base /= (1.0 + std_deg / (avg_deg + eps))\n\n    # Penalise extreme degree extremes\n    base /= (1.0 + max_deg / (avg_deg + eps))\n    base *= (1.0 + min_deg / (avg_deg + eps))\n\n    # Bonus from the harmonic mean of degrees (captures many low‑degree nodes)\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            inv_sum += 1.0 / (d + eps)\n        h_mean = n / (inv_sum + eps)\n        base += 0.02 * h_mean\n\n    # Ensure non‑negative output\n    return max(base, 0.0)\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using a compact,\n    non‑linear combination of global graph statistics.\n    The function relies only on the pre‑computed features provided\n    in the dictionary `s`.  No graph traversal or external libraries\n    are used.\n    \"\"\"\n    # Extract features and cast to float for numeric safety\n    n      = float(s['n'])\n    m      = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degs       = s['degrees']\n\n    eps = 1e-12  # small guard against division by zero\n\n    # Core connectivity factor (size & density vs. average degree)\n    base = (1.0 + n * density) / (avg_deg + 1.0)\n\n    # Triangle density – a richer local structure usually shortens paths\n    possible_tri = n * (n - 1) * (n - 2) / 6.0 if n >= 3 else 1.0\n    tri_frac = num_tri / (possible_tri + eps)\n    base *= (1.0 + tri_frac) ** 0.6\n\n    # Global clustering and transitivity introduce short cycles\n    base *= (1.0 + avg_clust) ** -0.5\n    base *= (1.0 + trans) ** -0.4\n\n    # Assortativity (absolute value) tends to stretch paths\n    base *= (1.0 + abs(assort)) ** 0.2\n\n    # Degree heterogeneity – hubs shrink distances\n    base /= (1.0 + std_deg / (avg_deg + eps))\n\n    # Penalise extreme degree extremes\n    base /= (1.0 + max_deg / (avg_deg + eps))\n    base *= (1.0 + min_deg / (avg_deg + eps))\n\n    # Bonus from the harmonic mean of degrees (captures many low‑degree nodes)\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            inv_sum += 1.0 / (d + eps)\n        h_mean = n / (inv_sum + eps)\n        base += 0.02 * h_mean\n\n    # Ensure non‑negative output\n    return max(base, 0.0)", "spearman": -0.5144033600840021, "pearson": -0.500038120074703, "rmse": 2.538075792247226, "mae": 2.3244136033999685}}
{"timestamp": "2026-02-17T10:16:10.830230+00:00", "event_type": "candidate_rejected", "payload": {"generation": 18, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:16:10.831329+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 18, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:16:44.888126+00:00", "event_type": "candidate_rejected", "payload": {"generation": 18, "island_id": 3, "population_idx": 4, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.110470", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:16:44.888466+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 18, "island_id": 3, "population_idx": 4, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:16:44.890720+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 19, "model_name": "gpt-oss:20b", "best_val_score": 0.5706469319419225, "no_improve_count": 3}}
{"timestamp": "2026-02-17T10:18:08.028959+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i0_p0_811803572", "generation": 19, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6207442977190877, "fitness_mode": "correlation", "simplicity_score": 0.2194330307315332, "novelty_bonus": 0.16966820858072063, "total_score": 0.4493209320671065, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Max/min degree ratio adjustment\n    # ------------------------------------------------------------------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.4\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, assortativity, degree heterogeneity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Degree heterogeneity and assortativity corrections\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 5. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, assortativity, degree heterogeneity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Degree heterogeneity and assortativity corrections\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 5. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7090677266931673, "pearson": 0.5098773808014339, "rmse": 0.941122760767, "mae": 0.590237554965218}}
{"timestamp": "2026-02-17T10:19:48.083504+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i0_p1_591539892", "generation": 19, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6207442977190877, "fitness_mode": "correlation", "simplicity_score": 0.21889336671188897, "novelty_bonus": 0.16966820858072063, "total_score": 0.44921299926317765, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Max/min degree ratio adjustment\n    # ------------------------------------------------------------------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.4\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, density, clustering, triangle density,\n    assortativity, degree heterogeneity, and a harmonic mean of degrees.\n    Only built‑in Python operations are used – no imports, no graph traversal.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    if avg_deg > 0:\n        avg_deg_int = int(avg_deg)\n        log_avg_deg = avg_deg_int.bit_length() - 1\n    else:\n        log_avg_deg = 0\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Assortativity and degree heterogeneity corrections\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 5. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        if inv_sum > 0:\n            harmonic_mean = n / (inv_sum + eps)\n            base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, density, clustering, triangle density,\n    assortativity, degree heterogeneity, and a harmonic mean of degrees.\n    Only built‑in Python operations are used – no imports, no graph traversal.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    if avg_deg > 0:\n        avg_deg_int = int(avg_deg)\n        log_avg_deg = avg_deg_int.bit_length() - 1\n    else:\n        log_avg_deg = 0\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Assortativity and degree heterogeneity corrections\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 5. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        if inv_sum > 0:\n            harmonic_mean = n / (inv_sum + eps)\n            base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7090677266931673, "pearson": 0.5098773808014339, "rmse": 0.941122760767, "mae": 0.590237554965218}}
{"timestamp": "2026-02-17T10:20:30.186155+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i0_p2_560863448", "generation": 19, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6207442977190877, "fitness_mode": "correlation", "simplicity_score": 0.2194330307315332, "novelty_bonus": 0.16966820858072063, "total_score": 0.4493209320671065, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Max/min degree ratio adjustment\n    # ------------------------------------------------------------------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.4\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses only built‑in Python operations and avoids any imports.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    if n <= 1:\n        return 0.0\n\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Degree heterogeneity correction\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 5. Assortativity correction\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 6. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 7. Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula uses only built‑in Python operations and avoids any imports.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    if n <= 1:\n        return 0.0\n\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Degree heterogeneity correction\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 5. Assortativity correction\n    base *= (1 + abs(assort)) ** 0.05\n\n    # 6. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 7. Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7090677266931673, "pearson": 0.5098773808014339, "rmse": 0.9411227607670002, "mae": 0.590237554965218}}
{"timestamp": "2026-02-17T10:21:12.160198+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i0_p3_42856196", "generation": 19, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.6207442977190877, "fitness_mode": "correlation", "simplicity_score": 0.21847449196895993, "novelty_bonus": 0.16966820858072063, "total_score": 0.44912922431459185, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Max/min degree ratio adjustment\n    # ------------------------------------------------------------------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.4\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics (ensure integer types where required)\n    n   = int(s.get('n', 0))\n    m   = int(s.get('m', 0))\n    density      = s.get('density', 0.0)\n    avg_deg      = s.get('avg_degree', 0.0)\n    max_deg      = int(s.get('max_degree', 0))\n    min_deg      = int(s.get('min_degree', 0))\n    std_deg      = s.get('std_degree', 0.0)\n    avg_clust    = s.get('avg_clustering', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    num_tri      = int(s.get('num_triangles', 0))\n    degrees      = s.get('degrees', [])\n\n    # Handle trivial graphs\n    if n <= 1:\n        return 0.0\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Assortativity and degree heterogeneity corrections\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 5. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics (ensure integer types where required)\n    n   = int(s.get('n', 0))\n    m   = int(s.get('m', 0))\n    density      = s.get('density', 0.0)\n    avg_deg      = s.get('avg_degree', 0.0)\n    max_deg      = int(s.get('max_degree', 0))\n    min_deg      = int(s.get('min_degree', 0))\n    std_deg      = s.get('std_degree', 0.0)\n    avg_clust    = s.get('avg_clustering', 0.0)\n    assort       = s.get('degree_assortativity', 0.0)\n    num_tri      = int(s.get('num_triangles', 0))\n    degrees      = s.get('degrees', [])\n\n    # Handle trivial graphs\n    if n <= 1:\n        return 0.0\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Assortativity and degree heterogeneity corrections\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 5. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base", "spearman": 0.7090677266931673, "pearson": 0.5098773808014339, "rmse": 0.941122760767, "mae": 0.590237554965218}}
{"timestamp": "2026-02-17T10:22:43.001101+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i0_p4_991587175", "generation": 19, "island_id": 0, "model_name": "gpt-oss:20b", "train_signal": 0.632845138055222, "fitness_mode": "correlation", "simplicity_score": 0.2188317116485725, "novelty_bonus": 0.1504793626083154, "total_score": 0.4476171187864011, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_0_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Max/min degree ratio adjustment\n    # ------------------------------------------------------------------\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, degree, density, clustering,\n    triangle density, degree heterogeneity, assortativity, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n = s['n']\n    if n <= 1:\n        return 0.0\n\n    avg_deg = s['avg_degree']\n    density = s['density']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # Logarithmic approximations using bit length (base‑2)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n\n    # Base estimate from random‑graph intuition\n    base = log_n / max(1, log_avg_deg)\n\n    # Adjust for density: denser graphs have shorter paths\n    base *= (1 + density) ** -0.4\n\n    # Adjust for clustering: higher clustering can reduce path length\n    base *= (1 + avg_clust) ** -0.2\n\n    # Triangle fraction adjustment\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # Degree heterogeneity adjustment\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # Assortativity adjustment\n    base *= (1 + abs(assort)) ** 0.05\n\n    # Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # Harmonic mean of degrees contribution\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula is a non‑linear combination of size, density, clustering,\n    triangle density, assortativity, degree heterogeneity and the harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degs       = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Logarithmic base (size vs. average degree)\n    # ------------------------------------------------------------------\n    log_n = n.bit_length() - 1\n    # Convert avg_deg to int for bit_length; guard against zero\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # ------------------------------------------------------------------\n    # 2. Adjust for connectivity (density) and clustering\n    # ------------------------------------------------------------------\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density factor\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity and degree heterogeneity corrections\n    # ------------------------------------------------------------------\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # ------------------------------------------------------------------\n    # 5. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nno_valid_train_predictions: runtime_exception: AttributeError: 'float' object has no attribute 'bit_length'\nbelow_novelty_threshold: novelty_bonus=0.148435\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, density, clustering, triangle density,\n    assortativity, degree heterogeneity, max/min degree ratio, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics (ensure integers where needed)\n    n = int(s['n'])\n    if n <= 1:\n        return 0.0\n    m = int(s['m'])\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Assortativity and degree heterogeneity corrections\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 5. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    # 7. Small adjustment based on average degree\n    base *= (1 + avg_deg) ** -0.05\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from pre‑computed graph statistics.\n    The formula combines logarithmic size, density, clustering, triangle density,\n    assortativity, degree heterogeneity, max/min degree ratio, and a harmonic\n    mean of degrees.  Only built‑in Python operations are used – no imports,\n    no graph traversal, no external libraries.\n    \"\"\"\n    eps = 1e-12  # small constant to avoid division by zero\n\n    # Basic graph statistics (ensure integers where needed)\n    n = int(s['n'])\n    if n <= 1:\n        return 0.0\n    m = int(s['m'])\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_clust = s['avg_clustering']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']\n\n    # 1. Logarithmic base (size vs. average degree)\n    log_n = n.bit_length() - 1\n    avg_deg_int = int(avg_deg) if avg_deg > 0 else 1\n    log_avg_deg = avg_deg_int.bit_length() - 1\n    base = log_n / max(1, log_avg_deg)\n\n    # 2. Adjust for connectivity (density) and clustering\n    base *= (1 + density) ** -0.4\n    base *= (1 + avg_clust) ** -0.2\n\n    # 3. Triangle density factor\n    if n >= 3:\n        possible_tri = n * (n - 1) * (n - 2) // 6\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    base *= (1 + tri_frac) ** -0.3\n\n    # 4. Assortativity and degree heterogeneity corrections\n    base *= (1 + abs(assort)) ** 0.05\n    if max_deg > 0:\n        base *= (1 + std_deg / max_deg) ** 0.1\n\n    # 5. Max/min degree ratio adjustment\n    if min_deg > 0:\n        base *= (1 + max_deg / min_deg) ** -0.05\n\n    # 6. Harmonic mean of degrees (captures prevalence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        base += harmonic_mean / (max_deg + 1)\n\n    # 7. Small adjustment based on average degree\n    base *= (1 + avg_deg) ** -0.05\n\n    return base", "spearman": 0.7174139353483839, "pearson": 0.5198575309016764, "rmse": 0.9255180858197328, "mae": 0.5821026233392139}}
{"timestamp": "2026-02-17T10:23:16.643689+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i1_p0_217090647", "generation": 19, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.137863\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T10:23:56.038858+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i1_p1_149389497", "generation": 19, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.137863\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T10:24:27.217348+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i1_p2_64043348", "generation": 19, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.7029531812725089, "fitness_mode": "correlation", "simplicity_score": 0.12250856077870916, "novelty_bonus": 0.185688142203555, "total_score": 0.4606304153733223, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nbelow_train_threshold: train_signal=0.137863\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )", "spearman": 0.7608445211130279, "pearson": 0.7144760221485571, "rmse": 2.7823376098555697, "mae": 2.637614706993982}}
{"timestamp": "2026-02-17T10:25:18.406413+00:00", "event_type": "candidate_rejected", "payload": {"generation": 19, "island_id": 1, "population_idx": 3, "attempt_index": 0, "reason": "below_train_threshold", "failure_feedback": "train_signal=0.166867", "model_name": "gpt-oss:20b", "train_signal": 0.16686674669867946}}
{"timestamp": "2026-02-17T10:26:00.690388+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i1_p4_704144695", "generation": 19, "island_id": 1, "model_name": "gpt-oss:20b", "train_signal": 0.39486194477791114, "fitness_mode": "correlation", "simplicity_score": 0.11783462977617248, "novelty_bonus": 0.26159169004296534, "total_score": 0.23185317818675455, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_1_free\n\nStrategy: Combine elements from the top 2 formulas into a new one. Merge their strengths into a single improved formula.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity.\n    \"\"\"\n    n = s['n']\n    m = s['m']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    avg_cluster = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    triangles = s['num_triangles']\n\n    # Triangle density\n    possible_triangles = n * (n - 1) * (n - 2) / 6 if n > 2 else 1\n    triangle_ratio = triangles / possible_triangles\n\n    # Size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1)\n\n    # Degree spread and variability\n    denom = max_deg + 1\n    degree_spread = (max_deg - min_deg + 1) / denom\n    degree_variability = 1 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Clustering dampening\n    clustering_factor = (1 + avg_cluster) / (1 + trans)\n\n    # Triangle factor\n    triangle_factor = triangle_ratio + 0.1\n\n    # Assortativity influence\n    assort_factor = 1 + abs(assort)\n\n    # Size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant combining size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\n\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, and assortativity into a single scalar.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = (n * (n - 1) * (n - 2) / 6.0) if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread and variability\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor\n    )\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_train_threshold: train_signal=0.265978\nbelow_train_threshold: train_signal=0.166867\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, assortativity, and median degree into a single\n    scalar value.  The input `s` is a dictionary of pre‑computed graph\n    statistics.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n    degrees    = s['degrees']          # sorted degree list\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread, variability, and median\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    # median degree from the sorted list\n    L = len(degrees)\n    if L % 2 == 1:\n        median_deg = degrees[L // 2]\n    else:\n        median_deg = (degrees[L // 2 - 1] + degrees[L // 2]) / 2.0\n    median_factor = median_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability * median_factor\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density scaling\n    density_factor = density\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor\n    )\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Composite graph invariant that blends size, density, degree distribution,\n    clustering, triangle density, assortativity, and median degree into a single\n    scalar value.  The input `s` is a dictionary of pre‑computed graph\n    statistics.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    avg_cluster= s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    triangles  = s['num_triangles']\n    degrees    = s['degrees']          # sorted degree list\n\n    # Triangle density (ratio of existing to possible triangles)\n    possible_triangles = n * (n - 1) * (n - 2) / 6.0 if n > 2 else 1.0\n    triangle_ratio = triangles / possible_triangles\n\n    # Component 1 – size‑to‑edge ratio\n    size_edge_ratio = n / (m + 1.0)\n\n    # Component 2 – degree spread, variability, and median\n    denom = max_deg + 1.0\n    degree_spread = (max_deg - min_deg + 1.0) / denom\n    degree_variability = 1.0 + std_deg / denom\n    # median degree from the sorted list\n    L = len(degrees)\n    if L % 2 == 1:\n        median_deg = degrees[L // 2]\n    else:\n        median_deg = (degrees[L // 2 - 1] + degrees[L // 2]) / 2.0\n    median_factor = median_deg / denom\n    degree_factor = (avg_deg / denom) * degree_spread * degree_variability * median_factor\n\n    # Component 3 – clustering dampening (local vs global)\n    clustering_factor = (1.0 + avg_cluster) / (1.0 + trans)\n\n    # Component 4 – triangle density boost\n    triangle_factor = triangle_ratio + 0.1\n\n    # Component 5 – assortativity influence\n    assort_factor = 1.0 + abs(assort)\n\n    # Component 6 – size scaling\n    size_factor = n ** 0.5\n\n    # Component 7 – density scaling\n    density_factor = density\n\n    # Combine all components multiplicatively\n    return (\n        size_edge_ratio *\n        degree_factor *\n        clustering_factor *\n        triangle_factor *\n        assort_factor *\n        size_factor *\n        density_factor\n    )", "spearman": -0.25961749043726096, "pearson": -0.16368720747423135, "rmse": 2.9057453052329474, "mae": 2.756867039139129}}
{"timestamp": "2026-02-17T10:26:58.771029+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i2_p0_469752146", "generation": 19, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9527490996398559, "fitness_mode": "correlation", "simplicity_score": 0.21999977568039208, "novelty_bonus": 0.1910563285070458, "total_score": 0.5525431343452086, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = max(s.get('avg_degree', 0.0), 1e-6)\n\n    # Core connectivity term\n    base = n / (avg_deg * density + 1e-6)\n\n    # Shortcuts from clustering and transitivity\n    base *= 1.0 + s.get('avg_clustering', 0.0) + s.get('transitivity', 0.0)\n\n    # Effect of assortativity (magnitude only)\n    base *= 1.0 + abs(s.get('degree_assortativity', 0.0))\n\n    # Triangle density adjustment\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= 1.0 + std_deg / avg_deg\n    min_deg = s.get('min_degree', 0)\n    base /= 1.0 + min_deg / avg_deg\n\n    # Penalise very high maximum degree\n    max_deg = max(s.get('max_degree', 1), 1)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / avg_deg\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= 1.0 + (m ** 0.5) / (n + 1e-6)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.102123\nbelow_novelty_threshold: novelty_bonus=0.111091\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of pre‑computed\n    graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    # Core connectivity term: larger density and average degree shorten paths\n    base = n / (max(avg_deg, 1e-6) * max(density, 1e-6) + 1e-6)\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    # Additional density scaling\n    base *= (1.0 + density)\n\n    # Average degree relative to maximum degree\n    base *= (1.0 + avg_deg / (max_deg + 1e-6))\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of pre‑computed\n    graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)– degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = s.get('avg_degree', 0.0)\n    max_deg = s.get('max_degree', 1)\n    min_deg = s.get('min_degree', 0)\n    std_deg = s.get('std_degree', 0.0)\n    avg_clust = s.get('avg_clustering', 0.0)\n    trans = s.get('transitivity', 0.0)\n    assort = s.get('degree_assortativity', 0.0)\n    tri = s.get('num_triangles', 0)\n    degrees = s.get('degrees', [])\n\n    # Core connectivity term: larger density and average degree shorten paths\n    base = n / (max(avg_deg, 1e-6) * max(density, 1e-6) + 1e-6)\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    # Additional density scaling\n    base *= (1.0 + density)\n\n    # Average degree relative to maximum degree\n    base *= (1.0 + avg_deg / (max_deg + 1e-6))\n\n    return base", "spearman": 0.902452561314033, "pearson": 0.8254664103219594, "rmse": 36.84878497590009, "mae": 24.11296774685258}}
{"timestamp": "2026-02-17T10:27:45.031611+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i2_p1_276481902", "generation": 19, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9760864345738295, "fitness_mode": "correlation", "simplicity_score": 0.22051463019207068, "novelty_bonus": 0.18032055788563106, "total_score": 0.5677970833538524, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = max(s.get('avg_degree', 0.0), 1e-6)\n\n    # Core connectivity term\n    base = n / (avg_deg * density + 1e-6)\n\n    # Shortcuts from clustering and transitivity\n    base *= 1.0 + s.get('avg_clustering', 0.0) + s.get('transitivity', 0.0)\n\n    # Effect of assortativity (magnitude only)\n    base *= 1.0 + abs(s.get('degree_assortativity', 0.0))\n\n    # Triangle density adjustment\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= 1.0 + std_deg / avg_deg\n    min_deg = s.get('min_degree', 0)\n    base /= 1.0 + min_deg / avg_deg\n\n    # Penalise very high maximum degree\n    max_deg = max(s.get('max_degree', 1), 1)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / avg_deg\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= 1.0 + (m ** 0.5) / (n + 1e-6)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.102123\nbelow_novelty_threshold: novelty_bonus=0.111091\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / (denom_conn + 1e-6)\n\n    # Shortcuts from clustering and transitivity\n    base *= 1.0 + avg_clust + trans\n\n    # Effect of assortativity (magnitude only)\n    base *= 1.0 + abs(assort)\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # Normalize by degree heterogeneity\n    base /= 1.0 + std_deg / max(avg_deg, 1e-6)\n    base /= 1.0 + min_deg / max(avg_deg, 1e-6)\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6)\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= 1.0 + (m ** 0.5) / (n + 1e-6)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / (denom_conn + 1e-6)\n\n    # Shortcuts from clustering and transitivity\n    base *= 1.0 + avg_clust + trans\n\n    # Effect of assortativity (magnitude only)\n    base *= 1.0 + abs(assort)\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # Normalize by degree heterogeneity\n    base /= 1.0 + std_deg / max(avg_deg, 1e-6)\n    base /= 1.0 + min_deg / max(avg_deg, 1e-6)\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6)\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= 1.0 + (m ** 0.5) / (n + 1e-6)\n\n    return base", "spearman": 0.9391959798994978, "pearson": 0.8461658298020363, "rmse": 23.050542955780035, "mae": 13.952593399801541}}
{"timestamp": "2026-02-17T10:28:11.801575+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i2_p2_576627228", "generation": 19, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9760864345738295, "fitness_mode": "correlation", "simplicity_score": 0.22084478163114366, "novelty_bonus": 0.18032055788563106, "total_score": 0.567863113641667, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = max(s.get('avg_degree', 0.0), 1e-6)\n\n    # Core connectivity term\n    base = n / (avg_deg * density + 1e-6)\n\n    # Shortcuts from clustering and transitivity\n    base *= 1.0 + s.get('avg_clustering', 0.0) + s.get('transitivity', 0.0)\n\n    # Effect of assortativity (magnitude only)\n    base *= 1.0 + abs(s.get('degree_assortativity', 0.0))\n\n    # Triangle density adjustment\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= 1.0 + std_deg / avg_deg\n    min_deg = s.get('min_degree', 0)\n    base /= 1.0 + min_deg / avg_deg\n\n    # Penalise very high maximum degree\n    max_deg = max(s.get('max_degree', 1), 1)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / avg_deg\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= 1.0 + (m ** 0.5) / (n + 1e-6)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.102123\nbelow_novelty_threshold: novelty_bonus=0.111091\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters with safe defaults\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = max(s.get('avg_degree', 0.0), 1e-6)\n    max_deg    = max(s.get('max_degree', 1), 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # 1. Core connectivity: larger density/avg degree → shorter paths\n    base = n / (avg_deg * max(density, 1e-6) + 1e-6)\n\n    # 2. Shortcuts from clustering and transitivity\n    base *= 1.0 + avg_clust + trans\n\n    # 3. Effect of assortativity (use magnitude only)\n    base *= 1.0 + abs(assort)\n\n    # 4. Triangle density adjustment\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # 5. Normalize by degree heterogeneity\n    base /= 1.0 + std_deg / avg_deg\n    base /= 1.0 + min_deg / avg_deg\n\n    # 6. Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # 7. Median degree adjustment (skewness)\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / avg_deg\n\n    # 8. Edge‑count scaling – more edges usually reduce path length\n    base *= 1.0 + pow(m, 0.5) / (n + 1e-6)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    # Basic parameters with safe defaults\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = max(s.get('avg_degree', 0.0), 1e-6)\n    max_deg    = max(s.get('max_degree', 1), 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # 1. Core connectivity: larger density/avg degree → shorter paths\n    base = n / (avg_deg * max(density, 1e-6) + 1e-6)\n\n    # 2. Shortcuts from clustering and transitivity\n    base *= 1.0 + avg_clust + trans\n\n    # 3. Effect of assortativity (use magnitude only)\n    base *= 1.0 + abs(assort)\n\n    # 4. Triangle density adjustment\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # 5. Normalize by degree heterogeneity\n    base /= 1.0 + std_deg / avg_deg\n    base /= 1.0 + min_deg / avg_deg\n\n    # 6. Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # 7. Median degree adjustment (skewness)\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / avg_deg\n\n    # 8. Edge‑count scaling – more edges usually reduce path length\n    base *= 1.0 + pow(m, 0.5) / (n + 1e-6)\n\n    return base", "spearman": 0.9391959798994978, "pearson": 0.8461658298020363, "rmse": 23.050542955780035, "mae": 13.952593399801541}}
{"timestamp": "2026-02-17T10:28:45.089683+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i2_p3_670658885", "generation": 19, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9760864345738295, "fitness_mode": "correlation", "simplicity_score": 0.22087307486785207, "novelty_bonus": 0.18032055788563106, "total_score": 0.5678687722890087, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = max(s.get('avg_degree', 0.0), 1e-6)\n\n    # Core connectivity term\n    base = n / (avg_deg * density + 1e-6)\n\n    # Shortcuts from clustering and transitivity\n    base *= 1.0 + s.get('avg_clustering', 0.0) + s.get('transitivity', 0.0)\n\n    # Effect of assortativity (magnitude only)\n    base *= 1.0 + abs(s.get('degree_assortativity', 0.0))\n\n    # Triangle density adjustment\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= 1.0 + std_deg / avg_deg\n    min_deg = s.get('min_degree', 0)\n    base /= 1.0 + min_deg / avg_deg\n\n    # Penalise very high maximum degree\n    max_deg = max(s.get('max_degree', 1), 1)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / avg_deg\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= 1.0 + (m ** 0.5) / (n + 1e-6)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.102123\nbelow_novelty_threshold: novelty_bonus=0.111091\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of pre‑computed\n    graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = max(s.get('avg_degree', 0.0), 1e-6)\n    max_deg    = max(s.get('max_degree', 1), 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity: higher density and average degree shorten paths\n    base = n / (avg_deg * max(density, 1e-6) + 1e-6)\n\n    # Shortcuts from clustering and transitivity\n    base *= 1.0 + avg_clust + trans\n\n    # Effect of assortativity (magnitude only)\n    base *= 1.0 + abs(assort)\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # Normalise by degree heterogeneity\n    base /= 1.0 + std_deg / avg_deg\n    base /= 1.0 + min_deg / avg_deg\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / avg_deg\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= 1.0 + (m ** 0.5) / (n + 1e-6)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of pre‑computed\n    graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = max(s.get('avg_degree', 0.0), 1e-6)\n    max_deg    = max(s.get('max_degree', 1), 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity: higher density and average degree shorten paths\n    base = n / (avg_deg * max(density, 1e-6) + 1e-6)\n\n    # Shortcuts from clustering and transitivity\n    base *= 1.0 + avg_clust + trans\n\n    # Effect of assortativity (magnitude only)\n    base *= 1.0 + abs(assort)\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # Normalise by degree heterogeneity\n    base /= 1.0 + std_deg / avg_deg\n    base /= 1.0 + min_deg / avg_deg\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / avg_deg\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= 1.0 + (m ** 0.5) / (n + 1e-6)\n\n    return base", "spearman": 0.9391959798994978, "pearson": 0.8461658298020363, "rmse": 23.050542955780035, "mae": 13.952593399801541}}
{"timestamp": "2026-02-17T10:29:32.631189+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i2_p4_486891567", "generation": 19, "island_id": 2, "model_name": "gpt-oss:20b", "train_signal": 0.9741656662665067, "fitness_mode": "correlation", "simplicity_score": 0.22051463019207068, "novelty_bonus": 0.19244158923238974, "total_score": 0.5690325827376294, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_2_free\n\nStrategy: Improve the best existing formula. Make small targeted changes to refine accuracy while keeping the formula simple.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalise by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m = s.get('m', 0)\n    density = s.get('density', 0.0)\n    avg_deg = max(s.get('avg_degree', 0.0), 1e-6)\n\n    # Core connectivity term\n    base = n / (avg_deg * density + 1e-6)\n\n    # Shortcuts from clustering and transitivity\n    base *= 1.0 + s.get('avg_clustering', 0.0) + s.get('transitivity', 0.0)\n\n    # Effect of assortativity (magnitude only)\n    base *= 1.0 + abs(s.get('degree_assortativity', 0.0))\n\n    # Triangle density adjustment\n    tri = s.get('num_triangles', 0)\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # Normalize by degree heterogeneity\n    std_deg = s.get('std_degree', 0.0)\n    base /= 1.0 + std_deg / avg_deg\n    min_deg = s.get('min_degree', 0)\n    base /= 1.0 + min_deg / avg_deg\n\n    # Penalise very high maximum degree\n    max_deg = max(s.get('max_degree', 1), 1)\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    degrees = s.get('degrees', [])\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / avg_deg\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= 1.0 + (m ** 0.5) / (n + 1e-6)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: higher density/average degree shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= (1.0 + avg_clust + trans)\n\n    # Effect of assortativity (magnitude only)\n    base *= (1.0 + abs(assort))\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Normalize by degree heterogeneity\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= (1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6))\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= (1.0 + (m ** 0.5) / (n + 1e-6))\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.102123\nbelow_novelty_threshold: novelty_bonus=0.111091\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: more edges or higher density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= 1.0 + avg_clust + trans\n\n    # Effect of assortativity (magnitude only, dampened)\n    base *= 1.0 + abs(assort) * 0.5\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # Normalize by degree heterogeneity\n    base /= 1.0 + std_deg / max(avg_deg, 1e-6)\n    base /= 1.0 + min_deg / max(avg_deg, 1e-6)\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6)\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= 1.0 + (m ** 0.5) / (n + 1e-6)\n\n    return base\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from a dictionary of\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n (int)                     – number of nodes\n            m (int)                     – number of edges\n            density (float)             – edge density\n            avg_degree (float)          – average degree\n            max_degree (int)            – maximum degree\n            min_degree (int)            – minimum degree\n            std_degree (float)          – standard deviation of degrees\n            avg_clustering (float)      – average clustering coefficient\n            transitivity (float)        – global transitivity\n            degree_assortativity (float)- degree assortativity coefficient\n            num_triangles (int)         – total number of triangles\n            degrees (list[int])         – sorted list of degrees\n\n    Returns\n    -------\n    float\n        Estimated average shortest path length.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    trans      = s.get('transitivity', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n    degrees    = s.get('degrees', [])\n\n    # Core connectivity term: more edges or higher density shortens paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Shortcuts from clustering and transitivity\n    base *= 1.0 + avg_clust + trans\n\n    # Effect of assortativity (magnitude only, dampened)\n    base *= 1.0 + abs(assort) * 0.5\n\n    # Triangle density adjustment\n    if m > 0:\n        base *= 1.0 + tri / m\n\n    # Normalize by degree heterogeneity\n    base /= 1.0 + std_deg / max(avg_deg, 1e-6)\n    base /= 1.0 + min_deg / max(avg_deg, 1e-6)\n\n    # Penalise very high maximum degree\n    base /= (max_deg + 1.0)\n\n    # Median degree adjustment – captures skewness of the degree distribution\n    if degrees:\n        median_deg = degrees[len(degrees) // 2]\n        base *= 1.0 + (avg_deg - median_deg) / max(avg_deg, 1e-6)\n\n    # Edge‑count scaling – more edges generally reduce path length\n    base *= 1.0 + (m ** 0.5) / (n + 1e-6)\n\n    return base", "spearman": 0.9343943598589967, "pearson": 0.8215829272628226, "rmse": 20.477573073074602, "mae": 12.538177592015797}}
{"timestamp": "2026-02-17T10:30:15.460666+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i3_p0_447224928", "generation": 19, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.6716446578631452, "fitness_mode": "correlation", "simplicity_score": 0.16484330735126598, "novelty_bonus": 0.16447503868185187, "total_score": 0.4069365387089496, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of\n    pre‑computed graph statistics.  The estimator is a handcrafted\n    non‑linear combination of size, density, degree, clustering,\n    triangles, assortativity, and degree heterogeneity.  It uses only\n    basic Python operations (no external imports, no graph traversal).\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph descriptors with keys:\n        - 'n'                   : int      number of vertices\n        - 'm'                   : int      number of edges\n        - 'density'             : float    edge density\n        - 'avg_degree'          : float    average degree\n        - 'max_degree'          : int\n        - 'min_degree'          : int\n        - 'std_degree'          : float\n        - 'avg_clustering'      : float\n        - 'transitivity'        : float\n        - 'degree_assortativity': float\n        - 'num_triangles'       : int\n        - 'degrees'             : list[int] sorted degree sequence\n\n    Returns\n    -------\n    float\n        A proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # Extract features as floats\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12  # to avoid divisions by zero\n\n    # --------------------\n    # 1. Core scaling\n    #    In sparse or very large graphs the distance is large.\n    #    We use the square‑root of the size and divide by density\n    #    and average degree, which are classic ingredients for path length\n    #    in random graph theory.\n    # --------------------\n    base = (n ** 0.5) / ((density + eps) * (avg_deg + eps))\n\n    # --------------------\n    # 2. Modulators that lengthen or shorten paths\n    # --------------------\n    # 2a. Clustering / transitivity usually provide shortcuts:\n    #     we let them *increase* the base value (making it larger) and then\n    #     scale it by the same factor, effectively reducing the final output.\n    base *= (1 + avg_clust + eps)\n    base *= (1 + trans + eps)\n\n    # 2b. Assortativity magnitude tends to increase distances,\n    #     irrespective of its sign, so we multiply by a factor\n    #     that grows with |assort|.\n    base *= (1 + abs(assort) + eps)\n\n    # 2c. Triangles create many local cycles; the more abundant\n    #     they are relative to the edge count, the shorter the global\n    #     distance tends to be.  We therefore shrink the base in\n    #     proportion to the triangle-to‑edge ratio.\n    if m > 0:\n        tri_ratio = num_tri / (m + eps)\n        base *= (1 - 0.3 * tri_ratio)  # 0.3 is an empirically chosen weight\n\n    # --------------------\n    # 3. Heterogeneity corrections\n    # --------------------\n    # High degree variance (hubs) typically reduce distances.\n    base /= (1 + std_deg / (avg_deg + eps))\n\n    # The presence of very high or very low degrees also influences\n    # connectivity.  We penalise a high maximum degree (fewer hubs)\n    # and reward a higher minimum degree (fewer isolated nodes).\n    base /= (1 + max_deg / (avg_deg + eps))\n    base *= (1 + min_deg / (avg_deg + eps))\n\n    # --------------------\n    # 4. Harmonic‑mean bonus\n    # --------------------\n    # A large harmonic mean indicates many low‑degree nodes, which tends\n    # to increase distances.  We add a small scaled bonus to capture this.\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        h_mean = n / (inv_sum + eps)\n        base += 0.05 * h_mean\n\n    # Ensure a non‑negative return\n    return max(base, 0.0)\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.104613\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.110470\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n", "llm_response": "```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed graph\n    statistics.  The estimator is a handcrafted non‑linear combination of\n    size, density, degree distribution, clustering, triangles, assortativity\n    and degree heterogeneity.  It uses only plain Python operations and\n    does not perform any graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph descriptors with keys:\n            n                     : int          number of vertices\n            m                     : int          number of edges\n            density               : float        edge density\n            avg_degree            : float        average vertex degree\n            max_degree            : int\n            min_degree            : int\n            std_degree            : float        degree standard deviation\n            avg_clustering        : float        average local clustering\n            transitivity          : float        global transitivity\n            degree_assortativity  : float        assortativity coefficient\n            num_triangles         : int          number of triangles\n            degrees               : list[int]    sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.  The value\n        grows approximately monotonically with the true average shortest‑path\n        length while remaining bounded and robust to extreme feature values.\n    \"\"\"\n    # Pull features out of the dict\n    n           = float(s['n'])\n    m           = float(s['m'])\n    density     = float(s['density'])\n    avg_deg     = float(s['avg_degree'])\n    max_deg     = float(s['max_degree'])\n    min_deg     = float(s['min_degree'])\n    std_deg     = float(s['std_degree'])\n    avg_clust   = float(s['avg_clustering'])\n    trans       = float(s['transitivity'])\n    assort      = float(s['degree_assortativity'])\n    num_tri     = float(s['num_triangles'])\n    degs        = s['degrees']\n\n    # small epsilon to avoid division by zero\n    eps = 1e-12\n\n    # ------------------------------------------------------------------\n    # 1. Base scale:   size, connectivity and density.\n    #    Larger graphs with sparse connectivity have larger average\n    #    shortest‑path length, so we start with a term that grows with\n    #    n and shrinks with both m and density.\n    # ------------------------------------------------------------------\n    base = (n + eps) / ((m + eps) * (density + eps))\n\n    # ------------------------------------------------------------------\n    # 2. Clustering / transitivity term – high clustering typically\n    #    provides many local shortcuts which reduce the global\n    #    distance.  We therefore attenuate the base by an exponential\n    #    factor that depends on the sum of avg_clustering and transitivity.\n    # ------------------------------------------------------------------\n    cluster_factor = (avg_clust + trans + eps)\n    base *= (1.0 / (1.0 + cluster_factor))\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density influence – triangles create cycles and\n    #    further reduce distances.  We compute a normalized triangle\n    #    ratio and shrink the base proportionally.\n    # ------------------------------------------------------------------\n    possible_tri = max(1.0, n * (n - 1.0) * (n - 2.0) / 6.0)\n    tri_ratio = num_tri / (possible_tri + eps)\n    base *= (1.0 / (1.0 + tri_ratio))\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity effect – both positive and negative assortativity\n    #    tend to increase average distances relative to a neutral network.\n    #    We penalise the base by the magnitude of assortativity.\n    # ------------------------------------------------------------------\n    base *= (1.0 / (1.0 + abs(assort) + eps))\n\n    # ------------------------------------------------------------------\n    # 5. Degree heterogeneity correction – networks with large\n    #    variability (hubs) typically have shorter paths.  We divide by\n    #    a factor that depends on the coefficient of variation of\n    #    the degree sequence.\n    # ------------------------------------------------------------------\n    cv = std_deg / (avg_deg + eps)      # coefficient of variation\n    base /= (1.0 + cv + eps)\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic mean of degrees – captures the proportion of low‑degree\n    #    nodes, which usually inflate distances.  The harmonic mean is\n    #    computed directly from the degree list to avoid a separate import.\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        # High harmonic mean (many low‑degree nodes) increases the estimate\n        base *= (1.0 + harmonic_mean / (max_deg + eps))\n    else:\n        # If degree list is empty, keep base unchanged\n        pass\n\n    # ------------------------------------------------------------------\n    # 7. Small constant bias – stabilises the estimator for very small\n    #    graphs where the above terms can become extreme.\n    # ------------------------------------------------------------------\n    bias = 0.1\n\n    return base + bias\n```", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed graph\n    statistics.  The estimator is a handcrafted non‑linear combination of\n    size, density, degree distribution, clustering, triangles, assortativity\n    and degree heterogeneity.  It uses only plain Python operations and\n    does not perform any graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph descriptors with keys:\n            n                     : int          number of vertices\n            m                     : int          number of edges\n            density               : float        edge density\n            avg_degree            : float        average vertex degree\n            max_degree            : int\n            min_degree            : int\n            std_degree            : float        degree standard deviation\n            avg_clustering        : float        average local clustering\n            transitivity          : float        global transitivity\n            degree_assortativity  : float        assortativity coefficient\n            num_triangles         : int          number of triangles\n            degrees               : list[int]    sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.  The value\n        grows approximately monotonically with the true average shortest‑path\n        length while remaining bounded and robust to extreme feature values.\n    \"\"\"\n    # Pull features out of the dict\n    n           = float(s['n'])\n    m           = float(s['m'])\n    density     = float(s['density'])\n    avg_deg     = float(s['avg_degree'])\n    max_deg     = float(s['max_degree'])\n    min_deg     = float(s['min_degree'])\n    std_deg     = float(s['std_degree'])\n    avg_clust   = float(s['avg_clustering'])\n    trans       = float(s['transitivity'])\n    assort      = float(s['degree_assortativity'])\n    num_tri     = float(s['num_triangles'])\n    degs        = s['degrees']\n\n    # small epsilon to avoid division by zero\n    eps = 1e-12\n\n    # ------------------------------------------------------------------\n    # 1. Base scale:   size, connectivity and density.\n    #    Larger graphs with sparse connectivity have larger average\n    #    shortest‑path length, so we start with a term that grows with\n    #    n and shrinks with both m and density.\n    # ------------------------------------------------------------------\n    base = (n + eps) / ((m + eps) * (density + eps))\n\n    # ------------------------------------------------------------------\n    # 2. Clustering / transitivity term – high clustering typically\n    #    provides many local shortcuts which reduce the global\n    #    distance.  We therefore attenuate the base by an exponential\n    #    factor that depends on the sum of avg_clustering and transitivity.\n    # ------------------------------------------------------------------\n    cluster_factor = (avg_clust + trans + eps)\n    base *= (1.0 / (1.0 + cluster_factor))\n\n    # ------------------------------------------------------------------\n    # 3. Triangle density influence – triangles create cycles and\n    #    further reduce distances.  We compute a normalized triangle\n    #    ratio and shrink the base proportionally.\n    # ------------------------------------------------------------------\n    possible_tri = max(1.0, n * (n - 1.0) * (n - 2.0) / 6.0)\n    tri_ratio = num_tri / (possible_tri + eps)\n    base *= (1.0 / (1.0 + tri_ratio))\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity effect – both positive and negative assortativity\n    #    tend to increase average distances relative to a neutral network.\n    #    We penalise the base by the magnitude of assortativity.\n    # ------------------------------------------------------------------\n    base *= (1.0 / (1.0 + abs(assort) + eps))\n\n    # ------------------------------------------------------------------\n    # 5. Degree heterogeneity correction – networks with large\n    #    variability (hubs) typically have shorter paths.  We divide by\n    #    a factor that depends on the coefficient of variation of\n    #    the degree sequence.\n    # ------------------------------------------------------------------\n    cv = std_deg / (avg_deg + eps)      # coefficient of variation\n    base /= (1.0 + cv + eps)\n\n    # ------------------------------------------------------------------\n    # 6. Harmonic mean of degrees – captures the proportion of low‑degree\n    #    nodes, which usually inflate distances.  The harmonic mean is\n    #    computed directly from the degree list to avoid a separate import.\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n        # High harmonic mean (many low‑degree nodes) increases the estimate\n        base *= (1.0 + harmonic_mean / (max_deg + eps))\n    else:\n        # If degree list is empty, keep base unchanged\n        pass\n\n    # ------------------------------------------------------------------\n    # 7. Small constant bias – stabilises the estimator for very small\n    #    graphs where the above terms can become extreme.\n    # ------------------------------------------------------------------\n    bias = 0.1\n\n    return base + bias", "spearman": 0.6492507312682817, "pearson": 0.48897687482233676, "rmse": 3.0444949101186545, "mae": 1.7417949242057913}}
{"timestamp": "2026-02-17T10:31:08.756526+00:00", "event_type": "candidate_rejected", "payload": {"generation": 19, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.067010", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:31:08.757399+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 19, "island_id": 3, "population_idx": 1, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.067010", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:32:15.277643+00:00", "event_type": "candidate_rejected", "payload": {"generation": 19, "island_id": 3, "population_idx": 1, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.096798", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:32:15.280562+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 19, "island_id": 3, "population_idx": 1, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:32:48.019491+00:00", "event_type": "candidate_rejected", "payload": {"generation": 19, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:32:48.020404+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 19, "island_id": 3, "population_idx": 2, "attempt_index": 0, "reason": "no_valid_train_predictions", "failure_feedback": "static_invalid: forbidden token detected: import ", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:33:26.762743+00:00", "event_type": "candidate_rejected", "payload": {"generation": 19, "island_id": 3, "population_idx": 2, "attempt_index": 1, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.097707", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:33:26.763413+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 19, "island_id": 3, "population_idx": 2, "status": "failed", "reason": "below_novelty_threshold", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:34:53.365324+00:00", "event_type": "candidate_rejected", "payload": {"generation": 19, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.108550", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:34:53.366217+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 19, "island_id": 3, "population_idx": 3, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.108550", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:35:45.392143+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i3_p3_423842923", "generation": 19, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.9464105642256901, "fitness_mode": "correlation", "simplicity_score": 0.13685456449863564, "novelty_bonus": 0.1826167278073174, "total_score": 0.5059607763630505, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of\n    pre‑computed graph statistics.  The estimator is a handcrafted\n    non‑linear combination of size, density, degree, clustering,\n    triangles, assortativity, and degree heterogeneity.  It uses only\n    basic Python operations (no external imports, no graph traversal).\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph descriptors with keys:\n        - 'n'                   : int      number of vertices\n        - 'm'                   : int      number of edges\n        - 'density'             : float    edge density\n        - 'avg_degree'          : float    average degree\n        - 'max_degree'          : int\n        - 'min_degree'          : int\n        - 'std_degree'          : float\n        - 'avg_clustering'      : float\n        - 'transitivity'        : float\n        - 'degree_assortativity': float\n        - 'num_triangles'       : int\n        - 'degrees'             : list[int] sorted degree sequence\n\n    Returns\n    -------\n    float\n        A proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # Extract features as floats\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12  # to avoid divisions by zero\n\n    # --------------------\n    # 1. Core scaling\n    #    In sparse or very large graphs the distance is large.\n    #    We use the square‑root of the size and divide by density\n    #    and average degree, which are classic ingredients for path length\n    #    in random graph theory.\n    # --------------------\n    base = (n ** 0.5) / ((density + eps) * (avg_deg + eps))\n\n    # --------------------\n    # 2. Modulators that lengthen or shorten paths\n    # --------------------\n    # 2a. Clustering / transitivity usually provide shortcuts:\n    #     we let them *increase* the base value (making it larger) and then\n    #     scale it by the same factor, effectively reducing the final output.\n    base *= (1 + avg_clust + eps)\n    base *= (1 + trans + eps)\n\n    # 2b. Assortativity magnitude tends to increase distances,\n    #     irrespective of its sign, so we multiply by a factor\n    #     that grows with |assort|.\n    base *= (1 + abs(assort) + eps)\n\n    # 2c. Triangles create many local cycles; the more abundant\n    #     they are relative to the edge count, the shorter the global\n    #     distance tends to be.  We therefore shrink the base in\n    #     proportion to the triangle-to‑edge ratio.\n    if m > 0:\n        tri_ratio = num_tri / (m + eps)\n        base *= (1 - 0.3 * tri_ratio)  # 0.3 is an empirically chosen weight\n\n    # --------------------\n    # 3. Heterogeneity corrections\n    # --------------------\n    # High degree variance (hubs) typically reduce distances.\n    base /= (1 + std_deg / (avg_deg + eps))\n\n    # The presence of very high or very low degrees also influences\n    # connectivity.  We penalise a high maximum degree (fewer hubs)\n    # and reward a higher minimum degree (fewer isolated nodes).\n    base /= (1 + max_deg / (avg_deg + eps))\n    base *= (1 + min_deg / (avg_deg + eps))\n\n    # --------------------\n    # 4. Harmonic‑mean bonus\n    # --------------------\n    # A large harmonic mean indicates many low‑degree nodes, which tends\n    # to increase distances.  We add a small scaled bonus to capture this.\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        h_mean = n / (inv_sum + eps)\n        base += 0.05 * h_mean\n\n    # Ensure a non‑negative return\n    return max(base, 0.0)\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\nRecent failures:\nbelow_novelty_threshold: novelty_bonus=0.096798\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.097707\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: novelty_bonus=0.108550\nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed graph\n    statistics.  The estimator is a handcrafted, non‑linear combination of\n    size, density, degree, clustering, triangles, assortativity and degree\n    heterogeneity.  It uses only basic Python operations (no imports, no\n    graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph descriptors.  Expected keys:\n        - 'n'                     : int            number of vertices\n        - 'm'                     : int            number of edges\n        - 'density'               : float          edge density\n        - 'avg_degree'            : float          average degree\n        - 'max_degree'            : int\n        - 'min_degree'            : int\n        - 'std_degree'            : float          standard deviation of degrees\n        - 'avg_clustering'        : float          average local clustering\n        - 'transitivity'          : float          global transitivity\n        - 'degree_assortativity'  : float          assortativity coefficient\n        - 'num_triangles'         : int            number of triangles\n        - 'degrees'               : list[int]      sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # to avoid divisions by zero\n\n    # Basic numeric values\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1.  Harmonic mean of the degree sequence (high values → many low\n    #     degree vertices → longer distances)\n    # ------------------------------------------------------------------\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            inv_sum += 1.0 / (float(d) + eps)\n        h_mean = n / (inv_sum + eps)\n    else:\n        h_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2.  Median degree – a crude central tendency that complements the\n    #     mean and can catch skew in the distribution.\n    # ------------------------------------------------------------------\n    deg_len = len(degrees)\n    if deg_len > 0:\n        if deg_len % 2 == 1:\n            median_deg = float(degrees[deg_len // 2])\n        else:\n            median_deg = (float(degrees[deg_len // 2 - 1]) +\n                          float(degrees[deg_len // 2])) * 0.5\n    else:\n        median_deg = 0.0\n\n    # ------------------------------------------------------------------\n    # 3.  Triangle density ratio – a high ratio typically shortens paths.\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_ratio = num_tri / (possible_tri + eps)\n    else:\n        tri_ratio = 0.0\n\n    # ------------------------------------------------------------------\n    # 4.  Core scaling: size vs. connectivity\n    # ------------------------------------------------------------------\n    base = (n ** 0.5) / ((density + eps) * (avg_deg + eps))\n\n    # ------------------------------------------------------------------\n    # 5.  Modulators that shrink or stretch the estimate\n    # ------------------------------------------------------------------\n    # Clustering & transitivity usually provide shortcuts\n    base *= 1.0 / (1.0 + avg_clust + eps)\n    base *= 1.0 / (1.0 + trans + eps)\n\n    # Triangles: many triangles → shorter global distances\n    base *= (1.0 - 0.4 * tri_ratio)\n\n    # Assortativity magnitude tends to increase distances (irrespective of sign)\n    base *= (1.0 + abs(assort) * 0.3)\n\n    # Heterogeneity – high variance with hubs typically shortens paths\n    base *= 1.0 / (1.0 + std_deg / (avg_deg + eps))\n\n    # Max degree – few very large hubs → paths may get longer\n    base *= 1.0 / (1.0 + max_deg / (n * avg_deg + eps))\n\n    # Minimum degree – isolated or low‑degree vertices lengthen paths\n    if min_deg > 0:\n        base *= 1.0 + (avg_deg / min_deg - 1.0) * 0.5\n\n    # Harmonic‑mean bonus – many low‑degree nodes tend to increase distances\n    base *= (1.0 + h_mean / n * 0.05)\n\n    # Median‑degree adjustment – a quick check against the mean\n    if avg_deg > 0:\n        base *= 1.0 + (median_deg / avg_deg - 1.0) * 0.1\n\n    # Ensure non‑negative return\n    return max(base, 0.0)\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using only the supplied\n    statistics.  The estimator is a hand‑crafted nonlinear combination of\n    size, connectivity, degree heterogeneity, clustering, assortativity\n    and triangle density.  No external libraries are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph descriptors.  Expected keys are\n        (all optional – defaults are provided where appropriate):\n          n                      int      number of nodes\n          m                      int      number of edges\n          density                float    2m/(n*(n-1))\n          avg_degree             float    average degree\n          max_degree             int\n          min_degree             int\n          std_degree             float    std deviation of degrees\n          avg_clustering         float    average local clustering\n          transitivity           float    global transitivity\n          degree_assortativity   float    assortativity coefficient\n          num_triangles          int      triangle count\n          degrees                list[int] sorted degree sequence\n\n    Returns\n    -------\n    float\n        Proxy value for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # guard against division by zero\n\n    # --- basic scalars ----------------------------------------------------\n    n   = float(s.get('n', 1))\n    m   = float(s.get('m', 0))\n    dens = float(s.get('density', 0.0))\n    avg_deg  = float(s.get('avg_degree', 0.0))\n    max_deg  = float(s.get('max_degree', 0))\n    min_deg  = float(s.get('min_degree', 0))\n    std_deg  = float(s.get('std_degree', 0.0))\n    avg_clust = float(s.get('avg_clustering', 0.0))\n    trans    = float(s.get('transitivity', 0.0))\n    assort   = float(s.get('degree_assortativity', 0.0))\n    num_tri  = float(s.get('num_triangles', 0))\n    degs     = s.get('degrees', [])\n\n    # --- derived structural terms -----------------------------------------\n    # triangle density ratio\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_ratio = num_tri / (possible_tri + eps)\n    else:\n        tri_ratio = 0.0\n\n    # harmonic mean of degrees (captures the burden of many low‑degree nodes)\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            inv_sum += 1.0 / (float(d) + eps)\n        h_mean = n / (inv_sum + eps)\n    else:\n        h_mean = 0.0\n\n    # median degree for a quick skew check\n    dlen = len(degs)\n    if dlen > 0:\n        if dlen % 2 == 1:\n            median_deg = float(degs[dlen // 2])\n        else:\n            median_deg = (float(degs[dlen // 2 - 1]) +\n                          float(degs[dlen // 2])) * 0.5\n    else:\n        median_deg = 0.0\n\n    # --- base scaling -----------------------------------------------------\n    # Larger graphs with sparser connectivity produce longer paths.\n    # The power 0.6 on n provides sub‑linear growth, while the denominator\n    # combines average degree with a density term to shorten the base.\n    base = (n ** 0.6) / ((avg_deg + eps) * (1.0 + dens))\n\n    # --- modulate by structural features ---------------------------------\n    # Clustering and transitivity give shortcuts, so we *increase* the\n    # base in proportion to them.\n    base *= (1.0 + avg_clust + eps)\n    base *= (1.0 + trans + eps)\n\n    # More triangles -> shorter paths: shrink the base according to tri_ratio.\n    base *= (1.0 - 0.35 * tri_ratio)\n\n    # Assortativity magnitude typically lengthens paths; treat positive\n    # and negative values symmetrically.\n    base *= (1.0 + abs(assort) * 0.25)\n\n    # Degree dispersion: a larger std deviation (many hubs) shortens paths.\n    base /= (1.0 + std_deg / (avg_deg + eps))\n\n    # Max and min degree influence connectivity.  High max degree implies\n    # fewer hubs relative to the graph size, so we mildly penalise it.\n    base /= (1.0 + max_deg / (n * avg_deg + eps))\n\n    # A small minimum degree hints at dangling nodes; we give a gentle\n    # penalty for very low min_deg.\n    if min_deg > 0:\n        base *= (1.0 + (avg_deg / min_deg - 1.0) * 0.15)\n\n    # Harmonic mean bonus: more low‑degree nodes inflate distances.\n    base += h_mean * 0.02\n\n    # Median‑degree check: if the median is below the mean, paths are\n    # likely longer than predicted by the mean alone.\n    if avg_deg > 0:\n        base *= (1.0 + (median_deg / avg_deg - 1.0) * 0.1)\n\n    # Final sanity check – the estimate must be non‑negative.\n    return base if base > 0.0 else 0.0", "extracted_code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length using only the supplied\n    statistics.  The estimator is a hand‑crafted nonlinear combination of\n    size, connectivity, degree heterogeneity, clustering, assortativity\n    and triangle density.  No external libraries are used.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph descriptors.  Expected keys are\n        (all optional – defaults are provided where appropriate):\n          n                      int      number of nodes\n          m                      int      number of edges\n          density                float    2m/(n*(n-1))\n          avg_degree             float    average degree\n          max_degree             int\n          min_degree             int\n          std_degree             float    std deviation of degrees\n          avg_clustering         float    average local clustering\n          transitivity           float    global transitivity\n          degree_assortativity   float    assortativity coefficient\n          num_triangles          int      triangle count\n          degrees                list[int] sorted degree sequence\n\n    Returns\n    -------\n    float\n        Proxy value for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # guard against division by zero\n\n    # --- basic scalars ----------------------------------------------------\n    n   = float(s.get('n', 1))\n    m   = float(s.get('m', 0))\n    dens = float(s.get('density', 0.0))\n    avg_deg  = float(s.get('avg_degree', 0.0))\n    max_deg  = float(s.get('max_degree', 0))\n    min_deg  = float(s.get('min_degree', 0))\n    std_deg  = float(s.get('std_degree', 0.0))\n    avg_clust = float(s.get('avg_clustering', 0.0))\n    trans    = float(s.get('transitivity', 0.0))\n    assort   = float(s.get('degree_assortativity', 0.0))\n    num_tri  = float(s.get('num_triangles', 0))\n    degs     = s.get('degrees', [])\n\n    # --- derived structural terms -----------------------------------------\n    # triangle density ratio\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_ratio = num_tri / (possible_tri + eps)\n    else:\n        tri_ratio = 0.0\n\n    # harmonic mean of degrees (captures the burden of many low‑degree nodes)\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            inv_sum += 1.0 / (float(d) + eps)\n        h_mean = n / (inv_sum + eps)\n    else:\n        h_mean = 0.0\n\n    # median degree for a quick skew check\n    dlen = len(degs)\n    if dlen > 0:\n        if dlen % 2 == 1:\n            median_deg = float(degs[dlen // 2])\n        else:\n            median_deg = (float(degs[dlen // 2 - 1]) +\n                          float(degs[dlen // 2])) * 0.5\n    else:\n        median_deg = 0.0\n\n    # --- base scaling -----------------------------------------------------\n    # Larger graphs with sparser connectivity produce longer paths.\n    # The power 0.6 on n provides sub‑linear growth, while the denominator\n    # combines average degree with a density term to shorten the base.\n    base = (n ** 0.6) / ((avg_deg + eps) * (1.0 + dens))\n\n    # --- modulate by structural features ---------------------------------\n    # Clustering and transitivity give shortcuts, so we *increase* the\n    # base in proportion to them.\n    base *= (1.0 + avg_clust + eps)\n    base *= (1.0 + trans + eps)\n\n    # More triangles -> shorter paths: shrink the base according to tri_ratio.\n    base *= (1.0 - 0.35 * tri_ratio)\n\n    # Assortativity magnitude typically lengthens paths; treat positive\n    # and negative values symmetrically.\n    base *= (1.0 + abs(assort) * 0.25)\n\n    # Degree dispersion: a larger std deviation (many hubs) shortens paths.\n    base /= (1.0 + std_deg / (avg_deg + eps))\n\n    # Max and min degree influence connectivity.  High max degree implies\n    # fewer hubs relative to the graph size, so we mildly penalise it.\n    base /= (1.0 + max_deg / (n * avg_deg + eps))\n\n    # A small minimum degree hints at dangling nodes; we give a gentle\n    # penalty for very low min_deg.\n    if min_deg > 0:\n        base *= (1.0 + (avg_deg / min_deg - 1.0) * 0.15)\n\n    # Harmonic mean bonus: more low‑degree nodes inflate distances.\n    base += h_mean * 0.02\n\n    # Median‑degree check: if the median is below the mean, paths are\n    # likely longer than predicted by the mean alone.\n    if avg_deg > 0:\n        base *= (1.0 + (median_deg / avg_deg - 1.0) * 0.1)\n\n    # Final sanity check – the estimate must be non‑negative.\n    return base if base > 0.0 else 0.0", "spearman": 0.8476096902422563, "pearson": 0.8267617765516391, "rmse": 0.7205554259402309, "mae": 0.5437386606752138}}
{"timestamp": "2026-02-17T10:35:45.393073+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 19, "island_id": 3, "population_idx": 3, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:36:24.376190+00:00", "event_type": "candidate_rejected", "payload": {"generation": 19, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.071670", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:36:24.377469+00:00", "event_type": "candidate_repair_attempted", "payload": {"generation": 19, "island_id": 3, "population_idx": 4, "attempt_index": 0, "reason": "below_novelty_threshold", "failure_feedback": "novelty_bonus=0.071670", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:37:31.290874+00:00", "event_type": "candidate_evaluated", "payload": {"candidate_id": "g19_i3_p4_225109638", "generation": 19, "island_id": 3, "model_name": "gpt-oss:20b", "train_signal": 0.6179591836734694, "fitness_mode": "correlation", "simplicity_score": 0.13904771641762587, "novelty_bonus": 0.17246502738285918, "total_score": 0.3512860949244686, "prompt": "You are discovering graph invariant formulas for target `average_shortest_path_length`.\nIsland mode: island_3_free\n\nStrategy: Invent a completely novel mathematical formula. Think about how it relates to density, degree distribution, clustering, and other structural features.\nBest formulas:\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The formula starts with the graph size divided by a connectivity term and\n    then applies multiplicative adjustments for clustering, assortativity,\n    triangle density, and normalises by degree heterogeneity and maximum\n    degree.  No external libraries are required.\n    \"\"\"\n    n = s.get('n', 1)\n    if n <= 1:\n        return 0.0\n\n    m          = s.get('m', 0)\n    density    = s.get('density', 0.0)\n    avg_deg    = s.get('avg_degree', 0.0)\n    max_deg    = s.get('max_degree', 1)\n    min_deg    = s.get('min_degree', 0)\n    std_deg    = s.get('std_degree', 0.0)\n    avg_clust  = s.get('avg_clustering', 0.0)\n    assort     = s.get('degree_assortativity', 0.0)\n    tri        = s.get('num_triangles', 0)\n\n    # Connectivity denominator – higher density and average degree shorten paths\n    denom_conn = max(avg_deg, 1e-6) * max(density, 1e-6)\n    base = n / denom_conn\n\n    # Clustering creates shortcuts\n    base *= (1.0 + avg_clust)\n\n    # Assortativity affects path length – treat magnitude symmetrically\n    base *= (1.0 + abs(assort))\n\n    # Triangle density – more triangles usually reduce average distance\n    if m > 0:\n        base *= (1.0 + tri / m)\n\n    # Degree heterogeneity – highly heterogeneous networks (hubs) typically\n    # have shorter paths, so we divide by the spread\n    base /= (1.0 + std_deg / max(avg_deg, 1e-6))\n    base /= (1.0 + min_deg / max(avg_deg, 1e-6))\n\n    # Penalise very high maximum degree (few hubs) to avoid over‑shortening\n    base /= (max_deg + 1.0)\n\n    return base\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of\n    pre‑computed graph statistics.  The estimator is a handcrafted\n    non‑linear combination of size, density, degree, clustering,\n    triangles, assortativity, and degree heterogeneity.  It uses only\n    basic Python operations (no external imports, no graph traversal).\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of pre‑computed graph descriptors with keys:\n        - 'n'                   : int      number of vertices\n        - 'm'                   : int      number of edges\n        - 'density'             : float    edge density\n        - 'avg_degree'          : float    average degree\n        - 'max_degree'          : int\n        - 'min_degree'          : int\n        - 'std_degree'          : float\n        - 'avg_clustering'      : float\n        - 'transitivity'        : float\n        - 'degree_assortativity': float\n        - 'num_triangles'       : int\n        - 'degrees'             : list[int] sorted degree sequence\n\n    Returns\n    -------\n    float\n        A proxy that grows monotonically with the true average shortest‑path length.\n    \"\"\"\n    # Extract features as floats\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = float(s['avg_degree'])\n    max_deg    = float(s['max_degree'])\n    min_deg    = float(s['min_degree'])\n    std_deg    = float(s['std_degree'])\n    avg_clust  = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    num_tri    = float(s['num_triangles'])\n    degrees    = s['degrees']\n\n    eps = 1e-12  # to avoid divisions by zero\n\n    # --------------------\n    # 1. Core scaling\n    #    In sparse or very large graphs the distance is large.\n    #    We use the square‑root of the size and divide by density\n    #    and average degree, which are classic ingredients for path length\n    #    in random graph theory.\n    # --------------------\n    base = (n ** 0.5) / ((density + eps) * (avg_deg + eps))\n\n    # --------------------\n    # 2. Modulators that lengthen or shorten paths\n    # --------------------\n    # 2a. Clustering / transitivity usually provide shortcuts:\n    #     we let them *increase* the base value (making it larger) and then\n    #     scale it by the same factor, effectively reducing the final output.\n    base *= (1 + avg_clust + eps)\n    base *= (1 + trans + eps)\n\n    # 2b. Assortativity magnitude tends to increase distances,\n    #     irrespective of its sign, so we multiply by a factor\n    #     that grows with |assort|.\n    base *= (1 + abs(assort) + eps)\n\n    # 2c. Triangles create many local cycles; the more abundant\n    #     they are relative to the edge count, the shorter the global\n    #     distance tends to be.  We therefore shrink the base in\n    #     proportion to the triangle-to‑edge ratio.\n    if m > 0:\n        tri_ratio = num_tri / (m + eps)\n        base *= (1 - 0.3 * tri_ratio)  # 0.3 is an empirically chosen weight\n\n    # --------------------\n    # 3. Heterogeneity corrections\n    # --------------------\n    # High degree variance (hubs) typically reduce distances.\n    base /= (1 + std_deg / (avg_deg + eps))\n\n    # The presence of very high or very low degrees also influences\n    # connectivity.  We penalise a high maximum degree (fewer hubs)\n    # and reward a higher minimum degree (fewer isolated nodes).\n    base /= (1 + max_deg / (avg_deg + eps))\n    base *= (1 + min_deg / (avg_deg + eps))\n\n    # --------------------\n    # 4. Harmonic‑mean bonus\n    # --------------------\n    # A large harmonic mean indicates many low‑degree nodes, which tends\n    # to increase distances.  We add a small scaled bonus to capture this.\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        h_mean = n / (inv_sum + eps)\n        base += 0.05 * h_mean\n\n    # Ensure a non‑negative return\n    return max(base, 0.0)\n\ndef new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a collection of\n    pre‑computed graph statistics.  The formula is a non‑linear\n    combination of size, density, clustering, triangles, assortativity,\n    and degree heterogeneity.  It uses only basic Python operations\n    (no imports, no graph traversal, no external libraries).\n\n    Parameters\n    ----------\n    s : dict\n        Graph features.  Expected keys:\n            n                     (int)      number of vertices\n            m                     (int)      number of edges\n            density               (float)    2m/(n(n-1))\n            avg_degree            (float)    average vertex degree\n            max_degree            (int)\n            min_degree            (int)\n            std_degree            (float)\n            avg_clustering        (float)    average local clustering\n            transitivity          (float)    global transitivity\n            degree_assortativity  (float)    assortativity coefficient\n            num_triangles         (int)      count of triangles\n            degrees               (list[int]) sorted degree sequence\n\n    Returns\n    -------\n    float\n        A scalar proxy for the average shortest‑path length.\n    \"\"\"\n    eps = 1e-12  # prevents divisions by zero\n\n    n = float(s['n'])\n    m = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degs = s['degrees']\n\n    # ------------------------------------------------------------------\n    # 1. Harmonic mean of degrees (captures how many low‑degree nodes exist)\n    # ------------------------------------------------------------------\n    if degs:\n        inv_sum = 0.0\n        for d in degs:\n            if d > 0:\n                inv_sum += 1.0 / (d + eps)\n        harmonic_mean = n / (inv_sum + eps)\n    else:\n        harmonic_mean = 0.0\n\n    # ------------------------------------------------------------------\n    # 2. Triangle density factor (non‑linear, bell‑shaped influence)\n    # ------------------------------------------------------------------\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_term = tri_frac * (1.0 - tri_frac)  # maximised near tri_frac≈0.5\n\n    # ------------------------------------------------------------------\n    # 3. Core multiplicative base: relates size & connectivity\n    # ------------------------------------------------------------------\n    base = (1.0 + n * density) / (1.0 + avg_deg + harmonic_mean)\n\n    # ------------------------------------------------------------------\n    # 4. Modulate with structural features\n    # ------------------------------------------------------------------\n    base *= (1.0 + tri_term) ** 0.6\n    base *= (1.0 - avg_clust) ** 0.4\n    base *= (1.0 - trans) ** 0.3\n    base *= (1.0 - assort) ** 0.2\n\n    # ------------------------------------------------------------------\n    # 5. Dispersion correction: captures heterogeneity in degrees\n    # ------------------------------------------------------------------\n    if degs:\n        mean_sq = sum(d * d for d in degs) / n\n    else:\n        mean_sq = 0.0\n    disp_term = (std_deg / (max_deg + eps)) * (mean_sq / (max_deg + eps))\n    base += disp_term\n\n    return base\nRecent failures:\nno_valid_train_predictions: static_invalid: forbidden token detected: import \nbelow_novelty_threshold: novelty_bonus=0.097707\nbelow_novelty_threshold: novelty_bonus=0.108550\nReturn only python code defining `def new_invariant(s):` where s is a dict of pre-computed graph features.\nAvailable keys in s: n (node count), m (edge count), density, avg_degree, max_degree, min_degree, std_degree, avg_clustering, transitivity, degree_assortativity, num_triangles, degrees (sorted degree list).\n\nFORBIDDEN: Do NOT return a single feature directly (e.g., return s['diameter']).\nDo NOT implement BFS/DFS/shortest-path algorithms.\nThe input is a pre-computed feature dict, not a graph object.\n\nExample formulas:\ndef new_invariant(s): return s['n'] / (s['m'] + 1)\ndef new_invariant(s): return np.log(s['n']) * np.mean(s['degrees']) / max(s['max_degree'], 1)\ndef new_invariant(s): return np.sqrt(s['n']) / (1 + s['avg_clustering'])\n\n\nRepair this candidate. It failed evaluation.\nFailure: novelty_bonus=0.071670\nPrevious candidate code:\n```python\ndef new_invariant(s):\n    \"\"\"\n    Heuristic estimate of the average shortest‑path length based solely on\n    a handful of pre‑computed graph descriptors.\n\n    Parameters\n    ----------\n    s : dict\n        Dictionary of graph statistics.  Expected keys:\n            - 'n'                    : int        number of vertices\n            - 'm'                    : int        number of edges\n            - 'density'              : float      2m/(n(n‑1))\n            - 'avg_degree'           : float      average degree\n            - 'max_degree'           : int\n            - 'min_degree'           : int\n            - 'std_degree'           : float      standard deviation of degrees\n            - 'avg_clustering'       : float\n            - 'transitivity'         : float\n            - 'degree_assortativity' : float\n            - 'num_triangles'        : int\n            - 'degrees'              : list[int]  sorted degree sequence\n\n    Returns\n    -------\n    float\n        A single scalar that increases (approximately) monotonically with\n        the true average shortest‑path length.  No graph traversal or\n        external libraries are required.\n    \"\"\"\n    eps = 1e-12  # safeguard against division by zero\n\n    # Basic node / edge counts\n    n = float(s['n'])\n    m = float(s['m'])\n\n    # Connectivity proxies\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    # ---------- 1. Harmonic mean of degrees (captures presence of low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            # add eps to avoid division by zero for isolated nodes\n            inv_sum += 1.0 / (d + eps)\n        h_mean = n / (inv_sum + eps)\n    else:\n        h_mean = 0.0\n\n    # ---------- 2. Triangle density factor (non‑linear influence)\n    if n >= 3:\n        possible_tri = n * (n - 1.0) * (n - 2.0) / 6.0\n        tri_frac = num_tri / (possible_tri + eps)\n    else:\n        tri_frac = 0.0\n    tri_factor = 1.0 + tri_frac * (1.0 - tri_frac)  # peaked when tri_frac ~ 0.5\n\n    # ---------- 3. Core scaling: size × density, divided by connectivity\n    connectivity = (avg_deg + 1.0) * (density + eps)\n    core_scale = (n + 1.0) / (connectivity + eps)\n\n    # ---------- 4. Heterogeneity adjustment (hubs shorten paths)\n    hetero = 1.0 + std_deg / (avg_deg + eps)\n\n    # ---------- 5. Assemble base estimate\n    base = core_scale * hetero\n\n    # ---------- 6. Modulate with higher‑order structural cues\n    base *= tri_factor\n    base *= (1.0 + avg_clust)**0.5\n    base *= (1.0 + trans)**0.4\n    base *= (1.0 + abs(assort))**0.3\n\n    # ---------- 7. Penalise/ reward extreme degrees\n    base /= (max_deg + 1.0)\n    base *= (min_deg + 1.0)\n\n    # ---------- 8. Add a harmonic‑mean bonus to reflect low‑degree inflation\n    base += 0.05 * h_mean\n\n    # ---------- 9. Ensure non‑negative output\n    return base if base > 0.0 else 0.0\n```\nReturn only corrected python code defining `def new_invariant(s):`.", "llm_response": "```python\ndef new_invariant(s):\n    eps = 1e-12  # safeguard for divisions\n\n    # feature extraction\n    n      = float(s['n'])\n    m      = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    # 1. Harmonic mean of degrees (captures low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            inv_sum += 1.0 / (d + eps)\n        h_mean = n / (inv_sum + eps)\n    else:\n        h_mean = 0.0\n\n    # 2. Triangle to edge ratio\n    tri_ratio = num_tri / (m + eps)\n\n    # 3. Core size‑density scaling\n    core = (n ** 0.5) * (density + eps) / (avg_deg + eps)\n\n    # 4. Heterogeneity multiplier (hubs shorten paths)\n    hetero = pow(1 + std_deg / (avg_deg + eps), 0.4)\n\n    # 5. Triangle influence (non‑linear)\n    tri_fac = pow(1 + tri_ratio, 0.5)\n\n    # 6. Degree extremes weighting\n    extremes = pow(min_deg + 1, 0.2) / pow(max_deg + 1, 0.2)\n\n    # 7. Modulators from higher‑order features\n    mod = pow(1 + avg_clust, 0.3)\n    mod *= pow(1 + trans, 0.25)\n    mod *= pow(1 + abs(assort), 0.35)\n\n    # 8. Size‑clustering coupling\n    size_clust = pow(n, avg_clust * 0.05)\n\n    # 9. Harmonic‑mean bonus\n    h_bonus = 0.03 * h_mean\n\n    # Assemble the estimate\n    base = core\n    base *= hetero\n    base *= tri_fac\n    base *= extremes\n    base *= mod\n    base *= size_clust\n    base += h_bonus\n\n    return base if base > 0.0 else 0.0\n```", "extracted_code": "def new_invariant(s):\n    eps = 1e-12  # safeguard for divisions\n\n    # feature extraction\n    n      = float(s['n'])\n    m      = float(s['m'])\n    density = float(s['density'])\n    avg_deg = float(s['avg_degree'])\n    max_deg = float(s['max_degree'])\n    min_deg = float(s['min_degree'])\n    std_deg = float(s['std_degree'])\n    avg_clust = float(s['avg_clustering'])\n    trans = float(s['transitivity'])\n    assort = float(s['degree_assortativity'])\n    num_tri = float(s['num_triangles'])\n    degrees = s['degrees']\n\n    # 1. Harmonic mean of degrees (captures low‑degree nodes)\n    if degrees:\n        inv_sum = 0.0\n        for d in degrees:\n            inv_sum += 1.0 / (d + eps)\n        h_mean = n / (inv_sum + eps)\n    else:\n        h_mean = 0.0\n\n    # 2. Triangle to edge ratio\n    tri_ratio = num_tri / (m + eps)\n\n    # 3. Core size‑density scaling\n    core = (n ** 0.5) * (density + eps) / (avg_deg + eps)\n\n    # 4. Heterogeneity multiplier (hubs shorten paths)\n    hetero = pow(1 + std_deg / (avg_deg + eps), 0.4)\n\n    # 5. Triangle influence (non‑linear)\n    tri_fac = pow(1 + tri_ratio, 0.5)\n\n    # 6. Degree extremes weighting\n    extremes = pow(min_deg + 1, 0.2) / pow(max_deg + 1, 0.2)\n\n    # 7. Modulators from higher‑order features\n    mod = pow(1 + avg_clust, 0.3)\n    mod *= pow(1 + trans, 0.25)\n    mod *= pow(1 + abs(assort), 0.35)\n\n    # 8. Size‑clustering coupling\n    size_clust = pow(n, avg_clust * 0.05)\n\n    # 9. Harmonic‑mean bonus\n    h_bonus = 0.03 * h_mean\n\n    # Assemble the estimate\n    base = core\n    base *= hetero\n    base *= tri_fac\n    base *= extremes\n    base *= mod\n    base *= size_clust\n    base += h_bonus\n\n    return base if base > 0.0 else 0.0", "spearman": -0.5434740868521714, "pearson": -0.3703109371274037, "rmse": 2.569152616758584, "mae": 2.3644526781266393}}
{"timestamp": "2026-02-17T10:37:31.292039+00:00", "event_type": "candidate_repair_result", "payload": {"generation": 19, "island_id": 3, "population_idx": 4, "status": "success", "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:37:31.293358+00:00", "event_type": "generation_migration", "payload": {"generation": 19, "model_name": "gpt-oss:20b"}}
{"timestamp": "2026-02-17T10:37:31.297394+00:00", "event_type": "generation_summary", "payload": {"experiment_id": "seed_55", "generation": 20, "model_name": "gpt-oss:20b", "best_val_score": 0.5706469319419225, "no_improve_count": 4}}
