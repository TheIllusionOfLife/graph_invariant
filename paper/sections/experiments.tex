\section{Experiments}\label{sec:experiments}

\subsection{Knowledge Graph Domains}

We evaluate on five curated KGs spanning scientific disciplines.  Each KG uses
the shared seven-relation type vocabulary (Section~\ref{sec:schema}) and is
constructed from established textbook knowledge:

\begin{itemize}[nosep]
  \item \textbf{Linear algebra}: 17 entities (matrix, vector, eigenvalue,
    determinant, rank, etc.) with algebraic dependency and derivation edges.
  \item \textbf{Periodic table}: 20+ chemical elements and properties with
    trends, groups, and reactivity relations.
  \item \textbf{Astronomy}: celestial objects (star, planet, black hole, nebula)
    and astrophysical processes.
  \item \textbf{Physics}: fundamental concepts (force, energy, momentum,
    gravity) and their theoretical inter-relations.
  \item \textbf{Materials science}: material properties, compounds, and
    structure--property relationships.
\end{itemize}

The first two domains serve as \emph{calibration} targets (known structure for
gate validation); the latter three are \emph{discovery} targets where we assess
the framework's ability to generate novel, plausible proposals.

\subsection{Dataset Splitting}

For each KG, we apply an 80/10/10/10 split: 80\% of edges for training, 10\%
each for validation, test, and a hidden backtesting set.  The hidden set is
withheld from all metric computations and proposal generation, providing an
unbiased evaluation of generativity on unseen edges.

\subsection{Baselines}

We compare Harmony-guided proposals against three baselines that use the same
DistMult link-prediction protocol (identical edge splits, model architecture,
and training):

\begin{enumerate}[nosep]
  \item \textbf{Random}: propose edges between random entity pairs with random
    relation types.
  \item \textbf{Frequency}: propose the most frequent relation type between the
    most-connected entity pairs.
  \item \textbf{DistMult-alone}: use DistMult's own top-ranked predictions
    without Harmony scoring or LLM involvement.
\end{enumerate}

\subsection{Evaluation Protocol}

\paragraph{Quantitative metrics.}
We report Hits@10, Hits@3, Hits@1, and Mean Reciprocal Rank (MRR):
\begin{equation}\label{eq:mrr}
  \text{MRR} = \frac{1}{|Q|} \sum_{i=1}^{|Q|} \frac{1}{\text{rank}_i},
\end{equation}
where $Q$ is the set of masked test edges and $\text{rank}_i$ is the rank of
the true target entity among all candidates.  Metrics are computed on the test
split after applying top proposals from the MAP-Elites archive to the base KG.

\paragraph{Calibration gate.}
Before running discovery experiments, we verify on the two calibration domains
(linear algebra, periodic table) that: (i)~Harmony mean $\geq 10\%$ above the
frequency baseline, and (ii)~the bootstrap 95\% CI lower bound exceeds the
frequency mean, across six pre-registered weight configurations ($\alpha \in
\{0.3, 0.5, 0.7\}$, $\beta \in \{0.1, 0.3\}$, $\gamma = \delta = 0.25$).

\paragraph{Expert rubric.}
For the best-performing discovery domain, we apply a five-criterion rubric
scoring each of the top-5 proposals on a 1--5 scale: \emph{plausibility},
\emph{novelty}, \emph{falsifiability}, \emph{specificity}, and
\emph{coherence with existing knowledge}.  The gate requires mean plausibility
$\geq 3.0$.

\paragraph{Archive diversity.}
We report MAP-Elites coverage (fraction of occupied cells in the $5 \times 5$
grid), best and mean fitness, and qualitative inspection of proposals across
behavioural descriptor bins.
