# NeurIPS 2025 Peer Review

## Paper: "Harmony-Driven Theory Discovery in Knowledge Graphs via LLM-Guided Island Search"

---

## Summary

本論文は、科学的知識グラフ（KG）における理論発見を自動化するフレームワーク「Harmony」を提案している。Harmonyスコアは、圧縮性（compressibility）、整合性（coherence）、対称性（symmetry）、生成性（generativity）の4つの信号を組み合わせた複合品質指標であり、LLMが提案するKGの変異（エッジ・エンティティの追加）を評価する。MAP-Elitesアーカイブとアイランドモデル探索を用いて、品質と多様性を両立する提案を生成する。線形代数・周期表KGでのキャリブレーション実験と、天文学・物理学・材料科学KGでの発見実験を通じて評価を行っている。

---

## Overall Assessment

**Recommendation: Borderline Reject (4/10)**

アイデア自体は興味深く、KG補完を単なるリンク予測から「理論レベルの命題生成」に引き上げるという方向性には価値がある。しかし、実験規模の小ささ、評価の不十分さ、および手法の新規性に関する懸念が、NeurIPSのフルペーパーとしての採択基準を満たしていないと判断する。

---

## Strengths

### S1: 問題設定の明確さと動機付け
KG補完を個別トリプル予測から理論レベルの命題生成へと昇華させるという問題設定は明確で、科学的発見の自動化という大きなビジョンに根ざしている。Proposalスキーマに反証可能性条件を含める設計は、科学哲学的に適切である。

### S2: Harmonyメトリクスの解釈可能性
4つのコンポーネント（圧縮性・整合性・対称性・生成性）はそれぞれ直感的に理解しやすく、[0,1]に正規化されている。各成分が異なる「良い知識グラフ」の側面を捉えており、ablation study（Table 2）で各成分の寄与が確認されている。

### S3: 探索アーキテクチャの設計
MAP-Elitesとアイランドモデルの組み合わせは品質-多様性トレードオフを扱う上で合理的であり、停滞回復メカニズム（constrained prompting）やマイグレーション戦略など、エンジニアリング上の工夫が見られる。

### S4: 再現性への配慮
ハイパーパラメータの完全な列挙（Appendix E）、データセット統計（Appendix A）、バリデーションルール（Appendix C）が提供されており、再現性への意識が高い。CPU-onlyで30分以内という計算コストの低さも好印象。

---

## Weaknesses

### W1: 実験規模が極めて小さい（Critical）
最大でも22エンティティ・58エッジという規模のKGは、手法の有効性を主張するには不十分である。

- **17〜22エンティティ**は「知識グラフ」と呼ぶにはあまりに小さく、toy exampleの域を出ない。実世界の科学的KG（例：Wikidata, UMLS, Materials Projectなど）は数千〜数百万エンティティを持つ。
- この規模では、DistMultの学習自体が統計的に不安定であり（著者自身もSection 6で「≥10 training edgesが必要」と認めている）、generativityコンポーネントの信頼性が疑わしい。
- 20%マスキングで得られるテストエッジ数は5〜12程度であり、Hits@10の差異が統計的に有意かどうか判断できない。

### W2: 単一シードでの評価（Critical）
Table 1の主要結果が単一シード（s=42）のみで報告されており、error barが一切ない。これはNeurIPSの実験基準として不十分である。

- KGの規模が小さいため、データ分割のランダム性が結果に大きく影響する可能性が高い。
- 著者はSection 6でこの制限を認めているが、"future work"として扱うのは不適切。少なくとも5シード程度の評価は必須。
- キャリブレーションゲートではbootstrap CIが報告されているが、主要な発見実験では報告されていない不整合がある。

### W3: ベースラインの不十分さ（Major）
比較対象がRandom、Frequency、DistMult-aloneの3つのみで、いずれも弱いベースラインである。

- **KG補完の標準的手法**（TransE, RotatE, ComplEx, TuckER）との比較がない。特にRotatEは関連研究で言及されているにもかかわらず、ベースラインに含まれていない。
- **LLMベースのKG推論手法**（例：KG-BERT, StAR, ChatKBQAなど）との比較がない。LLMをKGに適用する研究は急速に増えており、これらとの差異を実験的に示す必要がある。
- FunSearchやPySRは問題設定が異なるため直接比較は不要だが、LLM+KGの既存手法との比較は不可欠。

### W4: Expert Rubricの詳細が不足（Major）
- 評価者の人数、専門分野、評価者間の一致度（inter-rater agreement）が一切報告されていない。
- "expert" の定義が不明確。単一の評価者による可能性もあり、その場合バイアスの懸念が大きい。
- Top-5提案のみの評価は、手法全体の品質を代表しているかどうか疑問。MAP-Elitesアーカイブ内の中位・下位の提案についても評価が必要。
- 平均plausibility 3.4/5.0は「まあまあ」程度であり、強い主張の根拠としては弱い。

### W5: Harmonyメトリクスの理論的正当化が不足（Major）
- なぜこの4つのコンポーネントが「良い科学的理論」を捉えるのかについて、理論的な議論がほぼない。
- 均等重み（α=β=γ=δ=0.25）がデフォルトとされているが、ドメインによって最適な重みが異なる可能性が高い。Figure 4で重み感度分析があるが、線形代数KGのみでの評価。
- 圧縮性と生成性のトレードオフ（Section 6で言及）は本質的な設計上の問題であり、もっと深い分析が必要。
- Coherenceの三角形ベースの定義は、スパースなKGでは三角形がほとんど存在しないため機能しない（著者自身がablationで認めている）。

### W6: LLM依存性の分析不足（Moderate）
- 使用したLLMの具体的なモデル名が明記されていない（"locally served Ollama" としか書かれていない）。
- 異なるLLMでの性能差が検証されていない。提案の品質がLLMの能力に強く依存するにもかかわらず。
- LLMのプロンプトテンプレートが本文にもAppendixにも含まれていない。再現性の観点から問題。

### W7: Table 1とFigure 1の数値の不一致（Minor）
Table 1とFigure 1のHits@10の数値が一致していない（例：Astronomy - Harmony: Table 1では0.67、Figure 1では0.56程度に見える。DistMult-alone: Table 1では0.58、Figure 1では0.44）。これは深刻な不整合であり、どちらかが誤りである可能性がある。

---

## Questions for Authors

1. **Table 1とFigure 1の数値不一致について**: どちらが正しいデータか？不一致の原因は何か？
2. **LLMの具体的なモデル**: Ollamaで提供されるどのモデルを使用したか？モデルサイズは？
3. **スケーラビリティ**: エンティティ数が100以上のKGでの予備実験はあるか？Harmonyスコアの計算コストはグラフサイズに対してどうスケールするか？
4. **Expert評価**: 評価者は何名か？評価者間一致度は？評価者はこの研究に関与していないか？
5. **提案の反証可能性**: 生成された反証条件は実際にテスト可能か？具体的にどの程度の条件が実験的に検証可能か？
6. **7種類の関係タイプの選択根拠**: なぜこの7種類か？科学的KGの分析に基づいて選定されたのか？

---

## Minor Issues

- Line 77-81: LLM-guided reasoning over KGsの関連研究セクションで、具体的な手法名（例：KAPING, Think-on-Graph, StructGPT）が引用されていない。"Surveys have explored" とのみ記述されている。
- Eq. 4: JS距離の定義で $\text{JS}(\cdot, \cdot) = \sqrt{\text{JSD}(\cdot \| \cdot)}$ とあるが、base 2の平方根をとることの意味についてもう少し説明が欲しい。
- Algorithm 1: `descriptor(p̂)` の具体的な計算方法が本文中で明示されていない。
- Section 4.2: 80/10/10分割の説明があるが、バリデーションセットがどのように使用されているか不明。早期停止？ハイパーパラメータ選択？
- Table 4: Periodic tableのEntitiesが22だが、本文（Line 160）では"20+"と記述されており微妙に不一致。

---

## Verdict

本論文は、知識グラフにおける理論発見という興味深い問題に取り組んでおり、Harmonyメトリクスやアイランドモデル探索といった構成要素は個別には合理的である。しかし、**toy規模のKGでの単一シード評価**、**弱いベースラインとの比較のみ**、**Table 1とFigure 1の数値不一致**、**expert評価の詳細不足**という複数の重大な問題があり、主張を十分に裏付ける実験的証拠が提供されていない。

NeurIPSへの再投稿に向けては、以下を強く推奨する：
1. 数百〜数千エンティティ規模のKGでの評価（例：Wikidata subsets）
2. 複数シードでのerror bar付き報告
3. TransE, RotatE, ComplEx等の標準的KGCベースラインとの比較
4. 複数の独立した専門家による評価とinter-rater agreementの報告
5. Table 1/Figure 1の不整合の解消
6. LLMのモデル名・プロンプトテンプレートの完全な開示

---

## Scores

| Criterion | Score |
|---|---|
| Soundness | 2/4 |
| Contribution | 2/4 |
| Clarity | 3/4 |
| Significance | 2/4 |
| **Overall** | **4/10** |
| **Confidence** | **4/5** |
