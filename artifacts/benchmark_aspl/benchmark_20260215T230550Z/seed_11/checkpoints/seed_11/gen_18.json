{
  "experiment_id": "seed_11",
  "generation": 18,
  "rng_seed": 11,
  "rng_state": {
    "bit_generator": "PCG64",
    "state": {
      "state": 264245021544690650460529517242940236425,
      "inc": 7937318808080196428804369945471644491
    },
    "has_uint32": 0,
    "uinteger": 2138208034
  },
  "best_val_score": 0.5462604653336615,
  "no_improve_count": 1,
  "island_stagnation": {
    "0": 0,
    "1": 0,
    "2": 0,
    "3": 0
  },
  "island_prompt_mode": {
    "0": "free",
    "1": "free",
    "2": "free",
    "3": "free"
  },
  "island_constrained_generations": {
    "0": 0,
    "1": 0,
    "2": 0,
    "3": 0
  },
  "island_recent_failures": {
    "0": [
      "below_novelty_threshold: novelty_bonus=0.123776",
      "no_valid_train_predictions: static_invalid: forbidden token detected: import ",
      "below_novelty_threshold: novelty_bonus=0.125387"
    ],
    "1": [
      "below_novelty_threshold: novelty_bonus=0.138052",
      "below_novelty_threshold: novelty_bonus=0.131782",
      "below_novelty_threshold: novelty_bonus=0.122394"
    ],
    "2": [
      "below_novelty_threshold: novelty_bonus=0.110022",
      "no_valid_train_predictions: static_invalid: forbidden token detected: import ",
      "below_novelty_threshold: novelty_bonus=0.024060"
    ],
    "3": [
      "below_novelty_threshold: novelty_bonus=0.112033",
      "no_valid_train_predictions: static_invalid: forbidden token detected: import ",
      "below_novelty_threshold: novelty_bonus=0.049373"
    ]
  },
  "islands": {
    "0": [
      {
        "id": "g16_i0_p2_826671415",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a size/degree baseline and multiplicative\n    adjustments that capture density, clustering, transitivity, assortativity,\n    degree extremes, degree heterogeneity, triangle density, and degree skew.\n    All operations use only built‑in arithmetic; no external imports are required.\n    \"\"\"\n    # Basic graph quantities with guards against division by zero\n    n          = float(s['n'])\n    avg_deg    = max(float(s['avg_degree']), 1.0)   # avoid division by zero\n    min_deg    = max(float(s['min_degree']), 1.0)\n    max_deg    = max(float(s['max_degree']), 1.0)\n    std_deg    = max(float(s['std_degree']), 0.0)\n    density    = float(s['density'])\n    density    = min(max(density, 0.0), 1.0)         # clamp to [0,1]\n    clust      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    triangles  = float(s['num_triangles'])\n\n    # Base estimate: grows with graph size (linear) and shrinks with average degree\n    base = n / (avg_deg + 1.0)\n\n    # Adjustment factors\n    density_factor = 1.0 / (density + 0.05)                     # denser → shorter\n    cluster_factor = 1.0 + clust                                # more clustering → longer\n    trans_factor   = 1.0 + trans                                # more transitivity → longer\n    assort_factor  = 1.0 + abs(assort)                          # disassortative → longer\n    min_factor     = 1.0 + 1.0 / (min_deg + 1.0)                # low min degree → longer\n    max_factor     = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))    # high max degree → shorter\n    heter_factor   = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))    # high heterogeneity → shorter\n\n    # Triangle density effect: many triangles can reduce global path length\n    possible_triangles = (n * (n - 1) * (n - 2)) / 6.0\n    tri_factor = 1.0 / (1.0 + triangles / (possible_triangles + 1.0))\n\n    # Degree skew factor: larger spread between max and min degree tends to increase path length\n    skew_factor = 1.0 + (max_deg - min_deg) / (max_deg + 1.0)\n\n    # Combine all factors\n    estimate = (base * density_factor * cluster_factor *\n                trans_factor * assort_factor * min_factor *\n                max_factor * heter_factor * tri_factor * skew_factor)\n\n    return estimate",
        "island_id": 0,
        "generation": 16,
        "train_score": 0.8480672268907563,
        "val_score": 0.5462604653336615,
        "simplicity_score": 0.17794959142981298,
        "novelty_bonus": 0.22346318752643035
      },
      {
        "id": "g17_i0_p0_830550268",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a size/degree baseline and multiplicative\n    adjustments that capture density, clustering, transitivity, assortativity,\n    degree extremes, degree heterogeneity, triangle density, and degree skew.\n    All operations use only built‑in arithmetic; no external imports are required.\n    \"\"\"\n    # Basic graph quantities with guards against division by zero\n    n          = float(s['n'])\n    avg_deg    = max(float(s['avg_degree']), 1.0)   # avoid division by zero\n    min_deg    = max(float(s['min_degree']), 1.0)\n    max_deg    = max(float(s['max_degree']), 1.0)\n    std_deg    = max(float(s['std_degree']), 0.0)\n    density    = float(s['density'])\n    density    = min(max(density, 0.0), 1.0)         # clamp to [0,1]\n    clust      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    triangles  = float(s['num_triangles'])\n\n    # Base estimate: grows with graph size and shrinks with average degree\n    base = n / (avg_deg + 1.0)\n\n    # Adjustment factors\n    density_factor = 1.0 / (density + 0.05)                     # denser → shorter\n    cluster_factor = 1.0 + clust                                # more clustering → longer\n    trans_factor   = 1.0 + trans                                # more transitivity → longer\n    assort_factor  = 1.0 + abs(assort)                          # disassortative → longer\n    min_factor     = 1.0 + 1.0 / (min_deg + 1.0)                # low min degree → longer\n    max_factor     = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))    # high max degree → shorter\n    heter_factor   = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))    # high heterogeneity → shorter\n\n    # Triangle density effect: many triangles can reduce global path length\n    possible_triangles = (n * (n - 1) * (n - 2)) / 6.0\n    tri_factor = 1.0 / (1.0 + triangles / (possible_triangles + 1.0))\n\n    # Degree skew factor: larger spread between max and min degree tends to increase path length\n    skew_factor = 1.0 + (max_deg - min_deg) / (max_deg + 1.0)\n\n    # Combine all factors\n    estimate = (base * density_factor * cluster_factor *\n                trans_factor * assort_factor * min_factor *\n                max_factor * heter_factor * tri_factor * skew_factor)\n\n    return estimate",
        "island_id": 0,
        "generation": 17,
        "train_score": 0.8480672268907563,
        "val_score": 0.5462604653336615,
        "simplicity_score": 0.17794959142981298,
        "novelty_bonus": 0.22346318752643035
      },
      {
        "id": "g13_i0_p1_544610280",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a size/degree baseline and multiplicative\n    adjustments that capture density, clustering, transitivity, assortativity,\n    degree extremes, degree heterogeneity, and triangle density.\n    All operations use only built‑in arithmetic; no external imports are required.\n    \"\"\"\n    # Basic graph quantities with guards against division by zero\n    n          = float(s['n'])\n    avg_deg    = max(float(s['avg_degree']), 1.0)   # avoid division by zero\n    min_deg    = max(float(s['min_degree']), 1.0)\n    max_deg    = max(float(s['max_degree']), 1.0)\n    std_deg    = max(float(s['std_degree']), 0.0)\n    density    = float(s['density'])\n    density    = min(max(density, 0.0), 1.0)         # clamp to [0,1]\n    clust      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    triangles  = float(s['num_triangles'])\n\n    # Base estimate: grows with size (sqrt) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # Adjustment factors\n    density_factor = 1.0 / (density + 0.05)                     # denser → shorter\n    cluster_factor = 1.0 + clust                                # more clustering → longer\n    trans_factor   = 1.0 + trans                                # more transitivity → longer\n    assort_factor  = 1.0 + abs(assort)                          # disassortative → longer\n    min_factor     = 1.0 + 1.0 / (min_deg + 1.0)                # low min degree → longer\n    max_factor     = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))    # high max degree → shorter\n    heter_factor   = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))    # high heterogeneity → shorter\n\n    # Triangle density effect: many triangles can reduce global path length\n    possible_triangles = (n * (n - 1) * (n - 2)) / 6.0\n    tri_factor = 1.0 / (1.0 + triangles / (possible_triangles + 1.0))\n\n    # Combine all factors\n    estimate = (base * density_factor * cluster_factor *\n                trans_factor * assort_factor * min_factor *\n                max_factor * heter_factor * tri_factor)\n\n    return estimate",
        "island_id": 0,
        "generation": 13,
        "train_score": 0.9345018007202881,
        "val_score": 0.5460083136677563,
        "simplicity_score": 0.17843277811902547,
        "novelty_bonus": 0.1576539413485336
      },
      {
        "id": "g14_i0_p3_610979787",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a size/degree baseline and multiplicative\n    adjustments that capture density, clustering, transitivity, assortativity,\n    degree extremes, degree heterogeneity, and triangle density.\n    All operations use only built‑in arithmetic; no external imports are required.\n    \"\"\"\n    # Basic graph quantities with guards against division by zero\n    n          = float(s['n'])\n    avg_deg    = max(float(s['avg_degree']), 1.0)   # avoid division by zero\n    min_deg    = max(float(s['min_degree']), 1.0)\n    max_deg    = max(float(s['max_degree']), 1.0)\n    std_deg    = max(float(s['std_degree']), 0.0)\n    density    = float(s['density'])\n    density    = min(max(density, 0.0), 1.0)         # clamp to [0,1]\n    clust      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    triangles  = float(s['num_triangles'])\n\n    # Base estimate: grows with graph size (sqrt) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # Adjustment factors\n    density_factor = 1.0 / (density + 0.05)                     # denser → shorter\n    cluster_factor = 1.0 + clust                                # more clustering → longer\n    trans_factor   = 1.0 + trans                                # more transitivity → longer\n    assort_factor  = 1.0 + abs(assort)                          # disassortative → longer\n    min_factor     = 1.0 + 1.0 / (min_deg + 1.0)                # low min degree → longer\n    max_factor     = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))    # high max degree → shorter\n    heter_factor   = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))    # high heterogeneity → shorter\n\n    # Triangle density effect: many triangles can reduce global path length\n    possible_triangles = (n * (n - 1) * (n - 2)) / 6.0\n    tri_factor = 1.0 / (1.0 + triangles / (possible_triangles + 1.0))\n\n    # Combine all factors\n    estimate = (base * density_factor * cluster_factor *\n                trans_factor * assort_factor * min_factor *\n                max_factor * heter_factor * tri_factor)\n\n    return estimate",
        "island_id": 0,
        "generation": 14,
        "train_score": 0.9345018007202881,
        "val_score": 0.5460083136677563,
        "simplicity_score": 0.17843277811902547,
        "novelty_bonus": 0.1576539413485336
      },
      {
        "id": "g15_i0_p1_91892005",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate is a product of a size/degree baseline and multiplicative\n    adjustments that capture density, clustering, transitivity, assortativity,\n    degree extremes, degree heterogeneity, and triangle density.\n    All operations use only built‑in arithmetic; no external imports are required.\n    \"\"\"\n    # Basic graph quantities with guards against division by zero\n    n          = float(s['n'])\n    avg_deg    = max(float(s['avg_degree']), 1.0)   # avoid division by zero\n    min_deg    = max(float(s['min_degree']), 1.0)\n    max_deg    = max(float(s['max_degree']), 1.0)\n    std_deg    = max(float(s['std_degree']), 0.0)\n    density    = float(s['density'])\n    density    = min(max(density, 0.0), 1.0)         # clamp to [0,1]\n    clust      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    triangles  = float(s['num_triangles'])\n    degrees    = s['degrees']                       # sorted degree list\n\n    # Base estimate: grows with graph size (sqrt) and shrinks with average degree\n    base = (n ** 0.5) / (avg_deg + 1.0)\n\n    # Adjustment factors\n    density_factor = 1.0 / (density + 0.05)                     # denser → shorter\n    cluster_factor = 1.0 + clust                                # more clustering → longer\n    trans_factor   = 1.0 + trans                                # more transitivity → longer\n    assort_factor  = 1.0 + abs(assort)                          # disassortative → longer\n    min_factor     = 1.0 + 1.0 / (min_deg + 1.0)                # low min degree → longer\n    max_factor     = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))    # high max degree → shorter\n    heter_factor   = 1.0 / (1.0 + std_deg / (avg_deg + 1.0))    # high heterogeneity → shorter\n\n    # Triangle density effect: many triangles can reduce global path length\n    possible_triangles = (n * (n - 1) * (n - 2)) / 6.0\n    tri_factor = 1.0 / (1.0 + triangles / (possible_triangles + 1.0))\n\n    # Combine all factors\n    estimate = (base * density_factor * cluster_factor *\n                trans_factor * assort_factor * min_factor *\n                max_factor * heter_factor * tri_factor)\n\n    return estimate",
        "island_id": 0,
        "generation": 15,
        "train_score": 0.9345018007202881,
        "val_score": 0.5459687576606246,
        "simplicity_score": 0.17823499808336682,
        "novelty_bonus": 0.1576539413485336
      }
    ],
    "1": [
      {
        "id": "g6_i0_p4_691039916",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate starts from a baseline that grows with graph size and shrinks\n    with average degree, then applies multiplicative adjustments for density,\n    clustering, transitivity, assortativity, degree extremes, degree\n    heterogeneity (via the second moment), and triangle density.\n    All operations use only built‑in arithmetic; no external imports are required.\n    \"\"\"\n    # Basic quantities with guards against division by zero\n    n          = float(s['n'])\n    avg_deg    = max(float(s['avg_degree']), 1.0)\n    min_deg    = max(float(s['min_degree']), 1.0)\n    max_deg    = max(float(s['max_degree']), 1.0)\n    density    = min(max(float(s['density']), 0.0), 1.0)\n    clust      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    triangles  = float(s['num_triangles'])\n    degrees    = s['degrees']          # sorted degree list\n\n    # Baseline: larger n and smaller avg_deg → longer paths\n    base = n / (avg_deg + 1.0)\n\n    # Density effect: denser → shorter paths\n    density_factor = 1.0 / (density + 0.1)\n\n    # Clustering and transitivity effects: higher values tend to lengthen paths\n    cluster_factor = 1.0 + clust\n    trans_factor   = 1.0 + trans\n\n    # Assortativity effect: disassortative mixing tends to lengthen paths\n    assort_factor = 1.0 + abs(assort)\n\n    # Minimum degree effect: very low min degree tends to increase path length\n    min_factor = 1.0 + 1.0 / (min_deg + 1.0)\n\n    # Maximum degree effect: very high max degree tends to decrease path length\n    max_factor = 1.0 / (1.0 + max_deg / (avg_deg + 1.0))\n\n    # Degree heterogeneity via second moment\n    second_moment = sum(d * d for d in degrees) / n\n    heter_factor  = 1.0 / (1.0 + second_moment / (avg_deg * avg_deg + 1.0))\n\n    # Triangle density effect: many triangles can reduce global path length\n    tri_factor = 1.0 / (1.0 + triangles / (n * n + 1.0))\n\n    # Combine all multiplicative adjustments\n    estimate = (base * density_factor * cluster_factor * trans_factor *\n                assort_factor * min_factor * max_factor *\n                heter_factor * tri_factor)\n\n    return estimate",
        "island_id": 0,
        "generation": 6,
        "train_score": 0.8657382953181272,
        "val_score": 0.5437153078726051,
        "simplicity_score": 0.17861108457318928,
        "novelty_bonus": 0.22683364127667627
      },
      {
        "id": "g17_i1_p0_662988463",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate blends a size‑connectivity baseline with multiplicative\n    adjustments that capture density, clustering, transitivity, assortativity,\n    degree extremes, degree heterogeneity (second moment), triangle density,\n    and a damping factor that includes clustering, transitivity and degree\n    dispersion.  All arithmetic uses only built‑in operations; no external\n    imports are required.\n    \"\"\"\n    # Basic numeric values (converted to float for safety)\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = max(float(s['avg_degree']), 1.0)\n    max_deg    = max(float(s['max_degree']), 1.0)\n    min_deg    = max(float(s['min_degree']), 1.0)\n    std_deg    = max(float(s['std_degree']), 0.0)\n    clust      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    tri        = float(s['num_triangles'])\n    degrees    = s['degrees']          # sorted degree list\n\n    # 1. Size‑connectivity baseline (average of two complementary forms)\n    base1 = n / (avg_deg + 1.0)                     # simple size / degree baseline\n    base2 = (n ** 0.5) * ((m + 1.0) / (n + 1.0)) ** 0.5 / (avg_deg + 1.0) ** 0.5\n    base  = 0.5 * (base1 + base2)\n\n    # 2. Density adjustment: denser → shorter paths\n    density_adj = 1.0 / (density + 0.075)   # compromise between 0.1 and 0.05\n\n    # 3. Clustering & transitivity adjustment: higher values tend to lengthen paths\n    ct_adj = (1.0 + clust) * (1.0 + trans)\n\n    # 4. Assortativity adjustment: disassortative mixing tends to lengthen paths\n    assort_adj = 1.0 + abs(assort)\n\n    # 5. Degree extremes adjustment\n    min_factor = 1.0 + 1.0 / (min_deg + 1.0)          # very low min degree → longer paths\n    max_factor = (max_deg + 1.0) / (min_deg + 1.0)    # high max/min ratio → shorter paths\n\n    # 6. Degree heterogeneity adjustment (second moment)\n    second_moment = sum(d * d for d in degrees) / n\n    x = second_moment / (avg_deg * avg_deg + 1.0)\n    heter_adj = (1.0 / (1.0 + x) + (1.0 + x)) * 0.5\n\n    # 7. Triangle adjustment: many triangles can reduce global path length\n    tri_adj = 1.0 / (1.0 + tri / (n * n + 1.0))\n\n    # 8. Damping factor that includes clustering, transitivity and degree dispersion\n    denom = 1.0 + clust + trans + std_deg\n\n    # 9. Combine all multiplicative adjustments and apply damping\n    estimate = (base * density_adj * ct_adj * assort_adj *\n                min_factor * max_factor * heter_adj * tri_adj) / denom\n\n    return estimate",
        "island_id": 1,
        "generation": 17,
        "train_score": 0.7563505402160864,
        "val_score": 0.501112780487552,
        "simplicity_score": 0.17659959800556668,
        "novelty_bonus": 0.16325813500309638
      },
      {
        "id": "g17_i1_p4_789740514",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate blends a size‑connectivity baseline with multiplicative\n    adjustments that capture density, clustering, transitivity, assortativity,\n    degree extremes, degree heterogeneity (second moment), triangle density,\n    and a damping factor that includes clustering, transitivity and degree\n    dispersion.  All arithmetic uses only built‑in operations; no external\n    imports are required.\n    \"\"\"\n    # Basic numeric values (converted to float for safety)\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = max(float(s['avg_degree']), 1.0)\n    max_deg    = max(float(s['max_degree']), 1.0)\n    min_deg    = max(float(s['min_degree']), 1.0)\n    std_deg    = max(float(s['std_degree']), 0.0)\n    clust      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    tri        = float(s['num_triangles'])\n    degrees    = s['degrees']          # sorted degree list\n\n    # ---------- 1. Size‑connectivity baseline ----------\n    base1 = n / (avg_deg + 1.0)                     # simple size / degree baseline\n    base2 = (n ** 0.5) * ((m + 1.0) / (n + 1.0)) / (avg_deg + 1.0)  # sqrt‑size + edge density\n    base  = 0.5 * (base1 + base2)\n\n    # ---------- 2. Density adjustment ----------\n    dens_adj = 1.0 / (density + 0.0875)   # compromise between 0.1 and 0.075\n\n    # ---------- 3. Clustering & transitivity adjustment ----------\n    ct_adj = (1.0 + clust) * (1.0 + trans)\n\n    # ---------- 4. Assortativity adjustment ----------\n    assort_adj = 1.0 + abs(assort)\n\n    # ---------- 5. Degree extremes adjustment ----------\n    min_factor = 1.0 + 1.0 / (min_deg + 1.0)          # very low min degree → longer paths\n    max_factor = (max_deg + 1.0) / (min_deg + 1.0)    # high max/min ratio → shorter paths\n\n    # ---------- 6. Degree heterogeneity adjustment (second moment) ----------\n    second_moment = sum(d * d for d in degrees) / n\n    heter_factor1 = 1.0 / (1.0 + second_moment / (avg_deg * avg_deg + 1.0))\n    heter_factor2 = 1.0 + second_moment / (avg_deg * avg_deg + 1.0)\n    heter_adj = 0.5 * (heter_factor1 + heter_factor2)\n\n    # ---------- 7. Triangle adjustment ----------\n    tri_adj = 1.0 / (1.0 + tri / (n * n + 1.0))\n\n    # ---------- 8. Damping factor ----------\n    denom = 1.0 + clust + trans + std_deg\n\n    # ---------- 9. Combine all multiplicative adjustments ----------\n    estimate = (base * dens_adj * ct_adj * assort_adj *\n                min_factor * max_factor * heter_adj * tri_adj) / denom\n\n    return estimate",
        "island_id": 1,
        "generation": 17,
        "train_score": 0.7638415366146457,
        "val_score": 0.5009510456619328,
        "simplicity_score": 0.17641645202547407,
        "novelty_bonus": 0.1600810472360359
      },
      {
        "id": "g16_i1_p1_968955684",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate blends a size‑and‑connectivity baseline with multiplicative\n    adjustments that capture density, clustering, transitivity, assortativity,\n    degree extremes, degree heterogeneity (second moment), triangle density,\n    and a damping factor that includes clustering, transitivity and degree\n    dispersion.  All arithmetic uses only built‑in operations; no external\n    imports are required.\n    \"\"\"\n    # Basic numeric values (converted to float for safety)\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = max(float(s['avg_degree']), 1.0)\n    max_deg    = max(float(s['max_degree']), 1.0)\n    min_deg    = max(float(s['min_degree']), 1.0)\n    std_deg    = max(float(s['std_degree']), 0.0)\n    clust      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    tri        = float(s['num_triangles'])\n    degrees    = s['degrees']          # sorted degree list\n\n    # ------------------------------------------------------------------\n    # 1. Size‑and‑connectivity baseline (average of two complementary forms)\n    # ------------------------------------------------------------------\n    base1 = n / (avg_deg + 1.0)                     # simple size / degree baseline\n    base2 = (n ** 0.5) * ((m + 1.0) / (n + 1.0)) / (avg_deg + 1.0)  # sqrt‑size + edge density\n    base  = 0.5 * (base1 + base2)\n\n    # ------------------------------------------------------------------\n    # 2. Density adjustment: denser → shorter paths\n    # ------------------------------------------------------------------\n    dens_adj = 1.0 / (density + 0.075)   # compromise between 0.1 and 0.05\n\n    # ------------------------------------------------------------------\n    # 3. Clustering & transitivity adjustment: higher values tend to lengthen paths\n    # ------------------------------------------------------------------\n    ct_adj = (1.0 + clust) * (1.0 + trans)\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity adjustment: disassortative mixing tends to lengthen paths\n    # ------------------------------------------------------------------\n    assort_adj = 1.0 + abs(assort)\n\n    # ------------------------------------------------------------------\n    # 5. Degree extremes adjustment\n    # ------------------------------------------------------------------\n    min_factor = 1.0 + 1.0 / (min_deg + 1.0)          # very low min degree → longer paths\n    max_factor = (max_deg + 1.0) / (min_deg + 1.0)    # high max/min ratio → shorter paths\n\n    # ------------------------------------------------------------------\n    # 6. Degree heterogeneity adjustment (second moment)\n    # ------------------------------------------------------------------\n    second_moment = sum(d * d for d in degrees) / n\n    heter_adj1 = 1.0 / (1.0 + second_moment / (avg_deg * avg_deg + 1.0))\n    heter_adj2 = 1.0 + second_moment / (avg_deg * avg_deg + 1.0)\n    heter_adj  = 0.5 * (heter_adj1 + heter_adj2)\n\n    # ------------------------------------------------------------------\n    # 7. Triangle adjustment: many triangles can reduce global path length\n    # ------------------------------------------------------------------\n    tri_adj = 1.0 / (1.0 + tri / (n * n + 1.0))\n\n    # ------------------------------------------------------------------\n    # 8. Damping factor that includes clustering, transitivity and degree dispersion\n    # ------------------------------------------------------------------\n    denom = 1.0 + clust + trans + std_deg\n\n    # ------------------------------------------------------------------\n    # 9. Combine all multiplicative adjustments and apply damping\n    # ------------------------------------------------------------------\n    estimate = (base * dens_adj * ct_adj * assort_adj *\n                min_factor * max_factor * heter_adj * tri_adj) / denom\n\n    return estimate",
        "island_id": 1,
        "generation": 16,
        "train_score": 0.7624009603841537,
        "val_score": 0.49904239399070155,
        "simplicity_score": 0.17641645202547407,
        "novelty_bonus": 0.15505890849943604
      },
      {
        "id": "g17_i1_p3_75844719",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest path length from pre‑computed graph features.\n    The estimate blends a size‑connectivity baseline with multiplicative\n    adjustments that capture density, clustering, transitivity, assortativity,\n    degree extremes, degree heterogeneity (second moment), triangle density,\n    and a damping factor that includes clustering, transitivity and degree\n    dispersion.  All arithmetic uses only built‑in operations; no external\n    imports are required.\n    \"\"\"\n    # Basic numeric values (converted to float for safety)\n    n          = float(s['n'])\n    m          = float(s['m'])\n    density    = float(s['density'])\n    avg_deg    = max(float(s['avg_degree']), 1.0)\n    max_deg    = max(float(s['max_degree']), 1.0)\n    min_deg    = max(float(s['min_degree']), 1.0)\n    std_deg    = max(float(s['std_degree']), 0.0)\n    clust      = float(s['avg_clustering'])\n    trans      = float(s['transitivity'])\n    assort     = float(s['degree_assortativity'])\n    tri        = float(s['num_triangles'])\n    degrees    = s['degrees']          # sorted degree list\n\n    # ------------------------------------------------------------------\n    # 1. Size‑connectivity baseline (average of two complementary forms)\n    # ------------------------------------------------------------------\n    base1 = n / (avg_deg + 1.0)                     # simple size / degree baseline\n    base2 = (n ** 0.5) * ((m + 1.0) / (n + 1.0)) / (avg_deg + 1.0)  # sqrt‑size + edge density\n    base  = 0.5 * (base1 + base2)\n\n    # ------------------------------------------------------------------\n    # 2. Density adjustment: denser → shorter paths\n    # ------------------------------------------------------------------\n    dens_adj = 1.0 / (density + 0.075)   # compromise between 0.1 and 0.05\n\n    # ------------------------------------------------------------------\n    # 3. Clustering & transitivity adjustment: higher values tend to lengthen paths\n    # ------------------------------------------------------------------\n    ct_adj = (1.0 + clust) * (1.0 + trans)\n\n    # ------------------------------------------------------------------\n    # 4. Assortativity adjustment: disassortative mixing tends to lengthen paths\n    # ------------------------------------------------------------------\n    assort_adj = 1.0 + abs(assort)\n\n    # ------------------------------------------------------------------\n    # 5. Degree extremes adjustment\n    # ------------------------------------------------------------------\n    min_factor = 1.0 + 1.0 / (min_deg + 1.0)          # very low min degree → longer paths\n    max_factor = (max_deg + 1.0) / (min_deg + 1.0)    # high max/min ratio → shorter paths\n\n    # ------------------------------------------------------------------\n    # 6. Degree heterogeneity adjustment (second moment)\n    # ------------------------------------------------------------------\n    second_moment = sum(d * d for d in degrees) / n\n    heter_adj1 = 1.0 / (1.0 + second_moment / (avg_deg * avg_deg + 1.0))\n    heter_adj2 = 1.0 + second_moment / (avg_deg * avg_deg + 1.0)\n    heter_adj  = 0.5 * (heter_adj1 + heter_adj2)\n\n    # ------------------------------------------------------------------\n    # 7. Triangle adjustment: many triangles can reduce global path length\n    # ------------------------------------------------------------------\n    tri_adj = 1.0 / (1.0 + tri / (n * n + 1.0))\n\n    # ------------------------------------------------------------------\n    # 8. Damping factor that includes clustering, transitivity and degree dispersion\n    # ------------------------------------------------------------------\n    denom = 1.0 + clust + trans + std_deg\n\n    # ------------------------------------------------------------------\n    # 9. Combine all multiplicative adjustments and apply damping\n    # ------------------------------------------------------------------\n    estimate = (base * dens_adj * ct_adj * assort_adj *\n                min_factor * max_factor * heter_adj * tri_adj) / denom\n\n    return estimate",
        "island_id": 1,
        "generation": 17,
        "train_score": 0.7624009603841537,
        "val_score": 0.49904239399070155,
        "simplicity_score": 0.17641645202547407,
        "novelty_bonus": 0.15505890849943604
      }
    ],
    "2": [
      {
        "id": "g17_i2_p4_3097837",
        "code": "def new_invariant(s):\n    n = s['n']\n    m = s['m']\n    density = s['density']\n    avg_deg = s['avg_degree']\n    max_deg = s['max_degree']\n    min_deg = s['min_degree']\n    std_deg = s['std_degree']\n    clustering = s['avg_clustering']\n    trans = s['transitivity']\n    assort = s['degree_assortativity']\n    num_tri = s['num_triangles']\n    degrees = s['degrees']          # sorted list of degrees\n\n    # ---------- size / degree baseline ----------\n    base = (n.bit_length() + 1) / (avg_deg + 0.1)\n\n    # ---------- median degree ----------\n    l = len(degrees)\n    if l:\n        if l & 1:\n            median_deg = degrees[l >> 1]\n        else:\n            median_deg = (degrees[(l >> 1) - 1] + degrees[l >> 1]) * 0.5\n    else:\n        median_deg = avg_deg\n\n    # ---------- top‑10% mean ----------\n    top10 = max(1, l // 10)\n    top10_mean = sum(degrees[-top10:]) / top10\n\n    # ---------- hub / heterogeneity penalty ----------\n    hub = 1.0\n    if max_deg:\n        hub -= (max_deg - median_deg) / (max_deg + 1)\n        hub -= 0.05 * (std_deg / (max_deg + 1))\n        hub -= 0.10 * (top10_mean - median_deg) / (max_deg + 1)\n    hub = max(hub, 0.05)\n\n    # ---------- heterogeneity multiplier ----------\n    hetero = 1.0 + 0.04 * (std_deg / (avg_deg + 0.1))\n\n    # ---------- clustering penalty ----------\n    clu = 1.0 + 0.25 * ((1.0 - clustering) ** 0.5) + 0.17 * ((1.0 - trans) ** 0.5)\n    clu = max(clu, 0.1)\n\n    # ---------- density adjustment ----------\n    dens = (1.0 / (density + 0.01)) ** 0.90\n\n    # ---------- minimum‑degree boost ----------\n    min_factor = 1.0 + 0.065 * (1.0 - min_deg / (avg_deg + 0.01))\n\n    # ---------- triangle adjustment ----------\n    tri = 1.0 - 0.000115 * ((num_tri / (m + 1)) ** 1.35)\n\n    # ---------- assortativity multiplier ----------\n    assort_factor = 1.0 + 0.11 * assort\n\n    # ---------- skew factor ----------\n    if min_deg:\n        skew = max_deg / min_deg\n        skew_factor = 1.0 + 0.05 * (skew - 1.0)\n    else:\n        skew_factor = 1.0\n\n    # ---------- size scaling ----------\n    size = (n ** 0.5) / (avg_deg + 1)\n\n    # ---------- final estimate ----------\n    return (\n        base *\n        hub *\n        hetero *\n        clu *\n        dens *\n        min_factor *\n        tri *\n        assort_factor *\n        skew_factor *\n        size\n    )",
        "island_id": 2,
        "generation": 17,
        "train_score": 0.8995438175270108,
        "val_score": 0.4782142553210742,
        "simplicity_score": 0.1204670395807736,
        "novelty_bonus": 0.16747250142498338
      },
      {
        "id": "g11_i2_p1_479189782",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a compact set of\n    pre‑computed graph statistics.  The expression blends size,\n    degree distribution, hub concentration, clustering, density,\n    assortativity, triangle density, degree skewness and a mild\n    clustering/transitivity adjustment.  No external libraries or\n    graph traversal are required.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']          # sorted list of degrees\n\n    # ---------- size / degree baseline ----------\n    base = (n.bit_length() + 1) / (avg_deg + 0.1)\n\n    # ---------- median and top‑10% degree ----------\n    l = len(degrees)\n    if l == 0:\n        median_deg = avg_deg\n    elif l % 2:\n        median_deg = degrees[l // 2]\n    else:\n        median_deg = (degrees[l // 2 - 1] + degrees[l // 2]) * 0.5\n\n    top10 = max(1, l // 10)\n    top10_mean = sum(degrees[-top10:]) / top10\n\n    # ---------- hub / heterogeneity penalty ----------\n    hub_pen = 1.0\n    if max_deg > 0:\n        hub_pen -= (max_deg - median_deg) / (max_deg + 1)\n        hub_pen -= 0.04 * (std_deg / (max_deg + 1))\n        hub_pen -= 0.08 * (top10_mean - avg_deg) / (max_deg + 1)\n    hub_pen = max(hub_pen, 0.05)\n\n    # ---------- heterogeneity multiplier ----------\n    hetero = 1.0 + 0.05 * (std_deg / (avg_deg + 0.1))\n\n    # ---------- clustering penalty ----------\n    clu_pen = 1.0 + 0.20 * ((1.0 - clustering) ** 0.5) \\\n                  + 0.15 * ((1.0 - trans) ** 0.5)\n    clu_pen = max(clu_pen, 0.1)\n\n    # ---------- density factor ----------\n    dens = (1.0 / (density + 0.01)) ** 0.85\n\n    # ---------- assortativity multiplier ----------\n    assort_adj = 1.0 + 0.10 * assort\n\n    # ---------- triangle density factor ----------\n    tri_adj = 1.0 - 0.00012 * ((num_tri / (m + 1)) ** 1.3)\n\n    # ---------- degree skew factor ----------\n    if min_deg > 0:\n        skew = max_deg / min_deg\n        skew_adj = 1.0 + 0.04 * (skew - 1.0)\n    else:\n        skew_adj = 1.0\n\n    # ---------- minimum‑degree boost ----------\n    min_adj = 1.0 + 0.07 * (1.0 - min_deg / (avg_deg + 0.01))\n\n    # ---------- mild clustering/transitivity adjustment ----------\n    clust_adj = 1.0 + 0.03 * clustering\n    trans_adj = 1.0 + 0.02 * trans\n\n    # ---------- size scaling ----------\n    size = (n ** 0.5) / (avg_deg + 1)\n\n    # ---------- final estimate ----------\n    return (\n        base *\n        hub_pen *\n        hetero *\n        clu_pen *\n        dens *\n        assort_adj *\n        tri_adj *\n        skew_adj *\n        min_adj *\n        clust_adj *\n        trans_adj *\n        size\n    )",
        "island_id": 2,
        "generation": 11,
        "train_score": 0.8986794717887154,
        "val_score": 0.4772807796201291,
        "simplicity_score": 0.11607238981293824,
        "novelty_bonus": 0.16069301732543306
      },
      {
        "id": "g17_i2_p0_351341587",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a compact set of\n    pre‑computed graph statistics.  The expression is a product of\n    interpretable factors that capture size, degree heterogeneity,\n    hub concentration, clustering, density, assortativity,\n    triangle density, minimum‑degree boost and degree skewness.\n    No external libraries or graph traversal are required.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']          # sorted list of degrees\n\n    # ---------- size / degree baseline ----------\n    base = (n.bit_length() + 1) / (avg_deg + 0.1)\n\n    # ---------- median degree ----------\n    l = len(degrees)\n    if l:\n        if l & 1:\n            median_deg = degrees[l >> 1]\n        else:\n            median_deg = (degrees[(l >> 1) - 1] + degrees[l >> 1]) * 0.5\n    else:\n        median_deg = avg_deg\n\n    # ---------- top‑10% mean ----------\n    top10 = max(1, l // 10)\n    top10_mean = sum(degrees[-top10:]) / top10\n\n    # ---------- hub / heterogeneity penalty ----------\n    hub = 1.0\n    if max_deg:\n        hub -= (max_deg - median_deg) / (max_deg + 1)\n        hub -= (0.035 * std_deg) / (max_deg + 1)\n        hub -= (0.07 * (top10_mean - median_deg)) / (max_deg + 1)\n    if hub < 0.05:\n        hub = 0.05\n\n    # ---------- heterogeneity multiplier ----------\n    hetero = 1.0 + 0.045 * (std_deg / (avg_deg + 0.1))\n\n    # ---------- clustering penalty ----------\n    clu = 1.0 + 0.26 * ((1.0 - clustering) ** 0.5) + 0.19 * ((1.0 - trans) ** 0.5)\n    if clu < 0.1:\n        clu = 0.1\n\n    # ---------- density adjustment ----------\n    dens = (1.0 / (density + 0.01)) ** 0.87\n\n    # ---------- minimum‑degree boost ----------\n    min_factor = 1.0 + 0.065 * (1.0 - min_deg / (avg_deg + 0.01))\n\n    # ---------- triangle adjustment ----------\n    tri = 1.0 - 0.00011 * ((num_tri / (m + 1)) ** 1.4)\n\n    # ---------- assortativity multiplier ----------\n    assort_factor = 1.0 + 0.11 * assort\n\n    # ---------- skew factor ----------\n    if min_deg:\n        skew = max_deg / min_deg\n        skew_factor = 1.0 + 0.05 * (skew - 1.0)\n    else:\n        skew_factor = 1.0\n\n    # ---------- size scaling ----------\n    size = (n ** 0.5) / (avg_deg + 1)\n\n    # ---------- final estimate ----------\n    return (base *\n            hub *\n            hetero *\n            clu *\n            dens *\n            min_factor *\n            tri *\n            assort_factor *\n            skew_factor *\n            size)",
        "island_id": 2,
        "generation": 17,
        "train_score": 0.9025210084033614,
        "val_score": 0.4771704789886106,
        "simplicity_score": 0.12040755688485141,
        "novelty_bonus": 0.1623978612380308
      },
      {
        "id": "g15_i2_p0_569491496",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a compact set of\n    pre‑computed graph statistics.  The expression is a product of\n    interpretable factors that capture size, degree heterogeneity,\n    hub concentration, clustering, density, assortativity, triangle\n    density, minimum‑degree boost and degree skewness.  No external\n    libraries or graph traversal are required.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']          # sorted list of degrees\n\n    # ---------- log‑like surrogate for n / avg_degree ----------\n    base = (n.bit_length() + 1) / (avg_deg + 0.1)\n\n    # ---------- median degree ----------\n    l = len(degrees)\n    if l:\n        if l & 1:\n            median_deg = degrees[l >> 1]\n        else:\n            median_deg = (degrees[(l >> 1) - 1] + degrees[l >> 1]) * 0.5\n    else:\n        median_deg = avg_deg\n\n    # ---------- top‑10% mean ----------\n    top10 = max(1, l // 10)\n    top10_mean = sum(degrees[-top10:]) / top10\n\n    # ---------- hub / heterogeneity penalty ----------\n    hub = 1.0\n    if max_deg:\n        hub -= (max_deg - median_deg) / (max_deg + 1)\n        hub -= 0.04 * (std_deg / (max_deg + 1))\n        hub -= 0.08 * (top10_mean - median_deg) / (max_deg + 1)\n    hub = max(hub, 0.05)\n\n    # ---------- heterogeneity multiplier ----------\n    hetero = 1.0 + 0.05 * (std_deg / (avg_deg + 0.1))\n\n    # ---------- clustering penalty ----------\n    clu = 1.0 + 0.26 * ((1.0 - clustering) ** 0.5) + 0.19 * ((1.0 - trans) ** 0.5)\n    clu = max(clu, 0.1)\n\n    # ---------- density adjustment ----------\n    dens = (1.0 / (density + 0.01)) ** 0.88\n\n    # ---------- minimum‑degree boost ----------\n    min_factor = 1.0 + 0.065 * (1.0 - min_deg / (avg_deg + 0.01))\n\n    # ---------- triangle adjustment ----------\n    tri = 1.0 - 0.000115 * ((num_tri / (m + 1)) ** 1.38)\n\n    # ---------- assortativity multiplier ----------\n    assort_factor = 1.0 + 0.112 * assort\n\n    # ---------- skew factor ----------\n    if min_deg:\n        skew = max_deg / min_deg\n        skew_factor = 1.0 + 0.045 * (skew - 1.0)\n    else:\n        skew_factor = 1.0\n\n    # ---------- size scaling ----------\n    size = (n ** 0.5) / (avg_deg + 1)\n\n    # ---------- final estimate ----------\n    return (base *\n            hub *\n            hetero *\n            clu *\n            dens *\n            min_factor *\n            tri *\n            assort_factor *\n            skew_factor *\n            size)",
        "island_id": 2,
        "generation": 15,
        "train_score": 0.9012725090036015,
        "val_score": 0.4767333025832237,
        "simplicity_score": 0.12043722007569091,
        "novelty_bonus": 0.16498093259538582
      },
      {
        "id": "g16_i2_p0_767943929",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a compact set of\n    pre‑computed graph statistics.  The expression is a product of\n    simple, interpretable factors that capture size, degree\n    heterogeneity, hub concentration, clustering, density,\n    assortativity, triangle density, minimum‑degree boost and\n    degree skewness.  No external libraries or graph traversal are\n    required.\n    \"\"\"\n    # Basic statistics\n    n          = s['n']\n    m          = s['m']\n    density    = s['density']\n    avg_deg    = s['avg_degree']\n    max_deg    = s['max_degree']\n    min_deg    = s['min_degree']\n    std_deg    = s['std_degree']\n    clustering = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    num_tri    = s['num_triangles']\n    degrees    = s['degrees']          # sorted list of degrees\n\n    # ---------- size / degree baseline ----------\n    base = (n.bit_length() + 1) / (avg_deg + 0.1)\n\n    # ---------- median degree ----------\n    l = len(degrees)\n    if l:\n        if l & 1:\n            median_deg = degrees[l >> 1]\n        else:\n            median_deg = (degrees[(l >> 1) - 1] + degrees[l >> 1]) * 0.5\n    else:\n        median_deg = avg_deg\n\n    # ---------- top‑10% mean ----------\n    top10 = max(1, l // 10)\n    top10_mean = sum(degrees[-top10:]) / top10\n\n    # ---------- hub / heterogeneity penalty ----------\n    hub = 1.0\n    if max_deg:\n        hub -= (max_deg - median_deg) / (max_deg + 1)\n        hub -= (0.04 * std_deg) / (max_deg + 1)\n        hub -= (0.08 * (top10_mean - median_deg)) / (max_deg + 1)\n    if hub < 0.05:\n        hub = 0.05\n\n    # ---------- heterogeneity multiplier ----------\n    hetero = 1.0 + 0.04 * (std_deg / (avg_deg + 0.1))\n\n    # ---------- clustering penalty ----------\n    clu = 1.0 + 0.24 * ((1.0 - clustering) ** 0.5) + 0.18 * ((1.0 - trans) ** 0.5)\n    if clu < 0.1:\n        clu = 0.1\n\n    # ---------- density adjustment ----------\n    dens = (1.0 / (density + 0.01)) ** 0.85\n\n    # ---------- minimum‑degree boost ----------\n    min_factor = 1.0 + 0.06 * (1.0 - min_deg / (avg_deg + 0.01))\n\n    # ---------- triangle adjustment ----------\n    tri = 1.0 - 0.00012 * ((num_tri / (m + 1)) ** 1.4)\n\n    # ---------- assortativity multiplier ----------\n    assort_factor = 1.0 + 0.105 * assort\n\n    # ---------- skew factor ----------\n    if min_deg:\n        skew = max_deg / min_deg\n        skew_factor = 1.0 + 0.045 * (skew - 1.0)\n    else:\n        skew_factor = 1.0\n\n    # ---------- size scaling ----------\n    size = (n ** 0.5) / (avg_deg + 1)\n\n    # ---------- final estimate ----------\n    return (base *\n            hub *\n            hetero *\n            clu *\n            dens *\n            min_factor *\n            tri *\n            assort_factor *\n            skew_factor *\n            size)",
        "island_id": 2,
        "generation": 16,
        "train_score": 0.8982953181272508,
        "val_score": 0.4764347702084411,
        "simplicity_score": 0.12040755688485141,
        "novelty_bonus": 0.1633705842646065
      }
    ],
    "3": [
      {
        "id": "g15_i3_p0_561502026",
        "code": "def new_invariant(s):\n    # extract required statistics\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    min_deg    = s['min_degree']\n    max_deg    = s['max_degree']\n    std_deg    = s['std_degree']\n    num_tri    = s['num_triangles']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    degrees    = s['degrees']\n\n    # avoid division by zero\n    denom = avg_deg + 1.0\n\n    # 1. Size‑connectivity base: bigger/sparser graphs have longer paths\n    base = (n ** 0.5) / denom\n\n    # 2. Density adjustment (sparser → longer paths)\n    density_adj = 1.0 + (1.0 - density) * (1.0 + min_deg / denom)\n\n    # 3. Degree heterogeneity (high std → shorter via hubs)\n    heter_adj = 1.0 + std_deg / denom\n\n    # 4. Hub influence (large max degree shortens paths)\n    hub_adj = 1.0 / (1.0 + max_deg / denom)\n\n    # 5. Triangle density (more triangles → shorter paths)\n    max_tri = n * (n - 1) // 2\n    tri_adj = 1.0 + num_tri / (max_tri + 1.0)\n\n    # 6. Harmonic‑mean degree correction (low‑degree nodes elongate paths)\n    inv_sum = 0.0\n    for d in degrees:\n        inv_sum += 1.0 / (d + 1.0)          # +1 avoids division by zero\n    harm_mean = len(degrees) / inv_sum if inv_sum else 1.0\n    harm_adj  = 1.0 + harm_mean / denom\n\n    # 7. Clustering mismatch (local vs global)\n    cluster_adj = 1.0 + abs(avg_clust - trans)\n\n    # 8. Assortativity effect (moderately assortative graphs can have longer paths)\n    assort_adj = 1.0 + abs(assort) ** 0.3\n\n    # 9. Combine all multiplicative adjustments\n    result = (\n        base *\n        density_adj *\n        heter_adj *\n        hub_adj *\n        tri_adj *\n        harm_adj *\n        cluster_adj *\n        assort_adj\n    )\n    return result",
        "island_id": 3,
        "generation": 15,
        "train_score": 0.8803361344537814,
        "val_score": 0.5328963876327568,
        "simplicity_score": 0.19350995542825775,
        "novelty_bonus": 0.19412332537377275
      },
      {
        "id": "g17_i3_p2_390390033",
        "code": "def new_invariant(s):\n    \"\"\"\n    Analytic proxy for the average shortest‑path length based solely on\n    pre‑computed structural statistics.  No traversal or external\n    libraries are used – the formula combines size, density, degree\n    heterogeneity, clustering, and assortativity in a multiplicative\n    fashion.\n\n    Parameters\n    ----------\n    s : dict\n        Must contain the following keys:\n            n                : int          number of nodes\n            m                : int          number of edges\n            density          : float        edge density (m / (n*(n-1)/2))\n            avg_degree       : float        average degree\n            max_degree       : int          maximum degree\n            min_degree       : int          minimum degree\n            std_degree       : float        standard deviation of degrees\n            avg_clustering   : float        average local clustering\n            transitivity     : float        global clustering coefficient\n            degree_assortativity : float    degree assortativity\n            num_triangles    : int          number of triangles\n            degrees          : list[int]    sorted degree sequence\n\n    Returns\n    -------\n    float\n        An estimate of the average shortest‑path length.\n    \"\"\"\n    # Basic quantities\n    n         = s['n']\n    avg_deg   = s['avg_degree']\n    density   = s['density']\n    min_deg   = s['min_degree']\n    max_deg   = s['max_degree']\n    std_deg   = s['std_degree']\n    avg_clust = s['avg_clustering']\n    trans     = s['transitivity']\n    assort    = s['degree_assortativity']\n    num_tri   = s['num_triangles']\n    degrees   = s['degrees']\n\n    # Avoid division by zero\n    denom = avg_deg + 1.0\n\n    # 1. Size–connectivity base: larger or sparser graphs yield longer paths\n    base = (n ** 0.5) / denom\n\n    # 2. Sparsity adjustment (sparser → longer paths)\n    density_adj = 1.0 + (1.0 - density) * (1.0 + min_deg / denom)\n\n    # 3. Degree heterogeneity: high std indicates hubs → shorter paths\n    heter_adj = 1.0 + std_deg / denom\n\n    # 4. Hub influence: a very large maximum degree shortens paths\n    hub_adj = 1.0 / (1.0 + max_deg / denom)\n\n    # 5. Triangle density: more triangles shorten paths\n    max_tri_poss = n * (n - 1) // 2\n    tri_adj = 1.0 + num_tri / (max_tri_poss + 1.0)\n\n    # 6. Harmonic‑mean degree correction (isolated/low‑degree nodes elongate paths)\n    inv_sum = 0.0\n    for d in degrees:\n        inv_sum += 1.0 / (d + 1.0)          # +1 to avoid division by zero\n    harm_mean = len(degrees) / inv_sum if inv_sum else 1.0\n    harm_adj  = 1.0 + harm_mean / denom\n\n    # 7. Clustering mismatch (discrepancy between local and global clustering)\n    cluster_adj = 1.0 + abs(avg_clust - trans)\n\n    # 8. Assortativity effect (moderately assortative graphs can have longer paths)\n    assort_adj = 1.0 + abs(assort) ** 0.3\n\n    # 9. Combine all factors multiplicatively\n    result = (\n        base *\n        density_adj *\n        heter_adj *\n        hub_adj *\n        tri_adj *\n        harm_adj *\n        cluster_adj *\n        assort_adj\n    )\n    return result",
        "island_id": 3,
        "generation": 17,
        "train_score": 0.8803361344537814,
        "val_score": 0.532885384697146,
        "simplicity_score": 0.19345494075020336,
        "novelty_bonus": 0.19412332537377275
      },
      {
        "id": "g10_i3_p0_302088004",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed\n    graph statistics.  The formula is entirely analytic, uses only built‑in\n    Python functions and does not perform any graph traversal.\n\n    Parameters\n    ----------\n    s : dict\n        Expected keys:\n            n                (int)          number of nodes\n            m                (int)          number of edges\n            density          (float)        edge density\n            avg_degree       (float)        average degree\n            max_degree       (int)          maximum degree\n            min_degree       (int)          minimum degree\n            std_degree       (float)        standard deviation of degrees\n            avg_clustering   (float)        average local clustering\n            transitivity     (float)        global clustering coefficient\n            degree_assortativity (float)    degree assortativity\n            num_triangles    (int)          number of triangles\n            degrees          (list[int])    sorted degree sequence\n\n    Returns\n    -------\n    float\n        An analytic proxy for the average shortest‑path length.\n    \"\"\"\n\n    # Basic quantities\n    n            = s['n']\n    avg_deg      = s['avg_degree']\n    density      = s['density']\n    min_deg      = s['min_degree']\n    max_deg      = s['max_degree']\n    std_deg      = s['std_degree']\n    avg_clust    = s['avg_clustering']\n    trans        = s['transitivity']\n    assort       = s['degree_assortativity']\n    num_tri      = s['num_triangles']\n    degrees      = s['degrees']\n\n    # 1. Size–connectivity base: larger, sparser graphs → longer paths\n    base = (n ** 0.5) / (avg_deg + 1)\n\n    # 2. Sparsity adjustment (sparser → longer paths)\n    density_adj = 1 + (1 - density) * (1 + min_deg / (avg_deg + 1))\n\n    # 3. Degree heterogeneity (large std → shorter paths via hubs)\n    hetero_adj = 1 + std_deg / (avg_deg + 1)\n\n    # 4. Hub influence: high max degree shortens paths\n    hub_adj = 1 / (1 + max_deg / (avg_deg + 1))\n\n    # 5. Triangle density: more triangles shorten paths\n    max_tri_possible = n * (n - 1) // 2\n    tri_adj = 1 + num_tri / (max_tri_possible + 1)\n\n    # 6. Harmonic‑mean degree correction (isolated/low‑degree nodes elongate paths)\n    inv_sum = 0.0\n    for d in degrees:\n        inv_sum += 1.0 / (d + 1)          # avoid division by zero\n    harmonic_mean = len(degrees) / inv_sum if inv_sum else 1\n    harm_adj = 1 + harmonic_mean / (avg_deg + 1)\n\n    # 7. Clustering mismatch (discrepancy between local and global clustering)\n    cluster_adj = 1 + abs(avg_clust - trans)\n\n    # 8. Assortativity effect (moderately assortative graphs can have longer paths)\n    assort_adj = 1 + abs(assort) ** 0.3\n\n    # 9. Combine all multiplicatively\n    result = (base *\n              density_adj *\n              hetero_adj *\n              hub_adj *\n              tri_adj *\n              harm_adj *\n              cluster_adj *\n              assort_adj)\n\n    return result",
        "island_id": 3,
        "generation": 10,
        "train_score": 0.8803361344537814,
        "val_score": 0.5328476023902201,
        "simplicity_score": 0.19326602921557412,
        "novelty_bonus": 0.19412332537377275
      },
      {
        "id": "g14_i3_p4_137760185",
        "code": "def new_invariant(s):\n    \"\"\"\n    Estimate the average shortest‑path length from a set of pre‑computed\n    graph statistics.  The computation uses only built‑in Python\n    functionality – no graph traversal and no external libraries.\n    \"\"\"\n    # basic statistics -------------------------------------------------------\n    n        = s['n']\n    avg_deg  = s['avg_degree']\n    density  = s['density']\n    min_deg  = s['min_degree']\n    max_deg  = s['max_degree']\n    std_deg  = s['std_degree']\n    num_tri  = s['num_triangles']\n    avg_clust= s['avg_clustering']\n    trans    = s['transitivity']\n    assort   = s['degree_assortativity']\n    degrees  = s['degrees']\n\n    # common denominator to avoid division by zero --------------------------------\n    denom = avg_deg + 1.0\n\n    # 1. Size / connectivity base ---------------------------------------------\n    base = (n ** 0.5) / denom\n\n    # 2. Density adjustment (sparser → longer paths) ---------------------------\n    density_adj = 1.0 + (1.0 - density) * (1.0 + min_deg / denom)\n\n    # 3. Degree heterogeneity (high std → shorter via hubs) -------------------\n    heter_adj = 1.0 + std_deg / denom\n\n    # 4. Hub influence (large max degree shortens paths) -----------------------\n    hub_adj = 1.0 / (1.0 + max_deg / denom)\n\n    # 5. Triangle density (more triangles → shorter paths) -------------------\n    max_tri = n * (n - 1) // 2\n    tri_adj = 1.0 + num_tri / (max_tri + 1.0)\n\n    # 6. Harmonic‑mean degree correction (low‑degree nodes elongate paths)----\n    inv_sum = 0.0\n    for d in degrees:\n        inv_sum += 1.0 / (d + 1.0)       # +1 avoids division by zero\n    harm_mean = len(degrees) / inv_sum if inv_sum else 1.0\n    harm_adj  = 1.0 + harm_mean / denom\n\n    # 7. Clustering mismatch (local vs global) --------------------------------\n    cluster_adj = 1.0 + abs(avg_clust - trans)\n\n    # 8. Assortativity effect --------------------------------------------------\n    assort_adj = 1.0 + abs(assort) ** 0.35\n\n    # 9. Combine all factors multiplicatively ----------------------------------\n    result = (\n        base *\n        density_adj *\n        heter_adj *\n        hub_adj *\n        tri_adj *\n        harm_adj *\n        cluster_adj *\n        assort_adj\n    )\n    return result",
        "island_id": 3,
        "generation": 14,
        "train_score": 0.8744777911164465,
        "val_score": 0.531302121469483,
        "simplicity_score": 0.19345494075020336,
        "novelty_bonus": 0.18621321546741731
      },
      {
        "id": "g15_i3_p1_680148549",
        "code": "def new_invariant(s):\n    \"\"\"\n    Analytic proxy for the average shortest‑path length using only\n    pre‑computed graph statistics.\n\n    Parameters\n    ----------\n    s : dict\n        Must contain the following keys:\n\n        n                       : int      number of nodes\n        m                       : int      number of edges\n        density                 : float    edge density\n        avg_degree              : float    average degree\n        max_degree              : int      maximum degree\n        min_degree              : int      minimum degree\n        std_degree              : float    standard deviation of degrees\n        avg_clustering          : float    average local clustering\n        transitivity            : float    global clustering coefficient\n        degree_assortativity    : float    degree assortativity\n        num_triangles           : int      number of triangles\n        degrees                 : list[int] sorted degree sequence\n\n    Returns\n    -------\n    float\n        An estimate of the average shortest‑path length.\n    \"\"\"\n    # basic statistics\n    n          = s['n']\n    avg_deg    = s['avg_degree']\n    density    = s['density']\n    min_deg    = s['min_degree']\n    max_deg    = s['max_degree']\n    std_deg    = s['std_degree']\n    num_tri    = s['num_triangles']\n    avg_clust  = s['avg_clustering']\n    trans      = s['transitivity']\n    assort     = s['degree_assortativity']\n    degrees    = s['degrees']\n\n    denom = avg_deg + 1.0\n\n    # 1. Size / connectivity base\n    base = (n ** 0.5) / denom\n\n    # 2. Density adjustment (sparser → longer paths)\n    density_adj = 1.0 + (1.0 - density) * (1.0 + min_deg / denom)\n\n    # 3. Degree heterogeneity\n    hetero_adj = 1.0 + std_deg / denom\n\n    # 4. Hub influence\n    hub_adj = 1.0 / (1.0 + max_deg / denom)\n\n    # 5. Triangle density\n    max_tri = n * (n - 1) / 2\n    tri_adj = 1.0 + num_tri / (max_tri + 1.0)\n\n    # 6. Harmonic‑mean degree correction\n    inv_sum = 0.0\n    for d in degrees:\n        inv_sum += 1.0 / (d + 1.0)       # avoid division by zero\n    harm_mean = len(degrees) / inv_sum if inv_sum else 1.0\n    harm_adj  = 1.0 + harm_mean / denom\n\n    # 7. Clustering mismatch adjustment\n    cluster_adj = 1.0 + abs(avg_clust - trans)\n\n    # 8. Assortativity influence\n    assort_adj = 1.0 + abs(assort) ** 0.35\n\n    # 9. Combine all multiplicative adjustments\n    result = (\n        base *\n        density_adj *\n        hetero_adj *\n        hub_adj *\n        tri_adj *\n        harm_adj *\n        cluster_adj *\n        assort_adj\n    )\n\n    return result",
        "island_id": 3,
        "generation": 15,
        "train_score": 0.8744777911164465,
        "val_score": 0.531302121469483,
        "simplicity_score": 0.19345494075020336,
        "novelty_bonus": 0.18621321546741731
      }
    ]
  }
}