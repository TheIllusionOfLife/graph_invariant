# 論文レビュー

**Title:** LLM-Driven Discovery of Interpretable Graph Invariants via Island-Model Evolution
**Overall evaluation:** **Weak Accept ～ Borderline**（採録圏内だが改善余地大）

---

# 1. 研究の要旨（短く）

本論文は、

* LLMによる数式生成
* 島モデル進化
* MAP-Elites（多様性探索）
* 自己修復ループ

を組み合わせて、

> **解釈可能なグラフ不変量（閉形式）を自動発見する**

というフレームワークを提案しています。

結果として、

* ASPL（平均最短路長）予測で
  　**Spearman ρ ≈ 0.947** を達成
* PySRやRFと競合する精度
* かつ解釈可能な数式を出力

という主張です。 

---

# 2. 総合評価（スコア）

| 観点     | スコア（10点） | コメント                         |
| ------ | -------- | ---------------------------- |
| 新規性    | **7**    | FunSearch系の自然な発展だが、組み合わせ方は良い |
| 技術的妥当性 | **7**    | 実験は筋が通っているが規模が小さい            |
| 実験の説得力 | **6**    | データ規模とタスク多様性が不足              |
| 再現性    | **8**    | OSS・ローカルモデル使用で良い             |
| 理論的深さ  | **5**    | 「発見」だが数学的証明はない               |
| インパクト  | **7**    | 科学的発見系LLM研究として価値あり           |

**総合:** **6.7 / 10**

---

# 3. 強み（Major Strengths）

## ① システム設計が明確で再現可能

論文は以下の構成で整理されており、実装可能性が高い：

* 島モデル（4島） 
* MAP-Elites多様性アーカイブ 
* 自己修復ループ 
* サンドボックス実行 

これは**研究プロトタイプとして非常に健全な設計**です。

---

## ② 「解釈可能な数式」という明確な価値

現在の主流：

* GNN → ブラックボックス
* Random forest → ブラックボックス

対して本研究：

> 閉形式の数式を生成し、数学的に解析可能
>

これは**科学的発見系AIの本質的価値**に近い。

---

## ③ 自己修復ループの定量評価

失敗候補の

* **41〜48%を修復** 

という結果は、実用上かなり重要。

これは

> LLMが「式の直感」を保持したまま修正できる

という興味深い現象です。

---

# 4. 弱み（Major Weaknesses）

## ① 本当に「新しい不変量」か不明

現状の問題：

* 特徴量ベースの組み合わせ
* 既存不変量の関数的組み合わせ

と論文自身が認めています：

> pre-computed graph featuresに依存
>

つまり：

### 現状は

「新しい不変量の発見」
ではなく

> 既存統計量の組み合わせ最適化

に近い。

これは査読で必ず突かれます。

---

## ② ベースラインに勝っていない

ASPLタスク：

| 手法      | Test ρ    |
| ------- | --------- |
| PySR    | 0.975     |
| Linear  | 0.975     |
| RF      | 0.951     |
| **LLM** | **0.947** |



つまり：

> 精度では全ベースラインに負けている

論文の主張は：

> 解釈性とのトレードオフ

だが、査読では：

* 「ではなぜLLMを使うのか？」
* 「PySRで十分では？」

と必ず聞かれる。

---

## ③ データ規模が非常に小さい

訓練：

* train: **50グラフ**
* val/test: 各200


これは：

* 機械学習論文としては小さすぎる
* 科学的発見としても統計的に弱い

---

## ④ 本当に「発見」した証拠がない

現状：

* 数式が出た
* 相関が高い

だけ。

しかし論文では：

> 証明可能な形で使える
>

と主張しているが、

### 実際には

* 数学的証明なし
* 新規定理なし
* 既知不変量との関係分析なし

これは**理論系査読では致命傷**。

---

# 5. 最も重要な改善点（Top 3）

## ① 「本当に新しい不変量」を示す

最低限必要：

* 既存不変量との独立性証明
* 既存式で表せないことの証明
* 新しい上界・下界の定理

これがないと

> 単なる回帰式

扱いになる。

---

## ② 実験のスケールアップ

最低ライン：

* train: 500〜1000グラフ
* 複数ノードサイズ範囲
* 実グラフデータ（社会・生物など）

---

## ③ PySRに「勝つ」実験を1つ入れる

例：

* 複雑な非線形不変量
* 理論的制約付き探索
* ノイズ耐性
* 少数データ条件

どれかで

> LLMが唯一有効

という状況を作る。

---

# 6. 一言でいうとこの研究の位置づけ

この研究は

> 「LLMで数学的構造を探索する実験装置」

としては非常に良い。

しかし現状は

* 新理論は出ていない
* 精度も最強ではない

ので、

> 「面白いシステム論文」

の段階です。